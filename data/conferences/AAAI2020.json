[
	{
		"title": "InstaNAS: Instance‐aware Neural Architecture Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "BOWL: Bayesian Optimization for Weight Learning in Probabilistic Soft Logic ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Regularized Wasserstein Means for Aligning Distributional Data ",
		"abstract": "We propose to align distributional data from the perspective of Wasserstein means. We raise the problem of regularizing Wasserstein means and propose several terms tailored to tackle different problems. Our formulation is based on the variational transportation to distribute a sparse discrete measure into the target domain. The resulting sparse representation well captures the desired property of the domain while reducing the mapping cost. We demonstrate the scalability and robustness of our method with examples in domain adaptation, point set registration, and skeleton layout.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1812.00338v2"
	},
	{
		"title": "Geometry‐constrained Car Recognition Using a 3D Perspective Network ",
		"abstract": "We present a novel learning framework for vehicle recognition from a single RGB image. Unlike existing methods which only use attention mechanisms to locate 2D discriminative information, our work learns a novel 3D perspective feature representation of a vehicle, which is then fused with 2D appearance feature to predict the category. The framework is composed of a global network (GN), a 3D perspective network (3DPN), and a fusion network. The GN is used to locate the region of interest (RoI) and generate the 2D global feature. With the assistance of the RoI, the 3DPN estimates the 3D bounding box under the guidance of the proposed vanishing point loss, which provides a perspective geometry constraint. Then the proposed 3D representation is generated by eliminating the viewpoint variance of the 3D bounding box using perspective transformation. Finally, the 3D and 2D feature are fused to predict the category of the vehicle. We present qualitative and quantitative results on the vehicle classification and verification tasks in the BoxCars dataset. The results demonstrate that, by learning such a concise 3D representation, we can achieve superior performance to methods that only use 2D information while retain 3D meaningful information without the challenge of requiring a 3D CAD model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.07916v3"
	},
	{
		"title": "Further Understanding Videos through Adverbs: A New Video Task ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching ",
		"abstract": "State-of-the-art deep learning based stereo matching approaches treat disparity estimation as a regression problem, where loss function is directly defined on true disparities and their estimated ones. However, disparity is just a byproduct of a matching process modeled by cost volume, while indirectly learning cost volume driven by disparity regression is prone to overfitting since the cost volume is under constrained. In this paper, we propose to directly add constraints to the cost volume by filtering cost volume with unimodal distribution peaked at true disparities. In addition, variances of the unimodal distributions for each pixel are estimated to explicitly model matching uncertainty under different contexts. The proposed architecture achieves state-of-the-art performance on Scene Flow and two KITTI stereo benchmarks. In particular, our method ranked the $1^{st}$ place of KITTI 2012 evaluation and the $4^{th}$ place of KITTI 2015 evaluation (recorded on 2019.8.20). The codes of AcfNet are available at: https://github.com/DeepMotionAIResearch/DenseMatchingBenchmark.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03751v2"
	},
	{
		"title": "Distilling Portable Generative Adversarial Networks for Image Translation ",
		"abstract": "Despite Generative Adversarial Networks (GANs) have been widely used in various image-to-image translation tasks, they can be hardly applied on mobile devices due to their heavy computation and storage cost. Traditional network compression methods focus on visually recognition tasks, but never deal with generation tasks. Inspired by knowledge distillation, a student generator of fewer parameters is trained by inheriting the low-level and high-level information from the original heavy teacher generator. To promote the capability of student generator, we include a student discriminator to measure the distances between real images, and images generated by student and teacher generators. An adversarial learning process is therefore established to optimize student generator and student discriminator. Qualitative and quantitative analysis by conducting experiments on benchmark datasets demonstrate that the proposed method can learn portable generative models with strong performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.03519v1"
	},
	{
		"title": "Privacy‐Preserving Gradient Boosting Decision Trees ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Progressive Feature Polishing Network for Salient Object Detection ",
		"abstract": "Feature matters for salient object detection. Existing methods mainly focus on designing a sophisticated structure to incorporate multi-level features and filter out cluttered features. We present Progressive Feature Polishing Network (PFPN), a simple yet effective framework to progressively polish the multi-level features to be more accurate and representative. By employing multiple Feature Polishing Modules (FPMs) in a recurrent manner, our approach is able to detect salient objects with fine details without any post-processing. A FPM parallelly updates the features of each level by directly incorporating all higher level context information. Moreover, it can keep the dimensions and hierarchical structures of the feature maps, which makes it flexible to be integrated with any CNN-based models. Empirical experiments show that our results are monotonically getting better with increasing number of FPMs. Without bells and whistles, PFPN outperforms the state-of-the-art methods significantly on five benchmark datasets under various evaluation metrics.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05942v1"
	},
	{
		"title": "Deep Generative Probabilistic Graph Neural Networks for Scene Graph Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reinforcing an Image Caption Generator using Off‐line Human Feedback ",
		"abstract": "Human ratings are currently the most accurate way to assess the quality of an image captioning model, yet most often the only used outcome of an expensive human rating evaluation is a few overall statistics over the evaluation dataset. In this paper, we show that the signal from instance-level human caption ratings can be leveraged to improve captioning models, even when the amount of caption ratings is several orders of magnitude less than the caption training data. We employ a policy gradient method to maximize the human ratings as rewards in an off-policy reinforcement learning setting, where policy gradients are estimated by samples from a distribution that focuses on the captions in a caption ratings dataset. Our empirical evidence indicates that the proposed method learns to generalize the human raters' judgments to a previously unseen set of images, as judged by a different set of human judges, and additionally on a different, multi-dimensional side-by-side human evaluation procedure.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09753v1"
	},
	{
		"title": "Are Noisy Sentences Useless for Distant Supervised Relation Extraction? ",
		"abstract": "The noisy labeling problem has been one of the major obstacles for distant supervised relation extraction. Existing approaches usually consider that the noisy sentences are useless and will harm the model's performance. Therefore, they mainly alleviate this problem by reducing the influence of noisy sentences, such as applying bag-level selective attention or removing noisy sentences from sentence-bags. However, the underlying cause of the noisy labeling problem is not the lack of useful information, but the missing relation labels. Intuitively, if we can allocate credible labels for noisy sentences, they will be transformed into useful training data and benefit the model's performance. Thus, in this paper, we propose a novel method for distant supervised relation extraction, which employs unsupervised deep clustering to generate reliable labels for noisy sentences. Specifically, our model contains three modules: a sentence encoder, a noise detector and a label generator. The sentence encoder is used to obtain feature representations. The noise detector detects noisy sentences from sentence-bags, and the label generator produces high-confidence relation labels for noisy sentences. Extensive experimental results demonstrate that our model outperforms the state-of-the-art baselines on a popular benchmark dataset, and can indeed alleviate the noisy labeling problem.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09788v1"
	},
	{
		"title": "R$^2$MRF: Defocus Blur Detection via Recurrently Refining Multi‐scale Residual Features ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Pose‐Guided Multi‐Granularity Attention Network for Text‐Based Person Search ",
		"abstract": "Text-based person search aims to retrieve the corresponding person images in an image database by virtue of a describing sentence about the person, which poses great potential for various applications such as video surveillance. Extracting visual contents corresponding to the human description is the key to this cross-modal matching problem. Moreover, correlated images and descriptions involve different granularities of semantic relevance, which is usually ignored in previous methods. To exploit the multilevel corresponding visual contents, we propose a pose-guided multi-granularity attention network (PMA). Firstly, we propose a coarse alignment network (CA) to select the related image regions to the global description by a similarity-based attention. To further capture the phrase-related visual body part, a fine-grained alignment network (FA) is proposed, which employs pose information to learn latent semantic alignment between visual body part and textual noun phrase. To verify the effectiveness of our model, we perform extensive experiments on the CUHK Person Description Dataset (CUHK-PEDES) which is currently the only available dataset for text-based person search. Experimental results show that our approach outperforms the state-of-the-art methods by 15 \\% in terms of the top-1 metric.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1809.08440v3"
	},
	{
		"title": "Fast and Robust Face‐to‐Parameter Translation for Game Character Auto‐Creation ",
		"abstract": "With the rapid development of Role-Playing Games (RPGs), players are now allowed to edit the facial appearance of their in-game characters with their preferences rather than using default templates. This paper proposes a game character auto-creation framework that generates in-game characters according to a player's input face photo. Different from the previous methods that are designed based on neural style transfer or monocular 3D face reconstruction, we re-formulate the character auto-creation process in a different point of view: by predicting a large set of physically meaningful facial parameters under a self-supervised learning paradigm. Instead of updating facial parameters iteratively at the input end of the renderer as suggested by previous methods, which are time-consuming, we introduce a facial parameter translator so that the creation can be done efficiently through a single forward propagation from the face embeddings to parameters, with a considerable 1000x computational speedup. Despite its high efficiency, the interactivity is preserved in our method where users are allowed to optionally fine-tune the facial parameters on our creation according to their needs. Our approach also shows better robustness than previous methods, especially for those photos with head-pose variance. Comparison results and ablation analysis on seven public face verification datasets suggest the effectiveness of our method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.07132v1"
	},
	{
		"title": "Comparing Election Methods Where Each Voter Ranks Only Few Candidates ",
		"abstract": "Election rules are formal processes that aggregate voters preferences, typically to select a single candidate, called the winner. Most of the election rules studied in the literature require the voters to rank the candidates from the most to the least preferred one. This method of eliciting preferences is impractical when the number of candidates to be ranked is large. We ask how well certain election rules (focusing on positional scoring rules and the Minimax rule) can be approximated from partial preferences collected through one of the following procedures: (i) randomized-we ask each voter to rank a random subset of $\\ell$ candidates, and (ii) deterministic-we ask each voter to provide a ranking of her $\\ell$ most preferred candidates (the $\\ell$-truncated ballot). We establish theoretical bounds on the approximation ratios and we complement our theoretical analysis with computer simulations. We find that mostly (apart from the cases when the preferences have no or very little structure) it is better to use the randomized approach. While we obtain fairly good approximation guarantees for the Borda rule already for $\\ell = 2$, for approximating the Minimax rule one needs to ask each voter to compare a larger set of candidates in order to obtain good guarantees.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.10848v1"
	},
	{
		"title": "3D Crowd Counting via Multi‐View Fusion with 3D Gaussian Kernels ",
		"abstract": "Crowd counting has been studied for decades and a lot of works have achieved good performance, especially the DNNs-based density map estimation methods. Most existing crowd counting works focus on single-view counting, while few works have studied multi-view counting for large and wide scenes, where multiple cameras are used. Recently, an end-to-end multi-view crowd counting method called multi-view multi-scale (MVMS) has been proposed, which fuses multiple camera views using a CNN to predict a 2D scene-level density map on the ground-plane. Unlike MVMS, we propose to solve the multi-view crowd counting task through 3D feature fusion with 3D scene-level density maps, instead of the 2D ground-plane ones. Compared to 2D fusion, the 3D fusion extracts more information of the people along z-dimension (height), which helps to solve the scale variations across multiple views. The 3D density maps still preserve the 2D density maps property that the sum is the count, while also providing 3D information about the crowd density. We also explore the projection consistency among the 3D prediction and the ground-truth in the 2D views to further enhance the counting performance. The proposed method is tested on 3 multi-view counting datasets and achieves better or comparable counting performance to the state-of-the-art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.08162v1"
	},
	{
		"title": "Characterizing  Membership Privacy in Stochastic Gradient Langevin Dynamics ",
		"abstract": "Bayesian deep learning is recently regarded as an intrinsic way to characterize the weight uncertainty of deep neural networks~(DNNs). Stochastic Gradient Langevin Dynamics~(SGLD) is an effective method to enable Bayesian deep learning on large-scale datasets. Previous theoretical studies have shown various appealing properties of SGLD, ranging from the convergence properties to the generalization bounds. In this paper, we study the properties of SGLD from a novel perspective of membership privacy protection (i.e., preventing the membership attack). The membership attack, which aims to determine whether a specific sample is used for training a given DNN model, has emerged as a common threat against deep learning algorithms. To this end, we build a theoretical framework to analyze the information leakage (w.r.t. the training dataset) of a model trained using SGLD. Based on this framework, we demonstrate that SGLD can prevent the information leakage of the training dataset to a certain extent. Moreover, our theoretical analysis can be naturally extended to other types of Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) methods. Empirical results on different datasets and models verify our theoretical findings and suggest that the SGLD algorithm can not only reduce the information leakage but also improve the generalization ability of the DNN models in real-world applications.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.02249v1"
	},
	{
		"title": "Optimal Feature Transport for Cross‐View Image Geo‐Localization ",
		"abstract": "This paper addresses the problem of cross-view image geo-localization, where the geographic location of a ground-level street-view query image is estimated by matching it against a large scale aerial map (e.g., a high-resolution satellite image). State-of-the-art deep-learning based methods tackle this problem as deep metric learning which aims to learn global feature representations of the scene seen by the two different views. Despite promising results are obtained by such deep metric learning methods, they, however, fail to exploit a crucial cue relevant for localization, namely, the spatial layout of local features. Moreover, little attention is paid to the obvious domain gap (between aerial view and ground view) in the context of cross-view localization. This paper proposes a novel Cross-View Feature Transport (CVFT) technique to explicitly establish cross-view domain transfer that facilitates feature alignment between ground and aerial images. Specifically, we implement the CVFT as network layers, which transports features from one domain to the other, leading to more meaningful feature similarity comparison. Our model is differentiable and can be learned end-to-end. Experiments on large-scale datasets have demonstrated that our method has remarkably boosted the state-of-the-art cross-view localization performance, e.g., on the CVUSA dataset, with significant improvements for top-1 recall from 40.79% to 61.43%, and for top-10 from 76.36% to 90.49%. We expect the key insight of the paper (i.e., explicitly handling domain difference via domain transport) will prove to be useful for other similar problems in computer vision as well.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.05021v3"
	},
	{
		"title": "Machine Number Sense: A Dataset of Visual Arithmetic Problems for Abstract and Relational Reasoning ",
		"abstract": "As a comprehensive indicator of mathematical thinking and intelligence, the number sense (Dehaene 2011) bridges the induction of symbolic concepts and the competence of problem-solving. To endow such a crucial cognitive ability to machine intelligence, we propose a dataset, Machine Number Sense (MNS), consisting of visual arithmetic problems automatically generated using a grammar model--And-Or Graph (AOG). These visual arithmetic problems are in the form of geometric figures: each problem has a set of geometric shapes as its context and embedded number symbols. Solving such problems is not trivial; the machine not only has to recognize the number, but also to interpret the number with its contexts, shapes, and relations (e.g., symmetry) together with proper operations. We benchmark the MNS dataset using four predominant neural network models as baselines in this visual reasoning task. Comprehensive experiments show that current neural-network-based models still struggle to understand number concepts and relational operations. We show that a simple brute-force search algorithm could work out some of the problems without context information. Crucially, taking geometric context into account by an additional perception module would provide a sharp performance gain with fewer search steps. Altogether, we call for attention in fusing the classic search-based algorithms with modern neural networks to discover the essential number concepts in future research.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.12193v1"
	},
	{
		"title": "Google Research Football: A Novel Reinforcement Learning Environment ",
		"abstract": "Recent progress in the field of reinforcement learning has been accelerated by virtual learning environments such as video games, where novel algorithms and ideas can be quickly tested in a safe and reproducible manner. We introduce the Google Research Football Environment, a new reinforcement learning environment where agents are trained to play football in an advanced, physics-based 3D simulator. The resulting environment is challenging, easy to use and customize, and it is available under a permissive open-source license. In addition, it provides support for multiplayer and multi-agent experiments. We propose three full-game scenarios of varying difficulty with the Football Benchmarks and report baseline results for three commonly used reinforcement algorithms (IMPALA, PPO, and Ape-X DQN). We also provide a diverse set of simpler scenarios with the Football Academy and showcase several promising research directions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.11180v2"
	},
	{
		"title": "Chained Representation Cycling: Learning to Estimate 3D Human Pose and Shape by Cycling Between Representations ",
		"abstract": "The goal of many computer vision systems is to transform image pixels into 3D representations. Recent popular models use neural networks to regress directly from pixels to 3D object parameters. Such an approach works well when supervision is available, but in problems like human pose and shape estimation, it is difficult to obtain natural images with 3D ground truth. To go one step further, we propose a new architecture that facilitates unsupervised, or lightly supervised, learning. The idea is to break the problem into a series of transformations between increasingly abstract representations. Each step involves a cycle designed to be learnable without annotated training data, and the chain of cycles delivers the final solution. Specifically, we use 2D body part segments as an intermediate representation that contains enough information to be lifted to 3D, and at the same time is simple enough to be learned in an unsupervised way. We demonstrate the method by learning 3D human pose and shape from un-paired and un-annotated images. We also explore varying amounts of paired data and show that cycling greatly alleviates the need for paired data. While we present results for modeling humans, our formulation is general and can be applied to other vision problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.01613v1"
	},
	{
		"title": "PsyNet: Self‐supervised Approach to Object Localization using Point Symmetric Transformation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reduction and Local Search for Weighted Graph Coloring Problem ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Practical Approach to Forgetting in Description Logics with Nominals ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Blameworthiness in Security Games ",
		"abstract": "Security games are an example of a successful real-world application of game theory. The paper defines blameworthiness of the defender and the attacker in security games using the principle of alternative possibilities and provides a sound and complete logical system for reasoning about blameworthiness in such games. Two of the axioms of this system capture the asymmetry of information in security games.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.08647v2"
	},
	{
		"title": "Ranking‐Based Semantics for Sets of Attacking Arguments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Exploit and Replace: An Asymmetrical Two‐Stream Architecture for Versatile Light Field Saliency Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cascading Convolutional Color Constancy ",
		"abstract": "Regressing the illumination of a scene from the representations of object appearances is popularly adopted in computational color constancy. However, it's still challenging due to intrinsic appearance and label ambiguities caused by unknown illuminants, diverse reflection property of materials and extrinsic imaging factors (such as different camera sensors). In this paper, we introduce a novel algorithm by Cascading Convolutional Color Constancy (in short, C4) to improve robustness of regression learning and achieve stable generalization capability across datasets (different cameras and scenes) in a unique framework. The proposed C4 method ensembles a series of dependent illumination hypotheses from each cascade stage via introducing a weighted multiply-accumulate loss function, which can inherently capture different modes of illuminations and explicitly enforce coarse-to-fine network optimization. Experimental results on the public Color Checker and NUS 8-Camera benchmarks demonstrate superior performance of the proposed algorithm in comparison with the state-of-the-art methods, especially for more difficult scenes.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11180v1"
	},
	{
		"title": "V‐PROM: A Benchmark for Visual Reasoning Using Visual Progressive Matrices ",
		"abstract": "One of the primary challenges faced by deep learning is the degree to which current methods exploit superficial statistics and dataset bias, rather than learning to generalise over the specific representations they have experienced. This is a critical concern because generalisation enables robust reasoning over unseen data, whereas leveraging superficial statistics is fragile to even small changes in data distribution. To illuminate the issue and drive progress towards a solution, we propose a test that explicitly evaluates abstract reasoning over visual data. We introduce a large-scale benchmark of visual questions that involve operations fundamental to many high-level vision tasks, such as comparisons of counts and logical operations on complex visual properties. The benchmark directly measures a method's ability to infer high-level relationships and to generalise them over image-based concepts. It includes multiple training/test splits that require controlled levels of generalization. We evaluate a range of deep learning architectures, and find that existing models, including those popular for vision-and-language tasks, are unable to solve seemingly-simple instances. Models using relational networks fare better but leave substantial room for improvement.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.12271v1"
	},
	{
		"title": "Accurate Structured‐Text Spotting for Arithmetical Exercise Correction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "LT‐GAN: Image Location Transfer using GAN ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Gated Fully Fusion for Semantic Segmentation ",
		"abstract": "Semantic segmentation generates comprehensive understanding of scenes through densely predicting the category for each pixel. High-level features from Deep Convolutional Neural Networks already demonstrate their effectiveness in semantic segmentation tasks, however the coarse resolution of high-level features often leads to inferior results for small/thin objects where detailed information is important. It is natural to consider importing low level features to compensate for the lost detailed information in high-level features.Unfortunately, simply combining multi-level features suffers from the semantic gap among them. In this paper, we propose a new architecture, named Gated Fully Fusion (GFF), to selectively fuse features from multiple levels using gates in a fully connected way. Specifically, features at each level are enhanced by higher-level features with stronger semantics and lower-level features with more details, and gates are used to control the propagation of useful information which significantly reduces the noises during fusion. We achieve the state of the art results on four challenging scene parsing datasets including Cityscapes, Pascal Context, COCO-stuff and ADE20K.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.01803v2"
	},
	{
		"title": "Residual Neural Processes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TANet: Robust 3D Object Detection from Point Clouds with Triple Attention ",
		"abstract": "In this paper, we focus on exploring the robustness of the 3D object detection in point clouds, which has been rarely discussed in existing approaches. We observe two crucial phenomena: 1) the detection accuracy of the hard objects, e.g., Pedestrians, is unsatisfactory, 2) when adding additional noise points, the performance of existing approaches decreases rapidly. To alleviate these problems, a novel TANet is introduced in this paper, which mainly contains a Triple Attention (TA) module, and a Coarse-to-Fine Regression (CFR) module. By considering the channel-wise, point-wise and voxel-wise attention jointly, the TA module enhances the crucial information of the target while suppresses the unstable cloud points. Besides, the novel stacked TA further exploits the multi-level feature attention. In addition, the CFR module boosts the accuracy of localization without excessive computation cost. Experimental results on the validation set of KITTI dataset demonstrate that, in the challenging noisy cases, i.e., adding additional random noisy points around each object,the presented approach goes far beyond state-of-the-art approaches. Furthermore, for the 3D object detection task of the KITTI benchmark, our approach ranks the first place on Pedestrian class, by using the point clouds as the only input. The running speed is around 29 frames per second.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05163v1"
	},
	{
		"title": "Learning to Generate Maps from Trajectories ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Unified Vision‐Language Pre‐Training for Image Captioning and VQA ",
		"abstract": "This paper presents a unified Vision-Language Pre-training (VLP) model. The model is unified in that (1) it can be fine-tuned for either vision-language generation (e.g., image captioning) or understanding (e.g., visual question answering) tasks, and (2) it uses a shared multi-layer transformer network for both encoding and decoding, which differs from many existing methods where the encoder and decoder are implemented using separate models. The unified VLP model is pre-trained on a large amount of image-text pairs using the unsupervised learning objectives of two tasks: bidirectional and sequence-to-sequence (seq2seq) masked vision-language prediction. The two tasks differ solely in what context the prediction conditions on. This is controlled by utilizing specific self-attention masks for the shared transformer network. To the best of our knowledge, VLP is the first reported model that achieves state-of-the-art results on both vision-language generation and understanding tasks, as disparate as image captioning and visual question answering, across three challenging benchmark datasets: COCO Captions, Flickr30k Captions, and VQA 2.0. The code and the pre-trained models are available at https://github.com/LuoweiZhou/VLP.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.11059v3"
	},
	{
		"title": "URNet : User‐Resizable Residual Networks with Conditional Gating Module ",
		"abstract": "Convolutional Neural Networks are widely used to process spatial scenes, but their computational cost is fixed and depends on the structure of the network used. There are methods to reduce the cost by compressing networks or varying its computational path dynamically according to the input image. However, since a user can not control the size of the learned model, it is difficult to respond dynamically if the amount of service requests suddenly increases. We propose User-Resizable Residual Networks (URNet), which allows users to adjust the scale of the network as needed during evaluation. URNet includes Conditional Gating Module (CGM) that determines the use of each residual block according to the input image and the desired scale. CGM is trained in a supervised manner using the newly proposed scale loss and its corresponding training methods. URNet can control the amount of computation according to user's demand without degrading the accuracy significantly. It can also be used as a general compression method by fixing the scale size during training. In the experiments on ImageNet, URNet based on ResNet-101 maintains the accuracy of the baseline even when resizing it to approximately 80% of the original network, and demonstrates only about 1% accuracy degradation when using about 65% of the computation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.04687v2"
	},
	{
		"title": "Mis‐classified Vector Guided Softmax Loss for Face Recognition ",
		"abstract": "Face recognition has witnessed significant progress due to the advances of deep convolutional neural networks (CNNs), the central task of which is how to improve the feature discrimination. To this end, several margin-based (\\textit{e.g.}, angular, additive and additive angular margins) softmax loss functions have been proposed to increase the feature margin between different classes. However, despite great achievements have been made, they mainly suffer from three issues: 1) Obviously, they ignore the importance of informative features mining for discriminative learning; 2) They encourage the feature margin only from the ground truth class, without realizing the discriminability from other non-ground truth classes; 3) The feature margin between different classes is set to be same and fixed, which may not adapt the situations very well. To cope with these issues, this paper develops a novel loss function, which adaptively emphasizes the mis-classified feature vectors to guide the discriminative feature learning. Thus we can address all the above issues and achieve more discriminative face features. To the best of our knowledge, this is the first attempt to inherit the advantages of feature margin and feature mining into a unified loss function. Experimental results on several benchmarks have demonstrated the effectiveness of our method over state-of-the-art alternatives.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00833v1"
	},
	{
		"title": "Reinforcement Learning from Imperfect Demonstrations under Soft Expert Guidance ",
		"abstract": "In this paper, we study Reinforcement Learning from Demonstrations (RLfD) that improves the exploration efficiency of Reinforcement Learning (RL) by providing expert demonstrations. Most of existing RLfD methods require demonstrations to be perfect and sufficient, which yet is unrealistic to meet in practice. To work on imperfect demonstrations, we first define an imperfect expert setting for RLfD in a formal way, and then point out that previous methods suffer from two issues in terms of optimality and convergence, respectively. Upon the theoretical findings we have derived, we tackle these two issues by regarding the expert guidance as a soft constraint on regulating the policy exploration of the agent, which eventually leads to a constrained optimization problem. We further demonstrate that such problem is able to be addressed efficiently by performing a local linear search on its dual form. Considerable empirical evaluations on a comprehensive collection of benchmarks indicate our method attains consistent improvement over other RLfD counterparts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07109v2"
	},
	{
		"title": "MULE: Multimodal Universal Language Embedding ",
		"abstract": "Existing vision-language methods typically support two languages at a time at most. In this paper, we present a modular approach which can easily be incorporated into existing vision-language methods in order to support many languages. We accomplish this by learning a single shared Multimodal Universal Language Embedding (MULE) which has been visually-semantically aligned across all languages. Then we learn to relate MULE to visual data as if it were a single language. Our method is not architecture specific, unlike prior work which typically learned separate branches for each language, enabling our approach to easily be adapted to many vision-language methods and tasks. Since MULE learns a single language branch in the multimodal model, we can also scale to support many languages, and languages with fewer annotations can take advantage of the good representation learned from other (more abundant) language data. We demonstrate the effectiveness of MULE on the bidirectional image-sentence retrieval task, supporting up to four languages in a single model. In addition, we show that Machine Translation can be used for data augmentation in multilingual learning, which, combined with MULE, improves mean recall by up to 21.9% on a single-language compared to prior work, with the most significant gains seen on languages with relatively few annotations. Our code is publicly available.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03493v2"
	},
	{
		"title": "Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks ",
		"abstract": "Deep neural networks often consist of a great number of trainable parameters for extracting powerful features from given datasets. On one hand, massive trainable parameters significantly enhance the performance of these deep networks. On the other hand, they bring the problem of over-fitting. To this end, dropout based methods disable some elements in the output feature maps during the training phase for reducing the co-adaptation of neurons. Although the generalization ability of the resulting models can be enhanced by these approaches, the conventional binary dropout is not the optimal solution. Therefore, we investigate the empirical Rademacher complexity related to intermediate layers of deep neural networks and propose a feature distortion method (Disout) for addressing the aforementioned problem. In the training period, randomly selected elements in the feature maps will be replaced with specific values by exploiting the generalization error bound. The superiority of the proposed feature map distortion for producing deep neural network with higher testing performance is analyzed and demonstrated on several benchmark image datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.11022v1"
	},
	{
		"title": "Pruning from Scratch ",
		"abstract": "Network pruning is an important research field aiming at reducing computational costs of neural networks. Conventional approaches follow a fixed paradigm which first trains a large and redundant network, and then determines which units (e.g., channels) are less important and thus can be removed. In this work, we find that pre-training an over-parameterized model is not necessary for obtaining the target pruned structure. In fact, a fully-trained over-parameterized model will reduce the search space for the pruned structure. We empirically show that more diverse pruned structures can be directly pruned from randomly initialized weights, including potential models with better performance. Therefore, we propose a novel network pruning pipeline which allows pruning from scratch. In the experiments for compressing classification models on CIFAR10 and ImageNet datasets, our approach not only greatly reduces the pre-training burden of traditional pruning methods, but also achieves similar or even higher accuracy under the same computation budgets. Our results facilitate the community to rethink the effectiveness of existing techniques used for network pruning.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.12579v1"
	},
	{
		"title": "Semi‐Supervised Learning under Class Distribution Mismatch ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Meta Model for Zero‐ and Few‐shot Face Anti‐spoofing ",
		"abstract": "Face anti-spoofing is crucial to the security of face recognition systems. Most previous methods formulate face anti-spoofing as a supervised learning problem to detect various predefined presentation attacks, which need large scale training data to cover as many attacks as possible. However, the trained model is easy to overfit several common attacks and is still vulnerable to unseen attacks. To overcome this challenge, the detector should: 1) learn discriminative features that can generalize to unseen spoofing types from predefined presentation attacks; 2) quickly adapt to new spoofing types by learning from both the predefined attacks and a few examples of the new spoofing types. Therefore, we define face anti-spoofing as a zero- and few-shot learning problem. In this paper, we propose a novel Adaptive Inner-update Meta Face Anti-Spoofing (AIM-FAS) method to tackle this problem through meta-learning. Specifically, AIM-FAS trains a meta-learner focusing on the task of detecting unseen spoofing types by learning from predefined living and spoofing faces and a few examples of new attacks. To assess the proposed approach, we propose several benchmarks for zero- and few-shot FAS. Experiments show its superior performances on the presented benchmarks to existing methods in existing zero-shot FAS protocols.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.12490v3"
	},
	{
		"title": "RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation ",
		"abstract": "Object detection and instance segmentation are two fundamental computer vision tasks. They are closely correlated but their relations have not yet been fully explored in most previous work. This paper presents RDSNet, a novel deep architecture for reciprocal object detection and instance segmentation. To reciprocate these two tasks, we design a two-stream structure to learn features on both the object level (i.e., bounding boxes) and the pixel level (i.e., instance masks) jointly. Within this structure, information from the two streams is fused alternately, namely information on the object level introduces the awareness of instance and translation variance to the pixel level, and information on the pixel level refines the localization accuracy of objects on the object level in return. Specifically, a correlation module and a cropping module are proposed to yield instance masks, as well as a mask based boundary refinement module for more accurate bounding boxes. Extensive experimental analyses and comparisons on the COCO dataset demonstrate the effectiveness and efficiency of RDSNet. The source code is available at https://github.com/wangsr126/RDSNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05070v1"
	},
	{
		"title": "UCF‐STAR: A Large‐Scale Still Image Dataset for Understanding Human Actions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Transferable Adversarial Examples via Ghost Networks ",
		"abstract": "Recent development of adversarial attacks has proven that ensemble-based methods outperform traditional, non-ensemble ones in black-box attack. However, as it is computationally prohibitive to acquire a family of diverse models, these methods achieve inferior performance constrained by the limited number of models to be ensembled.   In this paper, we propose Ghost Networks to improve the transferability of adversarial examples. The critical principle of ghost networks is to apply feature-level perturbations to an existing model to potentially create a huge set of diverse models. After that, models are subsequently fused by longitudinal ensemble. Extensive experimental results suggest that the number of networks is essential for improving the transferability of adversarial examples, but it is less necessary to independently train different networks and ensemble them in an intensive aggregation way. Instead, our work can be used as a computationally cheap and easily applied plug-in to improve adversarial approaches both in single-model and multi-model attack, compatible with residual and non-residual networks. By reproducing the NeurIPS 2017 adversarial competition, our method outperforms the No.1 attack submission by a large margin, demonstrating its effectiveness and efficiency. Code is available at https://github.com/LiYingwei/ghost-network.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1812.03413v3"
	},
	{
		"title": "Pose‐Assisted Multi‐Camera Collaboration for Active Object Tracking ",
		"abstract": "Active Object Tracking (AOT) is crucial to many visionbased applications, e.g., mobile robot, intelligent surveillance. However, there are a number of challenges when deploying active tracking in complex scenarios, e.g., target is frequently occluded by obstacles. In this paper, we extend the single-camera AOT to a multi-camera setting, where cameras tracking a target in a collaborative fashion. To achieve effective collaboration among cameras, we propose a novel Pose-Assisted Multi-Camera Collaboration System, which enables a camera to cooperate with the others by sharing camera poses for active object tracking. In the system, each camera is equipped with two controllers and a switcher: The vision-based controller tracks targets based on observed images. The pose-based controller moves the camera in accordance to the poses of the other cameras. At each step, the switcher decides which action to take from the two controllers according to the visibility of the target. The experimental results demonstrate that our system outperforms all the baselines and is capable of generalizing to unseen environments. The code and demo videos are available on our website https://sites.google.com/view/pose-assistedcollaboration.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.05161v1"
	},
	{
		"title": "Bi‐objective Continual Learning: Learning `New' while Consolidating `Known' ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Beyond Unfolding: Exact Recovery of Latent Convex Tensor Decomposition under Reshuffling ",
		"abstract": "Exact recovery of tensor decomposition (TD) methods is a desirable property in both unsupervised learning and scientific data analysis. The numerical defects of TD methods, however, limit their practical applications on real-world data. As an alternative, convex tensor decomposition (CTD) was proposed to alleviate these problems, but its exact-recovery property is not properly addressed so far. To this end, we focus on latent convex tensor decomposition (LCTD), a practically widely-used CTD model, and rigorously prove a sufficient condition for its exact-recovery property. Furthermore, we show that such property can be also achieved by a more general model than LCTD. In the new model, we generalize the classic tensor (un-)folding into reshuffling operation, a more flexible mapping to relocate the entries of the matrix into a tensor. Armed with the reshuffling operations and exact-recovery property, we explore a totally novel application for (generalized) LCTD, i.e., image steganography. Experimental results on synthetic data validate our theory, and results on image steganography show that our method outperforms the state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1805.08465v3"
	},
	{
		"title": "A Spherical Convolution Approach for Learning Long Term Viewport Prediction in 360 Immersive Video ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Follow Directions in Street View ",
		"abstract": "Navigating and understanding the real world remains a key challenge in machine learning and inspires a great variety of research in areas such as language grounding, planning, navigation and computer vision. We propose an instruction-following task that requires all of the above, and which combines the practicality of simulated environments with the challenges of ambiguous, noisy real world data. StreetNav is built on top of Google Street View and provides visually accurate environments representing real places. Agents are given driving instructions which they must learn to interpret in order to successfully navigate in this environment. Since humans equipped with driving instructions can readily navigate in previously unseen cities, we set a high bar and test our trained agents for similar cognitive capabilities. Although deep reinforcement learning (RL) methods are frequently evaluated only on data that closely follow the training distribution, our dataset extends to multiple cities and has a clean train/test separation. This allows for thorough testing of generalisation ability. This paper presents the StreetNav environment and tasks, models that establish strong baselines, and extensive analysis of the task and the trained agents.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.00401v2"
	},
	{
		"title": "Proximal Distilled Evolutionary Reinforcement Learning ",
		"abstract": "Reinforcement Learning (RL) has achieved impressive performance in many complex environments due to the integration with Deep Neural Networks (DNNs). At the same time, Genetic Algorithms (GAs), often seen as a competing approach to RL, had limited success in scaling up to the DNNs required to solve challenging tasks. Contrary to this dichotomic view, in the physical world, evolution and learning are complementary processes that continuously interact. The recently proposed Evolutionary Reinforcement Learning (ERL) framework has demonstrated mutual benefits to performance when combining the two methods. However, ERL has not fully addressed the scalability problem of GAs. In this paper, we show that this problem is rooted in an unfortunate combination of a simple genetic encoding for DNNs and the use of traditional biologically-inspired variation operators. When applied to these encodings, the standard operators are destructive and cause catastrophic forgetting of the traits the networks acquired. We propose a novel algorithm called Proximal Distilled Evolutionary Reinforcement Learning (PDERL) that is characterised by a hierarchical integration between evolution and learning. The main innovation of PDERL is the use of learning-based variation operators that compensate for the simplicity of the genetic representation. Unlike traditional operators, our proposals meet the functional requirements of variation operators when applied on directly-encoded DNNs. We evaluate PDERL in five robot locomotion settings from the OpenAI gym. Our method outperforms ERL, as well as two state-of-the-art RL algorithms, PPO and TD3, in all tested environments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.09807v4"
	},
	{
		"title": "Re‐Attention for Visual Question Answering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "{Attention‐based View Selection Networks for Light‐field Disparity Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Coupled‐view Deep Classifier Learning from Multiple Noisy Annotators ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning‐based Efficient Graph Similarity Computation via Multi‐Scale Convolutional Set Matching ",
		"abstract": "Graph similarity computation is one of the core operations in many graph-based applications, such as graph similarity search, graph database analysis, graph clustering, etc. Since computing the exact distance/similarity between two graphs is typically NP-hard, a series of approximate methods have been proposed with a trade-off between accuracy and speed. Recently, several data-driven approaches based on neural networks have been proposed, most of which model the graph-graph similarity as the inner product of their graph-level representations, with different techniques proposed for generating one embedding per graph. However, using one fixed-dimensional embedding per graph may fail to fully capture graphs in varying sizes and link structures, a limitation that is especially problematic for the task of graph similarity computation, where the goal is to find the fine-grained difference between two graphs. In this paper, we address the problem of graph similarity computation from another perspective, by directly matching two sets of node embeddings without the need to use fixed-dimensional vectors to represent whole graphs for their similarity computation. The model, GraphSim, achieves the state-of-the-art performance on four real-world graph datasets under six out of eight settings (here we count a specific dataset and metric combination as one setting), compared to existing popular methods for approximate Graph Edit Distance (GED) and Maximum Common Subgraph (MCS) computation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1809.04440v2"
	},
	{
		"title": "Learning to Transfer: Unsupervised Domain Translation via Meta‐Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Leveraging Multi‐view Image Sets for Unsupervised Intrinsic Image Decomposition and Highlight Separation ",
		"abstract": "We present an unsupervised approach for factorizing object appearance into highlight, shading, and albedo layers, trained by multi-view real images. To do so, we construct a multi-view dataset by collecting numerous customer product photos online, which exhibit large illumination variations that make them suitable for training of reflectance separation and can facilitate object-level decomposition. The main contribution of our approach is a proposed image representation based on local color distributions that allows training to be insensitive to the local misalignments of multi-view images. In addition, we present a new guidance cue for unsupervised training that exploits synergy between highlight separation and intrinsic image decomposition. Over a broad range of objects, our technique is shown to yield state-of-the-art results for both of these tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07262v1"
	},
	{
		"title": "Logo‐2K+: A Large‐Scale Logo Dataset for Scalable Logo Classification ",
		"abstract": "Logo classification has gained increasing attention for its various applications, such as copyright infringement detection, product recommendation and contextual advertising. Compared with other types of object images, the real-world logo images have larger variety in logo appearance and more complexity in their background. Therefore, recognizing the logo from images is challenging. To support efforts towards scalable logo classification task, we have curated a dataset, Logo-2K+, a new large-scale publicly available real-world logo dataset with 2,341 categories and 167,140 images. Compared with existing popular logo datasets, such as FlickrLogos-32 and LOGO-Net, Logo-2K+ has more comprehensive coverage of logo categories and larger quantity of logo images. Moreover, we propose a Discriminative Region Navigation and Augmentation Network (DRNA-Net), which is capable of discovering more informative logo regions and augmenting these image regions for logo classification. DRNA-Net consists of four sub-networks: the navigator sub-network first selected informative logo-relevant regions guided by the teacher sub-network, which can evaluate its confidence belonging to the ground-truth logo class. The data augmentation sub-network then augments the selected regions via both region cropping and region dropping. Finally, the scrutinizer sub-network fuses features from augmented regions and the whole image for logo classification. Comprehensive experiments on Logo-2K+ and other three existing benchmark datasets demonstrate the effectiveness of proposed method. Logo-2K+ and the proposed strong baseline DRNA-Net are expected to further the development of scalable logo image recognition, and the Logo-2K+ dataset can be found at https://github.com/msn199959/Logo-2k-plus-Dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07924v1"
	},
	{
		"title": "Efficient Automatic CASH via Rising Bandits ",
		"abstract": "The Combined Algorithm Selection and Hyperparameter optimization (CASH) is one of the most fundamental problems in Automatic Machine Learning (AutoML). The existing Bayesian optimization (BO) based solutions turn the CASH problem into a Hyperparameter Optimization (HPO) problem by combining the hyperparameters of all machine learning (ML) algorithms, and use BO methods to solve it. As a result, these methods suffer from the low-efficiency problem due to the huge hyperparameter space in CASH. To alleviate this issue, we propose the alternating optimization framework, where the HPO problem for each ML algorithm and the algorithm selection problem are optimized alternately. In this framework, the BO methods are used to solve the HPO problem for each ML algorithm separately, incorporating a much smaller hyperparameter space for BO methods. Furthermore, we introduce Rising Bandits, a CASH-oriented Multi-Armed Bandits (MAB) variant, to model the algorithm selection in CASH. This framework can take the advantages of both BO in solving the HPO problem with a relatively small hyperparameter space and the MABs in accelerating the algorithm selection. Moreover, we further develop an efficient online algorithm to solve the Rising Bandits with provably theoretical guarantees. The extensive experiments on 30 OpenML datasets demonstrate the superiority of the proposed approach over the competitive baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2012.04371v1"
	},
	{
		"title": "Multi‐Objective Multi‐Agent Planning for Jointly Discovering and Tracking Mobile Objects ",
		"abstract": "We consider the challenging problem of online planning for a team of agents to autonomously search and track a time-varying number of mobile objects under the practical constraint of detection range limited onboard sensors. A standard POMDP with a value function that either encourages discovery or accurate tracking of mobile objects is inadequate to simultaneously meet the conflicting goals of searching for undiscovered mobile objects whilst keeping track of discovered objects. The planning problem is further complicated by misdetections or false detections of objects caused by range limited sensors and noise inherent to sensor measurements. We formulate a novel multi-objective POMDP based on information theoretic criteria, and an online multi-object tracking filter for the problem. Since controlling multi-agent is a well known combinatorial optimization problem, assigning control actions to agents necessitates a greedy algorithm. We prove that our proposed multi-objective value function is a monotone submodular set function; consequently, the greedy algorithm can achieve a (1-1/e) approximation for maximizing the submodular multi-objective function.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09807v1"
	},
	{
		"title": "Learning to Deblur Face Images via Sketch Synthesis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ZoomNet: Part‐Aware Adaptive Zooming Neural Network for 3D Object Detection ",
		"abstract": "3D object detection is an essential task in autonomous driving and robotics. Though great progress has been made, challenges remain in estimating 3D pose for distant and occluded objects. In this paper, we present a novel framework named ZoomNet for stereo imagery-based 3D detection. The pipeline of ZoomNet begins with an ordinary 2D object detection model which is used to obtain pairs of left-right bounding boxes. To further exploit the abundant texture cues in RGB images for more accurate disparity estimation, we introduce a conceptually straight-forward module -- adaptive zooming, which simultaneously resizes 2D instance bounding boxes to a unified resolution and adjusts the camera intrinsic parameters accordingly. In this way, we are able to estimate higher-quality disparity maps from the resized box images then construct dense point clouds for both nearby and distant objects. Moreover, we introduce to learn part locations as complementary features to improve the resistance against occlusion and put forward the 3D fitting score to better estimate the 3D detection quality. Extensive experiments on the popular KITTI 3D detection dataset indicate ZoomNet surpasses all previous state-of-the-art methods by large margins (improved by 9.4% on APbv (IoU=0.7) over pseudo-LiDAR). Ablation study also demonstrates that our adaptive zooming strategy brings an improvement of over 10% on AP3d (IoU=0.7). In addition, since the official KITTI benchmark lacks fine-grained annotations like pixel-wise part locations, we also present our KFG dataset by augmenting KITTI with detailed instance-wise annotations including pixel-wise part location, pixel-wise disparity, etc.. Both the KFG dataset and our codes will be publicly available at https://github.com/detectRecog/ZoomNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00529v1"
	},
	{
		"title": "Uncertainty‐aware Multi‐shot Knowledge Distillation for Image‐based Object Re‐identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Channel Pruning Guided by Classification Loss and Feature Importance ",
		"abstract": "In this work, we propose a new layer-by-layer channel pruning method called Channel Pruning guided by classification Loss and feature Importance (CPLI). In contrast to the existing layer-by-layer channel pruning approaches that only consider how to reconstruct the features from the next layer, our approach additionally take the classification loss into account in the channel pruning process. We also observe that some reconstructed features will be removed at the next pruning stage. So it is unnecessary to reconstruct these features. To this end, we propose a new strategy to suppress the influence of unimportant features (i.e., the features will be removed at the next pruning stage). Our comprehensive experiments on three benchmark datasets, i.e., CIFAR-10, ImageNet, and UCF-101, demonstrate the effectiveness of our CPLI method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.06757v1"
	},
	{
		"title": "Temporal Logics Over Finite Traces with Uncertainty ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Real‐time Scene Text Detection with Differentiable Binarization ",
		"abstract": "Recently, segmentation-based methods are quite popular in scene text detection, as the segmentation results can more accurately describe scene text of various shapes such as curve text. However, the post-processing of binarization is essential for segmentation-based detection, which converts probability maps produced by a segmentation method into bounding boxes/regions of text. In this paper, we propose a module named Differentiable Binarization (DB), which can perform the binarization process in a segmentation network. Optimized along with a DB module, a segmentation network can adaptively set the thresholds for binarization, which not only simplifies the post-processing but also enhances the performance of text detection. Based on a simple segmentation network, we validate the performance improvements of DB on five benchmark datasets, which consistently achieves state-of-the-art results, in terms of both detection accuracy and speed. In particular, with a light-weight backbone, the performance improvements by DB are significant so that we can look for an ideal tradeoff between detection accuracy and efficiency. Specifically, with a backbone of ResNet-18, our detector achieves an F-measure of 82.8, running at 62 FPS, on the MSRA-TD500 dataset. Code is available at: https://github.com/MhLiao/DB",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08947v2"
	},
	{
		"title": "FASTER Recurrent Networks for Efficient Video Classification ",
		"abstract": "Typical video classification methods often divide a video into short clips, do inference on each clip independently, then aggregate the clip-level predictions to generate the video-level results. However, processing visually similar clips independently ignores the temporal structure of the video sequence, and increases the computational cost at inference time. In this paper, we propose a novel framework named FASTER, i.e., Feature Aggregation for Spatio-TEmporal Redundancy. FASTER aims to leverage the redundancy between neighboring clips and reduce the computational cost by learning to aggregate the predictions from models of different complexities. The FASTER framework can integrate high quality representations from expensive models to capture subtle motion information and lightweight representations from cheap models to cover scene changes in the video. A new recurrent network (i.e., FAST-GRU) is designed to aggregate the mixture of different representations. Compared with existing approaches, FASTER can reduce the FLOPs by over 10x? while maintaining the state-of-the-art accuracy across popular datasets, such as Kinetics, UCF-101 and HMDB-51.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.04226v2"
	},
	{
		"title": "Learning from the Past: Continual Meta‐Learning with Bayesian Graph Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Visual‐Tactile Fusion Object Clustering ",
		"abstract": "Object clustering, aiming at grouping similar objects into one cluster with an unsupervised strategy, has been extensivelystudied among various data-driven applications. However, most existing state-of-the-art object clustering methods (e.g., single-view or multi-view clustering methods) only explore visual information, while ignoring one of most important sensing modalities, i.e., tactile information which can help capture different object properties and further boost the performance of object clustering task. To effectively benefit both visual and tactile modalities for object clustering, in this paper, we propose a deep Auto-Encoder-like Non-negative Matrix Factorization framework for visual-tactile fusion clustering. Specifically, deep matrix factorization constrained by an under-complete Auto-Encoder-like architecture is employed to jointly learn hierarchical expression of visual-tactile fusion data, and preserve the local structure of data generating distribution of visual and tactile modalities. Meanwhile, a graph regularizer is introduced to capture the intrinsic relations of data samples within each modality. Furthermore, we propose a modality-level consensus regularizer to effectively align thevisual and tactile data in a common subspace in which the gap between visual and tactile data is mitigated. For the model optimization, we present an efficient alternating minimization strategy to solve our proposed model. Finally, we conduct extensive experiments on public datasets to verify the effectiveness of our framework.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09430v1"
	},
	{
		"title": "Policy Search by Target Distribution Learning for Continuous Control ",
		"abstract": "We observe that several existing policy gradient methods (such as vanilla policy gradient, PPO, A2C) may suffer from overly large gradients when the current policy is close to deterministic (even in some very simple environments), leading to an unstable training process. To address this issue, we propose a new method, called \\emph{target distribution learning} (TDL), for policy improvement in reinforcement learning. TDL alternates between proposing a target distribution and training the policy network to approach the target distribution. TDL is more effective in constraining the KL divergence between updated policies, and hence leads to more stable policy improvements over iterations. Our experiments show that TDL algorithms perform comparably to (or better than) state-of-the-art algorithms for most continuous control tasks in the MuJoCo environment while being more stable in training.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.11041v2"
	},
	{
		"title": "On the Anatomy of MCMC‐Based Maximum Likelihood Learning of Energy‐Based Models ",
		"abstract": "This study investigates the effects of Markov chain Monte Carlo (MCMC) sampling in unsupervised Maximum Likelihood (ML) learning. Our attention is restricted to the family of unnormalized probability densities for which the negative log density (or energy function) is a ConvNet. We find that many of the techniques used to stabilize training in previous studies are not necessary. ML learning with a ConvNet potential requires only a few hyper-parameters and no regularization. Using this minimal framework, we identify a variety of ML learning outcomes that depend solely on the implementation of MCMC sampling.   On one hand, we show that it is easy to train an energy-based model which can sample realistic images with short-run Langevin. ML can be effective and stable even when MCMC samples have much higher energy than true steady-state samples throughout training. Based on this insight, we introduce an ML method with purely noise-initialized MCMC, high-quality short-run synthesis, and the same budget as ML with informative MCMC initialization such as CD or PCD. Unlike previous models, our energy model can obtain realistic high-diversity samples from a noise signal after training.   On the other hand, ConvNet potentials learned with non-convergent MCMC do not have a valid steady-state and cannot be considered approximate unnormalized densities of the training data because long-run MCMC samples differ greatly from observed images. We show that it is much harder to train a ConvNet potential to learn a steady-state over realistic images. To our knowledge, long-run MCMC samples of all previous models lose the realism of short-run samples. With correct tuning of Langevin noise, we train the first ConvNet potentials for which long-run and steady-state MCMC samples are realistic images.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.12370v4"
	},
	{
		"title": "Information Shaping for Enhanced Goal Recognition of Partially‐Informed Agents ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "AutoShrink: A Topology‐aware NAS for Discovering Efficient Neural Architecture ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Clustering‐aware Multiple Graph Matching via Decayed Pairwise Matching Composition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Practical Federated Gradient Boosting Decision Trees ",
		"abstract": "Gradient Boosting Decision Trees (GBDTs) have become very successful in recent years, with many awards in machine learning and data mining competitions. There have been several recent studies on how to train GBDTs in the federated learning setting. In this paper, we focus on horizontal federated learning, where data samples with the same features are distributed among multiple parties. However, existing studies are not efficient or effective enough for practical use. They suffer either from the inefficiency due to the usage of costly data transformations such as secret sharing and homomorphic encryption, or from the low model accuracy due to differential privacy designs. In this paper, we study a practical federated environment with relaxed privacy constraints. In this environment, a dishonest party might obtain some information about the other parties' data, but it is still impossible for the dishonest party to derive the actual raw data of other parties. Specifically, each party boosts a number of trees by exploiting similarity information based on locality-sensitive hashing. We prove that our framework is secure without exposing the original record to other parties, while the computation overhead in the training process is kept low. Our experimental studies show that, compared with normal training with the local data of each party, our approach can significantly improve the predictive accuracy, and achieve comparable accuracy to the original GBDT with the data from all parties.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04206v2"
	},
	{
		"title": "Tree‐Structured Policy based Progressive Reinforcement Learning for Temporally Language Grounding in Video ",
		"abstract": "Temporally language grounding in untrimmed videos is a newly-raised task in video understanding. Most of the existing methods suffer from inferior efficiency, lacking interpretability, and deviating from the human perception mechanism. Inspired by human's coarse-to-fine decision-making paradigm, we formulate a novel Tree-Structured Policy based Progressive Reinforcement Learning (TSP-PRL) framework to sequentially regulate the temporal boundary by an iterative refinement process. The semantic concepts are explicitly represented as the branches in the policy, which contributes to efficiently decomposing complex policies into an interpretable primitive action. Progressive reinforcement learning provides correct credit assignment via two task-oriented rewards that encourage mutual promotion within the tree-structured policy. We extensively evaluate TSP-PRL on the Charades-STA and ActivityNet datasets, and experimental results show that TSP-PRL achieves competitive performance over existing state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06680v1"
	},
	{
		"title": "A MaxSAT‐based Framework for Group Testing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Hierarchical Knowledge Squeezed Adversarial Network Compression ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation‐based ConvLSTM ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "The Missing Data Encoder: Cross‐Channel Image Completion with Hide‐And‐Seek Adversarial Network ",
		"abstract": "Image completion is the problem of generating whole images from fragments only. It encompasses inpainting (generating a patch given its surrounding), reverse inpainting/extrapolation (generating the periphery given the central patch) as well as colorization (generating one or several channels given other ones). In this paper, we employ a deep network to perform image completion, with adversarial training as well as perceptual and completion losses, and call it the ``missing data encoder'' (MDE). We consider several configurations based on how the seed fragments are chosen. We show that training MDE for ``random extrapolation and colorization'' (MDE-REC), i.e. using random channel-independent fragments, allows a better capture of the image semantics and geometry. MDE training makes use of a novel ``hide-and-seek'' adversarial loss, where the discriminator seeks the original non-masked regions, while the generator tries to hide them. We validate our models both qualitatively and quantitatively on several datasets, showing their interest for image completion, unsupervised representation learning as well as face occlusion handling.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.01861v1"
	},
	{
		"title": "DATA‐GRU: Dual‐Attention Time‐Aware Gated Recurrent Unit for Irregular Multivariate Time Series ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cost‐Effective Incentive Allocation via Structured Counterfactual Inference ",
		"abstract": "We address a practical problem ubiquitous in modern marketing campaigns, in which a central agent tries to learn a policy for allocating strategic financial incentives to customers and observes only bandit feedback. In contrast to traditional policy optimization frameworks, we take into account the additional reward structure and budget constraints common in this setting, and develop a new two-step method for solving this constrained counterfactual policy optimization problem. Our method first casts the reward estimation problem as a domain adaptation problem with supplementary structure, and then subsequently uses the estimators for optimizing the policy with constraints. We also establish theoretical error bounds for our estimation procedure and we empirically show that the approach leads to significant improvement on both synthetic and real datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.02495v3"
	},
	{
		"title": "VCG Under Sybil (False name) Attacks ‐‐‐ a Bayesian Analysis ",
		"abstract": "VCG is a classical combinatorial auction that maximizes social welfare. However, while the standard single-item Vickrey auction is false-name-proof, a major failure of multi-item VCG is its vulnerability to false-name attacks. This occurs already in the natural bare minimum model in which there are two identical items and bidders are single-minded. Previous solutions to this challenge focused on developing alternative mechanisms that compromise social welfare. We re-visit the VCG auction vulnerability and consider the bidder behavior in Bayesian settings. In service of that we introduce a novel notion, termed the granularity threshold, that characterizes VCG Bayesian resilience to false-name attacks as a function of the bidder type distribution. Using this notion we show a large class of cases in which VCG indeed obtains Bayesian resilience for the two-item single-minded setting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07210v2"
	},
	{
		"title": "Complementary‐View Multiple Human Tracking ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FDN: Feature Decoupling Network for Head Pose Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families ",
		"abstract": "The correspondence between residual networks and dynamical systems motivates researchers to unravel the physics of ResNets with well-developed tools in numeral methods of ODE systems. The Runge-Kutta-Fehlberg method is an adaptive time stepping that renders a good trade-off between the stability and efficiency. Can we also have an adaptive time stepping for ResNets to ensure both stability and performance? In this study, we analyze the effects of time stepping on the Euler method and ResNets. We establish a stability condition for ResNets with step sizes and weight parameters, and point out the effects of step sizes on the stability and performance. Inspired by our analyses, we develop an adaptive time stepping controller that is dependent on the parameters of the current step, and aware of previous steps. The controller is jointly optimized with the network training so that variable step sizes and evolution time can be adaptively adjusted. We conduct experiments on ImageNet and CIFAR to demonstrate the effectiveness. It is shown that our proposed method is able to improve both stability and accuracy without introducing additional overhead in inference phase.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10305v1"
	},
	{
		"title": "Region Normalization for Image Inpainting ",
		"abstract": "Feature Normalization (FN) is an important technique to help neural network training, which typically normalizes features across spatial dimensions. Most previous image inpainting methods apply FN in their networks without considering the impact of the corrupted regions of the input image on normalization, e.g. mean and variance shifts. In this work, we show that the mean and variance shifts caused by full-spatial FN limit the image inpainting network training and we propose a spatial region-wise normalization named Region Normalization (RN) to overcome the limitation. RN divides spatial pixels into different regions according to the input mask, and computes the mean and variance in each region for normalization. We develop two kinds of RN for our image inpainting network: (1) Basic RN (RN-B), which normalizes pixels from the corrupted and uncorrupted regions separately based on the original inpainting mask to solve the mean and variance shift problem; (2) Learnable RN (RN-L), which automatically detects potentially corrupted and uncorrupted regions for separate normalization, and performs global affine transformation to enhance their fusion. We apply RN-B in the early layers and RN-L in the latter layers of the network respectively. Experiments show that our method outperforms current state-of-the-art methods quantitatively and qualitatively. We further generalize RN to other inpainting networks and achieve consistent performance improvements.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10375v1"
	},
	{
		"title": "Representation Learning with Multiple Lipschitz‐constrained Alignments on Partially‐labeled Cross‐domain Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Refining HTN Methods via Task Insertion with Preferences ",
		"abstract": "Hierarchical Task Network (HTN) planning is showing its power in real-world planning. Although domain experts have partial hierarchical domain knowledge, it is time-consuming to specify all HTN methods, leaving them incomplete. On the other hand, traditional HTN learning approaches focus only on declarative goals, omitting the hierarchical domain knowledge. In this paper, we propose a novel learning framework to refine HTN methods via task insertion with completely preserving the original methods. As it is difficult to identify incomplete methods without designating declarative goals for compound tasks, we introduce the notion of prioritized preference to capture the incompleteness possibility of methods. Specifically, the framework first computes the preferred completion profile w.r.t. the prioritized preference to refine the incomplete methods. Then it finds the minimal set of refined methods via a method substitution operation. Experimental analysis demonstrates that our approach is effective, especially in solving new HTN planning instances.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12949v1"
	},
	{
		"title": "Gradient‐Aware Model‐based Policy Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Infrared‐Visible Cross‐Modal Person Re‐Identification with an X Modality ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Text Perceptron: Towards End‐to‐End Arbitrary‐Shaped Text Spotting ",
		"abstract": "Many approaches have recently been proposed to detect irregular scene text and achieved promising results. However, their localization results may not well satisfy the following text recognition part mainly because of two reasons: 1) recognizing arbitrary shaped text is still a challenging task, and 2) prevalent non-trainable pipeline strategies between text detection and text recognition will lead to suboptimal performances. To handle this incompatibility problem, in this paper we propose an end-to-end trainable text spotting approach named Text Perceptron. Concretely, Text Perceptron first employs an efficient segmentation-based text detector that learns the latent text reading order and boundary information. Then a novel Shape Transform Module (abbr. STM) is designed to transform the detected feature regions into regular morphologies without extra parameters. It unites text detection and the following recognition part into a whole framework, and helps the whole network achieve global optimization. Experiments show that our method achieves competitive performance on two standard text benchmarks, i.e., ICDAR 2013 and ICDAR 2015, and also obviously outperforms existing methods on irregular text benchmarks SCUT-CTW1500 and Total-Text.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06820v1"
	},
	{
		"title": "Multi‐label Causal Feature Selection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Automated Synthesis of Social Laws in STRIPS ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Attractive or Faithful? Popularity‐Reinforced Learning for Inspired Headline Generation ",
		"abstract": "With the rapid proliferation of online media sources and published news, headlines have become increasingly important for attracting readers to news articles, since users may be overwhelmed with the massive information. In this paper, we generate inspired headlines that preserve the nature of news articles and catch the eye of the reader simultaneously. The task of inspired headline generation can be viewed as a specific form of Headline Generation (HG) task, with the emphasis on creating an attractive headline from a given news article. To generate inspired headlines, we propose a novel framework called POpularity-Reinforced Learning for inspired Headline Generation (PORL-HG). PORL-HG exploits the extractive-abstractive architecture with 1) Popular Topic Attention (PTA) for guiding the extractor to select the attractive sentence from the article and 2) a popularity predictor for guiding the abstractor to rewrite the attractive sentence. Moreover, since the sentence selection of the extractor is not differentiable, techniques of reinforcement learning (RL) are utilized to bridge the gap with rewards obtained from a popularity score predictor. Through quantitative and qualitative experiments, we show that the proposed PORL-HG significantly outperforms the state-of-the-art headline generation models in terms of attractiveness evaluated by both human (71.03%) and the predictor (at least 27.60%), while the faithfulness of PORL-HG is also comparable to the state-of-the-art generation model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.02095v1"
	},
	{
		"title": "Aspect‐Aware Multimodal Summarization for Chinese E‐commerce Products ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Layerwise Sparse Coding for Pruned Deep Neural Networks with Extreme Compression Ratio ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Geometry Sharing Network for 3D Point Cloud Classification and Segmentation   ",
		"abstract": "In spite of the recent progresses on classifying 3D point cloud with deep CNNs, large geometric transformations like rotation and translation remain challenging problem and harm the final classification performance. To address this challenge, we propose Geometry Sharing Network (GS-Net) which effectively learns point descriptors with holistic context to enhance the robustness to geometric transformations. Compared with previous 3D point CNNs which perform convolution on nearby points, GS-Net can aggregate point features in a more global way. Specially, GS-Net consists of Geometry Similarity Connection (GSC) modules which exploit Eigen-Graph to group distant points with similar and relevant geometric information, and aggregate features from nearest neighbors in both Euclidean space and Eigenvalue space. This design allows GS-Net to efficiently capture both local and holistic geometric features such as symmetry, curvature, convexity and connectivity. Theoretically, we show the nearest neighbors of each point in Eigenvalue space are invariant to rotation and translation. We conduct extensive experiments on public datasets, ModelNet40, ShapeNet Part. Experiments demonstrate that GS-Net achieves the state-of-the-art performances on major datasets, 93.3% on ModelNet40, and are more robust to geometric transformations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10644v1"
	},
	{
		"title": "A Framework for Engineering Human/Agent Teaming Systems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Separate In Latent Space: Unsupervised Single Image Layer Separation ",
		"abstract": "Many real world vision tasks, such as reflection removal from a transparent surface and intrinsic image decomposition, can be modeled as single image layer separation. However, this problem is highly ill-posed, requiring accurately aligned and hard to collect triplet data to train the CNN models. To address this problem, this paper proposes an unsupervised method that requires no ground truth data triplet in training. At the core of the method are two assumptions about data distributions in the latent spaces of different layers, based on which a novel unsupervised layer separation pipeline can be derived. Then the method can be constructed based on the GANs framework with self-supervision and cycle consistency constraints, etc. Experimental results demonstrate its successfulness in outperforming existing unsupervised methods in both synthetic and real world tasks. The method also shows its ability to solve a more challenging multi-layer separation task.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.00734v3"
	},
	{
		"title": "Loss‐based Attention for Deep Multiple Instance Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Estimating Early Fundraising Performance of Innovations via Graph‐based Market Environment Model ",
		"abstract": "Well begun is half done. In the crowdfunding market, the early fundraising performance of the project is a concerned issue for both creators and platforms. However, estimating the early fundraising performance before the project published is very challenging and still under-explored. To that end, in this paper, we present a focused study on this important problem in a market modeling view. Specifically, we propose a Graph-based Market Environment model (GME) for estimating the early fundraising performance of the target project by exploiting the market environment. In addition, we discriminatively model the market competition and market evolution by designing two graph-based neural network architectures and incorporating them into the joint optimization stage. Finally, we conduct extensive experiments on the real-world crowdfunding data collected from Indiegogo.com. The experimental results clearly demonstrate the effectiveness of our proposed model for modeling and estimating the early fundraising performance of the target project.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06767v1"
	},
	{
		"title": "Multi‐Label Classification with Label Graph Superimposing ",
		"abstract": "Images or videos always contain multiple objects or actions. Multi-label recognition has been witnessed to achieve pretty performance attribute to the rapid development of deep learning technologies. Recently, graph convolution network (GCN) is leveraged to boost the performance of multi-label recognition. However, what is the best way for label correlation modeling and how feature learning can be improved with label system awareness are still unclear. In this paper, we propose a label graph superimposing framework to improve the conventional GCN+CNN framework developed for multi-label recognition in the following two aspects. Firstly, we model the label correlations by superimposing label graph built from statistical co-occurrence information into the graph constructed from knowledge priors of labels, and then multi-layer graph convolutions are applied on the final superimposed graph for label embedding abstraction. Secondly, we propose to leverage embedding of the whole label system for better representation learning. In detail, lateral connections between GCN and CNN are added at shallow, middle and deep layers to inject information of label system into backbone CNN for label-awareness in the feature learning process. Extensive experiments are carried out on MS-COCO and Charades datasets, showing that our proposed solution can greatly improve the recognition performance and achieves new state-of-the-art recognition performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09243v1"
	},
	{
		"title": "PedHunter: Occlusion Robust Pedestrian Detector in Crowded Scenes ",
		"abstract": "Pedestrian detection in crowded scenes is a challenging problem, because occlusion happens frequently among different pedestrians. In this paper, we propose an effective and efficient detection network to hunt pedestrians in crowd scenes. The proposed method, namely PedHunter, introduces strong occlusion handling ability to existing region-based detection networks without bringing extra computations in the inference stage. Specifically, we design a mask-guided module to leverage the head information to enhance the feature representation learning of the backbone network. Moreover, we develop a strict classification criterion by improving the quality of positive samples during training to eliminate common false positives of pedestrian detection in crowded scenes. Besides, we present an occlusion-simulated data augmentation to enrich the pattern and quantity of occlusion samples to improve the occlusion robustness. As a consequent, we achieve state-of-the-art results on three pedestrian detection datasets including CityPersons, Caltech-USA and CrowdHuman. To facilitate further studies on the occluded pedestrian detection in surveillance scenes, we release a new pedestrian dataset, called SUR-PED, with a total of over 162k high-quality manually labeled instances in 10k images. The proposed dataset, source codes and trained models will be released.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.06826v1"
	},
	{
		"title": "Relational Learning for Joint Head and Human Detection ",
		"abstract": "Head and human detection have been rapidly improved with the development of deep convolutional neural networks. However, these two tasks are often studied separately without considering their inherent correlation, leading to that 1) head detection is often trapped in more false positives, and 2) the performance of human detector frequently drops dramatically in crowd scenes. To handle these two issues, we present a novel joint head and human detection network, namely JointDet, which effectively detects head and human body simultaneously. Moreover, we design a head-body relationship discriminating module to perform relational learning between heads and human bodies, and leverage this learned relationship to regain the suppressed human detections and reduce head false positives. To verify the effectiveness of the proposed method, we annotate head bounding boxes of the CityPersons and Caltech-USA datasets, and conduct extensive experiments on the CrowdHuman, CityPersons and Caltech-USA datasets. As a consequence, the proposed JointDet detector achieves state-of-the-art performance on these three benchmarks. To facilitate further studies on the head and human detection problem, all new annotations, source codes and trained models will be public.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10674v1"
	},
	{
		"title": "Learning Deep Relations to Promote Saliency Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐spectral Vehicle Re‐identification: A Challenge ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RL‐Duet: Online Music Accompaniment Generation Using Deep Reinforcement Learning ",
		"abstract": "This paper presents a deep reinforcement learning algorithm for online accompaniment generation, with potential for real-time interactive human-machine duet improvisation. Different from offline music generation and harmonization, online music accompaniment requires the algorithm to respond to human input and generate the machine counterpart in a sequential order. We cast this as a reinforcement learning problem, where the generation agent learns a policy to generate a musical note (action) based on previously generated context (state). The key of this algorithm is the well-functioning reward model. Instead of defining it using music composition rules, we learn this model from monophonic and polyphonic training data. This model considers the compatibility of the machine-generated note with both the machine-generated context and the human-generated context. Experiments show that this algorithm is able to respond to the human part and generate a melodic, harmonic and diverse machine part. Subjective evaluations on preferences show that the proposed algorithm generates music pieces of higher quality than the baseline method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03082v1"
	},
	{
		"title": "CFGNN: Cross Flow Graph Neural Networks for Question Answering on Complex Tables ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Federated Learning for Vision‐and‐Language Grounding Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Computing Superior Counter‐Examples for Conformant Planning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Uncertainty‐Aware Deep Classifiers using Generative Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "End‐to‐End Unpaired Image Denoising with Conditional Adversarial Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Graph‐Based Decoding Model for Functional Alignment of Unaligned fMRI Data ",
		"abstract": "Aggregating multi-subject functional magnetic resonance imaging (fMRI) data is indispensable for generating valid and general inferences from patterns distributed across human brains. The disparities in anatomical structures and functional topographies of human brains warrant aligning fMRI data across subjects. However, the existing functional alignment methods cannot handle well various kinds of fMRI datasets today, especially when they are not temporally-aligned, i.e., some of the subjects probably lack the responses to some stimuli, or different subjects might follow different sequences of stimuli. In this paper, a cross-subject graph that depicts the (dis)similarities between samples across subjects is used as a priori for developing a more flexible framework that suits an assortment of fMRI datasets. However, the high dimension of fMRI data and the use of multiple subjects makes the crude framework time-consuming or unpractical. To address this issue, we further regularize the framework, so that a novel feasible kernel-based optimization, which permits nonlinear feature extraction, could be theoretically developed. Specifically, a low-dimension assumption is imposed on each new feature space to avoid overfitting caused by the highspatial-low-temporal resolution of fMRI data. Experimental results on five datasets suggest that the proposed method is not only superior to several state-of-the-art methods on temporally-aligned fMRI data, but also suitable for dealing `with temporally-unaligned fMRI data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.05468v8"
	},
	{
		"title": "Attention Based Data Hiding with Generative Adversarial Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Conditional Generative Neural Decoding with Structured CNN Feature Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Count‐Based Exploration with the Successor Representation ",
		"abstract": "In this paper we introduce a simple approach for exploration in reinforcement learning (RL) that allows us to develop theoretically justified algorithms in the tabular case but that is also extendable to settings where function approximation is required. Our approach is based on the successor representation (SR), which was originally introduced as a representation defining state generalization by the similarity of successor states. Here we show that the norm of the SR, while it is being learned, can be used as a reward bonus to incentivize exploration. In order to better understand this transient behavior of the norm of the SR we introduce the substochastic successor representation (SSR) and we show that it implicitly counts the number of times each state (or feature) has been observed. We use this result to introduce an algorithm that performs as well as some theoretically sample-efficient approaches. Finally, we extend these ideas to a deep RL algorithm and show that it achieves state-of-the-art performance in Atari 2600 games when in a low sample-complexity regime.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1807.11622v4"
	},
	{
		"title": "Document Summarization with VHTM:Variational Hierarchical Topic‐Aware Mechanism ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Eigenvalue Normalized Recurrent Neural Networks for Short Term Memory ",
		"abstract": "Several variants of recurrent neural networks (RNNs) with orthogonal or unitary recurrent matrices have recently been developed to mitigate the vanishing/exploding gradient problem and to model long-term dependencies of sequences. However, with the eigenvalues of the recurrent matrix on the unit circle, the recurrent state retains all input information which may unnecessarily consume model capacity. In this paper, we address this issue by proposing an architecture that expands upon an orthogonal/unitary RNN with a state that is generated by a recurrent matrix with eigenvalues in the unit disc. Any input to this state dissipates in time and is replaced with new inputs, simulating short-term memory. A gradient descent algorithm is derived for learning such a recurrent matrix. The resulting method, called the Eigenvalue Normalized RNN (ENRNN), is shown to be highly competitive in several experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07964v1"
	},
	{
		"title": "Knowledge‐Graph Augmented Word Representations For Named Entity Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "3D Single‐Person Concurrent Activity Detection Using Stacked Relation Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adversarial‐Learned Loss for Domain Adaptation ",
		"abstract": "Recently, remarkable progress has been made in learning transferable representation across domains. Previous works in domain adaptation are majorly based on two techniques: domain-adversarial learning and self-training. However, domain-adversarial learning only aligns feature distributions between domains but does not consider whether the target features are discriminative. On the other hand, self-training utilizes the model predictions to enhance the discrimination of target features, but it is unable to explicitly align domain distributions. In order to combine the strengths of these two methods, we propose a novel method called Adversarial-Learned Loss for Domain Adaptation (ALDA). We first analyze the pseudo-label method, a typical self-training method. Nevertheless, there is a gap between pseudo-labels and the ground truth, which can cause incorrect training. Thus we introduce the confusion matrix, which is learned through an adversarial manner in ALDA, to reduce the gap and align the feature distributions. Finally, a new loss function is auto-constructed from the learned confusion matrix, which serves as the loss for unlabeled target samples. Our ALDA outperforms state-of-the-art approaches in four standard domain adaptation datasets. Our code is available at https://github.com/ZJULearning/ALDA.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.01046v1"
	},
	{
		"title": "Distance‐IoU Loss: Faster and Better Learning for Bounding Box Regression ",
		"abstract": "Bounding box regression is the crucial step in object detection. In existing methods, while $\\ell_n$-norm loss is widely adopted for bounding box regression, it is not tailored to the evaluation metric, i.e., Intersection over Union (IoU). Recently, IoU loss and generalized IoU (GIoU) loss have been proposed to benefit the IoU metric, but still suffer from the problems of slow convergence and inaccurate regression. In this paper, we propose a Distance-IoU (DIoU) loss by incorporating the normalized distance between the predicted box and the target box, which converges much faster in training than IoU and GIoU losses. Furthermore, this paper summarizes three geometric factors in bounding box regression, \\ie, overlap area, central point distance and aspect ratio, based on which a Complete IoU (CIoU) loss is proposed, thereby leading to faster convergence and better performance. By incorporating DIoU and CIoU losses into state-of-the-art object detection algorithms, e.g., YOLO v3, SSD and Faster RCNN, we achieve notable performance gains in terms of not only IoU metric but also GIoU metric. Moreover, DIoU can be easily adopted into non-maximum suppression (NMS) to act as the criterion, further boosting performance improvement. The source code and trained models are available at https://github.com/Zzh-tju/DIoU.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08287v1"
	},
	{
		"title": "Bi‐Directional Generation for Unsupervised Domain Adaptation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TemPEST: Soft Template‐based Personalized EDM Subject Generation Through Collaborative Summarization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Integrated Enhancement Solution for 24‐hour Colorful Imaging ",
		"abstract": "The current industry practice for 24-hour outdoor imaging is to use a silicon camera supplemented with near-infrared (NIR) illumination. This will result in color images with poor contrast at daytime and absence of chrominance at nighttime. For this dilemma, all existing solutions try to capture RGB and NIR images separately. However, they need additional hardware support and suffer from various drawbacks, including short service life, high price, specific usage scenario, etc. In this paper, we propose a novel and integrated enhancement solution that produces clear color images, whether at abundant sunlight daytime or extremely low-light nighttime. Our key idea is to separate the VIS and NIR information from mixed signals, and enhance the VIS signal adaptively with the NIR signal as assistance. To this end, we build an optical system to collect a new VIS-NIR-MIX dataset and present a physically meaningful image processing algorithm based on CNN. Extensive experiments show outstanding results, which demonstrate the effectiveness of our solution.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.04580v1"
	},
	{
		"title": "A Framework for Measuring Information Asymmetry ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Incremental Symmetry Breaking Constraints for Graph Search Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Mastering Complex Control in MOBA Games with Deep Reinforcement Learning ",
		"abstract": "We study the reinforcement learning problem of complex action control in the Multi-player Online Battle Arena (MOBA) 1v1 games. This problem involves far more complicated state and action spaces than those of traditional 1v1 games, such as Go and Atari series, which makes it very difficult to search any policies with human-level performance. In this paper, we present a deep reinforcement learning framework to tackle this problem from the perspectives of both system and algorithm. Our system is of low coupling and high scalability, which enables efficient explorations at large scale. Our algorithm includes several novel strategies, including control dependency decoupling, action mask, target attention, and dual-clip PPO, with which our proposed actor-critic network can be effectively trained in our system. Tested on the MOBA game Honor of Kings, our AI agent, called Tencent Solo, can defeat top professional human players in full 1v1 games.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.09729v3"
	},
	{
		"title": "Do Subsampled Newton Methods Work for High‐Dimensional Data? ",
		"abstract": "Subsampled Newton methods approximate Hessian matrices through subsampling techniques, alleviating the cost of forming Hessian matrices but using sufficient curvature information. However, previous results require $\\Omega (d)$ samples to approximate Hessians, where $d$ is the dimension of data points, making it less practically feasible for high-dimensional data. The situation is deteriorated when $d$ is comparably as large as the number of data points $n$, which requires to take the whole dataset into account, making subsampling useless. This paper theoretically justifies the effectiveness of subsampled Newton methods on high dimensional data. Specifically, we prove only $\\widetilde{\\Theta}(d^\\gamma_{\\rm eff})$ samples are needed in the approximation of Hessian matrices, where $d^\\gamma_{\\rm eff}$ is the $\\gamma$-ridge leverage and can be much smaller than $d$ as long as $n\\gamma \\gg 1$. Additionally, we extend this result so that subsampled Newton methods can work for high-dimensional data on both distributed optimization problems and non-smooth regularized problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.04952v2"
	},
	{
		"title": "TextScanner: Reading Characters in Order for Robust Scene Text Recognition ",
		"abstract": "Driven by deep learning and the large volume of data, scene text recognition has evolved rapidly in recent years. Formerly, RNN-attention based methods have dominated this field, but suffer from the problem of \\textit{attention drift} in certain situations. Lately, semantic segmentation based algorithms have proven effective at recognizing text of different forms (horizontal, oriented and curved). However, these methods may produce spurious characters or miss genuine characters, as they rely heavily on a thresholding procedure operated on segmentation maps. To tackle these challenges, we propose in this paper an alternative approach, called TextScanner, for scene text recognition. TextScanner bears three characteristics: (1) Basically, it belongs to the semantic segmentation family, as it generates pixel-wise, multi-channel segmentation maps for character class, position and order; (2) Meanwhile, akin to RNN-attention based methods, it also adopts RNN for context modeling; (3) Moreover, it performs paralleled prediction for character position and class, and ensures that characters are transcripted in correct order. The experiments on standard benchmark datasets demonstrate that TextScanner outperforms the state-of-the-art methods. Moreover, TextScanner shows its superiority in recognizing more difficult text such Chinese transcripts and aligning with target characters.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.12422v2"
	},
	{
		"title": "Multimodal Summarization with Guidance of Multimodal Reference ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Iterative Delegations in Liquid Democracy with Restricted Preferences ",
		"abstract": "In this paper, we study liquid democracy, a collective decision making paradigm which lies between direct and representative democracy. One main feature of liquid democracy is that voters can delegate their votes in a transitive manner so that: A delegates to B and B delegates to C leads to A delegates to C. Unfortunately, this process may not converge as there may not even exist a stable state (also called equilibrium). In this paper, we investigate the stability of the delegation process in liquid democracy when voters have restricted types of preference on the agent representing them (e.g., single-peaked preferences). We show that various natural structures of preferences guarantee the existence of an equilibrium and we obtain both tractability and hardness results for the problem of computing several equilibria with some desirable properties.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1809.04362v2"
	},
	{
		"title": "Learning to Learn Morphological Inflection for Resource‐Poor Languages ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Query Answering with Guarded Existential Rules under Stable Model Semantics ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Target‐Aspect‐Sentiment Joint Detection for Aspect‐Based Sentiment Analysis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Compare for Better Training and Evaluation of Open Domain Text Generation Models ",
		"abstract": "Automated evaluation of open domain natural language generation (NLG) models remains a challenge and widely used metrics such as BLEU and Perplexity can be misleading in some cases. In our paper, we propose to evaluate natural language generation models by learning to compare a pair of generated sentences by fine-tuning BERT, which has been shown to have good natural language understanding ability. We also propose to evaluate the model-level quality of NLG models with sample-level comparison results with skill rating system. While able to be trained in a fully self-supervised fashion, our model can be further fine-tuned with a little amount of human preference annotation to better imitate human judgment. In addition to evaluating trained models, we propose to apply our model as a performance indicator during training for better hyperparameter tuning and early-stopping. We evaluate our approach on both story generation and chit-chat dialogue response generation. Experimental results show that our model correlates better with human preference compared with previous automated evaluation approaches. Training with the proposed metric yields better performance in human evaluation, which further demonstrates the effectiveness of the proposed model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.05058v1"
	},
	{
		"title": "Local Search with Dynamic‐threshold Configuration Checking and Incremental Neighborhood Updating for Maximum k‐plex Problem ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Who Likes What? – SplitLBI in Exploring Preferential Diversity of Ratings ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CIAN: Cross‐Image Affinity Net for Weakly Supervised Semantic Segmentation ",
		"abstract": "Weakly supervised semantic segmentation with only image-level labels saves large human effort to annotate pixel-level labels. Cutting-edge approaches rely on various innovative constraints and heuristic rules to generate the masks for every single image. Although great progress has been achieved by these methods, they treat each image independently and do not take account of the relationships across different images. In this paper, however, we argue that the cross-image relationship is vital for weakly supervised segmentation. Because it connects related regions across images, where supplementary representations can be propagated to obtain more consistent and integral regions. To leverage this information, we propose an end-to-end cross-image affinity module, which exploits pixel-level cross-image relationships with only image-level labels. By means of this, our approach achieves 64.3% and 65.3% mIoU on Pascal VOC 2012 validation and test set respectively, which is a new state-of-the-art result by only using image-level labels for weakly supervised semantic segmentation, demonstrating the superiority of our approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1811.10842v2"
	},
	{
		"title": "Web‐Supervised Network with Softly Update‐Drop Training for Fine‐Grained Visual Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Channel Interaction Networks for Fine‐Grained Image Categorization ",
		"abstract": "Fine-grained image categorization is challenging due to the subtle inter-class differences.We posit that exploiting the rich relationships between channels can help capture such differences since different channels correspond to different semantics. In this paper, we propose a channel interaction network (CIN), which models the channel-wise interplay both within an image and across images. For a single image, a self-channel interaction (SCI) module is proposed to explore channel-wise correlation within the image. This allows the model to learn the complementary features from the correlated channels, yielding stronger fine-grained features. Furthermore, given an image pair, we introduce a contrastive channel interaction (CCI) module to model the cross-sample channel interaction with a metric learning framework, allowing the CIN to distinguish the subtle visual differences between images. Our model can be trained efficiently in an end-to-end fashion without the need of multi-stage training and testing. Finally, comprehensive experiments are conducted on three publicly available benchmarks, where the proposed method consistently outperforms the state-of-theart approaches, such as DFL-CNN (Wang, Morariu, and Davis 2018) and NTS (Yang et al. 2018).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.05235v1"
	},
	{
		"title": "Fair Division of Mixed Divisible and Indivisible Goods ",
		"abstract": "We study the problem of fair division when the resources contain both divisible and indivisible goods. Classic fairness notions such as envy-freeness (EF) and envy-freeness up to one good (EF1) cannot be directly applied to the mixed goods setting. In this work, we propose a new fairness notion envy-freeness for mixed goods (EFM), which is a direct generalization of both EF and EF1 to the mixed goods setting. We prove that an EFM allocation always exists for any number of agents. We also propose efficient algorithms to compute an EFM allocation for two agents and for $n$ agents with piecewise linear valuations over the divisible goods. Finally, we relax the envy-free requirement, instead asking for $\\epsilon$-envy-freeness for mixed goods ($\\epsilon$-EFM), and present an algorithm that finds an $\\epsilon$-EFM allocation in time polynomial in the number of agents, the number of indivisible goods, and $1/\\epsilon$.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07048v3"
	},
	{
		"title": "KnowIT VQA: Answering Knowledge‐Based Questions about Videos ",
		"abstract": "We propose a novel video understanding task by fusing knowledge-based and video question answering. First, we introduce KnowIT VQA, a video dataset with 24,282 human-generated question-answer pairs about a popular sitcom. The dataset combines visual, textual and temporal coherence reasoning together with knowledge-based questions, which need of the experience obtained from the viewing of the series to be answered. Second, we propose a video understanding model by combining the visual and textual video content with specific knowledge about the show. Our main findings are: (i) the incorporation of knowledge produces outstanding improvements for VQA in video, and (ii) the performance on KnowIT VQA still lags well behind human accuracy, indicating its usefulness for studying current video modelling limitations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.10706v3"
	},
	{
		"title": "Minimizing the Bag‐of‐Ngrams Difference for Non‐Autoregressive Neural Machine Translation ",
		"abstract": "Non-Autoregressive Neural Machine Translation (NAT) achieves significant decoding speedup through generating target words independently and simultaneously. However, in the context of non-autoregressive translation, the word-level cross-entropy loss cannot model the target-side sequential dependency properly, leading to its weak correlation with the translation quality. As a result, NAT tends to generate influent translations with over-translation and under-translation errors. In this paper, we propose to train NAT to minimize the Bag-of-Ngrams (BoN) difference between the model output and the reference sentence. The bag-of-ngrams training objective is differentiable and can be efficiently calculated, which encourages NAT to capture the target-side sequential dependency and correlates well with the translation quality. We validate our approach on three translation tasks and show that our approach largely outperforms the NAT baseline by about 5.0 BLEU scores on WMT14 En$\\leftrightarrow$De and about 2.5 BLEU scores on WMT16 En$\\leftrightarrow$Ro.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09320v1"
	},
	{
		"title": "Nice Invincible Strategy for the Average‐Payoff IPD ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Few‐Shot Bayesian Imitation Learning with Logical Program Policies ",
		"abstract": "Humans can learn many novel tasks from a very small number (1--5) of demonstrations, in stark contrast to the data requirements of nearly tabula rasa deep learning methods. We propose an expressive class of policies, a strong but general prior, and a learning algorithm that, together, can learn interesting policies from very few examples. We represent policies as logical combinations of programs drawn from a domain-specific language (DSL), define a prior over policies with a probabilistic grammar, and derive an approximate Bayesian inference algorithm to learn policies from demonstrations. In experiments, we study five strategy games played on a 2D grid with one shared DSL. After a few demonstrations of each game, the inferred policies generalize to new game instances that differ substantially from the demonstrations. Our policy learning is 20--1,000x more data efficient than convolutional and fully convolutional policy learning and many orders of magnitude more computationally efficient than vanilla program induction. We argue that the proposed method is an apt choice for tasks that have scarce training data and feature significant, structured variation between task instances.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.06317v2"
	},
	{
		"title": "SOGNet: Scene Overlap Graph Network for Panoptic Segmentation ",
		"abstract": "The panoptic segmentation task requires a unified result from semantic and instance segmentation outputs that may contain overlaps. However, current studies widely ignore modeling overlaps. In this study, we aim to model overlap relations among instances and resolve them for panoptic segmentation. Inspired by scene graph representation, we formulate the overlapping problem as a simplified case, named scene overlap graph. We leverage each object's category, geometry and appearance features to perform relational embedding, and output a relation matrix that encodes overlap relations. In order to overcome the lack of supervision, we introduce a differentiable module to resolve the overlap between any pair of instances. The mask logits after removing overlaps are fed into per-pixel instance \\verb|id| classification, which leverages the panoptic supervision to assist in the modeling of overlap relations. Besides, we generate an approximate ground truth of overlap relations as the weak supervision, to quantify the accuracy of overlap relations predicted by our method. Experiments on COCO and Cityscapes demonstrate that our method is able to accurately predict overlap relations, and outperform the state-of-the-art performance for panoptic segmentation. Our method also won the Innovation Award in COCO 2019 challenge.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07527v1"
	},
	{
		"title": "Relational Prototypical Network for Weakly Supervised Temporal Action Localization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Part‐Level Graph Convolutional Network for Skeleton‐Based Action Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reliability Does Matter: An End‐to‐End Weakly Supervised Semantic Segmentation Approach ",
		"abstract": "Weakly supervised semantic segmentation is a challenging task as it only takes image-level information as supervision for training but produces pixel-level predictions for testing. To address such a challenging task, most recent state-of-the-art approaches propose to adopt two-step solutions, \\emph{i.e. } 1) learn to generate pseudo pixel-level masks, and 2) engage FCNs to train the semantic segmentation networks with the pseudo masks. However, the two-step solutions usually employ many bells and whistles in producing high-quality pseudo masks, making this kind of methods complicated and inelegant. In this work, we harness the image-level labels to produce reliable pixel-level annotations and design a fully end-to-end network to learn to predict segmentation maps. Concretely, we firstly leverage an image classification branch to generate class activation maps for the annotated categories, which are further pruned into confident yet tiny object/background regions. Such reliable regions are then directly served as ground-truth labels for the parallel segmentation branch, where a newly designed dense energy loss function is adopted for optimization. Despite its apparent simplicity, our one-step solution achieves competitive mIoU scores (\\emph{val}: 62.6, \\emph{test}: 62.9) on Pascal VOC compared with those two-step state-of-the-arts. By extending our one-step method to two-step, we get a new state-of-the-art performance on the Pascal VOC (\\emph{val}: 66.3, \\emph{test}: 66.5).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08039v1"
	},
	{
		"title": "GRET: Global Representation Enhanced Transformer ",
		"abstract": "Transformer, based on the encoder-decoder framework, has achieved state-of-the-art performance on several natural language generation tasks. The encoder maps the words in the input sentence into a sequence of hidden states, which are then fed into the decoder to generate the output sentence. These hidden states usually correspond to the input words and focus on capturing local information. However, the global (sentence level) information is seldom explored, leaving room for the improvement of generation quality. In this paper, we propose a novel global representation enhanced Transformer (GRET) to explicitly model global representation in the Transformer network. Specifically, in the proposed model, an external state is generated for the global representation from the encoder. The global representation is then fused into the decoder during the decoding process to improve generation quality. We conduct experiments in two text generation tasks: machine translation and text summarization. Experimental results on four WMT machine translation tasks and LCSTS text summarization task demonstrate the effectiveness of the proposed approach on natural language generation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.10101v1"
	},
	{
		"title": "Stochastic Loss Function ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neural Cognitive Diagnosis for Intelligent Education Systems ",
		"abstract": "Cognitive diagnosis is a fundamental issue in intelligent education, which aims to discover the proficiency level of students on specific knowledge concepts. Existing approaches usually mine linear interactions of student exercising process by manual-designed function (e.g., logistic function), which is not sufficient for capturing complex relations between students and exercises. In this paper, we propose a general Neural Cognitive Diagnosis (NeuralCD) framework, which incorporates neural networks to learn the complex exercising interactions, for getting both accurate and interpretable diagnosis results. Specifically, we project students and exercises to factor vectors and leverage multi neural layers for modeling their interactions, where the monotonicity assumption is applied to ensure the interpretability of both factors. Furthermore, we propose two implementations of NeuralCD by specializing the required concepts of each exercise, i.e., the NeuralCDM with traditional Q-matrix and the improved NeuralCDM+ exploring the rich text content. Extensive experimental results on real-world datasets show the effectiveness of NeuralCD framework with both accuracy and interpretability.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.08733v3"
	},
	{
		"title": "Stable Prediction with Model Misspecification and Agnostic Distribution Shift ",
		"abstract": "For many machine learning algorithms, two main assumptions are required to guarantee performance. One is that the test data are drawn from the same distribution as the training data, and the other is that the model is correctly specified. In real applications, however, we often have little prior knowledge on the test data and on the underlying true model. Under model misspecification, agnostic distribution shift between training and test data leads to inaccuracy of parameter estimation and instability of prediction across unknown test data. To address these problems, we propose a novel Decorrelated Weighting Regression (DWR) algorithm which jointly optimizes a variable decorrelation regularizer and a weighted regression model. The variable decorrelation regularizer estimates a weight for each sample such that variables are decorrelated on the weighted training data. Then, these weights are used in the weighted regression to improve the accuracy of estimation on the effect of each variable, thus help to improve the stability of prediction across unknown test data. Extensive experiments clearly demonstrate that our DWR algorithm can significantly improve the accuracy of parameter estimation and stability of prediction with model misspecification and agnostic distribution shift.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.11713v1"
	},
	{
		"title": "Universal‐RCNN: Universal Object Detector via Transferable Graph R‐CNN ",
		"abstract": "The dominant object detection approaches treat each dataset separately and fit towards a specific domain, which cannot adapt to other domains without extensive retraining. In this paper, we address the problem of designing a universal object detection model that exploits diverse category granularity from multiple domains and predict all kinds of categories in one system. Existing works treat this problem by integrating multiple detection branches upon one shared backbone network. However, this paradigm overlooks the crucial semantic correlations between multiple domains, such as categories hierarchy, visual similarity, and linguistic relationship. To address these drawbacks, we present a novel universal object detector called Universal-RCNN that incorporates graph transfer learning for propagating relevant semantic information across multiple datasets to reach semantic coherency. Specifically, we first generate a global semantic pool by integrating all high-level semantic representation of all the categories. Then an Intra-Domain Reasoning Module learns and propagates the sparse graph representation within one dataset guided by a spatial-aware GCN. Finally, an InterDomain Transfer Module is proposed to exploit diverse transfer dependencies across all domains and enhance the regional feature representation by attending and transferring semantic contexts globally. Extensive experiments demonstrate that the proposed method significantly outperforms multiple-branch models and achieves the state-of-the-art results on multiple object detection benchmarks (mAP: 49.1% on COCO).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07417v1"
	},
	{
		"title": "Attribute Propagation Network for Graph Zero‐shot Learning ",
		"abstract": "The goal of zero-shot learning (ZSL) is to train a model to classify samples of classes that were not seen during training. To address this challenging task, most ZSL methods relate unseen test classes to seen(training) classes via a pre-defined set of attributes that can describe all classes in the same semantic space, so the knowledge learned on the training classes can be adapted to unseen classes. In this paper, we aim to optimize the attribute space for ZSL by training a propagation mechanism to refine the semantic attributes of each class based on its neighbors and related classes on a graph of classes. We show that the propagated attributes can produce classifiers for zero-shot classes with significantly improved performance in different ZSL settings. The graph of classes is usually free or very cheap to acquire such as WordNet or ImageNet classes. When the graph is not provided, given pre-defined semantic embeddings of the classes, we can learn a mechanism to generate the graph in an end-to-end manner along with the propagation mechanism. However, this graph-aided technique has not been well-explored in the literature. In this paper, we introduce the attribute propagation network (APNet), which is composed of 1) a graph propagation model generating attribute vector for each class and 2) a parameterized nearest neighbor (NN) classifier categorizing an image to the class with the nearest attribute vector to the image's embedding. For better generalization over unseen classes, different from previous methods, we adopt a meta-learning strategy to train the propagation mechanism and the similarity metric for the NN classifier on multiple sub-graphs, each associated with a classification task over a subset of training classes. In experiments with two zero-shot learning settings and five benchmark datasets, APNet achieves either compelling performance or new state-of-the-art results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2009.11816v1"
	},
	{
		"title": "An Adversarial Perturbation Oriented Domain Adaptation Approach for Semantic Segmentation ",
		"abstract": "We focus on Unsupervised Domain Adaptation (UDA) for the task of semantic segmentation. Recently, adversarial alignment has been widely adopted to match the marginal distribution of feature representations across two domains globally. However, this strategy fails in adapting the representations of the tail classes or small objects for semantic segmentation since the alignment objective is dominated by head categories or large objects. In contrast to adversarial alignment, we propose to explicitly train a domain-invariant classifier by generating and defensing against pointwise feature space adversarial perturbations. Specifically, we firstly perturb the intermediate feature maps with several attack objectives (i.e., discriminator and classifier) on each individual position for both domains, and then the classifier is trained to be invariant to the perturbations. By perturbing each position individually, our model treats each location evenly regardless of the category or object size and thus circumvents the aforementioned issue. Moreover, the domain gap in feature space is reduced by extrapolating source and target perturbed features towards each other with attack on the domain discriminator. Our approach achieves the state-of-the-art performance on two challenging domain adaptation tasks for semantic segmentation: GTA5 -> Cityscapes and SYNTHIA -> Cityscapes.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08954v1"
	},
	{
		"title": "Reborn Filters: Pruning Convolutional Neural Networks with Limited Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SADA: Semantic Adversarial Diagnostic Attacks for Autonomous Applications ",
		"abstract": "One major factor impeding more widespread adoption of deep neural networks (DNNs) is their lack of robustness, which is essential for safety-critical applications such as autonomous driving. This has motivated much recent work on adversarial attacks for DNNs, which mostly focus on pixel-level perturbations void of semantic meaning. In contrast, we present a general framework for adversarial attacks on trained agents, which covers semantic perturbations to the environment of the agent performing the task as well as pixel-level attacks. To do this, we re-frame the adversarial attack problem as learning a distribution of parameters that always fools the agent. In the semantic case, our proposed adversary (denoted as BBGAN) is trained to sample parameters that describe the environment with which the black-box agent interacts, such that the agent performs its dedicated task poorly in this environment. We apply BBGAN on three different tasks, primarily targeting aspects of autonomous navigation: object detection, self-driving, and autonomous UAV racing. On these tasks, BBGAN can generate failure cases that consistently fool a trained agent.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1812.02132v3"
	},
	{
		"title": "Monte Carlo Tree Search in continuous spaces using Voronoi optimistic optimization with regret bounds ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "POST: POlicy‐based Switch Tracking ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Overcoming Language Priors in VQA via Decomposed Linguistic Representations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "PEIA: Personality and Emotion Integrated Attentive Model for Music Recommendation on Social Media Platforms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Revisiting Online Quantum State Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Every Frame Counts: Joint Learning of Video Segmentation and Optical Flow ",
		"abstract": "A major challenge for video semantic segmentation is the lack of labeled data. In most benchmark datasets, only one frame of a video clip is annotated, which makes most supervised methods fail to utilize information from the rest of the frames. To exploit the spatio-temporal information in videos, many previous works use pre-computed optical flows, which encode the temporal consistency to improve the video segmentation. However, the video segmentation and optical flow estimation are still considered as two separate tasks. In this paper, we propose a novel framework for joint video semantic segmentation and optical flow estimation. Semantic segmentation brings semantic information to handle occlusion for more robust optical flow estimation, while the non-occluded optical flow provides accurate pixel-level temporal correspondences to guarantee the temporal consistency of the segmentation. Moreover, our framework is able to utilize both labeled and unlabeled frames in the video through joint training, while no additional calculation is required in inference. Extensive experiments show that the proposed model makes the video semantic segmentation and optical flow estimation benefit from each other and outperforms existing methods under the same settings in both tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12739v1"
	},
	{
		"title": "Improving Entity Linking by Modeling Latent Entity Type Information ",
		"abstract": "Existing state of the art neural entity linking models employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected, which causes the models often link mentions to incorrect entities with incorrect type. To tackle this problem, we propose to inject latent entity type information into the entity embeddings based on pre-trained BERT. In addition, we integrate a BERT-based entity similarity score into the local context model of a state-of-the-art model to better capture latent entity type information. Our model significantly outperforms the state-of-the-art entity linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis demonstrates that our model corrects most of the type errors produced by the direct baseline.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.01447v1"
	},
	{
		"title": "Improved Visual‐Semantic Alignment for Zero‐Shot Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Context‐Aware Zero‐Shot Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Forgetting to Learn Logic Programs ",
		"abstract": "Most program induction approaches require predefined, often hand-engineered, background knowledge (BK). To overcome this limitation, we explore methods to automatically acquire BK through multi-task learning. In this approach, a learner adds learned programs to its BK so that they can be reused to help learn other programs. To improve learning performance, we explore the idea of forgetting, where a learner can additionally remove programs from its BK. We consider forgetting in an inductive logic programming (ILP) setting. We show that forgetting can significantly reduce both the size of the hypothesis space and the sample complexity of an ILP learner. We introduce Forgetgol, a multi-task ILP learner which supports forgetting. We experimentally compare Forgetgol against approaches that either remember or forget everything. Our experimental results show that Forgetgol outperforms the alternative approaches when learning from over 10,000 tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06643v1"
	},
	{
		"title": "Adaptive Trust Region Policy Optimization: Global Convergence and Faster Rates for Regularized MDPs ",
		"abstract": "Trust region policy optimization (TRPO) is a popular and empirically successful policy search algorithm in Reinforcement Learning (RL) in which a surrogate problem, that restricts consecutive policies to be 'close' to one another, is iteratively solved. Nevertheless, TRPO has been considered a heuristic algorithm inspired by Conservative Policy Iteration (CPI). We show that the adaptive scaling mechanism used in TRPO is in fact the natural \"RL version\" of traditional trust-region methods from convex analysis. We first analyze TRPO in the planning setting, in which we have access to the model and the entire state space. Then, we consider sample-based TRPO and establish $\\tilde O(1/\\sqrt{N})$ convergence rate to the global optimum. Importantly, the adaptive scaling mechanism allows us to analyze TRPO in regularized MDPs for which we prove fast rates of $\\tilde O(1/N)$, much like results in convex optimization. This is the first result in RL of better rates when regularizing the instantaneous cost or reward.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02769v2"
	},
	{
		"title": "HDK: Toward High‐Performance Deep‐Learning‐Based Kirchhoff Analysis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "3D Shape Completion with Multi‐view Consistent Inference ",
		"abstract": "3D shape completion is important to enable machines to perceive the complete geometry of objects from partial observations. To address this problem, view-based methods have been presented. These methods represent shapes as multiple depth images, which can be back-projected to yield corresponding 3D point clouds, and they perform shape completion by learning to complete each depth image using neural networks. While view-based methods lead to state-of-the-art results, they currently do not enforce geometric consistency among the completed views during the inference stage. To resolve this issue, we propose a multi-view consistent inference technique for 3D shape completion, which we express as an energy minimization problem including a data term and a regularization term. We formulate the regularization term as a consistency loss that encourages geometric consistency among multiple views, while the data term guarantees that the optimized views do not drift away too much from a learned shape descriptor. Experimental results demonstrate that our method completes shapes more accurately than previous techniques.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12465v1"
	},
	{
		"title": "Subspace Capsule Network ",
		"abstract": "Convolutional neural networks (CNNs) have become a key asset to most of fields in AI. Despite their successful performance, CNNs suffer from a major drawback. They fail to capture the hierarchy of spatial relation among different parts of an entity. As a remedy to this problem, the idea of capsules was proposed by Hinton. In this paper, we propose the SubSpace Capsule Network (SCN) that exploits the idea of capsule networks to model possible variations in the appearance or implicitly defined properties of an entity through a group of capsule subspaces instead of simply grouping neurons to create capsules. A capsule is created by projecting an input feature vector from a lower layer onto the capsule subspace using a learnable transformation. This transformation finds the degree of alignment of the input with the properties modeled by the capsule subspace. We show that SCN is a general capsule network that can successfully be applied to both discriminative and generative models without incurring computational overhead compared to CNN during test time. Effectiveness of SCN is evaluated through a comprehensive set of experiments on supervised image classification, semi-supervised image classification and high-resolution image generation tasks using the generative adversarial network (GAN) framework. SCN significantly improves the performance of the baseline models in all 3 tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.02924v1"
	},
	{
		"title": "An Annotation Sparsification Strategy for 3D Medical Image Segmentation via Representative Selection and Self‐Training ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dual Relation Semi‐supervised Multi‐label Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Guiding CDCL SAT Search via Random Exploration amid Conflict Depression ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Stage Self‐Supervised Learning for Graph Convolutional Networks on Graphs with Few Labeled Nodes ",
		"abstract": "Graph Convolutional Networks(GCNs) play a crucial role in graph learning tasks, however, learning graph embedding with few supervised signals is still a difficult problem. In this paper, we propose a novel training algorithm for Graph Convolutional Network, called Multi-Stage Self-Supervised(M3S) Training Algorithm, combined with self-supervised learning approach, focusing on improving the generalization performance of GCNs on graphs with few labeled nodes. Firstly, a Multi-Stage Training Framework is provided as the basis of M3S training method. Then we leverage DeepCluster technique, a popular form of self-supervised learning, and design corresponding aligning mechanism on the embedding space to refine the Multi-Stage Training Framework, resulting in M3S Training Algorithm. Finally, extensive experimental results verify the superior performance of our algorithm on graphs with few labeled nodes under different label rates compared with other state-of-the-art approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.11038v2"
	},
	{
		"title": "Exploiting Motion Information from Unlabeled Videos for Image Action Recognition ",
		"abstract": "Static image action recognition, which aims to recognize action based on a single image, usually relies on expensive human labeling effort such as adequate labeled action images and large-scale labeled image dataset. In contrast, abundant unlabeled videos can be economically obtained. Therefore, several works have explored using unlabeled videos to facilitate image action recognition, which can be categorized into the following two groups: (a) enhance visual representations of action images with a designed proxy task on unlabeled videos, which falls into the scope of self-supervised learning; (b) generate auxiliary representations for action images with the generator learned from unlabeled videos. In this paper, we integrate the above two strategies in a unified framework, which consists of Visual Representation Enhancement (VRE) module and Motion Representation Augmentation (MRA) module. Specifically, the VRE module includes a proxy task which imposes pseudo motion label constraint and temporal coherence constraint on unlabeled videos, while the MRA module could predict the motion information of a static action image by exploiting unlabeled videos. We demonstrate the superiority of our framework based on four benchmark human action datasets with limited labeled data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00308v1"
	},
	{
		"title": "Scale‐wise Convolution for Image Restoration ",
		"abstract": "While scale-invariant modeling has substantially boosted the performance of visual recognition tasks, it remains largely under-explored in deep networks based image restoration. Naively applying those scale-invariant techniques (e.g. multi-scale testing, random-scale data augmentation) to image restoration tasks usually leads to inferior performance. In this paper, we show that properly modeling scale-invariance into neural networks can bring significant benefits to image restoration performance. Inspired from spatial-wise convolution for shift-invariance, \"scale-wise convolution\" is proposed to convolve across multiple scales for scale-invariance. In our scale-wise convolutional network (SCN), we first map the input image to the feature space and then build a feature pyramid representation via bi-linear down-scaling progressively. The feature pyramid is then passed to a residual network with scale-wise convolutions. The proposed scale-wise convolution learns to dynamically activate and aggregate features from different input scales in each residual building block, in order to exploit contextual information on multiple scales. In experiments, we compare the restoration accuracy and parameter efficiency among our model and many different variants of multi-scale neural networks. The proposed network with scale-wise convolution achieves superior performance in multiple image restoration tasks including image super-resolution, image denoising and image compression artifacts removal. Code and models are available at: https://github.com/ychfan/scn_sr",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.09028v1"
	},
	{
		"title": "Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language ",
		"abstract": "We address the problem of retrieving a specific moment from an untrimmed video by a query sentence. This is a challenging problem because a target moment may take place in relations to other temporal moments in the untrimmed video. Existing methods cannot tackle this challenge well since they consider temporal moments individually and neglect the temporal dependencies. In this paper, we model the temporal relations between video moments by a two-dimensional map, where one dimension indicates the starting time of a moment and the other indicates the end time. This 2D temporal map can cover diverse video moments with different lengths, while representing their adjacent relations. Based on the 2D map, we propose a Temporal Adjacent Network (2D-TAN), a single-shot framework for moment localization. It is capable of encoding the adjacent temporal relation, while learning discriminative features for matching video moments with referring expressions. We evaluate the proposed 2D-TAN on three challenging benchmarks, i.e., Charades-STA, ActivityNet Captions, and TACoS, where our 2D-TAN outperforms the state-of-the-art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.03590v3"
	},
	{
		"title": "Look One and More: Distilling Hybrid Order Relational Knowledge for Cross‐Resolution Image Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Accurate Temporal Action Proposal Generation with Relation‐Aware Pyramid Network ",
		"abstract": "Accurate temporal action proposals play an important role in detecting actions from untrimmed videos. The existing approaches have difficulties in capturing global contextual information and simultaneously localizing actions with different durations. To this end, we propose a Relation-aware pyramid Network (RapNet) to generate highly accurate temporal action proposals. In RapNet, a novel relation-aware module is introduced to exploit bi-directional long-range relations between local features for context distilling. This embedded module enhances the RapNet in terms of its multi-granularity temporal proposal generation ability, given predefined anchor boxes. We further introduce a two-stage adjustment scheme to refine the proposal boundaries and measure their confidence in containing an action with snippet-level actionness. Extensive experiments on the challenging ActivityNet and THUMOS14 benchmarks demonstrate our RapNet generates superior accurate proposals over the existing state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.04145v1"
	},
	{
		"title": "Understanding the Disharmony between Weight Normalization Family and Weight Decay ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Pixel‐wise Deep Function‐mixture network for Spectral Super‐resolution ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Causal Transfer for Imitation Learning and Decision Making under Sensor‐shift ",
		"abstract": "Learning from demonstrations (LfD) is an efficient paradigm to train AI agents. But major issues arise when there are differences between (a) the demonstrator's own sensory input, (b) our sensors that observe the demonstrator and (c) the sensory input of the agent we train. In this paper, we propose a causal model-based framework for transfer learning under such \"sensor-shifts\", for two common LfD tasks: (1) inferring the effect of the demonstrator's actions and (2) imitation learning. First we rigorously analyze, on the population-level, to what extent the relevant underlying mechanisms (the action effects and the demonstrator policy) can be identified and transferred from the available observations together with prior knowledge of sensor characteristics. And we device an algorithm to infer these mechanisms. Then we introduce several proxy methods which are easier to calculate, estimate from finite data and interpret than the exact solutions, alongside theoretical bounds on their closeness to the exact ones. We validate our two main methods on simulated and semi-real world data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00806v1"
	},
	{
		"title": "Joint Character Embedding and Adversarial Stability Training to Defend Adversarial Text ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MemCap: Memorizing Style Knowledge for Image Captioning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Revisiting Bilinear Pooling: A Coding Perspective ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Embedded Complementary and Interactive Information for Multi‐view Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Single Camera Training for Person Re‐identification ",
		"abstract": "Person re-identification (ReID) aims at finding the same person in different cameras. Training such systems usually requires a large amount of cross-camera pedestrians to be annotated from surveillance videos, which is labor-consuming especially when the number of cameras is large. Differently, this paper investigates ReID in an unexplored single-camera-training (SCT) setting, where each person in the training set appears in only one camera. To the best of our knowledge, this setting was never studied before. SCT enjoys the advantage of low-cost data collection and annotation, and thus eases ReID systems to be trained in a brand new environment. However, it raises major challenges due to the lack of cross-camera person occurrences, which conventional approaches heavily rely on to extract discriminative features. The key to dealing with the challenges in the SCT setting lies in designing an effective mechanism to complement cross-camera annotation. We start with a regular deep network for feature extraction, upon which we propose a novel loss function named multi-camera negative loss (MCNL). This is a metric learning loss motivated by probability, suggesting that in a multi-camera system, one image is more likely to be closer to the most similar negative sample in other cameras than to the most similar negative sample in the same camera. In experiments, MCNL significantly boosts ReID accuracy in the SCT setting, which paves the way of fast deployment of ReID systems with good performance on new target scenes.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10848v1"
	},
	{
		"title": "A New Ensemble Adversarial Attack Powered by Long‐term Gradient Memories ",
		"abstract": "Deep neural networks are vulnerable to adversarial attacks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07682v1"
	},
	{
		"title": "Graph Attention Based Proposal 3D ConvNets for Action Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Image Cropping with Composition and Saliency Aware Aesthetic Score Map ",
		"abstract": "Aesthetic image cropping is a practical but challenging task which aims at finding the best crops with the highest aesthetic quality in an image. Recently, many deep learning methods have been proposed to address this problem, but they did not reveal the intrinsic mechanism of aesthetic evaluation. In this paper, we propose an interpretable image cropping model to unveil the mystery. For each image, we use a fully convolutional network to produce an aesthetic score map, which is shared among all candidate crops during crop-level aesthetic evaluation. Then, we require the aesthetic score map to be both composition-aware and saliency-aware. In particular, the same region is assigned with different aesthetic scores based on its relative positions in different crops. Moreover, a visually salient region is supposed to have more sensitive aesthetic scores so that our network can learn to place salient objects at more proper positions. Such an aesthetic score map can be used to localize aesthetically important regions in an image, which sheds light on the composition rules learned by our model. We show the competitive performance of our model in the image cropping task on several benchmark datasets, and also demonstrate its generality in real-world applications.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10492v1"
	},
	{
		"title": "Sparsity‐inducing Binarized Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FAN‐Face: a simple orthogonal improvement to deep face recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Revisiting Image Aesthetic Assessment via Self‐Supervised Feature Learning ",
		"abstract": "Visual aesthetic assessment has been an active research field for decades. Although latest methods have achieved promising performance on benchmark datasets, they typically rely on a large number of manual annotations including both aesthetic labels and related image attributes. In this paper, we revisit the problem of image aesthetic assessment from the self-supervised feature learning perspective. Our motivation is that a suitable feature representation for image aesthetic assessment should be able to distinguish different expert-designed image manipulations, which have close relationships with negative aesthetic effects. To this end, we design two novel pretext tasks to identify the types and parameters of editing operations applied to synthetic instances. The features from our pretext tasks are then adapted for a one-layer linear classifier to evaluate the performance in terms of binary aesthetic classification. We conduct extensive quantitative experiments on three benchmark datasets and demonstrate that our approach can faithfully extract aesthetics-aware features and outperform alternative pretext schemes. Moreover, we achieve comparable results to state-of-the-art supervised methods that use 10 million labels from ImageNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11419v1"
	},
	{
		"title": "Online Hashing with Efficient Updating of Binary Codes ",
		"abstract": "Online hashing methods are efficient in learning the hash functions from the streaming data. However, when the hash functions change, the binary codes for the database have to be recomputed to guarantee the retrieval accuracy. Recomputing the binary codes by accumulating the whole database brings a timeliness challenge to the online retrieval process. In this paper, we propose a novel online hashing framework to update the binary codes efficiently without accumulating the whole database. In our framework, the hash functions are fixed and the projection functions are introduced to learn online from the streaming data. Therefore, inefficient updating of the binary codes by accumulating the whole database can be transformed to efficient updating of the binary codes by projecting the binary codes into another binary space. The queries and the binary code database are projected asymmetrically to further improve the retrieval accuracy. The experiments on two multi-label image databases demonstrate the effectiveness and the efficiency of our method for multi-label image retrieval.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12125v2"
	},
	{
		"title": "Generative Adversarial Networks for Video‐to‐Video Domain Adaptation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Incremental multi‐domain learning with network latent tensor factorization ",
		"abstract": "The prominence of deep learning, large amount of annotated data and increasingly powerful hardware made it possible to reach remarkable performance for supervised classification tasks, in many cases saturating the training sets. However the resulting models are specialized to a single very specific task and domain. Adapting the learned classification to new domains is a hard problem due to at least three reasons: (1) the new domains and the tasks might be drastically different; (2) there might be very limited amount of annotated data on the new domain and (3) full training of a new model for each new task is prohibitive in terms of computation and memory, due to the sheer number of parameters of deep CNNs. In this paper, we present a method to learn new-domains and tasks incrementally, building on prior knowledge from already learned tasks and without catastrophic forgetting. We do so by jointly parametrizing weights across layers using low-rank Tucker structure. The core is task agnostic while a set of task specific factors are learnt on each new domain. We show that leveraging tensor structure enables better performance than simply using matrix operations. Joint tensor modelling also naturally leverages correlations across different layers. Compared with previous methods which have focused on adapting each layer separately, our approach results in more compact representations for each new task/domain. We apply the proposed method to the 10 datasets of the Visual Decathlon Challenge and show that our method offers on average about 7.5x reduction in number of parameters and competitive performance in terms of both classification accuracy and Decathlon score.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.06345v2"
	},
	{
		"title": "Pairwise Learning with Differential Privacy Guarantees ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Shape‐Aware Organ Segmentation by Predicting Signed Distance Maps ",
		"abstract": "In this work, we propose to resolve the issue existing in current deep learning based organ segmentation systems that they often produce results that do not capture the overall shape of the target organ and often lack smoothness. Since there is a rigorous mapping between the Signed Distance Map (SDM) calculated from object boundary contours and the binary segmentation map, we exploit the feasibility of learning the SDM directly from medical scans. By converting the segmentation task into predicting an SDM, we show that our proposed method retains superior segmentation performance and has better smoothness and continuity in shape. To leverage the complementary information in traditional segmentation training, we introduce an approximated Heaviside function to train the model by predicting SDMs and segmentation maps simultaneously. We validate our proposed models by conducting extensive experiments on a hippocampus segmentation dataset and the public MICCAI 2015 Head and Neck Auto Segmentation Challenge dataset with multiple organs. While our carefully designed backbone 3D segmentation network improves the Dice coefficient by more than 5% compared to current state-of-the-arts, the proposed model with SDM learning produces smoother segmentation results with smaller Hausdorff distance and average surface distance, thus proving the effectiveness of our method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.03849v1"
	},
	{
		"title": "Weakly Supervised Disentanglement by Pairwise Similarities ",
		"abstract": "Recently, researches related to unsupervised disentanglement learning with deep generative models have gained substantial popularity. However, without introducing supervision, there is no guarantee that the factors of interest can be successfully recovered. Motivated by a real-world problem, we propose a setting where the user introduces weak supervision by providing similarities between instances based on a factor to be disentangled. The similarity is provided as either a binary (yes/no) or a real-valued label describing whether a pair of instances are similar or not. We propose a new method for weakly supervised disentanglement of latent variables within the framework of Variational Autoencoder. Experimental results demonstrate that utilizing weak supervision improves the performance of the disentanglement method substantially.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.01044v2"
	},
	{
		"title": "Keywords‐Guided Abstractive Sentence Summarization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SPSTracker: Sub‐Peak Suppression of Response Map for Robust Object Tracking ",
		"abstract": "Modern visual trackers usually construct online learning models under the assumption that the feature response has a Gaussian distribution with target-centered peak response. Nevertheless, such an assumption is implausible when there is progressive interference from other targets and/or background noise, which produce sub-peaks on the tracking response map and cause model drift. In this paper, we propose a rectified online learning approach for sub-peak response suppression and peak response enforcement and target at handling progressive interference in a systematic way. Our approach, referred to as SPSTracker, applies simple-yet-efficient Peak Response Pooling (PRP) to aggregate and align discriminative features, as well as leveraging a Boundary Response Truncation (BRT) to reduce the variance of feature response. By fusing with multi-scale features, SPSTracker aggregates the response distribution of multiple sub-peaks to a single maximum peak, which enforces the discriminative capability of features for robust object tracking. Experiments on the OTB, NFS and VOT2018 benchmarks demonstrate that SPSTrack outperforms the state-of-the-art real-time trackers with significant margins.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00597v3"
	},
	{
		"title": "Mega‐Reward: Achieving Human‐Level Play without Extrinsic Rewards ",
		"abstract": "Intrinsic rewards were introduced to simulate how human intelligence works; they are usually evaluated by intrinsically-motivated play, i.e., playing games without extrinsic rewards but evaluated with extrinsic rewards. However, none of the existing intrinsic reward approaches can achieve human-level performance under this very challenging setting of intrinsically-motivated play. In this work, we propose a novel megalomania-driven intrinsic reward (called mega-reward), which, to our knowledge, is the first approach that achieves human-level performance in intrinsically-motivated play. Intuitively, mega-reward comes from the observation that infants' intelligence develops when they try to gain more control on entities in an environment; therefore, mega-reward aims to maximize the control capabilities of agents on given entities in a given environment. To formalize mega-reward, a relational transition model is proposed to bridge the gaps between direct and latent control. Experimental studies show that mega-reward (i) can greatly outperform all state-of-the-art intrinsic reward approaches, (ii) generally achieves the same level of performance as Ex-PPO and professional human-level scores, and (iii) has also a superior performance when it is incorporated with extrinsic rewards.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.04640v4"
	},
	{
		"title": "Knowledge Integration Networks for Action Recognition ",
		"abstract": "In this work, we propose Knowledge Integration Networks (referred as KINet) for video action recognition. KINet is capable of aggregating meaningful context features which are of great importance to identifying an action, such as human information and scene context. We design a three-branch architecture consisting of a main branch for action recognition, and two auxiliary branches for human parsing and scene recognition which allow the model to encode the knowledge of human and scene for action recognition. We explore two pre-trained models as teacher networks to distill the knowledge of human and scene for training the auxiliary tasks of KINet. Furthermore, we propose a two-level knowledge encoding mechanism which contains a Cross Branch Integration (CBI) module for encoding the auxiliary knowledge into medium-level convolutional features, and an Action Knowledge Graph (AKG) for effectively fusing high-level context information. This results in an end-to-end trainable framework where the three tasks can be trained collaboratively, allowing the model to compute strong context knowledge efficiently. The proposed KINet achieves the state-of-the-art performance on a large-scale action recognition benchmark Kinetics-400, with a top-1 accuracy of 77.8%. We further demonstrate that our KINet has strong capability by transferring the Kinetics-trained model to UCF-101, where it obtains 97.8% top-1 accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07471v1"
	},
	{
		"title": "Joint Commonsense and Relation Reasoning for Image and Video Captioning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Arena: A General Evaluation Platform and Building Toolkit for Multi‐Agent Intelligence ",
		"abstract": "Learning agents that are not only capable of taking tests, but also innovating is becoming a hot topic in AI. One of the most promising paths towards this vision is multi-agent learning, where agents act as the environment for each other, and improving each agent means proposing new problems for others. However, existing evaluation platforms are either not compatible with multi-agent settings, or limited to a specific game. That is, there is not yet a general evaluation platform for research on multi-agent intelligence. To this end, we introduce Arena, a general evaluation platform for multi-agent intelligence with 35 games of diverse logics and representations. Furthermore, multi-agent intelligence is still at the stage where many problems remain unexplored. Therefore, we provide a building toolkit for researchers to easily invent and build novel multi-agent problems from the provided game set based on a GUI-configurable social tree and five basic multi-agent reward schemes. Finally, we provide Python implementations of five state-of-the-art deep multi-agent reinforcement learning baselines. Along with the baseline implementations, we release a set of 100 best agents/teams that we can train with different training schemes for each game, as the base for evaluating agents with population performance. As such, the research community can perform comparisons under a stable and uniform standard. All the implementations and accompanied tutorials have been open-sourced for the community at https://sites.google.com/view/arena-unity/.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.08085v5"
	},
	{
		"title": "Coarse‐to‐Fine Hyper‐Prior Modeling for Learned Image Compression ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Asymptotic Risk of B\\'ezier Simplex Fitting ",
		"abstract": "The Bezier simplex fitting is a novel data modeling technique which exploits geometric structures of data to approximate the Pareto front of multi-objective optimization problems. There are two fitting methods based on different sampling strategies. The inductive skeleton fitting employs a stratified subsampling from each skeleton of a simplex, whereas the all-at-once fitting uses a non-stratified sampling which treats a simplex as a whole. In this paper, we analyze the asymptotic risks of those B\\'ezier simplex fitting methods and derive the optimal subsample ratio for the inductive skeleton fitting. It is shown that the inductive skeleton fitting with the optimal ratio has a smaller risk when the degree of a Bezier simplex is less than three. Those results are verified numerically under small to moderate sample sizes. In addition, we provide two complementary applications of our theory: a generalized location problem and a multi-objective hyper-parameter tuning of the group lasso. The former can be represented by a Bezier simplex of degree two where the inductive skeleton fitting outperforms. The latter can be represented by a Bezier simplex of degree three where the all-at-once fitting gets an advantage.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.06924v1"
	},
	{
		"title": "Posterior‐Guided Neural Architecture Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Brain‐mediated Transfer Learning of Convolutional Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Saliency‐free Model with Generic Features for Weakly‐supervised Semantic Segmentation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Multiarmed Bandit Based Incentive Mechanism for a Subset Selection of Customers for Demand Response in Smart Grids ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning End‐To‐End Scene Flow by Distilling Single Tasks Knowledge ",
		"abstract": "Scene flow is a challenging task aimed at jointly estimating the 3D structure and motion of the sensed environment. Although deep learning solutions achieve outstanding performance in terms of accuracy, these approaches divide the whole problem into standalone tasks (stereo and optical flow) addressing them with independent networks. Such a strategy dramatically increases the complexity of the training procedure and requires power-hungry GPUs to infer scene flow barely at 1 FPS. Conversely, we propose DWARF, a novel and lightweight architecture able to infer full scene flow jointly reasoning about depth and optical flow easily and elegantly trainable end-to-end from scratch. Moreover, since ground truth images for full scene flow are scarce, we propose to leverage on the knowledge learned by networks specialized in stereo or flow, for which much more data are available, to distill proxy annotations. Exhaustive experiments show that i) DWARF runs at about 10 FPS on a single high-end GPU and about 1 FPS on NVIDIA Jetson TX2 embedded at KITTI resolution, with moderate drop in accuracy compared to 10x deeper models, ii) learning from many distilled samples is more effective than from the few, annotated ones available. Code available at: https://github.com/FilippoAleotti/Dwarf-Tensorflow",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10090v1"
	},
	{
		"title": "Adversarial Domain Adaptation with Domain Mixup ",
		"abstract": "Recent works on domain adaptation reveal the effectiveness of adversarial learning on filling the discrepancy between source and target domains. However, two common limitations exist in current adversarial-learning-based methods. First, samples from two domains alone are not sufficient to ensure domain-invariance at most part of latent space. Second, the domain discriminator involved in these methods can only judge real or fake with the guidance of hard label, while it is more reasonable to use soft scores to evaluate the generated images or features, i.e., to fully utilize the inter-domain information. In this paper, we present adversarial domain adaptation with domain mixup (DM-ADA), which guarantees domain-invariance in a more continuous latent space and guides the domain discriminator in judging samples' difference relative to source and target domains. Domain mixup is jointly conducted on pixel and feature level to improve the robustness of models. Extensive experiments prove that the proposed approach can achieve superior performance on tasks with various degrees of domain shift and data complexity.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01805v1"
	},
	{
		"title": "Object Instance Mining for Weakly Supervised Object Detection ",
		"abstract": "Weakly supervised object detection (WSOD) using only image-level annotations has attracted growing attention over the past few years. Existing approaches using multiple instance learning easily fall into local optima, because such mechanism tends to learn from the most discriminative object in an image for each category. Therefore, these methods suffer from missing object instances which degrade the performance of WSOD. To address this problem, this paper introduces an end-to-end object instance mining (OIM) framework for weakly supervised object detection. OIM attempts to detect all possible object instances existing in each image by introducing information propagation on the spatial and appearance graphs, without any additional annotations. During the iterative learning process, the less discriminative object instances from the same class can be gradually detected and utilized for training. In addition, we design an object instance reweighted loss to learn larger portion of each object instance to further improve the performance. The experimental results on two publicly available databases, VOC 2007 and 2012, demonstrate the efficacy of proposed approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01087v1"
	},
	{
		"title": "Hierarchical Online Instance Matching for Person Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Camouflage Images ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Random Erasing Data Augmentation ",
		"abstract": "In this paper, we introduce Random Erasing, a new data augmentation method for training the convolutional neural network (CNN). In training, Random Erasing randomly selects a rectangle region in an image and erases its pixels with random values. In this process, training images with various levels of occlusion are generated, which reduces the risk of over-fitting and makes the model robust to occlusion. Random Erasing is parameter learning free, easy to implement, and can be integrated with most of the CNN-based recognition models. Albeit simple, Random Erasing is complementary to commonly used data augmentation techniques such as random cropping and flipping, and yields consistent improvement over strong baselines in image classification, object detection and person re-identification. Code is available at: https://github.com/zhunzhong07/Random-Erasing.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1708.04896v2"
	},
	{
		"title": "Pointwise Rotation‐invariant Network with Adaptive Sampling and 3D Spherical Voxel Convolution ",
		"abstract": "Point cloud analysis without pose priors is very challenging in real applications, as the orientations of point clouds are often unknown. In this paper, we propose a brand new point-set learning framework PRIN, namely, Pointwise Rotation-Invariant Network, focusing on rotation-invariant feature extraction in point clouds analysis. We construct spherical signals by Density Aware Adaptive Sampling to deal with distorted point distributions in spherical space. In addition, we propose Spherical Voxel Convolution and Point Re-sampling to extract rotation-invariant features for each point. Our network can be applied to tasks ranging from object classification, part segmentation, to 3D feature matching and label alignment. We show that, on the dataset with randomly rotated point clouds, PRIN demonstrates better performance than state-of-the-art methods without any data augmentation. We also provide theoretical analysis for the rotation-invariance achieved by our methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1811.09361v5"
	},
	{
		"title": "Lifted Fact‐Alternating Mutex Groups and Pruned Grounding of Classical Planning Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Lexical Simplification with Pretrained Encoders ",
		"abstract": "Lexical simplification (LS) aims to replace complex words in a given sentence with their simpler alternatives of equivalent meaning. Recently unsupervised lexical simplification approaches only rely on the complex word itself regardless of the given sentence to generate candidate substitutions, which will inevitably produce a large number of spurious candidates. We present a simple LS approach that makes use of the Bidirectional Encoder Representations from Transformers (BERT) which can consider both the given sentence and the complex word during generating candidate substitutions for the complex word. Specifically, we mask the complex word of the original sentence for feeding into the BERT to predict the masked token. The predicted results will be used as candidate substitutions. Despite being entirely unsupervised, experimental results show that our approach obtains obvious improvement compared with these baselines leveraging linguistic databases and parallel corpus, outperforming the state-of-the-art by more than 12 Accuracy points on three well-known benchmarks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.06226v5"
	},
	{
		"title": "Learning Cross‐modal Context Graph Networks for Visual Grounding ",
		"abstract": "Visual grounding is a ubiquitous building block in many vision-language tasks and yet remains challenging due to large variations in visual and linguistic features of grounding entities, strong context effect and the resulting semantic ambiguities. Prior works typically focus on learning representations of individual phrases with limited context information. To address their limitations, this paper proposes a language-guided graph representation to capture the global context of grounding entities and their relations, and develop a cross-modal graph matching strategy for the multiple-phrase visual grounding task. In particular, we introduce a modular graph neural network to compute context-aware representations of phrases and object proposals respectively via message propagation, followed by a graph-based matching module to generate globally consistent localization of grounding phrases. We train the entire graph neural network jointly in a two-stage strategy and evaluate it on the Flickr30K Entities benchmark. Extensive experiments show that our method outperforms the prior state of the arts by a sizable margin, evidencing the efficacy of our grounding framework. Code is available at \"https://github.com/youngfly11/LCMCG-PyTorch\".",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09042v2"
	},
	{
		"title": "Partner Selection for the Emergence of Cooperation in Multi‐Agent Systems using Reinforcement Learning ",
		"abstract": "Social dilemmas have been widely studied to explain how humans are able to cooperate in society. Considerable effort has been invested in designing artificial agents for social dilemmas that incorporate explicit agent motivations that are chosen to favor coordinated or cooperative responses. The prevalence of this general approach points towards the importance of achieving an understanding of both an agent's internal design and external environment dynamics that facilitate cooperative behavior. In this paper, we investigate how partner selection can promote cooperative behavior between agents who are trained to maximize a purely selfish objective function. Our experiments reveal that agents trained with this dynamic learn a strategy that retaliates against defectors while promoting cooperation with other agents resulting in a prosocial society.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.03185v4"
	},
	{
		"title": "Generative‐Discriminative Complementary Learning ",
		"abstract": "Majority of state-of-the-art deep learning methods are discriminative approaches, which model the conditional distribution of labels given inputs features. The success of such approaches heavily depends on high-quality labeled instances, which are not easy to obtain, especially as the number of candidate classes increases. In this paper, we study the complementary learning problem. Unlike ordinary labels, complementary labels are easy to obtain because an annotator only needs to provide a yes/no answer to a randomly chosen candidate class for each instance. We propose a generative-discriminative complementary learning method that estimates the ordinary labels by modeling both the conditional (discriminative) and instance (generative) distributions. Our method, we call Complementary Conditional GAN (CCGAN), improves the accuracy of predicting ordinary labels and can generate high-quality instances in spite of weak supervision. In addition to the extensive empirical studies, we also theoretically show that our model can retrieve the true conditional distribution from the complementarily-labeled data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.01612v4"
	},
	{
		"title": "An Iterative Polishing Framework based on Quality Aware Masked Language Model for Chinese Poetry Generation ",
		"abstract": "Owing to its unique literal and aesthetical characteristics, automatic generation of Chinese poetry is still challenging in Artificial Intelligence, which can hardly be straightforwardly realized by end-to-end methods. In this paper, we propose a novel iterative polishing framework for highly qualified Chinese poetry generation. In the first stage, an encoder-decoder structure is utilized to generate a poem draft. Afterwards, our proposed Quality-Aware Masked Language Model (QAMLM) is employed to polish the draft towards higher quality in terms of linguistics and literalness. Based on a multi-task learning scheme, QA-MLM is able to determine whether polishing is needed based on the poem draft. Furthermore, QAMLM is able to localize improper characters of the poem draft and substitute with newly predicted ones accordingly. Benefited from the masked language model structure, QAMLM incorporates global context information into the polishing process, which can obtain more appropriate polishing results than the unidirectional sequential decoding. Moreover, the iterative polishing process will be terminated automatically when QA-MLM regards the processed poem as a qualified one. Both human and automatic evaluation have been conducted, and the results demonstrate that our approach is effective to improve the performance of encoder-decoder structure.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.13182v1"
	},
	{
		"title": "Modeling Probabilistic Commitments for Maintenance Is Inherently Harder than for Achievement ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neural Machine Translation with Byte‐Level Subwords ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Constructing Minimal Perfect Hash Functions Using SAT Technology ",
		"abstract": "Minimal perfect hash functions (MPHFs) are used to provide efficient access to values of large dictionaries (sets of key-value pairs). Discovering new algorithms for building MPHFs is an area of active research, especially from the perspective of storage efficiency. The information-theoretic limit for MPHFs is 1/(ln 2) or roughly 1.44 bits per key. The current best practical algorithms range between 2 and 4 bits per key. In this article, we propose two SAT-based constructions of MPHFs. Our first construction yields MPHFs near the information-theoretic limit. For this construction, current state-of-the-art SAT solvers can handle instances where the dictionaries contain up to 40 elements, thereby outperforming the existing (brute-force) methods. Our second construction uses XOR-SAT filters to realize a practical approach with long-term storage of approximately 1.83 bits per key.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10099v1"
	},
	{
		"title": "A Multi‐Scale Approach for Graph Link Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "AutoDAL: Distributed Active Learning with Automatic Hyperparameter Selection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "General Partial Label Learning via Dual Bipartite Graph Autoencoder ",
		"abstract": "We formulate a practical yet challenging problem: General Partial Label Learning (GPLL). Compared to the traditional Partial Label Learning (PLL) problem, GPLL relaxes the supervision assumption from instance-level --- a label set partially labels an instance --- to group-level: 1) a label set partially labels a group of instances, where the within-group instance-label link annotations are missing, and 2) cross-group links are allowed --- instances in a group may be partially linked to the label set from another group. Such ambiguous group-level supervision is more practical in real-world scenarios as additional annotation on the instance-level is no longer required, e.g., face-naming in videos where the group consists of faces in a frame, labeled by a name set in the corresponding caption. In this paper, we propose a novel graph convolutional network (GCN) called Dual Bipartite Graph Autoencoder (DB-GAE) to tackle the label ambiguity challenge of GPLL. First, we exploit the cross-group correlations to represent the instance groups as dual bipartite graphs: within-group and cross-group, which reciprocally complements each other to resolve the linking ambiguities. Second, we design a GCN autoencoder to encode and decode them, where the decodings are considered as the refined results. It is worth noting that DB-GAE is self-supervised and transductive, as it only uses the group-level supervision without a separate offline training stage. Extensive experiments on two real-world datasets demonstrate that DB-GAE significantly outperforms the best baseline over absolute 0.159 F1-score and 24.8% accuracy. We further offer analysis on various levels of label ambiguities.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.01290v1"
	},
	{
		"title": "Multi‐Task Self‐Supervised  Learning for Disfluency Detection ",
		"abstract": "Most existing approaches to disfluency detection heavily rely on human-annotated data, which is expensive to obtain in practice. To tackle the training data bottleneck, we investigate methods for combining multiple self-supervised tasks-i.e., supervised tasks where data can be collected without manual labeling. First, we construct large-scale pseudo training data by randomly adding or deleting words from unlabeled news data, and propose two self-supervised pre-training tasks: (i) tagging task to detect the added noisy words. (ii) sentence classification to distinguish original sentences from grammatically-incorrect sentences. We then combine these two tasks to jointly train a network. The pre-trained network is then fine-tuned using human-annotated disfluency detection training data. Experimental results on the commonly used English Switchboard test set show that our approach can achieve competitive performance compared to the previous systems (trained using the full dataset) by using less than 1% (1000 sentences) of the training data. Our method trained on the full dataset significantly outperforms previous methods, reducing the error by 21% on English Switchboard.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.05378v2"
	},
	{
		"title": "Spatial‐Temporal Multi‐Cue Network for Continuous Sign Language Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adaptive Factorization Network: Learning Adaptive‐Order Feature Interactions ",
		"abstract": "Various factorization-based methods have been proposed to leverage second-order, or higher-order cross features for boosting the performance of predictive models. They generally enumerate all the cross features under a predefined maximum order, and then identify useful feature interactions through model training, which suffer from two drawbacks. First, they have to make a trade-off between the expressiveness of higher-order cross features and the computational cost, resulting in suboptimal predictions. Second, enumerating all the cross features, including irrelevant ones, may introduce noisy feature combinations that degrade model performance. In this work, we propose the Adaptive Factorization Network (AFN), a new model that learns arbitrary-order cross features adaptively from data. The core of AFN is a logarithmic transformation layer to convert the power of each feature in a feature combination into the coefficient to be learned. The experimental results on four real datasets demonstrate the superior predictive performance of AFN against the start-of-the-arts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03276v2"
	},
	{
		"title": "Divide and Conquer: Question‐Guided Spatio‐Temporal Contextual Attention for Video Question Answering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Release the power of online‐training for robust visual tracking ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RiskOracle: A Minute‐level Citywide Traffic Accident Forecasting Framework ",
		"abstract": "Real-time traffic accident forecasting is increasingly important for public safety and urban management (e.g., real-time safe route planning and emergency response deployment). Previous works on accident forecasting are often performed on hour levels, utilizing existed neural networks with static region-wise correlations taken into account. However, it is still challenging when the granularity of forecasting step improves as the highly dynamic nature of road network and inherent rareness of accident records in one training sample, which leads to biased results and zero-inflated issue. In this work, we propose a novel framework RiskOracle, to improve the prediction granularity to minute levels. Specifically, we first transform the zero-risk values in labels to fit the training network. Then, we propose the Differential Time-varying Graph neural network (DTGN) to capture the immediate changes of traffic status and dynamic inter-subregion correlations. Furthermore, we adopt multi-task and region selection schemes to highlight citywide most-likely accident subregions, bridging the gap between biased risk values and sporadic accident distribution. Extensive experiments on two real-world datasets demonstrate the effectiveness and scalability of our RiskOracle framework.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00819v1"
	},
	{
		"title": "Deep Object Co‐segmentation via Spatial‐Semantic Network Modulation ",
		"abstract": "Object co-segmentation is to segment the shared objects in multiple relevant images, which has numerous applications in computer vision. This paper presents a spatial and semantic modulated deep network framework for object co-segmentation. A backbone network is adopted to extract multi-resolution image features. With the multi-resolution features of the relevant images as input, we design a spatial modulator to learn a mask for each image. The spatial modulator captures the correlations of image feature descriptors via unsupervised learning. The learned mask can roughly localize the shared foreground object while suppressing the background. For the semantic modulator, we model it as a supervised image classification task. We propose a hierarchical second-order pooling module to transform the image features for classification use. The outputs of the two modulators manipulate the multi-resolution features by a shift-and-scale operation so that the features focus on segmenting co-object regions. The proposed model is trained end-to-end without any intricate post-processing. Extensive experiments on four image co-segmentation benchmark datasets demonstrate the superior accuracy of the proposed method compared to state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12950v1"
	},
	{
		"title": "Uncorrected least‐squares temporal difference with lambda‐return ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generating Persona Consistent Dialogues by Exploiting Natural Language Inference ",
		"abstract": "Consistency is one of the major challenges faced by dialogue agents. A human-like dialogue agent should not only respond naturally, but also maintain a consistent persona. In this paper, we exploit the advantages of natural language inference (NLI) technique to address the issue of generating persona consistent dialogues. Different from existing work that re-ranks the retrieved responses through an NLI model, we cast the task as a reinforcement learning problem and propose to exploit the NLI signals from response-persona pairs as rewards for the process of dialogue generation. Specifically, our generator employs an attention-based encoder-decoder to generate persona-based responses. Our evaluator consists of two components: an adversarially trained naturalness module and an NLI based consistency module. Moreover, we use another well-performed NLI model in the evaluation of persona-consistency. Experimental results on both human and automatic metrics, including the model-based consistency evaluation, demonstrate that the proposed approach outperforms strong generative baselines, especially in the persona-consistency of generated responses.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05889v4"
	},
	{
		"title": "Dynamic Sampling Network for Semantic Segmentation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Stochastic Online Learning with Probabilistic Graph Feedback ",
		"abstract": "We consider a problem of stochastic online learning with general probabilistic graph feedback, where each directed edge in the feedback graph has probability $p_{ij}$. Two cases are covered. (a) The one-step case, where after playing arm $i$ the learner observes a sample reward feedback of arm $j$ with independent probability $p_{ij}$. (b) The cascade case where after playing arm $i$ the learner observes feedback of all arms $j$ in a probabilistic cascade starting from $i$ -- for each $(i,j)$ with probability $p_{ij}$, if arm $i$ is played or observed, then a reward sample of arm $j$ would be observed with independent probability $p_{ij}$. Previous works mainly focus on deterministic graphs which corresponds to one-step case with $p_{ij} \\in \\{0,1\\}$, an adversarial sequence of graphs with certain topology guarantees, or a specific type of random graphs. We analyze the asymptotic lower bounds and design algorithms in both cases. The regret upper bounds of the algorithms match the lower bounds with high probability.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.01083v2"
	},
	{
		"title": "Binarized Neural Architecture Search ",
		"abstract": "Neural architecture search (NAS) can have a significant impact in computer vision by automatically designing optimal neural network architectures for various tasks. A variant, binarized neural architecture search (BNAS), with a search space of binarized convolutions, can produce extremely compressed models. Unfortunately, this area remains largely unexplored. BNAS is more challenging than NAS due to the learning inefficiency caused by optimization requirements and the huge architecture space. To address these issues, we introduce channel sampling and operation space reduction into a differentiable NAS to significantly reduce the cost of searching. This is accomplished through a performance-based strategy used to abandon less potential operations. Two optimization methods for binarized neural networks are used to validate the effectiveness of our BNAS. Extensive experiments demonstrate that the proposed BNAS achieves a performance comparable to NAS on both CIFAR and ImageNet databases. An accuracy of $96.53\\%$ vs. $97.22\\%$ is achieved on the CIFAR-10 dataset, but with a significantly compressed model, and a $40\\%$ faster search than the state-of-the-art PC-DARTS.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10862v2"
	},
	{
		"title": "Convergence of Opinion Diffusion is PSPACE‐complete ",
		"abstract": "We analyse opinion diffusion in social networks, where a finite set of individuals is connected in a directed graph and each simultaneously changes their opinion to that of the majority of their influencers. We study the algorithmic properties of the fixed-point behaviour of such networks, showing that the problem of establishing whether individuals converge to stable opinions is PSPACE-complete.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.09864v2"
	},
	{
		"title": "Towards Socially Responsible AI: Cognitive Bias‐Aware Multi‐Objective Learning  ",
		"abstract": "Human society had a long history of suffering from cognitive biases leading to social prejudices and mass injustice. The prevalent existence of cognitive biases in large volumes of historical data can pose a threat of being manifested as unethical and seemingly inhuman predictions as outputs of AI systems trained on such data. To alleviate this problem, we propose a bias-aware multi-objective learning framework that given a set of identity attributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories of the possible classes of prediction outputs, learns to reduce the frequency of predicting certain combinations of them, e.g. predicting stereotypes such as `most blacks use abusive language', or `fear is a virtue of women'. Our experiments conducted on an emotion prediction task with balanced class priors shows that a set of baseline bias-agnostic models exhibit cognitive biases with respect to gender, such as women are prone to be afraid whereas men are more prone to be angry. In contrast, our proposed bias-aware multi-objective learning methodology is shown to reduce such biases in the predictied emotions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.06618v2"
	},
	{
		"title": "Adversarial Deep Network Embedding for Cross‐network Node Classification ",
		"abstract": "In this paper, the task of cross-network node classification, which leverages the abundant labeled nodes from a source network to help classify unlabeled nodes in a target network, is studied. The existing domain adaptation algorithms generally fail to model the network structural information, and the current network embedding models mainly focus on single-network applications. Thus, both of them cannot be directly applied to solve the cross-network node classification problem. This motivates us to propose an adversarial cross-network deep network embedding (ACDNE) model to integrate adversarial domain adaptation with deep network embedding so as to learn network-invariant node representations that can also well preserve the network structural information. In ACDNE, the deep network embedding module utilizes two feature extractors to jointly preserve attributed affinity and topological proximities between nodes. In addition, a node classifier is incorporated to make node representations label-discriminative. Moreover, an adversarial domain adaptation technique is employed to make node representations network-invariant. Extensive experimental results demonstrate that the proposed ACDNE model achieves the state-of-the-art performance in cross-network node classification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07366v1"
	},
	{
		"title": "Dynamic Instance Normalization for Arbitrary Style Transfer ",
		"abstract": "Prior normalization methods rely on affine transformations to produce arbitrary image style transfers, of which the parameters are computed in a pre-defined way. Such manually-defined nature eventually results in the high-cost and shared encoders for both style and content encoding, making style transfer systems cumbersome to be deployed in resource-constrained environments like on the mobile-terminal side. In this paper, we propose a new and generalized normalization module, termed as Dynamic Instance Normalization (DIN), that allows for flexible and more efficient arbitrary style transfers. Comprising an instance normalization and a dynamic convolution, DIN encodes a style image into learnable convolution parameters, upon which the content image is stylized. Unlike conventional methods that use shared complex encoders to encode content and style, the proposed DIN introduces a sophisticated style encoder, yet comes with a compact and lightweight content encoder for fast inference. Experimental results demonstrate that the proposed approach yields very encouraging results on challenging style patterns and, to our best knowledge, for the first time enables an arbitrary style transfer using MobileNet-based lightweight architecture, leading to a reduction factor of more than twenty in computational cost as compared to existing approaches. Furthermore, the proposed DIN provides flexible support for state-of-the-art convolutional operations, and thus triggers novel functionalities, such as uniform-stroke placement for non-natural images and automatic spatial-stroke control.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06953v1"
	},
	{
		"title": "Adaptive Two‐Dimensional Embedded Image Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Rank3DGAN: Semantic mesh generation using relative attributes ",
		"abstract": "In this paper, we investigate a novel problem of using generative adversarial networks in the task of 3D shape generation according to semantic attributes. Recent works map 3D shapes into 2D parameter domain, which enables training Generative Adversarial Networks (GANs) for 3D shape generation task. We extend these architectures to the conditional setting, where we generate 3D shapes with respect to subjective attributes defined by the user. Given pairwise comparisons of 3D shapes, our model performs two tasks: it learns a generative model with a controlled latent space, and a ranking function for the 3D shapes based on their multi-chart representation in 2D. The capability of the model is demonstrated with experiments on HumanShape, Basel Face Model and reconstructed 3D CUB datasets. We also present various applications that benefit from our model, such as multi-attribute exploration, mesh editing, and mesh attribute transfer.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10257v2"
	},
	{
		"title": "Corpus wide argument mining ‐ a working solution ",
		"abstract": "One of the main tasks in argument mining is the retrieval of argumentative content pertaining to a given topic. Most previous work addressed this task by retrieving a relatively small number of relevant documents as the initial source for such content. This line of research yielded moderate success, which is of limited use in a real-world system. Furthermore, for such a system to yield a comprehensive set of relevant arguments, over a wide range of topics, it requires leveraging a large and diverse corpus in an appropriate manner. Here we present a first end-to-end high-precision, corpus-wide argument mining system. This is made possible by combining sentence-level queries over an appropriate indexing of a very large corpus of newspaper articles, with an iterative annotation scheme. This scheme addresses the inherent label bias in the data and pinpoints the regions of the sample space whose manual labeling is required to obtain high-precision among top-ranked candidates.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10763v1"
	},
	{
		"title": "Probing Brain Activation Patterns by Dissociating Semantics and Syntax in Sentences ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Temporal Context Enhanced Feature Aggregation for Video Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Message Passing Attention Networks for Document Understanding ",
		"abstract": "Graph neural networks have recently emerged as a very effective framework for processing graph-structured data. These models have achieved state-of-the-art performance in many tasks. Most graph neural networks can be described in terms of message passing, vertex update, and readout functions. In this paper, we represent documents as word co-occurrence networks and propose an application of the message passing framework to NLP, the Message Passing Attention network for Document understanding (MPAD). We also propose several hierarchical variants of MPAD. Experiments conducted on 10 standard text classification datasets show that our architectures are competitive with the state-of-the-art. Ablation studies reveal further insights about the impact of the different components on performance. Code is publicly available at: https://github.com/giannisnik/mpad .",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.06267v2"
	},
	{
		"title": "Learning to Optimize Computational Resources: Frugal Training with Generalization Guarantees ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Structured Output Learning with Conditional Generative Flows ",
		"abstract": "Traditional structured prediction models try to learn the conditional likelihood, i.e., p(y|x), to capture the relationship between the structured output y and the input features x. For many models, computing the likelihood is intractable. These models are therefore hard to train, requiring the use of surrogate objectives or variational inference to approximate likelihood. In this paper, we propose conditional Glow (c-Glow), a conditional generative flow for structured output learning. C-Glow benefits from the ability of flow-based models to compute p(y|x) exactly and efficiently. Learning with c-Glow does not require a surrogate objective or performing inference during training. Once trained, we can directly and efficiently generate conditional samples. We develop a sample-based prediction method, which can use this advantage to do efficient and effective inference. In our experiments, we test c-Glow on five different tasks. C-Glow outperforms the state-of-the-art baselines in some tasks and predicts comparable outputs in the other tasks. The results show that c-Glow is versatile and is applicable to many different structured prediction problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.13288v3"
	},
	{
		"title": "Privacy‐Preserving Gaussian Process Regression ‐ A Modular Approach to the Application of Homomorphic Encryption ",
		"abstract": "Much of machine learning relies on the use of large amounts of data to train models to make predictions. When this data comes from multiple sources, for example when evaluation of data against a machine learning model is offered as a service, there can be privacy issues and legal concerns over the sharing of data. Fully homomorphic encryption (FHE) allows data to be computed on whilst encrypted, which can provide a solution to the problem of data privacy. However, FHE is both slow and restrictive, so existing algorithms must be manipulated to make them work efficiently under the FHE paradigm. Some commonly used machine learning algorithms, such as Gaussian process regression, are poorly suited to FHE and cannot be manipulated to work both efficiently and accurately. In this paper, we show that a modular approach, which applies FHE to only the sensitive steps of a workflow that need protection, allows one party to make predictions on their data using a Gaussian process regression model built from another party's data, without either party gaining access to the other's data, in a way which is both accurate and efficient. This construction is, to our knowledge, the first example of an effectively encrypted Gaussian process.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.10893v1"
	},
	{
		"title": "On Succinct Groundings of HTN Planning Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Detecting Human‐Object Interactions via Functional Generalization ",
		"abstract": "We present an approach for detecting human-object interactions (HOIs) in images, based on the idea that humans interact with functionally similar objects in a similar manner. The proposed model is simple and efficiently uses the data, visual features of the human, relative spatial orientation of the human and the object, and the knowledge that functionally similar objects take part in similar interactions with humans. We provide extensive experimental validation for our approach and demonstrate state-of-the-art results for HOI detection. On the HICO-Det dataset our method achieves a gain of over 2.5% absolute points in mean average precision (mAP) over state-of-the-art. We also show that our approach leads to significant performance gains for zero-shot HOI detection in the seen object setting. We further demonstrate that using a generic object detector, our model can generalize to interactions involving previously unseen objects.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.03181v3"
	},
	{
		"title": "Envelope‐based Approaches to Real‐Time Heuristic Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Computing Equilibria in Binary Networked Public Goods Games ",
		"abstract": "Public goods games study the incentives of individuals to contribute to a public good and their behaviors in equilibria. In this paper, we examine a specific type of public goods game where players are networked and each has binary actions, and focus on the algorithmic aspects of such games. First, we show that checking the existence of a pure-strategy Nash equilibrium is NP-Complete. We then identify tractable instances based on restrictions of either utility functions or of the underlying graphical structure. In certain cases, we also show that we can efficiently compute a socially optimal Nash equilibrium. Finally, we propose a heuristic approach for computing approximate equilibria in general binary networked public goods games, and experimentally demonstrate its effectiveness.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05788v2"
	},
	{
		"title": "Corpus‐Level End‐to‐End Exploration for Interactive Systems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Beyond Pairwise Comparisons in Social Choice: A Setwise Kemeny Aggregation Problem ",
		"abstract": "In this paper, we advocate the use of setwise contests for aggregating a set of input rankings into an output ranking. We propose a generalization of the Kemeny rule where one minimizes the number of k-wise disagreements instead of pairwise disagreements (one counts 1 disagreement each time the top choice in a subset of alternatives of cardinality at most k differs between an input ranking and the output ranking). After an algorithmic study of this k-wise Kemeny aggregation problem, we introduce a k-wise counterpart of the majority graph. It reveals useful to divide the aggregation problem into several sub-problems. We conclude with numerical tests.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06226v1"
	},
	{
		"title": "Adversarial Learning of Privacy‐Preserving and Task‐Oriented Representations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Preventing Arbitrage From Collusion When Eliciting Probabilities ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Label Error Correction and Generation Through Label Relationships ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Clouseau: Generating Communication Protocols from Commitments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "OVL: One‐View Learning for Human Retrieval ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Expectation‐Aware Planning: A General Framework for Synthesizing and Executing Self‐Explaining Plans for Human‐AI Interaction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cycle‐CNN for Colorization towards Real Monochrome‐Color Camera Systems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Systematically exploring associations among multivariate data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CBNet:A Novel Composite Backbone Network Architecture for Object Detection ",
		"abstract": "In existing CNN based detectors, the backbone network is a very important component for basic feature extraction, and the performance of the detectors highly depends on it. In this paper, we aim to achieve better detection performance by building a more powerful backbone from existing backbones like ResNet and ResNeXt. Specifically, we propose a novel strategy for assembling multiple identical backbones by composite connections between the adjacent backbones, to form a more powerful backbone named Composite Backbone Network (CBNet). In this way, CBNet iteratively feeds the output features of the previous backbone, namely high-level features, as part of input features to the succeeding backbone, in a stage-by-stage fashion, and finally the feature maps of the last backbone (named Lead Backbone) are used for object detection. We show that CBNet can be very easily integrated into most state-of-the-art detectors and significantly improve their performances. For example, it boosts the mAP of FPN, Mask R-CNN and Cascade R-CNN on the COCO dataset by about 1.5 to 3.0 percent. Meanwhile, experimental results show that the instance segmentation results can also be improved. Specially, by simply integrating the proposed CBNet into the baseline detector Cascade Mask R-CNN, we achieve a new state-of-the-art result on COCO dataset (mAP of 53.3) with single model, which demonstrates great effectiveness of the proposed CBNet architecture. Code will be made available on https://github.com/PKUbahuangliuhe/CBNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03625v1"
	},
	{
		"title": "Leveraging Multi‐token Entities in Document‐level Named Entity Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Task Driven Feature Models for Thermal Infrared Tracking ",
		"abstract": "Existing deep Thermal InfraRed (TIR) trackers usually use the feature models of RGB trackers for representation. However, these feature models learned on RGB images are neither effective in representing TIR objects nor taking fine-grained TIR information into consideration. To this end, we develop a multi-task framework to learn the TIR-specific discriminative features and fine-grained correlation features for TIR tracking. Specifically, we first use an auxiliary classification network to guide the generation of TIR-specific discriminative features for distinguishing the TIR objects belonging to different classes. Second, we design a fine-grained aware module to capture more subtle information for distinguishing the TIR objects belonging to the same class. These two kinds of features complement each other and recognize TIR objects in the levels of inter-class and intra-class respectively. These two feature models are learned using a multi-task matching framework and are jointly optimized on the TIR tracking task. In addition, we develop a large-scale TIR training dataset to train the network for adapting the model to the TIR domain. Extensive experimental results on three benchmarks show that the proposed algorithm achieves a relative gain of 10% over the baseline and performs favorably against the state-of-the-art methods. Codes and the proposed TIR dataset are available at {https://github.com/QiaoLiuHit/MMNet}.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11384v1"
	},
	{
		"title": "Improving Domain‐Adapted Sentiment Classification by Deep Adversarial Mutual Learning ",
		"abstract": "Domain-adapted sentiment classification refers to training on a labeled source domain to well infer document-level sentiment on an unlabeled target domain. Most existing relevant models involve a feature extractor and a sentiment classifier, where the feature extractor works towards learning domain-invariant features from both domains, and the sentiment classifier is trained only on the source domain to guide the feature extractor. As such, they lack a mechanism to use sentiment polarity lying in the target domain. To improve domain-adapted sentiment classification by learning sentiment from the target domain as well, we devise a novel deep adversarial mutual learning approach involving two groups of feature extractors, domain discriminators, sentiment classifiers, and label probers. The domain discriminators enable the feature extractors to obtain domain-invariant features. Meanwhile, the label prober in each group explores document sentiment polarity of the target domain through the sentiment prediction generated by the classifier in the peer group, and guides the learning of the feature extractor in its own group. The proposed approach achieves the mutual learning of the two groups in an end-to-end manner. Experiments on multiple public datasets indicate our method obtains the state-of-the-art performance, validating the effectiveness of mutual learning through label probers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.00119v1"
	},
	{
		"title": "Generate, Segment and Refine: Towards Generic Manipulation Segmentation ",
		"abstract": "Detecting manipulated images has become a significant emerging challenge. The advent of image sharing platforms and the easy availability of advanced photo editing software have resulted in a large quantities of manipulated images being shared on the internet. While the intent behind such manipulations varies widely, concerns on the spread of fake news and misinformation is growing. Current state of the art methods for detecting these manipulated images suffers from the lack of training data due to the laborious labeling process. We address this problem in this paper, for which we introduce a manipulated image generation process that creates true positives using currently available datasets. Drawing from traditional work on image blending, we propose a novel generator for creating such examples. In addition, we also propose to further create examples that force the algorithm to focus on boundary artifacts during training. Strong experimental results validate our proposal.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1811.09729v3"
	},
	{
		"title": "Unsupervised Nonlinear Feature Selection from High‐dimensional Signed Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Ghost‐free Shadow Removal via Dual Hierarchical Aggregation Network and Shadow Matting GAN  ",
		"abstract": "Shadow removal is an essential task for scene understanding. Many studies consider only matching the image contents, which often causes two types of ghosts: color in-consistencies in shadow regions or artifacts on shadow boundaries. In this paper, we tackle these issues in two ways. First, to carefully learn the border artifacts-free image, we propose a novel network structure named the dual hierarchically aggregation network~(DHAN). It contains a series of growth dilated convolutions as the backbone without any down-samplings, and we hierarchically aggregate multi-context features for attention and prediction, respectively. Second, we argue that training on a limited dataset restricts the textural understanding of the network, which leads to the shadow region color in-consistencies. Currently, the largest dataset contains 2k+ shadow/shadow-free image pairs. However, it has only 0.1k+ unique scenes since many samples share exactly the same background with different shadow positions. Thus, we design a shadow matting generative adversarial network~(SMGAN) to synthesize realistic shadow mattings from a given shadow mask and shadow-free image. With the help of novel masks or scenes, we enhance the current datasets using synthesized shadow images. Experiments show that our DHAN can erase the shadows and produce high-quality ghost-free images. After training on the synthesized and real datasets, our network outperforms other state-of-the-art methods by a large margin. The code is available: http://github.com/vinthony/ghost-free-shadow-removal/",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08718v2"
	},
	{
		"title": "Topic Enhanced Sentiment Spreading Model in Social Networks Considering User Interest ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Point Semantic Representation for Intent Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GBCNs: Genetic Binary Convolutional Networks for Enhancing the Performance of 1‐bit DCNNs ",
		"abstract": "Training 1-bit deep convolutional neural networks (DCNNs) is one of the most challenging problems in computer vision, because it is much easier to get trapped into local minima than conventional DCNNs. The reason lies in that the binarized kernels and activations of 1-bit DCNNs cause a significant accuracy loss and training inefficiency. To address this problem, we propose Genetic Binary Convolutional Networks (GBCNs) to optimize 1-bit DCNNs, by introducing a new balanced Genetic Algorithm (BGA) to improve the representational ability in an end-to-end framework. The BGA method is proposed to modify the binary process of GBCNs to alleviate the local minima problem, which can significantly improve the performance of 1-bit DCNNs. We develop a new BGA module that is generic and flexible, and can be easily incorporated into existing DCNNs, such asWideResNets and ResNets. Extensive experiments on the object classification tasks (CIFAR, ImageNet) validate the effectiveness of the proposed method. To highlight, our method shows strong generalization on the object recognition task, i.e., face recognition, facial and person re-identification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11634v2"
	},
	{
		"title": "Reinforcing Neural Network Stability with Attractor Dynamics ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Scalable methods for computing state similarity in deterministic Markov Decision Processes ",
		"abstract": "We present new algorithms for computing and approximating bisimulation metrics in Markov Decision Processes (MDPs). Bisimulation metrics are an elegant formalism that capture behavioral equivalence between states and provide strong theoretical guarantees on differences in optimal behaviour. Unfortunately, their computation is expensive and requires a tabular representation of the states, which has thus far rendered them impractical for large problems. In this paper we present a new version of the metric that is tied to a behavior policy in an MDP, along with an analysis of its theoretical properties. We then present two new algorithms for approximating bisimulation metrics in large, deterministic MDPs. The first does so via sampling and is guaranteed to converge to the true metric. The second is a differentiable loss which allows us to learn an approximation even for continuous state MDPs, which prior to this work had not been possible.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09291v1"
	},
	{
		"title": "Peeking Behind the Ordinal Curtain: Improving Distortion via Cardinal Queries ",
		"abstract": "Aggregating the preferences of individuals into a collective decision is the core subject of study of social choice theory. In 2006, Procaccia and Rosenschein considered a utilitarian social choice setting, where the agents have explicit numerical values for the alternatives, yet they only report their linear orderings over them. To compare different aggregation mechanisms, Procaccia and Rosenschein introduced the notion of distortion, which quantifies the inefficiency of using only ordinal information when trying to maximize the social welfare, i.e., the sum of the underlying values of the agents for the chosen outcome. Since then, this research area has flourished and bounds on the distortion have been obtained for a wide variety of fundamental scenarios. However, the vast majority of the existing literature is focused on the case where nothing is known beyond the ordinal preferences of the agents over the alternatives. In this paper, we take a more expressive approach, and consider mechanisms that are allowed to further ask a few cardinal queries in order to gain partial access to the underlying values that the agents have for the alternatives. With this extra power, we design new deterministic mechanisms that achieve significantly improved distortion bounds and, in many cases, outperform the best-known randomized ordinal mechanisms. We paint an almost complete picture of the number of queries required by deterministic mechanisms to achieve specific distortion bounds.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.08165v3"
	},
	{
		"title": "Intention Nets: Psychology‐inspired User Choice Behavior Modeling for Next‐basket Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "AutoRemover: Automatic Object Removal for Autonomous Driving Videos ",
		"abstract": "Motivated by the need for photo-realistic simulation in autonomous driving, in this paper we present a video inpainting algorithm \\emph{AutoRemover}, designed specifically for generating street-view videos without any moving objects. In our setup we have two challenges: the first is the shadow, shadows are usually unlabeled but tightly coupled with the moving objects. The second is the large ego-motion in the videos. To deal with shadows, we build up an autonomous driving shadow dataset and design a deep neural network to detect shadows automatically. To deal with large ego-motion, we take advantage of the multi-source data, in particular the 3D data, in autonomous driving. More specifically, the geometric relationship between frames is incorporated into an inpainting deep neural network to produce high-quality structurally consistent video output. Experiments show that our method outperforms other state-of-the-art (SOTA) object removal algorithms, reducing the RMSE by over $19\\%$.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12588v1"
	},
	{
		"title": "Training Decision Trees as Replacement for Convolution Layers ",
		"abstract": "We present an alternative layer to convolution layers in convolutional neural networks (CNNs). Our approach reduces the complexity of convolutions by replacing it with binary decisions. Those binary decisions are used as indexes to conditional distributions where each weight represents a leaf in a decision tree. This means that only the indices to the weights need to be determined once, thus reducing the complexity of convolutions by the depth of the output tensor. Index computation is performed by simple binary decisions that require fewer cycles compared to conventionally used multiplications. In addition, we show how convolutions can be replaced by binary decisions. These binary decisions form indices in the conditional distributions and we show how they are used to replace 2D weight matrices as well as 3D weight tensors. These new layers can be trained like convolution layers in CNNs based on the backpropagation algorithm, for which we provide a formalization.   Our results on multiple publicly available data sets show that our approach performs similar to conventional neuronal networks. Beyond the formalized reduction of complexity and the improved qualitative performance, we show the runtime improvement empirically compared to convolution layers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10073v4"
	},
	{
		"title": "Importance‐Aware Semantic Segmentation in Self‐Driving with Discrete Wasserstein Training ",
		"abstract": "Semantic segmentation (SS) is an important perception manner for self-driving cars and robotics, which classifies each pixel into a pre-determined class. The widely-used cross entropy (CE) loss-based deep networks has achieved significant progress w.r.t. the mean Intersection-over Union (mIoU). However, the cross entropy loss can not take the different importance of each class in an self-driving system into account. For example, pedestrians in the image should be much more important than the surrounding buildings when make a decisions in the driving, so their segmentation results are expected to be as accurate as possible. In this paper, we propose to incorporate the importance-aware inter-class correlation in a Wasserstein training framework by configuring its ground distance matrix. The ground distance matrix can be pre-defined following a priori in a specific task, and the previous importance-ignored methods can be the particular cases. From an optimization perspective, we also extend our ground metric to a linear, convex or concave increasing function $w.r.t.$ pre-defined ground distance. We evaluate our method on CamVid and Cityscapes datasets with different backbones (SegNet, ENet, FCN and Deeplab) in a plug and play fashion. In our extenssive experiments, Wasserstein loss demonstrates superior segmentation performance on the predefined critical classes for safe-driving.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2010.12440v1"
	},
	{
		"title": "Adaptive Cross‐modal Embeddings for Image‐Text Alignment ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An ADMM Based Framework for AutoML Pipeline Configuration ",
		"abstract": "We study the AutoML problem of automatically configuring machine learning pipelines by jointly selecting algorithms and their appropriate hyper-parameters for all steps in supervised learning pipelines. This black-box (gradient-free) optimization with mixed integer & continuous variables is a challenging problem. We propose a novel AutoML scheme by leveraging the alternating direction method of multipliers (ADMM). The proposed framework is able to (i) decompose the optimization problem into easier sub-problems that have a reduced number of variables and circumvent the challenge of mixed variable categories, and (ii) incorporate black-box constraints along-side the black-box optimization objective. We empirically evaluate the flexibility (in utilizing existing AutoML techniques), effectiveness (against open source AutoML toolkits),and unique capability (of executing AutoML with practically motivated black-box constraints) of our proposed scheme on a collection of binary classification data sets from UCI ML& OpenML repositories. We observe that on an average our framework provides significant gains in comparison to other AutoML frameworks (Auto-sklearn & TPOT), highlighting the practical advantages of this framework.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.00424v5"
	},
	{
		"title": "Less Is Better: Unweighted Data Subsampling via Influence Function ",
		"abstract": "In the time of Big Data, training complex models on large-scale data sets is challenging, making it appealing to reduce data volume for saving computation resources by subsampling. Most previous works in subsampling are weighted methods designed to help the performance of subset-model approach the full-set-model, hence the weighted methods have no chance to acquire a subset-model that is better than the full-set-model. However, we question that how can we achieve better model with less data? In this work, we propose a novel Unweighted Influence Data Subsampling (UIDS) method, and prove that the subset-model acquired through our method can outperform the full-set-model. Besides, we show that overly confident on a given test set for sampling is common in Influence-based subsampling methods, which can eventually cause our subset-model's failure in out-of-sample test. To mitigate it, we develop a probabilistic sampling scheme to control the worst-case risk over all distributions close to the empirical distribution. The experiment results demonstrate our methods superiority over existed subsampling methods in diverse tasks, such as text classification, image classification, click-through prediction, etc.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01321v3"
	},
	{
		"title": "Price of Fairness in Budget Division and Probabilistic Social Choice ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Random Fourier Features via Fast Surrogate Leverage Weighted Sampling ",
		"abstract": "In this paper, we propose a fast surrogate leverage weighted sampling strategy to generate refined random Fourier features for kernel approximation. Compared to the current state-of-the-art method that uses the leverage weighted scheme [Li-ICML2019], our new strategy is simpler and more effective. It uses kernel alignment to guide the sampling process and it can avoid the matrix inversion operator when we compute the leverage function. Given n observations and s random features, our strategy can reduce the time complexity from O(ns^2+s^3) to O(ns^2), while achieving comparable (or even slightly better) prediction performance when applied to kernel ridge regression (KRR). In addition, we provide theoretical guarantees on the generalization performance of our approach, and in particular characterize the number of random features required to achieve statistical guarantees in KRR. Experiments on several benchmark datasets demonstrate that our algorithm achieves comparable prediction performance and takes less time cost when compared to [Li-ICML2019].",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09158v1"
	},
	{
		"title": "Hyperbolic Interaction Model for Hierarchical Multi‐Label Classification ",
		"abstract": "Different from the traditional classification tasks which assume mutual exclusion of labels, hierarchical multi-label classification (HMLC) aims to assign multiple labels to every instance with the labels organized under hierarchical relations. Besides the labels, since linguistic ontologies are intrinsic hierarchies, the conceptual relations between words can also form hierarchical structures. Thus it can be a challenge to learn mappings from word hierarchies to label hierarchies. We propose to model the word and label hierarchies by embedding them jointly in the hyperbolic space. The main reason is that the tree-likeness of the hyperbolic space matches the complexity of symbolic data with hierarchical structures. A new Hyperbolic Interaction Model (HyperIM) is designed to learn the label-aware document representations and make predictions for HMLC. Extensive experiments are conducted on three benchmark datasets. The results have demonstrated that the new model can realistically capture the complex data structures and further improve the performance for HMLC comparing with the state-of-the-art methods. To facilitate future research, our code is publicly available.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10802v2"
	},
	{
		"title": "Projective Quadratic Regression for Online Learning ",
		"abstract": "This paper considers online convex optimization (OCO) problems - the paramount framework for online learning algorithm design. The loss function of learning task in OCO setting is based on streaming data so that OCO is a powerful tool to model large scale applications such as online recommender systems. Meanwhile, real-world data are usually of extreme high-dimensional due to modern feature engineering techniques so that the quadratic regression is impractical. Factorization Machine as well as its variants are efficient models for capturing feature interactions with low-rank matrix model but they can't fulfill the OCO setting due to their non-convexity. In this paper, We propose a projective quadratic regression (PQR) model. First, it can capture the import second-order feature information. Second, it is a convex model, so the requirements of OCO are fulfilled and the global optimal solution can be achieved. Moreover, existing modern online optimization methods such as Online Gradient Descent (OGD) or Follow-The-Regularized-Leader (FTRL) can be applied directly. In addition, by choosing a proper hyper-parameter, we show that it has the same order of space and time complexity as the linear model and thus can handle high-dimensional data. Experimental results demonstrate the performance of the proposed PQR model in terms of accuracy and efficiency by comparing with the state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10658v1"
	},
	{
		"title": "Object‐Guided Instance Segmentation for Biological Images ",
		"abstract": "Instance segmentation of biological images is essential for studying object behaviors and properties. The challenges, such as clustering, occlusion, and adhesion problems of the objects, make instance segmentation a non-trivial task. Current box-free instance segmentation methods typically rely on local pixel-level information. Due to a lack of global object view, these methods are prone to over- or under-segmentation. On the contrary, the box-based instance segmentation methods incorporate object detection into the segmentation, performing better in identifying the individual instances. In this paper, we propose a new box-based instance segmentation method. Mainly, we locate the object bounding boxes from their center points. The object features are subsequently reused in the segmentation branch as a guide to separate the clustered instances within an RoI patch. Along with the instance normalization, the model is able to recover the target object distribution and suppress the distribution of neighboring attached objects. Consequently, the proposed model performs excellently in segmenting the clustered objects while retaining the target object details. The proposed method achieves state-of-the-art performances on three biological datasets: cell nuclei, plant phenotyping dataset, and neural cells.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09199v1"
	},
	{
		"title": "Associative Variational Auto‐encoder with Distributed Latent Spaces and Associators ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ABSent: Cross‐Lingual Sentence Representation Mapping with Bidirectional GANs ",
		"abstract": "A number of cross-lingual transfer learning approaches based on neural networks have been proposed for the case when large amounts of parallel text are at our disposal. However, in many real-world settings, the size of parallel annotated training data is restricted. Additionally, prior cross-lingual mapping research has mainly focused on the word level. This raises the question of whether such techniques can also be applied to effortlessly obtain cross-lingually aligned sentence representations. To this end, we propose an Adversarial Bi-directional Sentence Embedding Mapping (ABSent) framework, which learns mappings of cross-lingual sentence representations from limited quantities of parallel data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.11121v1"
	},
	{
		"title": "Particle Filter Recurrent Neural Networks ",
		"abstract": "Recurrent neural networks (RNNs) have been extraordinarily successful for prediction with sequential data. To tackle highly variable and noisy real-world data, we introduce Particle Filter Recurrent Neural Networks (PF-RNNs), a new RNN family that explicitly models uncertainty in its internal structure: while an RNN relies on a long, deterministic latent state vector, a PF-RNN maintains a latent state distribution, approximated as a set of particles. For effective learning, we provide a fully differentiable particle filter algorithm that updates the PF-RNN latent state distribution according to the Bayes rule. Experiments demonstrate that the proposed PF-RNNs outperform the corresponding standard gated RNNs on a synthetic robot localization dataset and 10 real-world sequence prediction datasets for text classification, stock price prediction, etc.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.12885v2"
	},
	{
		"title": "Joint Modeling of Local and Global Temporal Dynamics for Multivariate Time Series Forecasting with Missing Values ",
		"abstract": "Multivariate time series (MTS) forecasting is widely used in various domains, such as meteorology and traffic. Due to limitations on data collection, transmission, and storage, real-world MTS data usually contains missing values, making it infeasible to apply existing MTS forecasting models such as linear regression and recurrent neural networks. Though many efforts have been devoted to this problem, most of them solely rely on local dependencies for imputing missing values, which ignores global temporal dynamics. Local dependencies/patterns would become less useful when the missing ratio is high, or the data have consecutive missing values; while exploring global patterns can alleviate such problems. Thus, jointly modeling local and global temporal dynamics is very promising for MTS forecasting with missing values. However, work in this direction is rather limited. Therefore, we study a novel problem of MTS forecasting with missing values by jointly exploring local and global temporal dynamics. We propose a new framework LGnet, which leverages memory network to explore global patterns given estimations from local perspectives. We further introduce adversarial training to enhance the modeling of global temporal distribution. Experimental results on real-world datasets show the effectiveness of LGnet for MTS forecasting with missing values and its robustness under various missing ratios.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10273v1"
	},
	{
		"title": "Cross‐Modality Paired‐Images Generation for RGB‐Infrared Person Re‐Identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Zero‐Shot Sketch‐based Image Retrieval via Graph Convolution Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Morphing and Sampling Network for Dense Point Cloud Completion ",
		"abstract": "3D point cloud completion, the task of inferring the complete geometric shape from a partial point cloud, has been attracting attention in the community. For acquiring high-fidelity dense point clouds and avoiding uneven distribution, blurred details, or structural loss of existing methods' results, we propose a novel approach to complete the partial point cloud in two stages. Specifically, in the first stage, the approach predicts a complete but coarse-grained point cloud with a collection of parametric surface elements. Then, in the second stage, it merges the coarse-grained prediction with the input point cloud by a novel sampling algorithm. Our method utilizes a joint loss function to guide the distribution of the points. Extensive experiments verify the effectiveness of our method and demonstrate that it outperforms the existing methods in both the Earth Mover's Distance (EMD) and the Chamfer Distance (CD).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00280v1"
	},
	{
		"title": "Person Tube Retrieval via Language Description ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SG‐Net: Syntax‐Guided Machine Reading Comprehension ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Semantics‐aware BERT for Language Understanding ",
		"abstract": "The latest work on language representations carefully integrates contextualized features into language model training, which enables a series of success especially in various machine reading comprehension and natural language inference tasks. However, the existing language representation models including ELMo, GPT and BERT only exploit plain context-sensitive features such as character or word embeddings. They rarely consider incorporating structured semantic information which can provide rich semantics for language representation. To promote natural language understanding, we propose to incorporate explicit contextual semantics from pre-trained semantic role labeling, and introduce an improved language representation model, Semantics-aware BERT (SemBERT), which is capable of explicitly absorbing contextual semantics over a BERT backbone. SemBERT keeps the convenient usability of its BERT precursor in a light fine-tuning way without substantial task-specific modifications. Compared with BERT, semantics-aware BERT is as simple in concept but more powerful. It obtains new state-of-the-art or substantially improves results on ten reading comprehension and language inference tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02209v3"
	},
	{
		"title": "Light Multi‐segment Activation for Model Compression ",
		"abstract": "Model compression has become necessary when applying neural networks (NN) into many real application tasks that can accept slightly-reduced model accuracy with strict tolerance to model complexity. Recently, Knowledge Distillation, which distills the knowledge from well-trained and highly complex teacher model into a compact student model, has been widely used for model compression. However, under the strict requirement on the resource cost, it is quite challenging to achieve comparable performance with the teacher model, essentially due to the drastically-reduced expressiveness ability of the compact student model. Inspired by the nature of the expressiveness ability in Neural Networks, we propose to use multi-segment activation, which can significantly improve the expressiveness ability with very little cost, in the compact student model. Specifically, we propose a highly efficient multi-segment activation, called Light Multi-segment Activation (LMA), which can rapidly produce multiple linear regions with very few parameters by leveraging the statistical information. With using LMA, the compact student model is capable of achieving much better performance effectively and efficiently, than the ReLU-equipped one with same model scale. Furthermore, the proposed method is compatible with other model compression techniques, such as quantization, which means they can be used jointly for better compression performance. Experiments on state-of-the-art NN architectures over the real-world tasks demonstrate the effectiveness and extensibility of the LMA.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.06870v2"
	},
	{
		"title": "Overcoming Catastrophic Forgetting by Neuron‐level Plasticity Control ",
		"abstract": "To address the issue of catastrophic forgetting in neural networks, we propose a novel, simple, and effective solution called neuron-level plasticity control (NPC). While learning a new task, the proposed method preserves the knowledge for the previous tasks by controlling the plasticity of the network at the neuron level. NPC estimates the importance value of each neuron and consolidates important \\textit{neurons} by applying lower learning rates, rather than restricting individual connection weights to stay close to certain values. The experimental results on the incremental MNIST (iMNIST) and incremental CIFAR100 (iCIFAR100) datasets show that neuron-level consolidation is substantially more effective compared to the connection-level consolidation approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.13322v1"
	},
	{
		"title": "Cross‐Modality Attention with Semantic Graph Embedding for Multi‐Label Classification ",
		"abstract": "Multi-label image and video classification are fundamental yet challenging tasks in computer vision. The main challenges lie in capturing spatial or temporal dependencies between labels and discovering the locations of discriminative features for each class. In order to overcome these challenges, we propose to use cross-modality attention with semantic graph embedding for multi label classification. Based on the constructed label graph, we propose an adjacency-based similarity graph embedding method to learn semantic label embeddings, which explicitly exploit label relationships. Then our novel cross-modality attention maps are generated with the guidance of learned label embeddings. Experiments on two multi-label image classification datasets (MS-COCO and NUS-WIDE) show our method outperforms other existing state-of-the-arts. In addition, we validate our method on a large multi-label video classification dataset (YouTube-8M Segments) and the evaluation results demonstrate the generalization capability of our method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07872v2"
	},
	{
		"title": "Weakly‐Supervised Video Moment Retrieval via Semantic Completion Network ",
		"abstract": "Video moment retrieval is to search the moment that is most relevant to the given natural language query. Existing methods are mostly trained in a fully-supervised setting, which requires the full annotations of temporal boundary for each query. However, manually labeling the annotations is actually time-consuming and expensive. In this paper, we propose a novel weakly-supervised moment retrieval framework requiring only coarse video-level annotations for training. Specifically, we devise a proposal generation module that aggregates the context information to generate and score all candidate proposals in one single pass. We then devise an algorithm that considers both exploitation and exploration to select top-K proposals. Next, we build a semantic completion module to measure the semantic similarity between the selected proposals and query, compute reward and provide feedbacks to the proposal generation module for scoring refinement. Experiments on the ActivityCaptions and Charades-STA demonstrate the effectiveness of our proposed method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08199v3"
	},
	{
		"title": "Parsing as Pretraining ",
		"abstract": "Recent analyses suggest that encoders pretrained for language modeling capture certain morpho-syntactic structure. However, probing frameworks for word vectors still do not report results on standard setups such as constituent and dependency parsing. This paper addresses this problem and does full parsing (on English) relying only on pretraining architectures -- and no decoding. We first cast constituent and dependency parsing as sequence tagging. We then use a single feed-forward layer to directly map word vectors to labels that encode a linearized tree. This is used to: (i) see how far we can reach on syntax modelling with just pretrained encoders, and (ii) shed some light about the syntax-sensitivity of different word vectors (by freezing the weights of the pretraining network during training). For evaluation, we use bracketing F1-score and LAS, and analyze in-depth differences across representations for span lengths and dependency displacements. The overall results surpass existing sequence tagging parsers on the PTB (93.5%) and end-to-end EN-EWT UD (78.8%).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01685v1"
	},
	{
		"title": "Weakly‐Supervised Opinion Summarization by Leveraging External Information ",
		"abstract": "Opinion summarization from online product reviews is a challenging task, which involves identifying opinions related to various aspects of the product being reviewed. While previous works require additional human effort to identify relevant aspects, we instead apply domain knowledge from external sources to automatically achieve the same goal. This work proposes AspMem, a generative method that contains an array of memory cells to store aspect-related knowledge. This explicit memory can help obtain a better opinion representation and infer the aspect information more precisely. We evaluate this method on both aspect identification and opinion summarization tasks. Our experiments show that AspMem outperforms the state-of-the-art methods even though, unlike the baselines, it does not rely on human supervision which is carefully handcrafted for the given tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09844v1"
	},
	{
		"title": "From Few to More: Large‐scale Dynamic Multiagent Curriculum Learning ",
		"abstract": "A lot of efforts have been devoted to investigating how agents can learn effectively and achieve coordination in multiagent systems. However, it is still challenging in large-scale multiagent settings due to the complex dynamics between the environment and agents and the explosion of state-action space. In this paper, we design a novel Dynamic Multiagent Curriculum Learning (DyMA-CL) to solve large-scale problems by starting from learning on a multiagent scenario with a small size and progressively increasing the number of agents. We propose three transfer mechanisms across curricula to accelerate the learning process. Moreover, due to the fact that the state dimension varies across curricula,, and existing network structures cannot be applied in such a transfer setting since their network input sizes are fixed. Therefore, we design a novel network structure called Dynamic Agent-number Network (DyAN) to handle the dynamic size of the network input. Experimental results show that DyMA-CL using DyAN greatly improves the performance of large-scale multiagent learning compared with state-of-the-art deep reinforcement learning approaches. We also investigate the influence of three transfer mechanisms across curricula through extensive simulations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02790v2"
	},
	{
		"title": "On the Discrepancy between the Theoretical Analysis and Practical Implementations of Compressed Communication for Distributed Deep Learning ",
		"abstract": "Compressed communication, in the form of sparsification or quantization of stochastic gradients, is employed to reduce communication costs in distributed data-parallel training of deep neural networks. However, there exists a discrepancy between theory and practice: while theoretical analysis of most existing compression methods assumes compression is applied to the gradients of the entire model, many practical implementations operate individually on the gradients of each layer of the model. In this paper, we prove that layer-wise compression is, in theory, better, because the convergence rate is upper bounded by that of entire-model compression for a wide range of biased and unbiased compression methods. However, despite the theoretical bound, our experimental study of six well-known methods shows that convergence, in practice, may or may not be better, depending on the actual trained model and compression ratio. Our findings suggest that it would be advantageous for deep learning frameworks to include support for both layer-wise and entire-model compression.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08250v1"
	},
	{
		"title": "Attention‐over‐Attention Field‐aware Factorization Machine ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RefNet: A Reference‐aware Network for Background Based Conversation ",
		"abstract": "Existing conversational systems tend to generate generic responses. Recently, Background Based Conversations (BBCs) have been introduced to address this issue. Here, the generated responses are grounded in some background information. The proposed methods for BBCs are able to generate more informative responses, they either cannot generate natural responses or have difficulty in locating the right background information. In this paper, we propose a Reference-aware Network (RefNet) to address the two issues. Unlike existing methods that generate responses token by token, RefNet incorporates a novel reference decoder that provides an alternative way to learn to directly cite a semantic unit (e.g., a span containing complete semantic information) from the background. Experimental results show that RefNet significantly outperforms state-of-the-art methods in terms of both automatic and human evaluations, indicating that RefNet can generate more appropriate and human-like responses.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.06449v2"
	},
	{
		"title": "Discontinuous Constituent Parsing with Pointer Networks ",
		"abstract": "One of the most complex syntactic representations used in computational linguistics and NLP are discontinuous constituent trees, crucial for representing all grammatical phenomena of languages such as German. Recent advances in dependency parsing have shown that Pointer Networks excel in efficiently parsing syntactic relations between words in a sentence. This kind of sequence-to-sequence models achieve outstanding accuracies in building non-projective dependency trees, but its potential has not been proved yet on a more difficult task. We propose a novel neural network architecture that, by means of Pointer Networks, is able to generate the most accurate discontinuous constituent representations to date, even without the need of Part-of-Speech tagging information. To do so, we internally model discontinuous constituent structures as augmented non-projective dependency structures. The proposed approach achieves state-of-the-art results on the two widely-used NEGRA and TIGER benchmarks, outperforming previous work by a wide margin.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01824v1"
	},
	{
		"title": "POP ≡ POCL, right? ‐‐‐ Complexity Results for Partial Order (Causal Link) Makespan Minimization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "High Tissue Contrast MRI Synthesis Using Multi‐Stage Attention‐GAN for Glioma Segmentation ",
		"abstract": "Magnetic resonance imaging (MRI) provides varying tissue contrast images of internal organs based on a strong magnetic field. Despite the non-invasive advantage of MRI in frequent imaging, the low contrast MR images in the target area make tissue segmentation a challenging problem. This paper demonstrates the potential benefits of image-to-image translation techniques to generate synthetic high tissue contrast (HTC) images. Notably, we adopt a new cycle generative adversarial network (CycleGAN) with an attention mechanism to increase the contrast within underlying tissues. The attention block, as well as training on HTC images, guides our model to converge on certain tissues. To increase the resolution of HTC images, we employ multi-stage architecture to focus on one particular tissue as a foreground and filter out the irrelevant background in each stage. This multi-stage structure also alleviates the common artifacts of the synthetic images by decreasing the gap between source and target domains. We show the application of our method for synthesizing HTC images on brain MR scans, including glioma tumor. We also employ HTC MR images in both the end-to-end and two-stage segmentation structure to confirm the effectiveness of these images. The experiments over three competitive segmentation baselines on BraTS 2018 dataset indicate that incorporating the synthetic HTC images in the multi-modal segmentation framework improves the average Dice scores 0.8%, 0.6%, and 0.5% on the whole tumor, tumor core, and enhancing tumor, respectively, while eliminating one real MRI sequence from the segmentation procedure.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.05030v1"
	},
	{
		"title": "Where to Go Next: Modeling Long‐ and Short‐Term User Preferences for Point‐of‐Interest Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to Open Educational Resources ",
		"abstract": "The recent advances in computer-assisted learning systems and the availability of open educational resources today promise a pathway to providing cost-efficient, high-quality education to large masses of learners. One of the most ambitious use cases of computer-assisted learning is to build a lifelong learning recommendation system. Unlike short-term courses, lifelong learning presents unique challenges, requiring sophisticated recommendation models that account for a wide range of factors such as background knowledge of learners or novelty of the material while effectively maintaining knowledge states of masses of learners for significantly longer periods of time (ideally, a lifetime). This work presents the foundations towards building a dynamic, scalable and transparent recommendation system for education, modelling learner's knowledge from implicit data in the form of engagement with open educational resources. We i) use a text ontology based on Wikipedia to automatically extract knowledge components of educational resources and, ii) propose a set of online Bayesian strategies inspired by the well-known areas of item response theory and knowledge tracing. Our proposal, TrueLearn, focuses on recommendations for which the learner has enough background knowledge (so they are able to understand and learn from the material), and the material has enough novelty that would help the learner improve their knowledge about the subject and keep them engaged. We further construct a large open educational video lectures dataset and test the performance of the proposed algorithms, which show clear promise towards building an effective educational recommendation system.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09471v1"
	},
	{
		"title": "Learning from positive and unlabeled data without explicit estimation of class prior ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Path Planning Problems with Side Observations ‐ When Colonels Play Hide‐and‐Seek ",
		"abstract": "Resource allocation games such as the famous Colonel Blotto (CB) and Hide-and-Seek (HS) games are often used to model a large variety of practical problems, but only in their one-shot versions. Indeed, due to their extremely large strategy space, it remains an open question how one can efficiently learn in these games. In this work, we show that the online CB and HS games can be cast as path planning problems with side-observations (SOPPP): at each stage, a learner chooses a path on a directed acyclic graph and suffers the sum of losses that are adversarially assigned to the corresponding edges; and she then receives semi-bandit feedback with side-observations (i.e., she observes the losses on the chosen edges plus some others). We propose a novel algorithm, EXP3-OE, the first-of-its-kind with guaranteed efficient running time for SOPPP without requiring any auxiliary oracle. We provide an expected-regret bound of EXP3-OE in SOPPP matching the order of the best benchmark in the literature. Moreover, we introduce additional assumptions on the observability model under which we can further improve the regret bounds of EXP3-OE. We illustrate the benefit of using EXP3-OE in SOPPP by applying it to the online CB and HS games.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.11151v3"
	},
	{
		"title": "Unsupervised Deep Learning via Affinity Diffusion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Motion‐Attentive Transition for Zero‐Shot Video Object Segmentation ",
		"abstract": "In this paper, we present a novel Motion-Attentive Transition Network (MATNet) for zero-shot video object segmentation, which provides a new way of leveraging motion information to reinforce spatio-temporal object representation. An asymmetric attention block, called Motion-Attentive Transition (MAT), is designed within a two-stream encoder, which transforms appearance features into motion-attentive representations at each convolutional stage. In this way, the encoder becomes deeply interleaved, allowing for closely hierarchical interactions between object motion and appearance. This is superior to the typical two-stream architecture, which treats motion and appearance separately in each stream and often suffers from overfitting to appearance information. Additionally, a bridge network is proposed to obtain a compact, discriminative and scale-sensitive representation for multi-level encoder features, which is further fed into a decoder to achieve segmentation results. Extensive experiments on three challenging public benchmarks (i.e. DAVIS-16, FBMS and Youtube-Objects) show that our model achieves compelling performance against the state-of-the-arts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.04253v3"
	},
	{
		"title": "Deep Domain‐Adversarial Image Generation for Domain Generalisation ",
		"abstract": "Machine learning models typically suffer from the domain shift problem when trained on a source dataset and evaluated on a target dataset of different distribution. To overcome this problem, domain generalisation (DG) methods aim to leverage data from multiple source domains so that a trained model can generalise to unseen domains. In this paper, we propose a novel DG approach based on \\emph{Deep Domain-Adversarial Image Generation} (DDAIG). Specifically, DDAIG consists of three components, namely a label classifier, a domain classifier and a domain transformation network (DoTNet). The goal for DoTNet is to map the source training data to unseen domains. This is achieved by having a learning objective formulated to ensure that the generated data can be correctly classified by the label classifier while fooling the domain classifier. By augmenting the source training data with the generated unseen domain data, we can make the label classifier more robust to unknown domain changes. Extensive experiments on four DG datasets demonstrate the effectiveness of our approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.06054v1"
	},
	{
		"title": "Temporal Planning with Intermediate Conditions and Effects ",
		"abstract": "Automated temporal planning is the technology of choice when controlling systems that can execute more actions in parallel and when temporal constraints, such as deadlines, are needed in the model. One limitation of several action-based planning systems is that actions are modeled as intervals having conditions and effects only at the extremes and as invariants, but no conditions nor effects can be specified at arbitrary points or sub-intervals. In this paper, we address this limitation by providing an effective heuristic-search technique for temporal planning, allowing the definition of actions with conditions and effects at any arbitrary time within the action duration. We experimentally demonstrate that our approach is far better than standard encodings in PDDL 2.1 and is competitive with other approaches that can (directly or indirectly) represent intermediate action conditions or effects.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.11581v1"
	},
	{
		"title": "Double‐Oracle Sampling Method for Stackelberg Equilibrium Approximation in General‐Sum Extensive‐Form Games ",
		"abstract": "The paper presents a new method for approximating Strong Stackelberg Equilibrium in general-sum sequential games with imperfect information and perfect recall. The proposed approach is generic as it does not rely on any specific properties of a particular game model. The method is based on iterative interleaving of the two following phases: (1) guided Monte Carlo Tree Search sampling of the Follower's strategy space and (2) building the Leader's behavior strategy tree for which the sampled Follower's strategy is an optimal response. The above solution scheme is evaluated with respect to expected Leader's utility and time requirements on three sets of interception games with variable characteristics, played on graphs. A comparison with three state-of-the-art MILP/LP-based methods shows that in vast majority of test cases proposed simulation-based approach leads to optimal Leader's strategies, while excelling the competitive methods in terms of better time scalability and lower memory requirements.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03934v1"
	},
	{
		"title": "Efficient Model‐Based Diagnosis of Sequential Circuits ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Interpretation of Pairwise Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Uncertainty‐Aware Action Advising for Deep Reinforcement Learning Agents ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multiagent Evaluation Mechanisms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RoadTagger: Robust Road Attribute Inference with Graph Neural Networks ",
		"abstract": "Inferring road attributes such as lane count and road type from satellite imagery is challenging. Often, due to the occlusion in satellite imagery and the spatial correlation of road attributes, a road attribute at one position on a road may only be apparent when considering far-away segments of the road. Thus, to robustly infer road attributes, the model must integrate scattered information and capture the spatial correlation of features along roads. Existing solutions that rely on image classifiers fail to capture this correlation, resulting in poor accuracy. We find this failure is caused by a fundamental limitation -- the limited effective receptive field of image classifiers. To overcome this limitation, we propose RoadTagger, an end-to-end architecture which combines both Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs) to infer road attributes. The usage of graph neural networks allows information propagation on the road network graph and eliminates the receptive field limitation of image classifiers. We evaluate RoadTagger on both a large real-world dataset covering 688 km^2 area in 20 U.S. cities and a synthesized micro-dataset. In the evaluation, RoadTagger improves inference accuracy over the CNN image classifier based approaches. RoadTagger also demonstrates strong robustness against different disruptions in the satellite imagery and the ability to learn complicated inductive rules for aggregating scattered information along the road network.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.12408v1"
	},
	{
		"title": "Hybrid Graph Neural Networks for Crowd Counting ",
		"abstract": "Crowd counting is an important yet challenging task due to the large scale and density variation. Recent investigations have shown that distilling rich relations among multi-scale features and exploiting useful information from the auxiliary task, i.e., localization, are vital for this task. Nevertheless, how to comprehensively leverage these relations within a unified network architecture is still a challenging problem. In this paper, we present a novel network structure called Hybrid Graph Neural Network (HyGnn) which targets to relieve the problem by interweaving the multi-scale features for crowd density as well as its auxiliary task (localization) together and performing joint reasoning over a graph. Specifically, HyGnn integrates a hybrid graph to jointly represent the task-specific feature maps of different scales as nodes, and two types of relations as edges:(i) multi-scale relations for capturing the feature dependencies across scales and (ii) mutual beneficial relations building bridges for the cooperation between counting and localization. Thus, through message passing, HyGnn can distill rich relations between the nodes to obtain more powerful representations, leading to robust and accurate results. Our HyGnn performs significantly well on four challenging datasets: ShanghaiTech Part A, ShanghaiTech Part B, UCF_CC_50 and UCF_QNRF, outperforming the state-of-the-art approaches by a large margin.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.00092v1"
	},
	{
		"title": "Graph Few‐shot Learning via Knowledge Transfer ",
		"abstract": "Towards the challenging problem of semi-supervised node classification, there have been extensive studies. As a frontier, Graph Neural Networks (GNNs) have aroused great interest recently, which update the representation of each node by aggregating information of its neighbors. However, most GNNs have shallow layers with a limited receptive field and may not achieve satisfactory performance especially when the number of labeled nodes is quite small. To address this challenge, we innovatively propose a graph few-shot learning (GFL) algorithm that incorporates prior knowledge learned from auxiliary graphs to improve classification accuracy on the target graph. Specifically, a transferable metric space characterized by a node embedding and a graph-specific prototype embedding function is shared between auxiliary graphs and the target, facilitating the transfer of structural knowledge. Extensive experiments and ablation studies on four real-world graph datasets demonstrate the effectiveness of our proposed model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.03053v3"
	},
	{
		"title": "Towards Better Forecasting by Fusing Near and Distant Future Visions ",
		"abstract": "Multivariate time series forecasting is an important yet challenging problem in machine learning. Most existing approaches only forecast the series value of one future moment, ignoring the interactions between predictions of future moments with different temporal distance. Such a deficiency probably prevents the model from getting enough information about the future, thus limiting the forecasting accuracy. To address this problem, we propose Multi-Level Construal Neural Network (MLCNN), a novel multi-task deep learning framework. Inspired by the Construal Level Theory of psychology, this model aims to improve the predictive performance by fusing forecasting information (i.e., future visions) of different future time. We first use the Convolution Neural Network to extract multi-level abstract representations of the raw data for near and distant future predictions. We then model the interplay between multiple predictive tasks and fuse their future visions through a modified Encoder-Decoder architecture. Finally, we combine traditional Autoregression model with the neural network to solve the scale insensitive problem. Experiments on three real-world datasets show that our method achieves statistically significant improvements compared to the most state-of-the-art baseline methods, with average 4.59% reduction on RMSE metric and average 6.87% reduction on MAE metric.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05122v1"
	},
	{
		"title": "SK‐Net: Deep Learning on Point Cloud via End‐to‐end Discovery of Spatial Keypoints ",
		"abstract": "Since the PointNet was proposed, deep learning on point cloud has been the concentration of intense 3D research. However, existing point-based methods usually are not adequate to extract the local features and the spatial pattern of a point cloud for further shape understanding. This paper presents an end-to-end framework, SK-Net, to jointly optimize the inference of spatial keypoint with the learning of feature representation of a point cloud for a specific point cloud task. One key process of SK-Net is the generation of spatial keypoints (Skeypoints). It is jointly conducted by two proposed regulating losses and a task objective function without knowledge of Skeypoint location annotations and proposals. Specifically, our Skeypoints are not sensitive to the location consistency but are acutely aware of shape. Another key process of SK-Net is the extraction of the local structure of Skeypoints (detail feature) and the local spatial pattern of normalized Skeypoints (pattern feature). This process generates a comprehensive representation, pattern-detail (PD) feature, which comprises the local detail information of a point cloud and reveals its spatial pattern through the part district reconstruction on normalized Skeypoints. Consequently, our network is prompted to effectively understand the correlation between different regions of a point cloud and integrate contextual information of the point cloud. In point cloud tasks, such as classification and segmentation, our proposed method performs better than or comparable with the state-of-the-art approaches. We also present an ablation study to demonstrate the advantages of SK-Net.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.14014v1"
	},
	{
		"title": "Learning Long‐ and Short‐Term User Literal‐Preference with Multimodal Hierarchical Transformer Network for Personalized Image Caption ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Uncertainty‐Aware Search Framework for Multi‐Objective Bayesian Optimization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Linear Context Transform Block ",
		"abstract": "Squeeze-and-Excitation (SE) block presents a channel attention mechanism for modeling global context via explicitly capturing dependencies across channels. However, we are still far from understanding how the SE block works. In this work, we first revisit the SE block, and then present a detailed empirical study of the relationship between global context and attention distribution, based on which we propose a simple yet effective module, called Linear Context Transform (LCT) block. We divide all channels into different groups and normalize the globally aggregated context features within each channel group, reducing the disturbance from irrelevant channels. Through linear transform of the normalized context features, we model global context for each channel independently. The LCT block is extremely lightweight and easy to be plugged into different backbone models while with negligible parameters and computational burden increase. Extensive experiments show that the LCT block outperforms the SE block in image classification task on the ImageNet and object detection/segmentation on the COCO dataset with different backbone models. Moreover, LCT yields consistent performance gains over existing state-of-the-art detection architectures, e.g., 1.5$\\sim$1.7% AP$^{bbox}$ and 1.0$\\sim$1.2% AP$^{mask}$ improvements on the COCO benchmark, irrespective of different baseline models of varied capacities. We hope our simple yet effective approach will shed some light on future research of attention-based models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03834v2"
	},
	{
		"title": "MetaLight: Value‐based Meta‐reinforcement Learning for Traffic Signal Control ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": " Ladder Loss for Coherent Visual‐Semantic Embedding ",
		"abstract": "For visual-semantic embedding, the existing methods normally treat the relevance between queries and candidates in a bipolar way -- relevant or irrelevant, and all \"irrelevant\" candidates are uniformly pushed away from the query by an equal margin in the embedding space, regardless of their various proximity to the query. This practice disregards relatively discriminative information and could lead to suboptimal ranking in the retrieval results and poorer user experience, especially in the long-tail query scenario where a matching candidate may not necessarily exist. In this paper, we introduce a continuous variable to model the relevance degree between queries and multiple candidates, and propose to learn a coherent embedding space, where candidates with higher relevance degrees are mapped closer to the query than those with lower relevance degrees. In particular, the new ladder loss is proposed by extending the triplet loss inequality to a more general inequality chain, which implements variable push-away margins according to respective relevance degrees. In addition, a proper Coherent Score metric is proposed to better measure the ranking results including those \"irrelevant\" candidates. Extensive experiments on multiple datasets validate the efficacy of our proposed method, which achieves significant improvement over existing state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07528v1"
	},
	{
		"title": "Hashing based Answer Selection ",
		"abstract": "Answer selection is an important subtask of question answering (QA), where deep models usually achieve better performance. Most deep models adopt question-answer interaction mechanisms, such as attention, to get vector representations for answers. When these interaction based deep models are deployed for online prediction, the representations of all answers need to be recalculated for each question. This procedure is time-consuming for deep models with complex encoders like BERT which usually have better accuracy than simple encoders. One possible solution is to store the matrix representation (encoder output) of each answer in memory to avoid recalculation. But this will bring large memory cost. In this paper, we propose a novel method, called hashing based answer selection (HAS), to tackle this problem. HAS adopts a hashing strategy to learn a binary matrix representation for each answer, which can dramatically reduce the memory cost for storing the matrix representations of answers. Hence, HAS can adopt complex encoders like BERT in the model, but the online prediction of HAS is still fast with a low memory cost. Experimental results on three popular answer selection datasets show that HAS can outperform existing models to achieve state-of-the-art performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10718v1"
	},
	{
		"title": "GMAN: A Graph Multi‐Attention Network for Traffic Prediction ",
		"abstract": "Long-term traffic prediction is highly challenging due to the complexity of traffic systems and the constantly changing nature of many impacting factors. In this paper, we focus on the spatio-temporal factors, and propose a graph multi-attention network (GMAN) to predict traffic conditions for time steps ahead at different locations on a road network graph. GMAN adapts an encoder-decoder architecture, where both the encoder and the decoder consist of multiple spatio-temporal attention blocks to model the impact of the spatio-temporal factors on traffic conditions. The encoder encodes the input traffic features and the decoder predicts the output sequence. Between the encoder and the decoder, a transform attention layer is applied to convert the encoded traffic features to generate the sequence representations of future time steps as the input of the decoder. The transform attention mechanism models the direct relationships between historical and future time steps that helps to alleviate the error propagation problem among prediction time steps. Experimental results on two real-world traffic prediction tasks (i.e., traffic volume prediction and traffic speed prediction) demonstrate the superiority of GMAN. In particular, in the 1 hour ahead prediction, GMAN outperforms state-of-the-art methods by up to 4% improvement in MAE measure. The source code is available at https://github.com/zhengchuanpan/GMAN.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08415v2"
	},
	{
		"title": "Patchy Image Structure Classification Using Multi‐Orientation Region Transform ",
		"abstract": "Exterior contour and interior structure are both vital features for classifying objects. However, most of the existing methods consider exterior contour feature and internal structure feature separately, and thus fail to function when classifying patchy image structures that have similar contours and flexible structures. To address above limitations, this paper proposes a novel Multi-Orientation Region Transform (MORT), which can effectively characterize both contour and structure features simultaneously, for patchy image structure classification. MORT is performed over multiple orientation regions at multiple scales to effectively integrate patchy features, and thus enables a better description of the shape in a coarse-to-fine manner. Moreover, the proposed MORT can be extended to combine with the deep convolutional neural network techniques, for further enhancement of classification accuracy. Very encouraging experimental results on the challenging ultra-fine-grained cultivar recognition task, insect wing recognition task, and large variation butterfly recognition task are obtained, which demonstrate the effectiveness and superiority of the proposed MORT over the state-of-the-art methods in classifying patchy image structures. Our code and three patchy image structure datasets are available at: https://github.com/XiaohanYu-GU/MReT2019.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00622v1"
	},
	{
		"title": "DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue ",
		"abstract": "Different from Visual Question Answering task that requires to answer only one question about an image, Visual Dialogue involves multiple questions which cover a broad range of visual content that could be related to any objects, relationships or semantics. The key challenge in Visual Dialogue task is thus to learn a more comprehensive and semantic-rich image representation which may have adaptive attentions on the image for variant questions. In this research, we propose a novel model to depict an image from both visual and semantic perspectives. Specifically, the visual view helps capture the appearance-level information, including objects and their relationships, while the semantic view enables the agent to understand high-level visual semantics from the whole image to the local regions. Futhermore, on top of such multi-view image features, we propose a feature selection framework which is able to adaptively capture question-relevant information hierarchically in fine-grained level. The proposed method achieved state-of-the-art results on benchmark Visual Dialogue datasets. More importantly, we can tell which modality (visual or semantic) has more contribution in answering the current question by visualizing the gate values. It gives us insights in understanding of human cognition in Visual Dialogue.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07251v1"
	},
	{
		"title": "Adaptive Quantitative Trading: an Imitative Deep Reinforcement Learning Approach ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Find Objects and Focus on Highlights:  Mining Object Semantics for Video Highlight Detection via Graph Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Cross‐modality Medical Image Segmentation with Online Mutual Knowledge Distillation ",
		"abstract": "The success of deep convolutional neural networks is partially attributed to the massive amount of annotated training data. However, in practice, medical data annotations are usually expensive and time-consuming to be obtained. Considering multi-modality data with the same anatomic structures are widely available in clinic routine, in this paper, we aim to exploit the prior knowledge (e.g., shape priors) learned from one modality (aka., assistant modality) to improve the segmentation performance on another modality (aka., target modality) to make up annotation scarcity. To alleviate the learning difficulties caused by modality-specific appearance discrepancy, we first present an Image Alignment Module (IAM) to narrow the appearance gap between assistant and target modality data.We then propose a novel Mutual Knowledge Distillation (MKD) scheme to thoroughly exploit the modality-shared knowledge to facilitate the target-modality segmentation. To be specific, we formulate our framework as an integration of two individual segmentors. Each segmentor not only explicitly extracts one modality knowledge from corresponding annotations, but also implicitly explores another modality knowledge from its counterpart in mutual-guided manner. The ensemble of two segmentors would further integrate the knowledge from both modalities and generate reliable segmentation results on target modality. Experimental results on the public multi-class cardiac segmentation data, i.e., MMWHS 2017, show that our method achieves large improvements on CT segmentation by utilizing additional MRI data and outperforms other state-of-the-art multi-modality learning methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2010.01532v1"
	},
	{
		"title": "Tensor‐SVD Based Graph Learning for Multi‐View Subspace Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neural Architecture Search using Deep Neural Networks and Monte Carlo Tree Search ",
		"abstract": "Neural Architecture Search (NAS) has shown great success in automating the design of neural networks, but the prohibitive amount of computations behind current NAS methods requires further investigations in improving the sample efficiency and the network evaluation cost to get better results in a shorter time. In this paper, we present a novel scalable Monte Carlo Tree Search (MCTS) based NAS agent, named AlphaX, to tackle these two aspects. AlphaX improves the search efficiency by adaptively balancing the exploration and exploitation at the state level, and by a Meta-Deep Neural Network (DNN) to predict network accuracies for biasing the search toward a promising region. To amortize the network evaluation cost, AlphaX accelerates MCTS rollouts with a distributed design and reduces the number of epochs in evaluating a network by transfer learning, which is guided with the tree structure in MCTS. In 12 GPU days and 1000 samples, AlphaX found an architecture that reaches 97.84\\% top-1 accuracy on CIFAR-10, and 75.5\\% top-1 accuracy on ImageNet, exceeding SOTA NAS methods in both the accuracy and sampling efficiency. Particularly, we also evaluate AlphaX on NASBench-101, a large scale NAS dataset; AlphaX is 3x and 2.8x more sample efficient than Random Search and Regularized Evolution in finding the global optimum. Finally, we show the searched architecture improves a variety of vision applications from Neural Style Transfer, to Image Captioning and Object Detection.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1805.07440v5"
	},
	{
		"title": "Video Frame Interpolation via Deformable Separable Convolution ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "NeoNav: Improving the Generalization of Visual Navigation via Generating Next Expected Observations ",
		"abstract": "We propose improving the cross-target and cross-scene generalization of visual navigation through learning an agent that is guided by conceiving the next observations it expects to see. This is achieved by learning a variational Bayesian model, called NeoNav, which generates the next expected observations (NEO) conditioned on the current observations of the agent and the target view. Our generative model is learned through optimizing a variational objective encompassing two key designs. First, the latent distribution is conditioned on current observations and the target view, leading to a model-based, target-driven navigation. Second, the latent space is modeled with a Mixture of Gaussians conditioned on the current observation and the next best action. Our use of mixture-of-posteriors prior effectively alleviates the issue of over-regularized latent space, thus significantly boosting the model generalization for new targets and in novel scenes. Moreover, the NEO generation models the forward dynamics of agent-environment interaction, which improves the quality of approximate inference and hence benefits data efficiency. We have conducted extensive evaluations on both real-world and synthetic benchmarks, and show that our model consistently outperforms the state-of-the-art models in terms of success rate, data efficiency, and generalization.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.07207v3"
	},
	{
		"title": "Few‐Shot Knowledge Graph Completion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Regret Minimisation in Multi‐Armed Bandits Using Bounded Arm Memory ",
		"abstract": "In this paper, we propose a constant word (RAM model) algorithm for regret minimisation for both finite and infinite Stochastic Multi-Armed Bandit (MAB) instances. Most of the existing regret minimisation algorithms need to remember the statistics of all the arms they encounter. This may become a problem for the cases where the number of available words of memory is limited. Designing an efficient regret minimisation algorithm that uses a constant number of words has long been interesting to the community. Some early attempts consider the number of arms to be infinite, and require the reward distribution of the arms to belong to some particular family. Recently, for finitely many-armed bandits an explore-then-commit based algorithm~\\citep{Liau+PSY:2018} seems to escape such assumption. However, due to the underlying PAC-based elimination their method incurs a high regret. We present a conceptually simple, and efficient algorithm that needs to remember statistics of at most $M$ arms, and for any $K$-armed finite bandit instance it enjoys a $O(KM +K^{1.5}\\sqrt{T\\log (T/MK)}/M)$ upper-bound on regret. We extend it to achieve sub-linear \\textit{quantile-regret}~\\citep{RoyChaudhuri+K:2018} and empirically verify the efficiency of our algorithm via experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.08387v1"
	},
	{
		"title": "Neural Graph Embedding for Neural Architecture Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Awareness of Human Relational Strategies in Virtual Agents ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Finding Good Subtrees for Constraint Optimization Problems Using Frequent Pattern Mining ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning General Latent‐Variable Graphical Models with Predictive Belief Propagation ",
		"abstract": "Learning general latent-variable probabilistic graphical models is a key theoretical challenge in machine learning and artificial intelligence. All previous methods, including the EM algorithm and the spectral algorithms, face severe limitations that largely restrict their applicability and affect their performance. In order to overcome these limitations, in this paper we introduce a novel formulation of message-passing inference over junction trees named predictive belief propagation, and propose a new learning and inference algorithm for general latent-variable graphical models based on this formulation. Our proposed algorithm reduces the hard parameter learning problem into a sequence of supervised learning problems, and unifies the learning of different kinds of latent graphical models into a single learning framework, which is local-optima-free and statistically consistent. We then give a proof of the correctness of our algorithm and show in experiments on both synthetic and real datasets that our algorithm significantly outperforms both the EM algorithm and the spectral algorithm while also being orders of magnitude faster to compute.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1712.02046v2"
	},
	{
		"title": "Solving Sequential Text Classification as Board‐Game Playing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Agent Communication under Limited Bandwidth by Message Pruning ",
		"abstract": "Communication is a crucial factor for the big multi-agent world to stay organized and productive. Recently, Deep Reinforcement Learning (DRL) has been applied to learn the communication strategy and the control policy for multiple agents. However, the practical \\emph{\\textbf{limited bandwidth}} in multi-agent communication has been largely ignored by the existing DRL methods. Specifically, many methods keep sending messages incessantly, which consumes too much bandwidth. As a result, they are inapplicable to multi-agent systems with limited bandwidth. To handle this problem, we propose a gating mechanism to adaptively prune less beneficial messages. We evaluate the gating mechanism on several tasks. Experiments demonstrate that it can prune a lot of messages with little impact on performance. In fact, the performance may be greatly improved by pruning redundant messages. Moreover, the proposed gating mechanism is applicable to several previous methods, equipping them the ability to address bandwidth restricted settings.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05304v1"
	},
	{
		"title": "Neighborhood Cognition Consistent Multi‐Agent Reinforcement Learning ",
		"abstract": "Social psychology and real experiences show that cognitive consistency plays an important role to keep human society in order: if people have a more consistent cognition about their environments, they are more likely to achieve better cooperation. Meanwhile, only cognitive consistency within a neighborhood matters because humans only interact directly with their neighbors. Inspired by these observations, we take the first step to introduce \\emph{neighborhood cognitive consistency} (NCC) into multi-agent reinforcement learning (MARL). Our NCC design is quite general and can be easily combined with existing MARL methods. As examples, we propose neighborhood cognition consistent deep Q-learning and Actor-Critic to facilitate large-scale multi-agent cooperations. Extensive experiments on several challenging tasks (i.e., packet routing, wifi configuration, and Google football player control) justify the superior performance of our methods compared with state-of-the-art MARL approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01160v2"
	},
	{
		"title": "Grapy‐ML: Graph Pyramid Mutual Learning for Cross‐dataset Human Parsing ",
		"abstract": "Human parsing, or human body part semantic segmentation, has been an active research topic due to its wide potential applications. In this paper, we propose a novel GRAph PYramid Mutual Learning (Grapy-ML) method to address the cross-dataset human parsing problem, where the annotations are at different granularities. Starting from the prior knowledge of the human body hierarchical structure, we devise a graph pyramid module (GPM) by stacking three levels of graph structures from coarse granularity to fine granularity subsequently. At each level, GPM utilizes the self-attention mechanism to model the correlations between context nodes. Then, it adopts a top-down mechanism to progressively refine the hierarchical features through all the levels. GPM also enables efficient mutual learning. Specifically, the network weights of the first two levels are shared to exchange the learned coarse-granularity information across different datasets. By making use of the multi-granularity labels, Grapy-ML learns a more discriminative feature representation and achieves state-of-the-art performance, which is demonstrated by extensive experiments on the three popular benchmarks, e.g. CIHP dataset. The source code is publicly available at https://github.com/Charleshhy/Grapy-ML.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12053v1"
	},
	{
		"title": "SMIX($\\lambda$): Enhancing Centralized Value Functions for Cooperative Multi‐Agent Reinforcement Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Lifelong Spectral Clustering ",
		"abstract": "In the past decades, spectral clustering (SC) has become one of the most effective clustering algorithms. However, most previous studies focus on spectral clustering tasks with a fixed task set, which cannot incorporate with a new spectral clustering task without accessing to previously learned tasks. In this paper, we aim to explore the problem of spectral clustering in a lifelong machine learning framework, i.e., Lifelong Spectral Clustering (L2SC). Its goal is to efficiently learn a model for a new spectral clustering task by selectively transferring previously accumulated experience from knowledge library. Specifically, the knowledge library of L2SC contains two components: 1) orthogonal basis library: capturing latent cluster centers among the clusters in each pair of tasks; 2) feature embedding library: embedding the feature manifold information shared among multiple related tasks. As a new spectral clustering task arrives, L2SC firstly transfers knowledge from both basis library and feature library to obtain encoding matrix, and further redefines the library base over time to maximize performance across all the clustering tasks. Meanwhile, a general online update formulation is derived to alternatively update the basis library and feature library. Finally, the empirical experiments on several real-world benchmark datasets demonstrate that our L2SC model can effectively improve the clustering performance when comparing with other state-of-the-art spectral clustering algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11908v2"
	},
	{
		"title": "Order Matters: Semantic‐Aware Neural Networks for Binary Code Similarity Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "KPNet: Towards Minimal Face Detector ",
		"abstract": "The small receptive field and capacity of minimal neural networks limit their performance when using them to be the backbone of detectors. In this work, we find that the appearance feature of a generic face is discriminative enough for a tiny and shallow neural network to verify from the background. And the essential barriers behind us are 1) the vague definition of the face bounding box and 2) tricky design of anchor-boxes or receptive field. Unlike most top-down methods for joint face detection and alignment, the proposed KPNet detects small facial keypoints instead of the whole face by in a bottom-up manner. It first predicts the facial landmarks from a low-resolution image via the well-designed fine-grained scale approximation and scale adaptive soft-argmax operator. Finally, the precise face bounding boxes, no matter how we define it, can be inferred from the keypoints. Without any complex head architecture or meticulous network designing, the KPNet achieves state-of-the-art accuracy on generic face detection and alignment benchmarks with only $\\sim1M$ parameters, which runs at 1000fps on GPU and is easy to perform real-time on most modern front-end chips.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.07543v1"
	},
	{
		"title": "SSAH: Semi‐supervised Adversarial Deep Hashing with Self‐paced Hard Sample Generation ",
		"abstract": "Deep hashing methods have been proved to be effective and efficient for large-scale Web media search. The success of these data-driven methods largely depends on collecting sufficient labeled data, which is usually a crucial limitation in practical cases. The current solutions to this issue utilize Generative Adversarial Network (GAN) to augment data in semi-supervised learning. However, existing GAN-based methods treat image generations and hashing learning as two isolated processes, leading to generation ineffectiveness. Besides, most works fail to exploit the semantic information in unlabeled data. In this paper, we propose a novel Semi-supervised Self-pace Adversarial Hashing method, named SSAH to solve the above problems in a unified framework. The SSAH method consists of an adversarial network (A-Net) and a hashing network (H-Net). To improve the quality of generative images, first, the A-Net learns hard samples with multi-scale occlusions and multi-angle rotated deformations which compete against the learning of accurate hashing codes. Second, we design a novel self-paced hard generation policy to gradually increase the hashing difficulty of generated samples. To make use of the semantic information in unlabeled ones, we propose a semi-supervised consistent loss. The experimental results show that our method can significantly improve state-of-the-art models on both the widely-used hashing datasets and fine-grained datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08688v1"
	},
	{
		"title": "Ultrafast Video Attention Prediction with Coupled Knowledge Distillation ",
		"abstract": "Large convolutional neural network models have recently demonstrated impressive performance on video attention prediction. Conventionally, these models are with intensive computation and large memory. To address these issues, we design an extremely light-weight network with ultrafast speed, named UVA-Net. The network is constructed based on depth-wise convolutions and takes low-resolution images as input. However, this straight-forward acceleration method will decrease performance dramatically. To this end, we propose a coupled knowledge distillation strategy to augment and train the network effectively. With this strategy, the model can further automatically discover and emphasize implicit useful cues contained in the data. Both spatial and temporal knowledge learned by the high-resolution complex teacher networks also can be distilled and transferred into the proposed low-resolution light-weight spatiotemporal network. Experimental results show that the performance of our model is comparable to 11 state-of-the-art models in video attention prediction, while it costs only 0.68 MB memory footprint, runs about 10,106 FPS on GPU and 404 FPS on CPU, which is 206 times faster than previous models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.04449v2"
	},
	{
		"title": "Interactive Rare‐Category‐of‐Interest Mining from Large Datasets ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "OOGAN: Disentangling GAN with One‐Hot Sampling and Orthogonal Regularization ",
		"abstract": "Exploring the potential of GANs for unsupervised disentanglement learning, this paper proposes a novel GAN-based disentanglement framework with One-Hot Sampling and Orthogonal Regularization (OOGAN). While previous works mostly attempt to tackle disentanglement learning through VAE and seek to implicitly minimize the Total Correlation (TC) objective with various sorts of approximation methods, we show that GANs have a natural advantage in disentangling with an alternating latent variable (noise) sampling method that is straightforward and robust. Furthermore, we provide a brand-new perspective on designing the structure of the generator and discriminator, demonstrating that a minor structural change and an orthogonal regularization on model weights entails an improved disentanglement. Instead of experimenting on simple toy datasets, we conduct experiments on higher-resolution images and show that OOGAN greatly pushes the boundary of unsupervised disentanglement.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10836v5"
	},
	{
		"title": "Multimodal Structure‐Consistent Image‐to‐Image Translation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bi‐level Actor‐Critic for Multi‐agent Coordination ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Agent Game Abstraction via Graph Attention Neural Network ",
		"abstract": "In large-scale multi-agent systems, the large number of agents and complex game relationship cause great difficulty for policy learning. Therefore, simplifying the learning process is an important research issue. In many multi-agent systems, the interactions between agents often happen locally, which means that agents neither need to coordinate with all other agents nor need to coordinate with others all the time. Traditional methods attempt to use pre-defined rules to capture the interaction relationship between agents. However, the methods cannot be directly used in a large-scale environment due to the difficulty of transforming the complex interactions between agents into rules. In this paper, we model the relationship between agents by a complete graph and propose a novel game abstraction mechanism based on two-stage attention network (G2ANet), which can indicate whether there is an interaction between two agents and the importance of the interaction. We integrate this detection mechanism into graph neural network-based multi-agent reinforcement learning for conducting game abstraction and propose two novel learning algorithms GA-Comm and GA-AC. We conduct experiments in Traffic Junction and Predator-Prey. The results indicate that the proposed methods can simplify the learning process and meanwhile get better asymptotic performance compared with state-of-the-art algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10715v1"
	},
	{
		"title": "Estimating Stochastic Linear Combination of Non‐linear Regressions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Novel Model for Imbalanced Data Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cross‐Modal Subspace Clustering via Deep Canonical Correlation Analysis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Exchangeable Feature Alignment for Arbitrary Style Transfer ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "F3Net: Fusion, Feedback and Focus for Salient Object Detection ",
		"abstract": "Most of existing salient object detection models have achieved great progress by aggregating multi-level features extracted from convolutional neural networks. However, because of the different receptive fields of different convolutional layers, there exists big differences between features generated by these layers. Common feature fusion strategies (addition or concatenation) ignore these differences and may cause suboptimal solutions. In this paper, we propose the F3Net to solve above problem, which mainly consists of cross feature module (CFM) and cascaded feedback decoder (CFD) trained by minimizing a new pixel position aware loss (PPA). Specifically, CFM aims to selectively aggregate multi-level features. Different from addition and concatenation, CFM adaptively selects complementary components from input features before fusion, which can effectively avoid introducing too much redundant information that may destroy the original features. Besides, CFD adopts a multi-stage feedback mechanism, where features closed to supervision will be introduced to the output of previous layers to supplement them and eliminate the differences between features. These refined features will go through multiple similar iterations before generating the final saliency maps. Furthermore, different from binary cross entropy, the proposed PPA loss doesn't treat pixels equally, which can synthesize the local structure information of a pixel to guide the network to focus more on local details. Hard pixels from boundaries or error-prone parts will be given more attention to emphasize their importance. F3Net is able to segment salient object regions accurately and provide clear local details. Comprehensive experiments on five benchmark datasets demonstrate that F3Net outperforms state-of-the-art approaches on six evaluation metrics.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11445v1"
	},
	{
		"title": "A Coarse‐to‐Fine Adaptive Network for Appearance‐Based Gaze Estimation ",
		"abstract": "Human gaze is essential for various appealing applications. Aiming at more accurate gaze estimation, a series of recent works propose to utilize face and eye images simultaneously. Nevertheless, face and eye images only serve as independent or parallel feature sources in those works, the intrinsic correlation between their features is overlooked. In this paper we make the following contributions: 1) We propose a coarse-to-fine strategy which estimates a basic gaze direction from face image and refines it with corresponding residual predicted from eye images. 2) Guided by the proposed strategy, we design a framework which introduces a bi-gram model to bridge gaze residual and basic gaze direction, and an attention component to adaptively acquire suitable fine-grained feature. 3) Integrating the above innovations, we construct a coarse-to-fine adaptive network named CA-Net and achieve state-of-the-art performances on MPIIGaze and EyeDiap.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.00187v1"
	},
	{
		"title": "Deterministic Value‐Policy Gradients ",
		"abstract": "Reinforcement learning algorithms such as the deep deterministic policy gradient algorithm (DDPG) has been widely used in continuous control tasks. However, the model-free DDPG algorithm suffers from high sample complexity. In this paper we consider the deterministic value gradients to improve the sample efficiency of deep reinforcement learning algorithms. Previous works consider deterministic value gradients with the finite horizon, but it is too myopic compared with infinite horizon. We firstly give a theoretical guarantee of the existence of the value gradients in this infinite setting. Based on this theoretical guarantee, we propose a class of the deterministic value gradient algorithm (DVG) with infinite horizon, and different rollout steps of the analytical gradients by the learned model trade off between the variance of the value gradients and the model bias. Furthermore, to better combine the model-based deterministic value gradient estimators with the model-free deterministic policy gradient estimator, we propose the deterministic value-policy gradient (DVPG) algorithm. We finally conduct extensive experiments comparing DVPG with state-of-the-art methods on several standard continuous control benchmarks. Results demonstrate that DVPG substantially outperforms other baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03939v2"
	},
	{
		"title": "How Should an Agent Practice? ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Suspicion‐Free Adversarial Attacks on Clustering Algorithms ",
		"abstract": "Clustering algorithms are used in a large number of applications and play an important role in modern machine learning-- yet, adversarial attacks on clustering algorithms seem to be broadly overlooked unlike supervised learning. In this paper, we seek to bridge this gap by proposing a black-box adversarial attack for clustering models for linearly separable clusters. Our attack works by perturbing a single sample close to the decision boundary, which leads to the misclustering of multiple unperturbed samples, named spill-over adversarial samples. We theoretically show the existence of such adversarial samples for the K-Means clustering. Our attack is especially strong as (1) we ensure the perturbed sample is not an outlier, hence not detectable, and (2) the exact metric used for clustering is not known to the attacker. We theoretically justify that the attack can indeed be successful without the knowledge of the true metric. We conclude by providing empirical results on a number of datasets, and clustering algorithms. To the best of our knowledge, this is the first work that generates spill-over adversarial samples without the knowledge of the true metric ensuring that the perturbed sample is not an outlier, and theoretically proves the above.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07015v1"
	},
	{
		"title": "LS‐Tree: Model Interpretation When the Data Are Linguistic ",
		"abstract": "We study the problem of interpreting trained classification models in the setting of linguistic data sets. Leveraging a parse tree, we propose to assign least-squares based importance scores to each word of an instance by exploiting syntactic constituency structure. We establish an axiomatic characterization of these importance scores by relating them to the Banzhaf value in coalitional game theory. Based on these importance scores, we develop a principled method for detecting and quantifying interactions between words in a sentence. We demonstrate that the proposed method can aid in interpretability and diagnostics for several widely-used language models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.04187v1"
	},
	{
		"title": "ML‐LOO: Detecting Adversarial Examples with Feature Attribution ",
		"abstract": "Deep neural networks obtain state-of-the-art performance on a series of tasks. However, they are easily fooled by adding a small adversarial perturbation to input. The perturbation is often human imperceptible on image data. We observe a significant difference in feature attributions of adversarially crafted examples from those of original ones. Based on this observation, we introduce a new framework to detect adversarial examples through thresholding a scale estimate of feature attribution scores. Furthermore, we extend our method to include multi-layer feature attributions in order to tackle the attacks with mixed confidence levels. Through vast experiments, our method achieves superior performances in distinguishing adversarial examples from popular attack methods on a variety of real data sets among state-of-the-art detection methods. In particular, our method is able to detect adversarial examples of mixed confidence levels, and transfer between different attacking methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.03499v1"
	},
	{
		"title": "Fractional Skipping: Toward Finer‐Grained Dynamic Inference ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Attentive Pairwise Interaction for Fine‐Grained Classification ",
		"abstract": "Fine-grained classification is a challenging problem, due to subtle differences among highly-confused categories. Most approaches address this difficulty by learning discriminative representation of individual input image. On the other hand, humans can effectively identify contrastive clues by comparing image pairs. Inspired by this fact, this paper proposes a simple but effective Attentive Pairwise Interaction Network (API-Net), which can progressively recognize a pair of fine-grained images by interaction. Specifically, API-Net first learns a mutual feature vector to capture semantic differences in the input pair. It then compares this mutual vector with individual vectors to generate gates for each input image. These distinct gate vectors inherit mutual context on semantic differences, which allow API-Net to attentively capture contrastive clues by pairwise interaction between two images. Additionally, we train API-Net in an end-to-end manner with a score ranking regularization, which can further generalize API-Net by taking feature priorities into account. We conduct extensive experiments on five popular benchmarks in fine-grained classification. API-Net outperforms the recent SOTA methods, i.e., CUB-200-2011 (90.0%), Aircraft(93.9%), Stanford Cars (95.3%), Stanford Dogs (90.3%), and NABirds (88.1%).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.10191v1"
	},
	{
		"title": "Context‐Transformer: Tackling Object Confusion for Few‐Shot Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Knowledge‐Aware Attentional Reasoning Network for Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Collaborative Graph Convolutional Networks: Unsupervised Learning Meets Semi‐Supervised Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Task Learning with Generative Adversarial Training for Multi‐Passage Machine Reading Comprehension ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Region Focus Network for Joint Optic Disc and Cup Segmentation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Video Cloze Procedure for Self‐Supervised Spatio‐Temporal Learning ",
		"abstract": "We propose a novel self-supervised method, referred to as Video Cloze Procedure (VCP), to learn rich spatial-temporal representations. VCP first generates \"blanks\" by withholding video clips and then creates \"options\" by applying spatio-temporal operations on the withheld clips. Finally, it fills the blanks with \"options\" and learns representations by predicting the categories of operations applied on the clips. VCP can act as either a proxy task or a target task in self-supervised learning. As a proxy task, it converts rich self-supervised representations into video clip operations (options), which enhances the flexibility and reduces the complexity of representation learning. As a target task, it can assess learned representation models in a uniform and interpretable manner. With VCP, we train spatial-temporal representation models (3D-CNNs) and apply such models on action recognition and video retrieval tasks. Experiments on commonly used benchmarks show that the trained models outperform the state-of-the-art self-supervised models with significant margins.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.00294v1"
	},
	{
		"title": "Fine‐Grained Named Entity Typing over Distantly Supervised Data Based on Refined Representations ",
		"abstract": "Fine-Grained Named Entity Typing (FG-NET) is a key component in Natural Language Processing (NLP). It aims at classifying an entity mention into a wide range of entity types. Due to a large number of entity types, distant supervision is used to collect training data for this task, which noisily assigns type labels to entity mentions irrespective of the context. In order to alleviate the noisy labels, existing approaches on FGNET analyze the entity mentions entirely independent of each other and assign type labels solely based on mention sentence-specific context. This is inadequate for highly overlapping and noisy type labels as it hinders information passing across sentence boundaries. For this, we propose an edge-weighted attentive graph convolution network that refines the noisy mention representations by attending over corpus-level contextual clues prior to the end classification. Experimental evaluation shows that the proposed model outperforms the existing research by a relative score of upto 10.2% and 8.3% for macro f1 and micro f1 respectively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.03554v1"
	},
	{
		"title": "Transparent Classification with Multilayer Logical Perceptrons and Random Binarization ",
		"abstract": "Models with transparent inner structure and high classification performance are required to reduce potential risk and provide trust for users in domains like health care, finance, security, etc. However, existing models are hard to simultaneously satisfy the above two properties. In this paper, we propose a new hierarchical rule-based model for classification tasks, named Concept Rule Sets (CRS), which has both a strong expressive ability and a transparent inner structure. To address the challenge of efficiently learning the non-differentiable CRS model, we propose a novel neural network architecture, Multilayer Logical Perceptron (MLLP), which is a continuous version of CRS. Using MLLP and the Random Binarization (RB) method we proposed, we can search the discrete solution of CRS in continuous space using gradient descent and ensure the discrete CRS acts almost the same as the corresponding continuous MLLP. Experiments on 12 public data sets show that CRS outperforms the state-of-the-art approaches and the complexity of the learned CRS is close to the simple decision tree. Source code is available at https://github.com/12wang3/mllp.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.04695v2"
	},
	{
		"title": "Spherical Criteria for Fast and Accurate 360° Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "HAL: Improved Text‐Image Matching by Mitigating Visual Semantic Hubs ",
		"abstract": "The hubness problem widely exists in high-dimensional embedding space and is a fundamental source of error for cross-modal matching tasks. In this work, we study the emergence of hubs in Visual Semantic Embeddings (VSE) with application to text-image matching. We analyze the pros and cons of two widely adopted optimization objectives for training VSE and propose a novel hubness-aware loss function (HAL) that addresses previous methods' defects. Unlike (Faghri et al.2018) which simply takes the hardest sample within a mini-batch, HAL takes all samples into account, using both local and global statistics to scale up the weights of \"hubs\". We experiment our method with various configurations of model architectures and datasets. The method exhibits exceptionally good robustness and brings consistent improvement on the task of text-image matching across all settings. Specifically, under the same model architectures as (Faghri et al. 2018) and (Lee at al. 2018), by switching only the learning objective, we report a maximum R@1improvement of 7.4% on MS-COCO and 8.3% on Flickr30k.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10097v1"
	},
	{
		"title": "Large‐scale Multi‐view Subspace Clustering in Linear Time ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ReCO: A Large Scale Chinese Reading Comprehension Dataset on Opinion ",
		"abstract": "This paper presents the ReCO, a human-curated ChineseReading Comprehension dataset on Opinion. The questions in ReCO are opinion based queries issued to the commercial search engine. The passages are provided by the crowdworkers who extract the support snippet from the retrieved documents. Finally, an abstractive yes/no/uncertain answer was given by the crowdworkers. The release of ReCO consists of 300k questions that to our knowledge is the largest in Chinese reading comprehension. A prominent characteristic of ReCO is that in addition to the original context paragraph, we also provided the support evidence that could be directly used to answer the question. Quality analysis demonstrates the challenge of ReCO that requires various types of reasoning skills, such as causal inference, logical reasoning, etc. Current QA models that perform very well on many question answering problems, such as BERT, only achieve 77% accuracy on this dataset, a large margin behind humans nearly 92% performance, indicating ReCO presents a good challenge for machine reading comprehension. The codes, datasets are freely available at https://github.com/benywon/ReCO.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.12146v1"
	},
	{
		"title": "EEMEFN: Low‐Light Image Enhancement via Edge‐Enhanced Multi‐Exposure Fusion Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Unifying View on Individual Bounds and Heuristic Inaccuracies in Bidirectional Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "PSENet: Psoriasis Severity Evaluation Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Relation‐Guided Spatial Attention and Temporal Refinement for Video‐based Person Re‐Identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improved Subsampled Randomized Hadamard Transform for Linear SVM ",
		"abstract": "Subsampled Randomized Hadamard Transform (SRHT), a popular random projection method that can efficiently project a $d$-dimensional data into $r$-dimensional space ($r \\ll d$) in $O(dlog(d))$ time, has been widely used to address the challenge of high-dimensionality in machine learning. SRHT works by rotating the input data matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ by Randomized Walsh-Hadamard Transform followed with a subsequent uniform column sampling on the rotated matrix. Despite the advantages of SRHT, one limitation of SRHT is that it generates the new low-dimensional embedding without considering any specific properties of a given dataset. Therefore, this data-independent random projection method may result in inferior and unstable performance when used for a particular machine learning task, e.g., classification. To overcome this limitation, we analyze the effect of using SRHT for random projection in the context of linear SVM classification. Based on our analysis, we propose importance sampling and deterministic top-$r$ sampling to produce effective low-dimensional embedding instead of uniform sampling SRHT. In addition, we also proposed a new supervised non-uniform sampling method. Our experimental results have demonstrated that our proposed methods can achieve higher classification accuracies than SRHT and other random projection methods on six real-life datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01628v1"
	},
	{
		"title": "End‐to‐end Learning of Object Motion Estimation from Retinal Events for Event‐based Object Tracking ",
		"abstract": "Event cameras, which are asynchronous bio-inspired vision sensors, have shown great potential in computer vision and artificial intelligence. However, the application of event cameras to object-level motion estimation or tracking is still in its infancy. The main idea behind this work is to propose a novel deep neural network to learn and regress a parametric object-level motion/transform model for event-based object tracking. To achieve this goal, we propose a synchronous Time-Surface with Linear Time Decay (TSLTD) representation, which effectively encodes the spatio-temporal information of asynchronous retinal events into TSLTD frames with clear motion patterns. We feed the sequence of TSLTD frames to a novel Retinal Motion Regression Network (RMRNet) to perform an end-to-end 5-DoF object motion regression. Our method is compared with state-of-the-art object tracking methods, that are based on conventional cameras or event cameras. The experimental results show the superiority of our method in handling various challenging environments such as fast motion and low illumination conditions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.05911v1"
	},
	{
		"title": "Context Modulated Dynamic Networks for Actor and Action Video Segmentation with Language Queries ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dynamic Network Pruning with Interpretable Layerwise Channel Selection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Potential Passenger Flow Prediction: A Novel Study for Urban Transportation Development ",
		"abstract": "Recently, practical applications for passenger flow prediction have brought many benefits to urban transportation development. With the development of urbanization, a real-world demand from transportation managers is to construct a new metro station in one city area that never planned before. Authorities are interested in the picture of the future volume of commuters before constructing a new station, and estimate how would it affect other areas. In this paper, this specific problem is termed as potential passenger flow (PPF) prediction, which is a novel and important study connected with urban computing and intelligent transportation systems. For example, an accurate PPF predictor can provide invaluable knowledge to designers, such as the advice of station scales and influences on other areas, etc. To address this problem, we propose a multi-view localized correlation learning method. The core idea of our strategy is to learn the passenger flow correlations between the target areas and their localized areas with adaptive-weight. To improve the prediction accuracy, other domain knowledge is involved via a multi-view learning process. We conduct intensive experiments to evaluate the effectiveness of our method with real-world official transportation datasets. The results demonstrate that our method can achieve excellent performance compared with other available baselines. Besides, our method can provide an effective solution to the cold-start problem in the recommender system as well, which proved by its outperformed experimental results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.03440v1"
	},
	{
		"title": "SetRank: A Setwise Bayesian Approach for Collaborative Ranking from Implicit Feedback ",
		"abstract": "The recent development of online recommender systems has a focus on collaborative ranking from implicit feedback, such as user clicks and purchases. Different from explicit ratings, which reflect graded user preferences, the implicit feedback only generates positive and unobserved labels. While considerable efforts have been made in this direction, the well-known pairwise and listwise approaches have still been limited by various challenges. Specifically, for the pairwise approaches, the assumption of independent pairwise preference is not always held in practice. Also, the listwise approaches cannot efficiently accommodate \"ties\" due to the precondition of the entire list permutation. To this end, in this paper, we propose a novel setwise Bayesian approach for collaborative ranking, namely SetRank, to inherently accommodate the characteristics of implicit feedback in recommender system. Specifically, SetRank aims at maximizing the posterior probability of novel setwise preference comparisons and can be implemented with matrix factorization and neural networks. Meanwhile, we also present the theoretical analysis of SetRank to show that the bound of excess risk can be proportional to $\\sqrt{M/N}$, where $M$ and $N$ are the numbers of items and users, respectively. Finally, extensive experiments on four real-world datasets clearly validate the superiority of SetRank compared with various state-of-the-art baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.09841v1"
	},
	{
		"title": "Tell Me What They’re Holding: Weakly‐supervised Object Detection with Transferable Knowledge from Human‐object Interaction ",
		"abstract": "In this work, we introduce a novel weakly supervised object detection (WSOD) paradigm to detect objects belonging to rare classes that have not many examples using transferable knowledge from human-object interactions (HOI). While WSOD shows lower performance than full supervision, we mainly focus on HOI as the main context which can strongly supervise complex semantics in images. Therefore, we propose a novel module called RRPN (relational region proposal network) which outputs an object-localizing attention map only with human poses and action verbs. In the source domain, we fully train an object detector and the RRPN with full supervision of HOI. With transferred knowledge about localization map from the trained RRPN, a new object detector can learn unseen objects with weak verbal supervision of HOI without bounding box annotations in the target domain. Because the RRPN is designed as an add-on type, we can apply it not only to the object detection but also to other domains such as semantic segmentation. The experimental results on HICO-DET dataset show the possibility that the proposed method can be a cheap alternative for the current supervised object detection paradigm. Moreover, qualitative results demonstrate that our model can properly localize unseen objects on HICO-DET and V-COCO datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08141v1"
	},
	{
		"title": "Instance Enhancement Batch Normalization: An Adaptive Regulator of Batch Noise ",
		"abstract": "Batch Normalization (BN)(Ioffe and Szegedy 2015) normalizes the features of an input image via statistics of a batch of images and hence BN will bring the noise to the gradient of the training loss. Previous works indicate that the noise is important for the optimization and generalization of deep neural networks, but too much noise will harm the performance of networks. In our paper, we offer a new point of view that self-attention mechanism can help to regulate the noise by enhancing instance-specific information to obtain a better regularization effect. Therefore, we propose an attention-based BN called Instance Enhancement Batch Normalization (IEBN) that recalibrates the information of each channel by a simple linear transformation. IEBN has a good capacity of regulating noise and stabilizing network training to improve generalization even in the presence of two kinds of noise attacks during training. Finally, IEBN outperforms BN with only a light parameter increment in image classification tasks for different network structures and benchmark datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.04008v2"
	},
	{
		"title": "Unpaired Image Enhancement Featuring Reinforcement‐Learning‐Controlled Image Editing Software ",
		"abstract": "This paper tackles unpaired image enhancement, a task of learning a mapping function which transforms input images into enhanced images in the absence of input-output image pairs. Our method is based on generative adversarial networks (GANs), but instead of simply generating images with a neural network, we enhance images utilizing image editing software such as Adobe Photoshop for the following three benefits: enhanced images have no artifacts, the same enhancement can be applied to larger images, and the enhancement is interpretable. To incorporate image editing software into a GAN, we propose a reinforcement learning framework where the generator works as the agent that selects the software's parameters and is rewarded when it fools the discriminator. Our framework can use high-quality non-differentiable filters present in image editing software, which enables image enhancement with high performance. We apply the proposed method to two unpaired image enhancement tasks: photo enhancement and face beautification. Our experimental results demonstrate that the proposed method achieves better performance, compared to the performances of the state-of-the-art methods based on unpaired learning.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07833v1"
	},
	{
		"title": "Towards Omni‐Supervised Face Alignment for Large Scale Unlabeled Videos ",
		"abstract": "In this paper, we propose a spatial-temporal relational reasoning networks (STRRN) approach to investigate the problem of omni-supervised face alignment in videos. Unlike existing fully supervised methods which rely on numerous annotations by hand, our learner exploits large scale unlabeled videos plus available labeled data to generate auxiliary plausible training annotations. Motivated by the fact that neighbouring facial landmarks are usually correlated and coherent across consecutive frames, our approach automatically reasons about discriminative spatial-temporal relationships among landmarks for stable face tracking. Specifically, we carefully develop an interpretable and efficient network module, which disentangles facial geometry relationship for every static frame and simultaneously enforces the bi-directional cycle-consistency across adjacent frames, thus allowing the modeling of intrinsic spatial-temporal relations from raw face sequences. Extensive experimental results demonstrate that our approach surpasses the performance of most fully supervised state-of-the-arts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07243v1"
	},
	{
		"title": "Semantics‐Aligned Representation Learning for Person Re‐identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Segmenting Medical MRI via Recurrent Decoding Cell ",
		"abstract": "The encoder-decoder networks are commonly used in medical image segmentation due to their remarkable performance in hierarchical feature fusion. However, the expanding path for feature decoding and spatial recovery does not consider the long-term dependency when fusing feature maps from different layers, and the universal encoder-decoder network does not make full use of the multi-modality information to improve the network robustness especially for segmenting medical MRI. In this paper, we propose a novel feature fusion unit called Recurrent Decoding Cell (RDC) which leverages convolutional RNNs to memorize the long-term context information from the previous layers in the decoding phase. An encoder-decoder network, named Convolutional Recurrent Decoding Network (CRDN), is also proposed based on RDC for segmenting multi-modality medical MRI. CRDN adopts CNN backbone to encode image features and decode them hierarchically through a chain of RDCs to obtain the final high-resolution score map. The evaluation experiments on BrainWeb, MRBrainS and HVSMR datasets demonstrate that the introduction of RDC effectively improves the segmentation accuracy as well as reduces the model size, and the proposed CRDN owns its robustness to image noise and intensity non-uniformity in medical MRI.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09401v1"
	},
	{
		"title": "Graph LSTM with Context‐Gated Mechanism for Spoken Language Understanding ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Hide‐and‐Tell: Learning to Bridge Photo Streams for Visual Storytelling ",
		"abstract": "Visual storytelling is a task of creating a short story based on photo streams. Unlike existing visual captioning, storytelling aims to contain not only factual descriptions, but also human-like narration and semantics. However, the VIST dataset consists only of a small, fixed number of photos per story. Therefore, the main challenge of visual storytelling is to fill in the visual gap between photos with narrative and imaginative story. In this paper, we propose to explicitly learn to imagine a storyline that bridges the visual gap. During training, one or more photos is randomly omitted from the input stack, and we train the network to produce a full plausible story even with missing photo(s). Furthermore, we propose for visual storytelling a hide-and-tell model, which is designed to learn non-local relations across the photo streams and to refine and improve conventional RNN-based models. In experiments, we show that our scheme of hide-and-tell, and the network design are indeed effective at storytelling, and that our model outperforms previous state-of-the-art methods in automatic metrics. Finally, we qualitatively show the learned ability to interpolate storyline over visual gaps.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.00774v1"
	},
	{
		"title": "Symbiotic Attention with Privileged Information for Egocentric Action Recognition ",
		"abstract": "Egocentric video recognition is a natural testbed for diverse interaction reasoning. Due to the large action vocabulary in egocentric video datasets, recent studies usually utilize a two-branch structure for action recognition, ie, one branch for verb classification and the other branch for noun classification. However, correlation studies between the verb and the noun branches have been largely ignored. Besides, the two branches fail to exploit local features due to the absence of a position-aware attention mechanism. In this paper, we propose a novel Symbiotic Attention framework leveraging Privileged information (SAP) for egocentric video recognition. Finer position-aware object detection features can facilitate the understanding of actor's interaction with the object. We introduce these features in action recognition and regard them as privileged information. Our framework enables mutual communication among the verb branch, the noun branch, and the privileged information. This communication process not only injects local details into global features but also exploits implicit guidance about the spatio-temporal position of an on-going action. We introduce novel symbiotic attention (SA) to enable effective communication. It first normalizes the detection guided features on one branch to underline the action-relevant information from the other branch. SA adaptively enhances the interactions among the three sources. To further catalyze this communication, spatial relations are uncovered for the selection of most action-relevant information. It identifies the most valuable and discriminative feature for classification. We validate the effectiveness of our SAP quantitatively and qualitatively. Notably, it achieves the state-of-the-art on two large-scale egocentric video datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03137v1"
	},
	{
		"title": "Crowdfunding Dynamics Tracking: A Reinforcement Learning Approach ",
		"abstract": "Recent years have witnessed the increasing interests in research of crowdfunding mechanism. In this area, dynamics tracking is a significant issue but is still under exploration. Existing studies either fit the fluctuations of time-series or employ regularization terms to constrain learned tendencies. However, few of them take into account the inherent decision-making process between investors and crowdfunding dynamics. To address the problem, in this paper, we propose a Trajectory-based Continuous Control for Crowdfunding (TC3) algorithm to predict the funding progress in crowdfunding. Specifically, actor-critic frameworks are employed to model the relationship between investors and campaigns, where all of the investors are viewed as an agent that could interact with the environment derived from the real dynamics of campaigns. Then, to further explore the in-depth implications of patterns (i.e., typical characters) in funding series, we propose to subdivide them into $\\textit{fast-growing}$ and $\\textit{slow-growing}$ ones. Moreover, for the purpose of switching from different kinds of patterns, the actor component of TC3 is extended with a structure of options, which comes to the TC3-Options. Finally, extensive experiments on the Indiegogo dataset not only demonstrate the effectiveness of our methods, but also validate our assumption that the entire pattern learned by TC3-Options is indeed the U-shaped one.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.12016v1"
	},
	{
		"title": "Meta‐Learning for Generalized Zero‐Shot Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Intrinsically‐Motivated Approach for Learning Highly Exploring and Fast Mixing Policies ",
		"abstract": "What is a good exploration strategy for an agent that interacts with an environment in the absence of external rewards? Ideally, we would like to get a policy driving towards a uniform state-action visitation (highly exploring) in a minimum number of steps (fast mixing), in order to ease efficient learning of any goal-conditioned policy later on. Unfortunately, it is remarkably arduous to directly learn an optimal policy of this nature. In this paper, we propose a novel surrogate objective for learning highly exploring and fast mixing policies, which focuses on maximizing a lower bound to the entropy of the steady-state distribution induced by the policy. In particular, we introduce three novel lower bounds, that lead to as many optimization problems, that tradeoff the theoretical guarantees with computational complexity. Then, we present a model-based reinforcement learning algorithm, IDE$^{3}$AL, to learn an optimal policy according to the introduced objective. Finally, we provide an empirical evaluation of this algorithm on a set of hard-exploration tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.04662v2"
	},
	{
		"title": "Fine‐Tuning by Curriculum Learning for Non‐Autoregressive Neural Machine Translation ",
		"abstract": "Non-autoregressive translation (NAT) models remove the dependence on previous target tokens and generate all target tokens in parallel, resulting in significant inference speedup but at the cost of inferior translation accuracy compared to autoregressive translation (AT) models. Considering that AT models have higher accuracy and are easier to train than NAT models, and both of them share the same model configurations, a natural idea to improve the accuracy of NAT models is to transfer a well-trained AT model to an NAT model through fine-tuning. However, since AT and NAT models differ greatly in training strategy, straightforward fine-tuning does not work well. In this work, we introduce curriculum learning into fine-tuning for NAT. Specifically, we design a curriculum in the fine-tuning process to progressively switch the training from autoregressive generation to non-autoregressive generation. Experiments on four benchmark translation datasets show that the proposed method achieves good improvement (more than $1$ BLEU score) over previous NAT baselines in terms of translation accuracy, and greatly speed up (more than $10$ times) the inference process over AT baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08717v2"
	},
	{
		"title": "Learning from Weak‐Label Data: A Deep Forest Expedition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Knowledge Graph Grounded Goal Planning for Open‐Domain Conversation Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Rethinking the Bottom‐Up Framework for Query‐based Video Localization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Beliefs We Can Believe In: Replacing Assumptions with Data in Real‐Time Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Instance‐Adaptive Graph for EEG Emotion Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SNEQ: Semi‐supervised Attributed Network Embedding with Attention‐based Quantisation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Match on Graph for Fashion Compatibility Modeling ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Lifting Preferences over Alternatives to Preferences over Sets of Alternatives:  The Complexity of Recognizing Desirable Families of Sets ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DCMN+: Dual Co‐Matching Network for Multi‐choice Reading Comprehension ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Enhancing Personalized Trip Recommendation with Attractive Routes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reasoning on Knowledge Graphs with Debate Dynamics ",
		"abstract": "We propose a novel method for automatic reasoning on knowledge graphs based on debate dynamics. The main idea is to frame the task of triple classification as a debate game between two reinforcement learning agents which extract arguments -- paths in the knowledge graph -- with the goal to promote the fact being true (thesis) or the fact being false (antithesis), respectively. Based on these arguments, a binary classifier, called the judge, decides whether the fact is true or false. The two agents can be considered as sparse, adversarial feature generators that present interpretable evidence for either the thesis or the antithesis. In contrast to other black-box methods, the arguments allow users to get an understanding of the decision of the judge. Since the focus of this work is to create an explainable method that maintains a competitive predictive accuracy, we benchmark our method on the triple classification and link prediction task. Thereby, we find that our method outperforms several baselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also conduct a survey and find that the extracted arguments are informative for users.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.00461v1"
	},
	{
		"title": "Domain Conditioned Adaptation Network ",
		"abstract": "Tremendous research efforts have been made to thrive deep domain adaptation (DA) by seeking domain-invariant features. Most existing deep DA models only focus on aligning feature representations of task-specific layers across domains while integrating a totally shared convolutional architecture for source and target. However, we argue that such strongly-shared convolutional layers might be harmful for domain-specific feature learning when source and target data distribution differs to a large extent. In this paper, we relax a shared-convnets assumption made by previous DA methods and propose a Domain Conditioned Adaptation Network (DCAN), which aims to excite distinct convolutional channels with a domain conditioned channel attention mechanism. As a result, the critical low-level domain-dependent knowledge could be explored appropriately. As far as we know, this is the first work to explore the domain-wise convolutional channel activation for deep DA networks. Moreover, to effectively align high-level feature distributions across two domains, we further deploy domain conditioned feature correction blocks after task-specific layers, which will explicitly correct the domain discrepancy. Extensive experiments on three cross-domain benchmarks demonstrate the proposed approach outperforms existing methods by a large margin, especially on very tough cross-domain learning tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.06717v1"
	},
	{
		"title": "End‐to‐End Thorough Body Perception for Person Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Accelerating Column Generation via Flexible Dual Optimal Inequalities with Application to Entity Resolution ",
		"abstract": "In this paper, we introduce a new optimization approach to Entity Resolution. Traditional approaches tackle entity resolution with hierarchical clustering, which does not benefit from a formal optimization formulation. In contrast, we model entity resolution as correlation-clustering, which we treat as a weighted set-packing problem and write as an integer linear program (ILP). In this case sources in the input data correspond to elements and entities in output data correspond to sets/clusters. We tackle optimization of weighted set packing by relaxing integrality in our ILP formulation. The set of potential sets/clusters can not be explicitly enumerated, thus motivating optimization via column generation. In addition to the novel formulation, we also introduce new dual optimal inequalities (DOI), that we call flexible dual optimal inequalities, which tightly lower-bound dual variables during optimization and accelerate column generation. We apply our formulation to entity resolution (also called de-duplication of records), and achieve state-of-the-art accuracy on two popular benchmark datasets. The project page is available at the following url, https://github.com/lokhande-vishnu/EntityResolution",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05460v3"
	},
	{
		"title": "A Variational Autoencoder with Deep Embedding Model  for Generalized Zero‐Shot Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Distributed Stochastic Gradient Descent with Event‐Triggered Communication ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adversarial Localized Energy Networks for Structured Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "High Performance Depthwise and Pointwise Convolutions on Mobile Devices ",
		"abstract": "Lightweight convolutional neural networks (e.g., MobileNets) are specifically designed to carry out inference directly on mobile devices. Among the various lightweight models, depthwise convolution (DWConv) and pointwise convolution (PWConv) are their key operations. In this paper, we observe that the existing implementations of DWConv and PWConv are not well utilizing the ARM processors in the mobile devices, and exhibit lots of cache misses under multi-core and poor data reuse at register level. We propose techniques to re-optimize the implementations of DWConv and PWConv based on ARM architecture. Experimental results show that our implementation can respectively achieve a speedup of up to 5.5x and 2.1x against TVM (Chen et al. 2018) on DWConv and PWConv.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.02504v1"
	},
	{
		"title": "Learning to Optimize Variational Quantum Circuits to Solve Combinatorial Problems ",
		"abstract": "Quantum computing is a computational paradigm with the potential to outperform classical methods for a variety of problems. Proposed recently, the Quantum Approximate Optimization Algorithm (QAOA) is considered as one of the leading candidates for demonstrating quantum advantage in the near term. QAOA is a variational hybrid quantum-classical algorithm for approximately solving combinatorial optimization problems. The quality of the solution obtained by QAOA for a given problem instance depends on the performance of the classical optimizer used to optimize the variational parameters. In this paper, we formulate the problem of finding optimal QAOA parameters as a learning task in which the knowledge gained from solving training instances can be leveraged to find high-quality solutions for unseen test instances. To this end, we develop two machine-learning-based approaches. Our first approach adopts a reinforcement learning (RL) framework to learn a policy network to optimize QAOA circuits. Our second approach adopts a kernel density estimation (KDE) technique to learn a generative model of optimal QAOA parameters. In both approaches, the training procedure is performed on small-sized problem instances that can be simulated on a classical computer; yet the learned RL policy and the generative model can be used to efficiently solve larger problems. Extensive simulations using the IBM Qiskit Aer quantum circuit simulator demonstrate that our proposed RL- and KDE-based approaches reduce the optimality gap by factors up to 30.15 when compared with other commonly used off-the-shelf optimizers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11071v1"
	},
	{
		"title": "AtLoc: Attention Guided Camera Localization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Harnessing GANs for Zero‐Shot Learning of New Classes in Visual Speech Recognition ",
		"abstract": "Visual Speech Recognition (VSR) is the process of recognizing or interpreting speech by watching the lip movements of the speaker. Recent machine learning based approaches model VSR as a classification problem; however, the scarcity of training data leads to error-prone systems with very low accuracies in predicting unseen classes. To solve this problem, we present a novel approach to zero-shot learning by generating new classes using Generative Adversarial Networks (GANs), and show how the addition of unseen class samples increases the accuracy of a VSR system by a significant margin of 27% and allows it to handle speaker-independent out-of-vocabulary phrases. We also show that our models are language agnostic and therefore capable of seamlessly generating, using English training data, videos for a new language (Hindi). To the best of our knowledge, this is the first work to show empirical evidence of the use of GANs for generating training samples of unseen classes in the domain of VSR, hence facilitating zero-shot learning. We make the added videos for new classes publicly available along with our code.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.10139v4"
	},
	{
		"title": "Differentiable Grammars for Videos ",
		"abstract": "This paper proposes a novel algorithm which learns a formal regular grammar from real-world continuous data, such as videos. Learning latent terminals, non-terminals, and production rules directly from continuous data allows the construction of a generative model capturing sequential structures with multiple possibilities. Our model is fully differentiable, and provides easily interpretable results which are important in order to understand the learned structures. It outperforms the state-of-the-art on several challenging datasets and is more accurate for forecasting future activities in videos. We plan to open-source the code. https://sites.google.com/view/differentiable-grammars",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.00505v2"
	},
	{
		"title": "Learning Graph Convolutional Network for Skeleton‐based Human Action Recognition by Neural Searching ",
		"abstract": "Human action recognition from skeleton data, fueled by the Graph Convolutional Network (GCN), has attracted lots of attention, due to its powerful capability of modeling non-Euclidean structure data. However, many existing GCN methods provide a pre-defined graph and fix it through the entire network, which can loss implicit joint correlations. Besides, the mainstream spectral GCN is approximated by one-order hop, thus higher-order connections are not well involved. Therefore, huge efforts are required to explore a better GCN architecture. To address these problems, we turn to Neural Architecture Search (NAS) and propose the first automatically designed GCN for skeleton-based action recognition. Specifically, we enrich the search space by providing multiple dynamic graph modules after fully exploring the spatial-temporal correlations between nodes. Besides, we introduce multiple-hop modules and expect to break the limitation of representational capacity caused by one-order approximation. Moreover, a sampling- and memory-efficient evolution strategy is proposed to search an optimal architecture for this task. The resulted architecture proves the effectiveness of the higher-order approximation and the dynamic graph modeling mechanism with temporal interactions, which is barely discussed before. To evaluate the performance of the searched model, we conduct extensive experiments on two very large scaled datasets and the results show that our model gets the state-of-the-art results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04131v1"
	},
	{
		"title": "Importance‐Aware Learning for Neural Headline Editing ",
		"abstract": "Many social media news writers are not professionally trained. Therefore, social media platforms have to hire professional editors to adjust amateur headlines to attract more readers. We propose to automate this headline editing process through neural network models to provide more immediate writing support for these social media news writers. To train such a neural headline editing model, we collected a dataset which contains articles with original headlines and professionally edited headlines. However, it is expensive to collect a large number of professionally edited headlines. To solve this low-resource problem, we design an encoder-decoder model which leverages large scale pre-trained language models. We further improve the pre-trained model's quality by introducing a headline generation task as an intermediate task before the headline editing task. Also, we propose Self Importance-Aware (SIA) loss to address the different levels of editing in the dataset by down-weighting the importance of easily classified tokens and sentences. With the help of Pre-training, Adaptation, and SIA, the model learns to generate headlines in the professional editor's style. Experimental results show that our method significantly improves the quality of headline editing comparing against previous methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01114v1"
	},
	{
		"title": "Path Ranking with Attention to Type Hierarchies ",
		"abstract": "The objective of the knowledge base completion problem is to infer missing information from existing facts in a knowledge base. Prior work has demonstrated the effectiveness of path-ranking based methods, which solve the problem by discovering observable patterns in knowledge graphs, consisting of nodes representing entities and edges representing relations. However, these patterns either lack accuracy because they rely solely on relations or cannot easily generalize due to the direct use of specific entity information. We introduce Attentive Path Ranking, a novel path pattern representation that leverages type hierarchies of entities to both avoid ambiguity and maintain generalization. Then, we present an end-to-end trained attention-based RNN model to discover the new path patterns from data. Experiments conducted on benchmark knowledge base completion datasets WN18RR and FB15k-237 demonstrate that the proposed model outperforms existing methods on the fact prediction task by statistically significant margins of 26% and 10%, respectively. Furthermore, quantitative and qualitative analyses show that the path patterns balance between generalization and discrimination.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10799v3"
	},
	{
		"title": "Efficient Heterogeneous Collaborative Filtering without Negative Sampling for Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Structure Learning for Approximate Solution of Many‐Player Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fragmentation Coagulation Based Mixed Membership Stochastic Blockmodel ",
		"abstract": "The Mixed-Membership Stochastic Blockmodel~(MMSB) is proposed as one of the state-of-the-art Bayesian relational methods suitable for learning the complex hidden structure underlying the network data. However, the current formulation of MMSB suffers from the following two issues: (1), the prior information~(e.g. entities' community structural information) can not be well embedded in the modelling; (2), community evolution can not be well described in the literature. Therefore, we propose a non-parametric fragmentation coagulation based Mixed Membership Stochastic Blockmodel (fcMMSB). Our model performs entity-based clustering to capture the community information for entities and linkage-based clustering to derive the group information for links simultaneously. Besides, the proposed model infers the network structure and models community evolution, manifested by appearances and disappearances of communities, using the discrete fragmentation coagulation process (DFCP). By integrating the community structure with the group compatibility matrix we derive a generalized version of MMSB. An efficient Gibbs sampling scheme with Polya Gamma (PG) approach is implemented for posterior inference. We validate our model on synthetic and real world data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.00901v1"
	},
	{
		"title": "Atari‐HEAD: Atari Human Eye‐Tracking and Demonstration Dataset ",
		"abstract": "Large-scale public datasets have been shown to benefit research in multiple areas of modern artificial intelligence. For decision-making research that requires human data, high-quality datasets serve as important benchmarks to facilitate the development of new methods by providing a common reproducible standard. Many human decision-making tasks require visual attention to obtain high levels of performance. Therefore, measuring eye movements can provide a rich source of information about the strategies that humans use to solve decision-making tasks. Here, we provide a large-scale, high-quality dataset of human actions with simultaneously recorded eye movements while humans play Atari video games. The dataset consists of 117 hours of gameplay data from a diverse set of 20 games, with 8 million action demonstrations and 328 million gaze samples. We introduce a novel form of gameplay, in which the human plays in a semi-frame-by-frame manner. This leads to near-optimal game decisions and game scores that are comparable or better than known human records. We demonstrate the usefulness of the dataset through two simple applications: predicting human gaze and imitating human demonstrated actions. The quality of the data leads to promising results in both tasks. Moreover, using a learned human gaze model to inform imitation learning leads to an 115\\% increase in game performance. We interpret these results as highlighting the importance of incorporating human visual attention in models of decision making and demonstrating the value of the current dataset to the research community. We hope that the scale and quality of this dataset can provide more opportunities to researchers in the areas of visual attention, imitation learning, and reinforcement learning.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.06754v2"
	},
	{
		"title": "On the Generation of Medical Question‐Answer Pairs ",
		"abstract": "Question answering (QA) has achieved promising progress recently. However, answering a question in real-world scenarios like the medical domain is still challenging, due to the requirement of external knowledge and the insufficient quantity of high-quality training data. In the light of these challenges, we study the task of generating medical QA pairs in this paper. With the insight that each medical question can be considered as a sample from the latent distribution of questions given answers, we propose an automated medical QA pair generation framework, consisting of an unsupervised key phrase detector that explores unstructured material for validity, and a generator that involves a multi-pass decoder to integrate structural knowledge for diversity. A series of experiments have been conducted on a real-world dataset collected from the National Medical Licensing Examination of China. Both automatic evaluation and human annotation demonstrate the effectiveness of the proposed method. Further investigation shows that, by incorporating the generated QA pairs for training, significant improvement in terms of accuracy can be achieved for the examination QA system.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1811.00681v2"
	},
	{
		"title": "STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits ",
		"abstract": "We present a novel classifier network called STEP, to classify perceived human emotion from gaits, based on a Spatial Temporal Graph Convolutional Network (ST-GCN) architecture. Given an RGB video of an individual walking, our formulation implicitly exploits the gait features to classify the emotional state of the human into one of four emotions: happy, sad, angry, or neutral. We use hundreds of annotated real-world gait videos and augment them with thousands of annotated synthetic gaits generated using a novel generative network called STEP-Gen, built on an ST-GCN based Conditional Variational Autoencoder (CVAE). We incorporate a novel push-pull regularization loss in the CVAE formulation of STEP-Gen to generate realistic gaits and improve the classification accuracy of STEP. We also release a novel dataset (E-Gait), which consists of $2,177$ human gaits annotated with perceived emotions along with thousands of synthetic gaits. In practice, STEP can learn the affective features and exhibits classification accuracy of 89% on E-Gait, which is 14 - 30% more accurate over prior methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.12906v1"
	},
	{
		"title": "Regional Tree Regularization for Interpretability in Deep Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generalized and Sub‐Optimal Bipartite Constraints for Conflict‐Based Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Generalized Framework for Edge‐preserving and Structure‐preserving Image Smoothing ",
		"abstract": "Image smoothing is a fundamental procedure in applications of both computer vision and graphics. The required smoothing properties can be different or even contradictive among different tasks. Nevertheless, the inherent smoothing nature of one smoothing operator is usually fixed and thus cannot meet the various requirements of different applications. In this paper, a non-convex non-smooth optimization framework is proposed to achieve diverse smoothing natures where even contradictive smoothing behaviors can be achieved. To this end, we first introduce the truncated Huber penalty function which has seldom been used in image smoothing. A robust framework is then proposed. When combined with the strong flexibility of the truncated Huber penalty function, our framework is capable of a range of applications and can outperform the state-of-the-art approaches in several tasks. In addition, an efficient numerical solution is provided and its convergence is theoretically guaranteed even the optimization framework is non-convex and non-smooth. The effectiveness and superior performance of our approach are validated through comprehensive experimental results in a range of applications.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.09642v4"
	},
	{
		"title": "Plug‐In, Trainable Gate for Streamlining Arbitrary Neural Networks ",
		"abstract": "Architecture optimization, which is a technique for finding an efficient neural network that meets certain requirements, generally reduces to a set of multiple-choice selection problems among alternative sub-structures or parameters. The discrete nature of the selection problem, however, makes this optimization difficult. To tackle this problem we introduce a novel concept of a trainable gate function. The trainable gate function, which confers a differentiable property to discretevalued variables, allows us to directly optimize loss functions that include non-differentiable discrete values such as 0-1 selection. The proposed trainable gate can be applied to pruning. Pruning can be carried out simply by appending the proposed trainable gate functions to each intermediate output tensor followed by fine-tuning the overall model, using any gradient-based training methods. So the proposed method can jointly optimize the selection of the pruned channels while fine-tuning the weights of the pruned model at the same time. Our experimental results demonstrate that the proposed method efficiently optimizes arbitrary neural networks in various tasks such as image classification, style transfer, optical flow estimation, and neural machine translation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.10921v2"
	},
	{
		"title": "LCD: Learned Cross‐Domain Descriptors for 2D‐3D Matching ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Relation Network for Person Re‐identification ",
		"abstract": "Person re-identification (reID) aims at retrieving an image of the person of interest from a set of images typically captured by multiple cameras. Recent reID methods have shown that exploiting local features describing body parts, together with a global feature of a person image itself, gives robust feature representations, even in the case of missing body parts. However, using the individual part-level features directly, without considering relations between body parts, confuses differentiating identities of different persons having similar attributes in corresponding parts. To address this issue, we propose a new relation network for person reID that considers relations between individual body parts and the rest of them. Our model makes a single part-level feature incorporate partial information of other body parts as well, supporting it to be more discriminative. We also introduce a global contrastive pooling (GCP) method to obtain a global feature of a person image. We propose to use contrastive features for GCP to complement conventional max and averaging pooling techniques. We show that our model outperforms the state of the art on the Market1501, DukeMTMC-reID and CUHK03 datasets, demonstrating the effectiveness of our approach on discriminative person representations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09318v2"
	},
	{
		"title": "Towards Query‐Efficient Black‐Box Adversary with Zeroth‐Order Natural Gradient Descent  ",
		"abstract": "Despite the great achievements of the modern deep neural networks (DNNs), the vulnerability/robustness of state-of-the-art DNNs raises security concerns in many application domains requiring high reliability. Various adversarial attacks are proposed to sabotage the learning performance of DNN models. Among those, the black-box adversarial attack methods have received special attentions owing to their practicality and simplicity. Black-box attacks usually prefer less queries in order to maintain stealthy and low costs. However, most of the current black-box attack methods adopt the first-order gradient descent method, which may come with certain deficiencies such as relatively slow convergence and high sensitivity to hyper-parameter settings. In this paper, we propose a zeroth-order natural gradient descent (ZO-NGD) method to design the adversarial attacks, which incorporates the zeroth-order gradient estimation technique catering to the black-box attack scenario and the second-order natural gradient descent to achieve higher query efficiency. The empirical evaluations on image classification datasets demonstrate that ZO-NGD can obtain significantly lower model query complexities compared with state-of-the-art attack methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07891v1"
	},
	{
		"title": "Co‐occurrence Estimation from Aggregated Data with Auxiliary Information ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Certificated Model Robustness Against Weight Perturbations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Appearance and Motion Enhancement for Video‐based Person Re‐identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Variational Pathway Reasoning for EEG Emotion Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Topic Modeling on Document Networks with Adjacent‐Encoder ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "EAC‐Net: Efficient and Accurate Convolutional Network for  Video Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Regularized Training and Tight Certification for Randomized Smoothed Classifier with Provable Robustness ",
		"abstract": "Recently smoothing deep neural network based classifiers via isotropic Gaussian perturbation is shown to be an effective and scalable way to provide state-of-the-art probabilistic robustness guarantee against $\\ell_2$ norm bounded adversarial perturbations. However, how to train a good base classifier that is accurate and robust when smoothed has not been fully investigated. In this work, we derive a new regularized risk, in which the regularizer can adaptively encourage the accuracy and robustness of the smoothed counterpart when training the base classifier. It is computationally efficient and can be implemented in parallel with other empirical defense methods. We discuss how to implement it under both standard (non-adversarial) and adversarial training scheme. At the same time, we also design a new certification algorithm, which can leverage the regularization effect to provide tighter robustness lower bound that holds with high probability. Our extensive experimentation demonstrates the effectiveness of the proposed training and certification approaches on CIFAR-10 and ImageNet datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07246v1"
	},
	{
		"title": "Simple Pose: Rethinking and Improving  a Bottom‐up Approach for Multi‐Person Pose Estimation ",
		"abstract": "We rethink a well-know bottom-up approach for multi-person pose estimation and propose an improved one. The improved approach surpasses the baseline significantly thanks to (1) an intuitional yet more sensible representation, which we refer to as body parts to encode the connection information between keypoints, (2) an improved stacked hourglass network with attention mechanisms, (3) a novel focal L2 loss which is dedicated to hard keypoint and keypoint association (body part) mining, and (4) a robust greedy keypoint assignment algorithm for grouping the detected keypoints into individual poses. Our approach not only works straightforwardly but also outperforms the baseline by about 15% in average precision and is comparable to the state of the art on the MS-COCO test-dev dataset. The code and pre-trained models are publicly available online.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10529v1"
	},
	{
		"title": "Self‐Attention ConvLSTM for Spatiotemporal Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FlowScope: Spotting Money Laundering Based on Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Solving Set Cover  and Dominating Set via Partial MaxSAT ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MIPaaL: Mixed Integer Program as a Layer ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Idle Time Optimization for Target Assignment and Path Finding in Sortation Centers ",
		"abstract": "In this paper, we study the one-shot and lifelong versions of the Target Assignment and Path Finding problem in automated sortation centers, where each agent needs to constantly assign itself a sorting station, move to its assigned station without colliding with obstacles or other agents, wait in the queue of that station to obtain a parcel for delivery, and then deliver the parcel to a sorting bin. The throughput of such centers is largely determined by the total idle time of all stations since their queues can frequently become empty. To address this problem, we first formalize and study the one-shot version that assigns stations to a set of agents and finds collision-free paths for the agents to their assigned stations. We present efficient algorithms for this task based on a novel min-cost max-flow formulation that minimizes the total idle time of all stations in a fixed time window. We then demonstrate how our algorithms for solving the one-shot problem can be applied to solving the lifelong problem as well. Experimentally, we believe to be the first researchers to consider real-world automated sortation centers using an industrial simulator with realistic data and a kinodynamic model of real robots. On this simulator, we showcase the benefits of our algorithms by demonstrating their efficiency and effectiveness for up to 350 agents.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00253v1"
	},
	{
		"title": "DeepDualMapper: A Gated Fusion Network for Automatic Map Extraction using Aerial Images and Trajectories ",
		"abstract": "Automatic map extraction is of great importance to urban computing and location-based services. Aerial image and GPS trajectory data refer to two different data sources that could be leveraged to generate the map, although they carry different types of information. Most previous works on data fusion between aerial images and data from auxiliary sensors do not fully utilize the information of both modalities and hence suffer from the issue of information loss. We propose a deep convolutional neural network called DeepDualMapper which fuses the aerial image and trajectory data in a more seamless manner to extract the digital map. We design a gated fusion module to explicitly control the information flows from both modalities in a complementary-aware manner. Moreover, we propose a novel densely supervised refinement decoder to generate the prediction in a coarse-to-fine way. Our comprehensive experiments demonstrate that DeepDualMapper can fuse the information of images and trajectories much more effectively than existing approaches, and is able to generate maps with higher accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06832v1"
	},
	{
		"title": "Fastened CROWN: Tightened Neural Network Robustness Certificates ",
		"abstract": "The rapid growth of deep learning applications in real life is accompanied by severe safety concerns. To mitigate this uneasy phenomenon, much research has been done providing reliable evaluations of the fragility level in different deep neural networks. Apart from devising adversarial attacks, quantifiers that certify safeguarded regions have also been designed in the past five years. The summarizing work of Salman et al. unifies a family of existing verifiers under a convex relaxation framework. We draw inspiration from such work and further demonstrate the optimality of deterministic CROWN (Zhang et al. 2018) solutions in a given linear programming problem under mild constraints. Given this theoretical result, the computationally expensive linear programming based method is shown to be unnecessary. We then propose an optimization-based approach \\textit{FROWN} (\\textbf{F}astened C\\textbf{ROWN}): a general algorithm to tighten robustness certificates for neural networks. Extensive experiments on various networks trained individually verify the effectiveness of FROWN in safeguarding larger robust regions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00574v1"
	},
	{
		"title": "FusionDN: A Unified Densely Connected Network for Image Fusion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Rethinking the Image Fusion: A Fast Unified Image Fusion Network based on Proportional Maintenance of Gradient and Intensity ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Hierarchy‐Aware Knowledge Graph Embeddings for Link Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Spiking‐YOLO: Spiking Neural Network for Energy‐Efficient Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "All‐Pay Bidding Games on Graphs ",
		"abstract": "In this paper we introduce and study {\\em all-pay bidding games}, a class of two player, zero-sum games on graphs. The game proceeds as follows. We place a token on some vertex in the graph and assign budgets to the two players. Each turn, each player submits a sealed legal bid (non-negative and below their remaining budget), which is deducted from their budget and the highest bidder moves the token onto an adjacent vertex. The game ends once a sink is reached, and \\PO pays \\PT the outcome that is associated with the sink. The players attempt to maximize their expected outcome. Our games model settings where effort (of no inherent value) needs to be invested in an ongoing and stateful manner. On the negative side, we show that even in simple games on DAGs, optimal strategies may require a distribution over bids with infinite support. A central quantity in bidding games is the {\\em ratio} of the players budgets. On the positive side, we show a simple FPTAS for DAGs, that, for each budget ratio, outputs an approximation for the optimal strategy for that ratio. We also implement it, show that it performs well, and suggests interesting properties of these games. Then, given an outcome $c$, we show an algorithm for finding the necessary and sufficient initial ratio for guaranteeing outcome $c$ with probability~$1$ and a strategy ensuring such. Finally, while the general case has not previously been studied, solving the specific game in which \\PO wins iff he wins the first two auctions, has been long stated as an open question, which we solve.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08360v1"
	},
	{
		"title": "Absum: Simple Regularization Method for Reducing Structural Sensitivity of Convolutional Neural Networks ",
		"abstract": "We propose Absum, which is a regularization method for improving adversarial robustness of convolutional neural networks (CNNs). Although CNNs can accurately recognize images, recent studies have shown that the convolution operations in CNNs commonly have structural sensitivity to specific noise composed of Fourier basis functions. By exploiting this sensitivity, they proposed a simple black-box adversarial attack: Single Fourier attack. To reduce structural sensitivity, we can use regularization of convolution filter weights since the sensitivity of linear transform can be assessed by the norm of the weights. However, standard regularization methods can prevent minimization of the loss function because they impose a tight constraint for obtaining high robustness. To solve this problem, Absum imposes a loose constraint; it penalizes the absolute values of the summation of the parameters in the convolution layers. Absum can improve robustness against single Fourier attack while being as simple and efficient as standard regularization methods (e.g., weight decay and L1 regularization). Our experiments demonstrate that Absum improves robustness against single Fourier attack more than standard regularization methods. Furthermore, we reveal that robust CNNs with Absum are more robust against transferred attacks due to decreasing the common sensitivity and against high-frequency noise than standard regularization methods. We also reveal that Absum can improve robustness against gradient-based attacks (projected gradient descent) when used with adversarial training.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.08830v1"
	},
	{
		"title": "PHASEN: A Phase‐and‐Harmonics‐Aware Speech Enhancement Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fair Procedures for Fair Stable Marriage Outcomes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Unsupervised Domain Adaptation on Reading Comprehension ",
		"abstract": "Reading comprehension (RC) has been studied in a variety of datasets with the boosted performance brought by deep neural networks. However, the generalization capability of these models across different domains remains unclear. To alleviate this issue, we are going to investigate unsupervised domain adaptation on RC, wherein a model is trained on labeled source domain and to be applied to the target domain with only unlabeled samples. We first show that even with the powerful BERT contextual representation, the performance is still unsatisfactory when the model trained on one dataset is directly applied to another target dataset. To solve this, we provide a novel conditional adversarial self-training method (CASe). Specifically, our approach leverages a BERT model fine-tuned on the source dataset along with the confidence filtering to generate reliable pseudo-labeled samples in the target domain for self-training. On the other hand, it further reduces domain distribution discrepancy through conditional adversarial learning across domains. Extensive experiments show our approach achieves comparable accuracy to supervised models on multiple large-scale benchmark datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06137v5"
	},
	{
		"title": "AdaCare: Explainable Clinical Health Status Representation Learning via Scale‐Adaptive Feature Extraction and Recalibration ",
		"abstract": "Deep learning-based health status representation learning and clinical prediction have raised much research interest in recent years. Existing models have shown superior performance, but there are still several major issues that have not been fully taken into consideration. First, the historical variation pattern of the biomarker in diverse time scales plays a vital role in indicating the health status, but it has not been explicitly extracted by existing works. Second, key factors that strongly indicate the health risk are different among patients. It is still challenging to adaptively make use of the features for patients in diverse conditions. Third, using prediction models as the black box will limit the reliability in clinical practice. However, none of the existing works can provide satisfying interpretability and meanwhile achieve high prediction performance. In this work, we develop a general health status representation learning model, named AdaCare. It can capture the long and short-term variations of biomarkers as clinical features to depict the health status in multiple time scales. It also models the correlation between clinical features to enhance the ones which strongly indicate the health status and thus can maintain a state-of-the-art performance in terms of prediction accuracy while providing qualitative interpretability. We conduct a health risk prediction experiment on two real-world datasets. Experiment results indicate that AdaCare outperforms state-of-the-art approaches and provides effective interpretability, which is verifiable by clinical experts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12205v1"
	},
	{
		"title": "Going Deep: Graph Convolutional Ladder‐Shape Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Quadruply Stochastic Gradient Method for Large Scale Nonlinear Semi‐Supervised Ordinal Regression AUC Optimization ",
		"abstract": "Semi-supervised ordinal regression (S$^2$OR) problems are ubiquitous in real-world applications, where only a few ordered instances are labeled and massive instances remain unlabeled. Recent researches have shown that directly optimizing concordance index or AUC can impose a better ranking on the data than optimizing the traditional error rate in ordinal regression (OR) problems. In this paper, we propose an unbiased objective function for S$^2$OR AUC optimization based on ordinal binary decomposition approach. Besides, to handle the large-scale kernelized learning problems, we propose a scalable algorithm called QS$^3$ORAO using the doubly stochastic gradients (DSG) framework for functional optimization. Theoretically, we prove that our method can converge to the optimal solution at the rate of $O(1/t)$, where $t$ is the number of iterations for stochastic data sampling. Extensive experimental results on various benchmark and real-world datasets also demonstrate that our method is efficient and effective while retaining similar generalization performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11193v1"
	},
	{
		"title": "Safe Sample Screening for Robust Support Vector Machine ",
		"abstract": "Robust support vector machine (RSVM) has been shown to perform remarkably well to improve the generalization performance of support vector machine under the noisy environment. Unfortunately, in order to handle the non-convexity induced by ramp loss in RSVM, existing RSVM solvers often adopt the DC programming framework which is computationally inefficient for running multiple outer loops. This hinders the application of RSVM to large-scale problems. Safe sample screening that allows for the exclusion of training samples prior to or early in the training process is an effective method to greatly reduce computational time. However, existing safe sample screening algorithms are limited to convex optimization problems while RSVM is a non-convex problem. To address this challenge, in this paper, we propose two safe sample screening rules for RSVM based on the framework of concave-convex procedure (CCCP). Specifically, we provide screening rule for the inner solver of CCCP and another rule for propagating screened samples between two successive solvers of CCCP. To the best of our knowledge, this is the first work of safe sample screening to a non-convex optimization problem. More importantly, we provide the security guarantee to our sample screening rules to RSVM. Experimental results on a variety of benchmark datasets verify that our safe sample screening rules can significantly reduce the computational time.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11217v1"
	},
	{
		"title": "Exact and Efficient Inference for Collective Flow Diffusion Model via Minimum Convex Cost Flow Algorithm ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Divide‐and‐Conquer Learning with Nystr\\\"{o}m: Optimal Rate and Algorithm ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Off‐Policy Evaluation in Partially Observable Environments ",
		"abstract": "This work studies the problem of batch off-policy evaluation for Reinforcement Learning in partially observable environments. Off-policy evaluation under partial observability is inherently prone to bias, with risk of arbitrarily large errors. We define the problem of off-policy evaluation for Partially Observable Markov Decision Processes (POMDPs) and establish what we believe is the first off-policy evaluation result for POMDPs. In addition, we formulate a model in which observed and unobserved variables are decoupled into two dynamic processes, called a Decoupled POMDP. We show how off-policy evaluation can be performed under this new model, mitigating estimation errors inherent to general POMDPs. We demonstrate the pitfalls of off-policy evaluation in POMDPs using a well-known off-policy method, Importance Sampling, and compare it with our result on synthetic medical data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03739v3"
	},
	{
		"title": "Effective Data Augmentation with Multi‐Domain Learning GANs ",
		"abstract": "For deep learning applications, the massive data development (e.g., collecting, labeling), which is an essential process in building practical applications, still incurs seriously high costs. In this work, we propose an effective data augmentation method based on generative adversarial networks (GANs), called Domain Fusion. Our key idea is to import the knowledge contained in an outer dataset to a target model by using a multi-domain learning GAN. The multi-domain learning GAN simultaneously learns the outer and target dataset and generates new samples for the target tasks. The simultaneous learning process makes GANs generate the target samples with high fidelity and variety. As a result, we can obtain accurate models for the target tasks by using these generated samples even if we only have an extremely low volume target dataset. We experimentally evaluate the advantages of Domain Fusion in image classification tasks on 3 target datasets: CIFAR-100, FGVC-Aircraft, and Indoor Scene Recognition. When trained on each target dataset reduced the samples to 5,000 images, Domain Fusion achieves better classification accuracy than the data augmentation using fine-tuned GANs. Furthermore, we show that Domain Fusion improves the quality of generated samples, and the improvements can contribute to higher accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11597v1"
	},
	{
		"title": "Computing Team‐Maxmin Equilibria in Zero‐Sum Multiplayer Extensive‐Form Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Domain Generalization Using a Mixture of Multiple Latent Domains ",
		"abstract": "When domains, which represent underlying data distributions, vary during training and testing processes, deep neural networks suffer a drop in their performance. Domain generalization allows improvements in the generalization performance for unseen target domains by using multiple source domains. Conventional methods assume that the domain to which each sample belongs is known in training. However, many datasets, such as those collected via web crawling, contain a mixture of multiple latent domains, in which the domain of each sample is unknown. This paper introduces domain generalization using a mixture of multiple latent domains as a novel and more realistic scenario, where we try to train a domain-generalized model without using domain labels. To address this scenario, we propose a method that iteratively divides samples into latent domains via clustering, and which trains the domain-invariant feature extractor shared among the divided latent domains via adversarial learning. We assume that the latent domain of images is reflected in their style, and thus, utilize style features for clustering. By using these features, our proposed method successfully discovers latent domains and achieves domain generalization even if the domain labels are not given. Experiments show that our proposed method can train a domain-generalized model without using domain labels. Moreover, it outperforms conventional domain generalization methods, including those that utilize domain labels.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07661v1"
	},
	{
		"title": "Causally Denoise Word Embeddings Using Half‐Sibling Regression ",
		"abstract": "Distributional representations of words, also known as word vectors, have become crucial for modern natural language processing tasks due to their wide applications. Recently, a growing body of word vector postprocessing algorithm has emerged, aiming to render off-the-shelf word vectors even stronger. In line with these investigations, we introduce a novel word vector postprocessing scheme under a causal inference framework. Concretely, the postprocessing pipeline is realized by Half-Sibling Regression (HSR), which allows us to identify and remove confounding noise contained in word vectors. Compared to previous work, our proposed method has the advantages of interpretability and transparency due to its causal inference grounding. Evaluated on a battery of standard lexical-level evaluation tasks and downstream sentiment analysis tasks, our method reaches state-of-the-art performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10524v1"
	},
	{
		"title": "Model and Reinforcement Learning for Markov Games with Risk Preferences ",
		"abstract": "We motivate and propose a new model for non-cooperative Markov game which considers the interactions of risk-aware players. This model characterizes the time-consistent dynamic \"risk\" from both stochastic state transitions (inherent to the game) and randomized mixed strategies (due to all other players). An appropriate risk-aware equilibrium concept is proposed and the existence of such equilibria is demonstrated in stationary strategies by an application of Kakutani's fixed point theorem. We further propose a simulation-based Q-learning type algorithm for risk-aware equilibrium computation. This algorithm works with a special form of minimax risk measures which can naturally be written as saddle-point stochastic optimization problems, and covers many widely investigated risk measures. Finally, the almost sure convergence of this simulation-based algorithm to an equilibrium is demonstrated under some mild conditions. Our numerical experiments on a two player queuing game validate the properties of our model and algorithm, and demonstrate their worth and applicability in real life competitive decision-making.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.04882v2"
	},
	{
		"title": "Label Enhancement with Sample Correlations via Low‐Rank Representation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Discriminative CNN with Temporal Ensembling for Ambiguously‐Labeled Image Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Attentive User‐Engaged Adversarial Neural Network for Community Question Answering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Gradient Boosts the Approximate Vanishing Ideal ",
		"abstract": "In the last decade, the approximate vanishing ideal and its basis construction algorithms have been extensively studied in computer algebra and machine learning as a general model to reconstruct the algebraic variety on which noisy data approximately lie. In particular, the basis construction algorithms developed in machine learning are widely used in applications across many fields because of their monomial-order-free property; however, they lose many of the theoretical properties of computer-algebraic algorithms. In this paper, we propose general methods that equip monomial-order-free algorithms with several advantageous theoretical properties. Specifically, we exploit the gradient to (i) sidestep the spurious vanishing problem in polynomial time to remove symbolically trivial redundant bases, (ii) achieve consistent output with respect to the translation and scaling of input, and (iii) remove nontrivially redundant bases. The proposed methods work in a fully numerical manner, whereas existing algorithms require the awkward monomial order or exponentially costly (and mostly symbolic) computation to realize properties (i) and (iii). To our knowledge, property (ii) has not been achieved by any existing basis construction algorithm of the approximate vanishing ideal.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04174v1"
	},
	{
		"title": "Show, Recall, and Tell: Image Captioning with Recall Mechanism ",
		"abstract": "Generating natural and accurate descriptions in image cap-tioning has always been a challenge. In this paper, we pro-pose a novel recall mechanism to imitate the way human con-duct captioning. There are three parts in our recall mecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS). Recall unit is a text-retrieval module designedto retrieve recalled words for images. SG and RWS are de-signed for the best use of recalled words. SG branch cangenerate a recalled context, which can guide the process ofgenerating caption. RWS branch is responsible for copyingrecalled words to the caption. Inspired by pointing mecha-nism in text summarization, we adopt a soft switch to balancethe generated-word probabilities between SG and RWS. Inthe CIDEr optimization step, we also introduce an individualrecalled-word reward (WR) to boost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr / SPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 / 22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the results of other state-of-the-artmethods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.05876v3"
	},
	{
		"title": "Knowledge Graph Alignment Network with Gated Multi‐hop Neighborhood Aggregation ",
		"abstract": "Graph neural networks (GNNs) have emerged as a powerful paradigm for embedding-based entity alignment due to their capability of identifying isomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart entities usually have non-isomorphic neighborhood structures, which easily causes GNNs to yield different representations for them. To tackle this problem, we propose a new KG alignment network, namely AliNet, aiming at mitigating the non-isomorphism of neighborhood structures in an end-to-end manner. As the direct neighbors of counterpart entities are usually dissimilar due to the schema heterogeneity, AliNet introduces distant neighbors to expand the overlap between their neighborhood structures. It employs an attention mechanism to highlight helpful distant neighbors and reduce noises. Then, it controls the aggregation of both direct and distant neighborhood information using a gating mechanism. We further propose a relation loss to refine entity representations. We perform thorough experiments with detailed ablation studies and analyses on five entity alignment datasets, demonstrating the effectiveness of AliNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08936v1"
	},
	{
		"title": "Online Metric Learning for Multi‐Label Classification ",
		"abstract": "Existing research into online multi-label classification, such as online sequential multi-label extreme learning machine (OSML-ELM) and stochastic gradient descent (SGD), has achieved promising performance. However, these works do not take label dependencies into consideration and lack a theoretical analysis of loss functions. Accordingly, we propose a novel online metric learning paradigm for multi-label classification to fill the current research gap. Generally, we first propose a new metric for multi-label classification which is based on $k$-Nearest Neighbour ($k$NN) and combined with large margin principle. Then, we adapt it to the online settting to derive our model which deals with massive volume ofstreaming data at a higher speed online. Specifically, in order to learn the new $k$NN-based metric, we first project instances in the training dataset into the label space, which make it possible for the comparisons of instances and labels in the same dimension. After that, we project both of them into a new lower dimension space simultaneously, which enables us to extract the structure of dependencies between instances and labels. Finally, we leverage the large margin and $k$NN principle to learn the metric with an efficient optimization algorithm. Moreover, we provide theoretical analysis on the upper bound of the cumulative loss for our method. Comprehensive experiments on a number of benchmark multi-label datasets validate our theoretical approach and illustrate that our proposed online metric learning (OML) algorithm outperforms state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.07092v1"
	},
	{
		"title": "LTLf Synthesis with Fairness and Stability Assumptions ",
		"abstract": "In synthesis, assumptions are constraints on the environment that rule out certain environment behaviors. A key observation here is that even if we consider systems with LTLf goals on finite traces, environment assumptions need to be expressed over infinite traces, since accomplishing the agent goals may require an unbounded number of environment action. To solve synthesis with respect to finite-trace LTLf goals under infinite-trace assumptions, we could reduce the problem to LTL synthesis. Unfortunately, while synthesis in LTLf and in LTL have the same worst-case complexity (both 2EXPTIME-complete), the algorithms available for LTL synthesis are much more difficult in practice than those for LTLf synthesis. In this work we show that in interesting cases we can avoid such a detour to LTL synthesis and keep the simplicity of LTLf synthesis. Specifically, we develop a BDD-based fixpoint-based technique for handling basic forms of fairness and of stability assumptions. We show, empirically, that this technique performs much better than standard LTL synthesis.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07804v1"
	},
	{
		"title": "Relation‐Aware Pedestrian Attribute Recognition with Graph Convolutional Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Scalable Probabilistic Matrix Factorization with Graph‐Based Priors ",
		"abstract": "In matrix factorization, available graph side-information may not be well suited for the matrix completion problem, having edges that disagree with the latent-feature relations learnt from the incomplete data matrix. We show that removing these $\\textit{contested}$ edges improves prediction accuracy and scalability. We identify the contested edges through a highly-efficient graphical lasso approximation. The identification and removal of contested edges adds no computational complexity to state-of-the-art graph-regularized matrix factorization, remaining linear with respect to the number of non-zeros. Computational load even decreases proportional to the number of edges removed. Formulating a probabilistic generative model and using expectation maximization to extend graph-regularised alternating least squares (GRALS) guarantees convergence. Rich simulated experiments illustrate the desired properties of the resulting algorithm. On real data experiments we demonstrate improved prediction accuracy with fewer graph edges (empirical evidence that graph side-information is often inaccurate). A 300 thousand dimensional graph with three million edges (Yahoo music side-information) can be analyzed in under ten minutes on a standard laptop computer demonstrating the efficiency of our graph update.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.09393v2"
	},
	{
		"title": "Graph‐based Transformer with Cross‐candidate Verification for Semantic Parsing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Balancing Spreads of Influence in a Social Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Recovering Causal Structures from Low‐Order Conditional Independencies ",
		"abstract": "One of the common obstacles for learning causal models from data is that high-order conditional independence (CI) relationships between random variables are difficult to estimate. Since CI tests with conditioning sets of low order can be performed accurately even for a small number of observations, a reasonable approach to determine casual structures is to base merely on the low-order CIs. Recent research has confirmed that, e.g. in the case of sparse true causal models, structures learned even from zero- and first-order conditional independencies yield good approximations of the models. However, a challenging task here is to provide methods that faithfully explain a given set of low-order CIs. In this paper, we propose an algorithm which, for a given set of conditional independencies of order less or equal to $k$, where $k$ is a small fixed number, computes a faithful graphical representation of the given set. Our results complete and generalize the previous work on learning from pairwise marginal independencies. Moreover, they enable to improve upon the 0-1 graph model which, e.g. is heavily used in the estimation of genome networks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2010.02675v1"
	},
	{
		"title": "CAWA: An Attention‐Network for Credit Attribution ",
		"abstract": "Credit attribution is the task of associating individual parts in a document with their most appropriate class labels. It is an important task with applications to information retrieval and text summarization. When labeled training data is available, traditional approaches for sequence tagging can be used for credit attribution. However, generating such labeled datasets is expensive and time-consuming. In this paper, we present \"Credit Attribution With Attention (CAWA)\", a neural-network-based approach, that instead of using sentence-level labeled data, uses the set of class labels that are associated with an entire document as a source of distant-supervision. CAWA combines an attention mechanism with a multilabel classifier into an end-to-end learning framework to perform credit attribution. CAWA labels the individual sentences from the input document using the resultant attention-weights. CAWA improves upon the state-of-the-art credit attribution approach by not constraining a sentence to belong to just one class, but modeling each sentence as a distribution over all classes, leading to better modeling of semantically-similar classes. Experiments on the credit attribution task on a variety of datasets show that the sentence class labels generated by CAWA outperform the competing approaches. Additionally, on the multilabel text classification task, CAWA performs better than the competing credit attribution approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11358v1"
	},
	{
		"title": "Learned Video Compression via Joint Spatial‐Temporal Correlation Exploration ",
		"abstract": "Traditional video compression technologies have been developed over decades in pursuit of higher coding efficiency. Efficient temporal information representation plays a key role in video coding. Thus, in this paper, we propose to exploit the temporal correlation using both first-order optical flow and second-order flow prediction. We suggest an one-stage learning approach to encapsulate flow as quantized features from consecutive frames which is then entropy coded with adaptive contexts conditioned on joint spatial-temporal priors to exploit second-order correlations. Joint priors are embedded in autoregressive spatial neighbors, co-located hyper elements and temporal neighbors using ConvLSTM recurrently. We evaluate our approach for the low-delay scenario with High-Efficiency Video Coding (H.265/HEVC), H.264/AVC and another learned video compression method, following the common test settings. Our work offers the state-of-the-art performance, with consistent gains across all popular test sequences.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06348v1"
	},
	{
		"title": "JSNet: Joint Instance and Semantic Segmentation of 3D Point Clouds ",
		"abstract": "In this paper, we propose a novel joint instance and semantic segmentation approach, which is called JSNet, in order to address the instance and semantic segmentation of 3D point clouds simultaneously. Firstly, we build an effective backbone network to extract robust features from the raw point clouds. Secondly, to obtain more discriminative features, a point cloud feature fusion module is proposed to fuse the different layer features of the backbone network. Furthermore, a joint instance semantic segmentation module is developed to transform semantic features into instance embedding space, and then the transformed features are further fused with instance features to facilitate instance segmentation. Meanwhile, this module also aggregates instance features into semantic feature space to promote semantic segmentation. Finally, the instance predictions are generated by applying a simple mean-shift clustering on instance embeddings. As a result, we evaluate the proposed JSNet on a large-scale 3D indoor point cloud dataset S3DIS and a part dataset ShapeNet, and compare it with existing approaches. Experimental results demonstrate our approach outperforms the state-of-the-art method in 3D instance segmentation with a significant improvement in 3D semantic prediction and our method is also beneficial for part segmentation. The source code for this work is available at https://github.com/dlinzhao/JSNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.09654v1"
	},
	{
		"title": "Self‐Attention Enhanced Selective Gate with Entity‐Aware Embedding for Distantly Supervised Relation Extraction ",
		"abstract": "Distantly supervised relation extraction intrinsically suffers from noisy labels due to the strong assumption of distant supervision. Most prior works adopt a selective attention mechanism over sentences in a bag to denoise from wrongly labeled data, which however could be incompetent when there is only one sentence in a bag. In this paper, we propose a brand-new light-weight neural framework to address the distantly supervised relation extraction problem and alleviate the defects in previous selective attention framework. Specifically, in the proposed framework, 1) we use an entity-aware word embedding method to integrate both relative position information and head/tail entity embeddings, aiming to highlight the essence of entities for this task; 2) we develop a self-attention mechanism to capture the rich contextual dependencies as a complement for local dependencies captured by piecewise CNN; and 3) instead of using selective attention, we design a pooling-equipped gate, which is based on rich contextual representations, as an aggregator to generate bag-level representation for final relation classification. Compared to selective attention, one major advantage of the proposed gating mechanism is that, it performs stably and promisingly even if only one sentence appears in a bag and thus keeps the consistency across all training examples. The experiments on NYT dataset demonstrate that our approach achieves a new state-of-the-art performance in terms of both AUC and top-n precision metrics.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11899v1"
	},
	{
		"title": "Dynamic Reward‐based Dueling Deep Dyna‐Q:  Robust Policy Learning in Noisy Environments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Explaining Propagators for String Edit Distance Constraints ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Planar Prior Assisted PatchMatch Multi‐View Stereo ",
		"abstract": "The completeness of 3D models is still a challenging problem in multi-view stereo (MVS) due to the unreliable photometric consistency in low-textured areas. Since low-textured areas usually exhibit strong planarity, planar models are advantageous to the depth estimation of low-textured areas. On the other hand, PatchMatch multi-view stereo is very efficient for its sampling and propagation scheme. By taking advantage of planar models and PatchMatch multi-view stereo, we propose a planar prior assisted PatchMatch multi-view stereo framework in this paper. In detail, we utilize a probabilistic graphical model to embed planar models into PatchMatch multi-view stereo and contribute a novel multi-view aggregated matching cost. This novel cost takes both photometric consistency and planar compatibility into consideration, making it suited for the depth estimation of both non-planar and planar regions. Experimental results demonstrate that our method can efficiently recover the depth information of extremely low-textured areas, thus obtaining high complete 3D models and achieving state-of-the-art performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11744v1"
	},
	{
		"title": "Learning Inverse Depth Regression for Multi‐View Stereo with Correlation Cost Volume ",
		"abstract": "Deep learning has shown to be effective for depth inference in multi-view stereo (MVS). However, the scalability and accuracy still remain an open problem in this domain. This can be attributed to the memory-consuming cost volume representation and inappropriate depth inference. Inspired by the group-wise correlation in stereo matching, we propose an average group-wise correlation similarity measure to construct a lightweight cost volume. This can not only reduce the memory consumption but also reduce the computational burden in the cost volume filtering. Based on our effective cost volume representation, we propose a cascade 3D U-Net module to regularize the cost volume to further boost the performance. Unlike the previous methods that treat multi-view depth inference as a depth regression problem or an inverse depth classification problem, we recast multi-view depth inference as an inverse depth regression task. This allows our network to achieve sub-pixel estimation and be applicable to large-scale scenes. Through extensive experiments on DTU dataset and Tanks and Temples dataset, we show that our proposed network with Correlation cost volume and Inverse DEpth Regression (CIDER), achieves state-of-the-art results, demonstrating its superior performance on scalability and accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11746v1"
	},
	{
		"title": "Real‐Time Object Tracking via Meta‐Learning: Efficient Model Adaptation and One‐Shot Channel Pruning ",
		"abstract": "We propose a novel meta-learning framework for real-time object tracking with efficient model adaptation and channel pruning. Given an object tracker, our framework learns to fine-tune its model parameters in only a few iterations of gradient-descent during tracking while pruning its network channels using the target ground-truth at the first frame. Such a learning problem is formulated as a meta-learning task, where a meta-tracker is trained by updating its meta-parameters for initial weights, learning rates, and pruning masks through carefully designed tracking simulations. The integrated meta-tracker greatly improves tracking performance by accelerating the convergence of online learning and reducing the cost of feature computation. Experimental evaluation on the standard datasets demonstrates its outstanding accuracy and speed compared to the state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11170v3"
	},
	{
		"title": "Symmetrical Synthesis for Deep Metric Learning ",
		"abstract": "Deep metric learning aims to learn embeddings that contain semantic similarity information among data points. To learn better embeddings, methods to generate synthetic hard samples have been proposed. Existing methods of synthetic hard sample generation are adopting autoencoders or generative adversarial networks, but this leads to more hyper-parameters, harder optimization, and slower training speed. In this paper, we address these problems by proposing a novel method of synthetic hard sample generation called symmetrical synthesis. Given two original feature points from the same class, the proposed method firstly generates synthetic points with each other as an axis of symmetry. Secondly, it performs hard negative pair mining within the original and synthetic points to select a more informative negative pair for computing the metric learning loss. Our proposed method is hyper-parameter free and plug-and-play for existing metric learning losses without network modification. We demonstrate the superiority of our proposed method over existing methods for a variety of loss functions on clustering and image retrieval tasks. Our implementations is publicly available.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.11658v3"
	},
	{
		"title": "Understanding and Improving Proximity Graph based Maximum Inner Product Search ",
		"abstract": "The inner-product navigable small world graph (ip-NSW) represents the state-of-the-art method for approximate maximum inner product search (MIPS) and it can achieve an order of magnitude speedup over the fastest baseline. However, to date it is still unclear where its exceptional performance comes from. In this paper, we show that there is a strong norm bias in the MIPS problem, which means that the large norm items are very likely to become the result of MIPS. Then we explain the good performance of ip-NSW as matching the norm bias of the MIPS problem - large norm items have big in-degrees in the ip-NSW proximity graph and a walk on the graph spends the majority of computation on these items, thus effectively avoids unnecessary computation on small norm items. Furthermore, we propose the ip-NSW+ algorithm, which improves ip-NSW by introducing an additional angular proximity graph. Search is first conducted on the angular graph to find the angular neighbors of a query and then the MIPS neighbors of these angular neighbors are used to initialize the candidate pool for search on the inner-product proximity graph. Experiment results show that ip-NSW+ consistently and significantly outperforms ip-NSW and provides more robust performance under different data distributions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.13459v2"
	},
	{
		"title": "Norm‐Explicit Quantization: Improving Vector Quantization for Maximum Inner Product Search ",
		"abstract": "Vector quantization (VQ) techniques are widely used in similarity search for data compression, fast metric computation and etc. Originally designed for Euclidean distance, existing VQ techniques (e.g., PQ, AQ) explicitly or implicitly minimize the quantization error. In this paper, we present a new angle to analyze the quantization error, which decomposes the quantization error into norm error and direction error. We show that quantization errors in norm have much higher influence on inner products than quantization errors in direction, and small quantization error does not necessarily lead to good performance in maximum inner product search (MIPS). Based on this observation, we propose norm-explicit quantization (NEQ) --- a general paradigm that improves existing VQ techniques for MIPS. NEQ quantizes the norms of items in a dataset explicitly to reduce errors in norm, which is crucial for MIPS. For the direction vectors, NEQ can simply reuse an existing VQ technique to quantize them without modification. We conducted extensive experiments on a variety of datasets and parameter configurations. The experimental results show that NEQ improves the performance of various VQ techniques for MIPS, including PQ, OPQ, RQ and AQ.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04654v2"
	},
	{
		"title": "An Attentional Recurrent Neural Network for Personalized Next Location Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Measuring and Relieving the Over‐smoothing Problem for Graph Neural Networks from the Topological View ",
		"abstract": "Graph Neural Networks (GNNs) have achieved promising performance on a wide range of graph-based tasks. Despite their success, one severe limitation of GNNs is the over-smoothing issue (indistinguishable representations of nodes in different classes). In this work, we present a systematic and quantitative study on the over-smoothing issue of GNNs. First, we introduce two quantitative metrics, MAD and MADGap, to measure the smoothness and over-smoothness of the graph nodes representations, respectively. Then, we verify that smoothing is the nature of GNNs and the critical factor leading to over-smoothness is the low information-to-noise ratio of the message received by the nodes, which is partially determined by the graph topology. Finally, we propose two methods to alleviate the over-smoothing issue from the topological view: (1) MADReg which adds a MADGap-based regularizer to the training objective;(2) AdaGraph which optimizes the graph topology based on the model predictions. Extensive experiments on 7 widely-used graph datasets with 10 typical GNN models show that the two proposed methods are effective for relieving the over-smoothing issue, thus improving the performance of various GNN models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03211v2"
	},
	{
		"title": "Multi‐type Resource Allocation with Partial Preferences ",
		"abstract": "We propose multi-type probabilistic serial (MPS) and multi-type random priority (MRP) as extensions of the well known PS and RP mechanisms to the multi-type resource allocation problem (MTRA) with partial preferences. In our setting, there are multiple types of divisible items, and a group of agents who have partial order preferences over bundles consisting of one item of each type. We show that for the unrestricted domain of partial order preferences, no mechanism satisfies both sd-efficiency and sd-envy-freeness. Notwithstanding this impossibility result, our main message is positive: When agents' preferences are represented by acyclic CP-nets, MPS satisfies sd-efficiency, sd-envy-freeness, ordinal fairness, and upper invariance, while MRP satisfies ex-post-efficiency, sd-strategy-proofness, and upper invariance, recovering the properties of PS and RP.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.06836v3"
	},
	{
		"title": "Unsupervised Neural Dialect Translation with Commonality and Diversity Modeling ",
		"abstract": "As a special machine translation task, dialect translation has two main characteristics: 1) lack of parallel training corpus; and 2) possessing similar grammar between two sides of the translation. In this paper, we investigate how to exploit the commonality and diversity between dialects thus to build unsupervised translation models merely accessing to monolingual data. Specifically, we leverage pivot-private embedding, layer coordination, as well as parameter sharing to sufficiently model commonality and diversity among source and target, ranging from lexical, through syntactic, to semantic levels. In order to examine the effectiveness of the proposed models, we collect 20 million monolingual corpus for each of Mandarin and Cantonese, which are official language and the most widely used dialect in China. Experimental results reveal that our methods outperform rule-based simplified and traditional Chinese conversion and conventional unsupervised translation models over 12 BLEU scores.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05134v1"
	},
	{
		"title": "Weakly‐Supervised Video Re‐Localization with Multiscale Attention Model ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Complexity of Computing the Shapley Value in Games with Externalities ",
		"abstract": "We study the complexity of computing the Shapley value in games with externalities. We focus on two representations based on marginal contribution nets (embedded MC-nets and weighted MC-nets). Our results show that while weighted MC-nets are more concise than embedded MC-nets, they have slightly worse computational properties when it comes to computing the Shapley value.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.01769v1"
	},
	{
		"title": "Towards Accurate Low Bit‐width Quantization with Multiple Phase Adaptations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Global Context‐Aware Progressive Aggregation Network for Salient Object Detection ",
		"abstract": "Deep convolutional neural networks have achieved competitive performance in salient object detection, in which how to learn effective and comprehensive features plays a critical role. Most of the previous works mainly adopted multiple level feature integration yet ignored the gap between different features. Besides, there also exists a dilution process of high-level features as they passed on the top-down pathway. To remedy these issues, we propose a novel network named GCPANet to effectively integrate low-level appearance features, high-level semantic features, and global context features through some progressive context-aware Feature Interweaved Aggregation (FIA) modules and generate the saliency map in a supervised way. Moreover, a Head Attention (HA) module is used to reduce information redundancy and enhance the top layers features by leveraging the spatial and channel-wise attention, and the Self Refinement (SR) module is utilized to further refine and heighten the input features. Furthermore, we design the Global Context Flow (GCF) module to generate the global context information at different stages, which aims to learn the relationship among different salient regions and alleviate the dilution effect of high-level features. Experimental results on six benchmark datasets demonstrate that the proposed approach outperforms the state-of-the-art methods both quantitatively and qualitatively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00651v1"
	},
	{
		"title": "Aggregated Learning: A Vector‐Quantization Approach to Learning Neural Network Classifiers ",
		"abstract": "We consider the problem of learning a neural network classifier. Under the information bottleneck (IB) principle, we associate with this classification problem a representation learning problem, which we call \"IB learning\". We show that IB learning is, in fact, equivalent to a special class of the quantization problem. The classical results in rate-distortion theory then suggest that IB learning can benefit from a \"vector quantization\" approach, namely, simultaneously learning the representations of multiple input objects. Such an approach assisted with some variational techniques, result in a novel learning framework, \"Aggregated Learning\", for classification with neural network models. In this framework, several objects are jointly classified by a single neural network. The effectiveness of this framework is verified through extensive experiments on standard image recognition and text classification tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.03955v3"
	},
	{
		"title": "Mechanism Design with Predicted Task Revenue for Bike Sharing Systems ",
		"abstract": "Bike sharing systems have been widely deployed around the world in recent years. A core problem in such systems is to reposition the bikes so that the distribution of bike supply is reshaped to better match the dynamic bike demand. When the bike-sharing company or platform is able to predict the revenue of each reposition task based on historic data, an additional constraint is to cap the payment for each task below its predicted revenue. In this paper, we propose an incentive mechanism called {\\em TruPreTar} to incentivize users to park bicycles at locations desired by the platform toward rebalancing supply and demand. TruPreTar possesses four important economic and computational properties such as truthfulness and budget feasibility. Furthermore, we prove that even when the payment budget is tight, the total revenue still exceeds or equals the budget. Otherwise, TruPreTar achieves 2-approximation as compared to the optimal (revenue-maximizing) solution, which is close to the lower bound of at least $\\sqrt{2}$ that we also prove. Using an industrial dataset obtained from a large bike-sharing company, our experiments show that TruPreTar is effective in rebalancing bike supply and demand and, as a result, generates high revenue that outperforms several benchmark mechanisms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07706v3"
	},
	{
		"title": " ODIN: ODE‐Informed Regression for Parameter and State Inference in Time‐Continuous Dynamical Systems  ",
		"abstract": "Parameter inference in ordinary differential equations is an important problem in many applied sciences and in engineering, especially in a data-scarce setting. In this work, we introduce a novel generative modeling approach based on constrained Gaussian processes and leverage it to build a computationally and data efficient algorithm for state and parameter inference. In an extensive set of experiments, our approach outperforms the current state of the art for parameter inference both in terms of accuracy and computational cost. It also shows promising results for the much more challenging problem of model selection.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.06278v3"
	},
	{
		"title": "Capturing Sentence Relations for Answer Sentence Selection with Multi‐Perspective Graph Encoding ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multiple Birds with One Stone: Beating 1/2 for EFX and GMMS via Envy Cycle Elimination ",
		"abstract": "Several relaxations of envy-freeness, tailored to fair division in settings with indivisible goods, have been introduced within the last decade. Due to the lack of general existence results for most of these concepts, great attention has been paid to establishing approximation guarantees. In this work, we propose a simple algorithm that is universally fair in the sense that it returns allocations that have good approximation guarantees with respect to four such fairness notions at once. In particular, this is the first algorithm achieving a $(\\phi-1)$-approximation of envy-freeness up to any good (EFX) and a $\\frac{2}{\\phi +2}$-approximation of groupwise maximin share fairness (GMMS), where $\\phi$ is the golden ratio ($\\phi \\approx 1.618$). The best known approximation factor for either one of these fairness notions prior to this work was $1/2$. Moreover, the returned allocation achieves envy-freeness up to one good (EF1) and a $2/3$-approximation of pairwise maximin share fairness (PMMS). While EFX is our primary focus, we also exhibit how to fine-tune our algorithm and improve the guarantees for GMMS or PMMS. Finally, we show that GMMS -- and thus PMMS and EFX -- allocations always exist when the number of goods does not exceed the number of agents by more than two.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07650v2"
	},
	{
		"title": "Random Intersection Graphs and Missing Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DIANet: Dense‐and‐Implicit Attention Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Spatial‐Temporal Gaussian Scale Mixture Modeling for Foreground Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations ",
		"abstract": "Word embedding has become essential for natural language processing as it boosts empirical performances of various tasks. However, recent research discovers that gender bias is incorporated in neural word embeddings, and downstream tasks that rely on these biased word vectors also produce gender-biased results. While some word-embedding gender-debiasing methods have been developed, these methods mainly focus on reducing gender bias associated with gender direction and fail to reduce the gender bias presented in word embedding relations. In this paper, we design a causal and simple approach for mitigating gender bias in word vector relation by utilizing the statistical dependency between gender-definition word embeddings and gender-biased word embeddings. Our method attains state-of-the-art results on gender-debiasing tasks, lexical- and sentence-level evaluation tasks, and downstream coreference resolution tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10787v1"
	},
	{
		"title": "PI‐RCNN: An Efficient Multi‐sensor 3D Object Detector with Point‐based Attentive Cont‐conv Fusion Module ",
		"abstract": "LIDAR point clouds and RGB-images are both extremely essential for 3D object detection. So many state-of-the-art 3D detection algorithms dedicate in fusing these two types of data effectively. However, their fusion methods based on Birds Eye View (BEV) or voxel format are not accurate. In this paper, we propose a novel fusion approach named Point-based Attentive Cont-conv Fusion(PACF) module, which fuses multi-sensor features directly on 3D points. Except for continuous convolution, we additionally add a Point-Pooling and an Attentive Aggregation to make the fused features more expressive. Moreover, based on the PACF module, we propose a 3D multi-sensor multi-task network called Pointcloud-Image RCNN(PI-RCNN as brief), which handles the image segmentation and 3D object detection tasks. PI-RCNN employs a segmentation sub-network to extract full-resolution semantic feature maps from images and then fuses the multi-sensor features via powerful PACF module. Beneficial from the effectiveness of the PACF module and the expressive semantic features from the segmentation module, PI-RCNN can improve much in 3D object detection. We demonstrate the effectiveness of the PACF module and PI-RCNN on the KITTI 3D Detection benchmark, and our method can achieve state-of-the-art on the metric of 3D AP.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06084v3"
	},
	{
		"title": "Boundary Enhanced Neural Span Classification for Nested Named Entity Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Coarse Correlation in Extensive‐Form Games ",
		"abstract": "Coarse correlation models strategic interactions of rational agents complemented by a correlation device, that is a mediator that can recommend behavior but not enforce it. Despite being a classical concept in the theory of normal-form games for more than forty years, not much is known about the merits of coarse correlation in extensive-form settings. In this paper, we consider two instantiations of the idea of coarse correlation in extensive-form games: normal-form coarse-correlated equilibrium (NFCCE), already defined in the literature, and extensive-form coarse-correlated equilibrium (EFCCE), which we introduce for the first time. We show that EFCCE is a subset of NFCCE and a superset of the related extensive-form correlated equilibrium. We also show that, in two-player extensive-form games, social-welfare-maximizing EFCCEs and NFCEEs are bilinear saddle points, and give new efficient algorithms for the special case of games with no chance moves. In our experiments, our proposed algorithm for NFCCE is two to four orders of magnitude faster than the prior state of the art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.09893v1"
	},
	{
		"title": "Graph‐Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering ",
		"abstract": "Commonsense question answering aims to answer questions which require background knowledge that is not explicitly expressed in the question. The key challenge is how to obtain evidence from external knowledge and make predictions based on the evidence. Recent works either learn to generate evidence from human-annotated evidence which is expensive to collect, or extract evidence from either structured or unstructured knowledge bases which fails to take advantages of both sources. In this work, we propose to automatically extract evidence from heterogeneous knowledge sources, and answer questions based on the extracted evidence. Specifically, we extract evidence from both structured knowledge base (i.e. ConceptNet) and Wikipedia plain texts. We construct graphs for both sources to obtain the relational structures of evidence. Based on these graphs, we propose a graph-based approach consisting of a graph-based contextual word representation learning module and a graph-based inference module. The first module utilizes graph structural information to re-define the distance between words for learning better contextual word representations. The second module adopts graph convolutional network to encode neighbor information into the representations of nodes, and aggregates evidence with graph attention mechanism for predicting the final answer. Experimental results on CommonsenseQA dataset illustrate that our graph-based approach over both knowledge sources brings improvement over strong baselines. Our approach achieves the state-of-the-art accuracy (75.3%) on the CommonsenseQA leaderboard.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05311v2"
	},
	{
		"title": "Hypothetical Answers to Continuous Queries over Data Streams ",
		"abstract": "Continuous queries over data streams may suffer from blocking operations and/or unbound wait, which may delay answers until some relevant input arrives through the data stream. These delays may turn answers, when they arrive, obsolete to users who sometimes have to make decisions with no help whatsoever. Therefore, it can be useful to provide hypothetical answers - \"given the current information, it is possible that X will become true at time t\" - instead of no information at all.   In this paper we present a semantics for queries and corresponding answers that covers such hypothetical answers, together with an online algorithm for updating the set of facts that are consistent with the currently available information.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.09610v2"
	},
	{
		"title": "Maximum Margin Multi‐Dimensional Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Frank‐Wolfe Framework for Efficient and Effective Adversarial Attacks ",
		"abstract": "Depending on how much information an adversary can access to, adversarial attacks can be classified as white-box attack and black-box attack. For white-box attack, optimization-based attack algorithms such as projected gradient descent (PGD) can achieve relatively high attack success rates within moderate iterates. However, they tend to generate adversarial examples near or upon the boundary of the perturbation set, resulting in large distortion. Furthermore, their corresponding black-box attack algorithms also suffer from high query complexities, thereby limiting their practical usefulness. In this paper, we focus on the problem of developing efficient and effective optimization-based adversarial attack algorithms. In particular, we propose a novel adversarial attack framework for both white-box and black-box settings based on a variant of Frank-Wolfe algorithm. We show in theory that the proposed attack algorithms are efficient with an $O(1/\\sqrt{T})$ convergence rate. The empirical results of attacking the ImageNet and MNIST datasets also verify the efficiency and effectiveness of the proposed algorithms. More specifically, our proposed algorithms attain the best attack performances in both white-box and black-box attacks among all baselines, and are more time and query efficient than the state-of-the-art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1811.10828v2"
	},
	{
		"title": "Learning Sparse Sharing Architectures for Multiple Tasks ",
		"abstract": "Most existing deep multi-task learning models are based on parameter sharing, such as hard sharing, hierarchical sharing, and soft sharing. How choosing a suitable sharing mechanism depends on the relations among the tasks, which is not easy since it is difficult to understand the underlying shared factors among these tasks. In this paper, we propose a novel parameter sharing mechanism, named \\emph{Sparse Sharing}. Given multiple tasks, our approach automatically finds a sparse sharing structure. We start with an over-parameterized base network, from which each task extracts a subnetwork. The subnetworks of multiple tasks are partially overlapped and trained in parallel. We show that both hard sharing and hierarchical sharing can be formulated as particular instances of the sparse sharing framework. We conduct extensive experiments on three sequence labeling tasks. Compared with single-task models and three typical multi-task learning baselines, our proposed approach achieves consistent improvement while requiring fewer parameters.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05034v2"
	},
	{
		"title": "CASE: Context‐Aware Semantic Expansion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Defending with Shared Resources on a Network ",
		"abstract": "In this paper we consider a defending problem on a network. In the model, the defender holds a total defending resource of R, which can be distributed to the nodes of the network. The defending resource allocated to a node can be shared by its neighbors. There is a weight associated with every edge that represents the efficiency defending resources are shared between neighboring nodes. We consider the setting when each attack can affect not only the target node, but its neighbors as well. Assuming that nodes in the network have different treasures to defend and different defending requirements, the defender aims at allocating the defending resource to the nodes to minimize the loss due to attack. We give polynomial time exact algorithms for two important special cases of the network defending problem. For the case when an attack can only affect the target node, we present an LP-based exact algorithm. For the case when defending resources cannot be shared, we present a max-flow-based exact algorithm. We show that the general problem is NP-hard, and we give a 2-approximation algorithm based on LP-rounding. Moreover, by giving a matching lower bound of 2 on the integrality gap on the LP relaxation, we show that our rounding is tight.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08196v1"
	},
	{
		"title": "On Performance Estimation in Automatic Algorithm Configuration ",
		"abstract": "Over the last decade, research on automated parameter tuning, often referred to as automatic algorithm configuration (AAC), has made significant progress. Although the usefulness of such tools has been widely recognized in real world applications, the theoretical foundations of AAC are still very weak. This paper addresses this gap by studying the performance estimation problem in AAC. More specifically, this paper first proves the universal best performance estimator in a practical setting, and then establishes theoretical bounds on the estimation error, i.e., the difference between the training performance and the true performance for a parameter configuration, considering finite and infinite configuration spaces respectively. These findings were verified in extensive experiments conducted on four algorithm configuration scenarios involving different problem domains. Moreover, insights for enhancing existing AAC methods are also identified.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08200v1"
	},
	{
		"title": "MTSS: Learn from Multiple Domain Teachers and Become a Multi‐domain Dialogue Expert ",
		"abstract": "How to build a high-quality multi-domain dialogue system is a challenging work due to its complicated and entangled dialogue state space among each domain, which seriously limits the quality of dialogue policy, and further affects the generated response. In this paper, we propose a novel method to acquire a satisfying policy and subtly circumvent the knotty dialogue state representation problem in the multi-domain setting. Inspired by real school teaching scenarios, our method is composed of multiple domain-specific teachers and a universal student. Each individual teacher only focuses on one specific domain and learns its corresponding domain knowledge and dialogue policy based on a precisely extracted single domain dialogue state representation. Then, these domain-specific teachers impart their domain knowledge and policies to a universal student model and collectively make this student model a multi-domain dialogue expert. Experiment results show that our method reaches competitive results with SOTAs in both multi-domain and single domain setting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.10450v1"
	},
	{
		"title": "An Ordinal Data Clustering Algorithm with Automated Distance Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Maximum Likelihood Embedding of Logistic Random Dot Product Graphs ",
		"abstract": "A latent space model for a family of random graphs assigns real-valued vectors to nodes of the graph such that edge probabilities are determined by latent positions. Latent space models provide a natural statistical framework for graph visualizing and clustering. A latent space model of particular interest is the Random Dot Product Graph (RDPG), which can be fit using an efficient spectral method; however, this method is based on a heuristic that can fail, even in simple cases. Here, we consider a closely related latent space model, the Logistic RDPG, which uses a logistic link function to map from latent positions to edge likelihoods. Over this model, we show that asymptotically exact maximum likelihood inference of latent position vectors can be achieved using an efficient spectral method. Our method involves computing top eigenvectors of a normalized adjacency matrix and scaling eigenvectors using a regression step. The novel regression scaling step is an essential part of the proposed method. In simulations, we show that our proposed method is more accurate and more robust than common practices. We also show the effectiveness of our approach over standard real networks of the karate club and political blogs.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1510.00850v3"
	},
	{
		"title": "Augmenting the Power of (Partial) MaxSat Resolution with Extension ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improving the Robustness of Wasserstein Embedding by Adversarial PAC‐Bayesian Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Refining Tournament Solutions via Margin of Victory ",
		"abstract": "Tournament solutions are frequently used to select winners from a set of alternatives based on pairwise comparisons between alternatives. Prior work has shown that several common tournament solutions tend to select large winner sets and therefore have low discriminative power. In this paper, we propose a general framework for refining tournament solutions. In order to distinguish between winning alternatives, and also between non-winning ones, we introduce the notion of margin of victory (MoV) for tournament solutions. MoV is a robustness measure for individual alternatives: For winners, the MoV captures the distance from dropping out of the winner set, and for non-winners, the distance from entering the set. In each case, distance is measured in terms of which pairwise comparisons would have to be reversed in order to achieve the desired outcome. For common tournament solutions, including the top cycle, the uncovered set, and the Banks set, we determine the complexity of computing the MoV and provide worst-case bounds on the MoV for both winners and non-winners. Our results can also be viewed from the perspective of bribery and manipulation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06289v1"
	},
	{
		"title": "Skeleton‐based Semantic Parsing for Complex Questions over Knowledge Bases ",
		"abstract": "Semantic parsing transforms a natural language question into a formal query over a knowledge base. Many existing methods rely on syntactic parsing like dependencies. However, the accuracy of producing such expressive formalisms is not satisfying on long complex questions. In this paper, we propose a novel skeleton grammar to represent the high-level structure of a complex question. This dedicated coarse-grained formalism with a BERT-based parsing algorithm helps to improve the accuracy of the downstream fine-grained semantic parsing. Besides, to align the structure of a question with the structure of a knowledge base, our multi-strategy method combines sentence-level and word-level semantics. Our approach shows promising performance on several datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.13956v1"
	},
	{
		"title": "Unsupervised Domain Adaptation via Discriminative Manifold Embedding and Alignment ",
		"abstract": "Unsupervised domain adaptation is effective in leveraging the rich information from the source domain to the unsupervised target domain. Though deep learning and adversarial strategy make an important breakthrough in the adaptability of features, there are two issues to be further explored. First, the hard-assigned pseudo labels on the target domain are risky to the intrinsic data structure. Second, the batch-wise training manner in deep learning limits the description of the global structure. In this paper, a Riemannian manifold learning framework is proposed to achieve transferability and discriminability consistently. As to the first problem, this method establishes a probabilistic discriminant criterion on the target domain via soft labels. Further, this criterion is extended to a global approximation scheme for the second issue; such approximation is also memory-saving. The manifold metric alignment is exploited to be compatible with the embedding space. A theoretical error bound is derived to facilitate the alignment. Extensive experiments have been conducted to investigate the proposal and results of the comparison study manifest the superiority of consistent manifold learning framework.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.08675v2"
	},
	{
		"title": "Memory Augmented Graph Neural Networks for Sequential Recommendation ",
		"abstract": "The chronological order of user-item interactions can reveal time-evolving and sequential user behaviors in many recommender systems. The items that users will interact with may depend on the items accessed in the past. However, the substantial increase of users and items makes sequential recommender systems still face non-trivial challenges: (1) the hardness of modeling the short-term user interests; (2) the difficulty of capturing the long-term user interests; (3) the effective modeling of item co-occurrence patterns. To tackle these challenges, we propose a memory augmented graph neural network (MA-GNN) to capture both the long- and short-term user interests. Specifically, we apply a graph neural network to model the item contextual information within a short-term period and utilize a shared memory network to capture the long-range dependencies between items. In addition to the modeling of user interests, we employ a bilinear function to capture the co-occurrence patterns of related items. We extensively evaluate our model on five real-world datasets, comparing with several state-of-the-art methods and using a variety of performance metrics. The experimental results demonstrate the effectiveness of our model for the task of Top-K sequential recommendation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11730v1"
	},
	{
		"title": "Distributionally Robust Counterfactual Risk Minimization ",
		"abstract": "This manuscript introduces the idea of using Distributionally Robust Optimization (DRO) for the Counterfactual Risk Minimization (CRM) problem. Tapping into a rich existing literature, we show that DRO is a principled tool for counterfactual decision making. We also show that well-established solutions to the CRM problem like sample variance penalization schemes are special instances of a more general DRO problem. In this unifying framework, a variety of distributionally robust counterfactual risk estimators can be constructed using various probability distances and divergences as uncertainty measures. We propose the use of Kullback-Leibler divergence as an alternative way to model uncertainty in CRM and derive a new robust counterfactual objective. In our experiments, we show that this approach outperforms the state-of-the-art on four benchmark datasets, validating the relevance of using other uncertainty measures in practical applications.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.06211v2"
	},
	{
		"title": "Improved PAC‐Bayesian Bounds for Linear Regression ",
		"abstract": "In this paper, we improve the PAC-Bayesian error bound for linear regression derived in Germain et al. [10]. The improvements are twofold. First, the proposed error bound is tighter, and converges to the generalization loss with a well-chosen temperature parameter. Second, the error bound also holds for training data that are not independently sampled. In particular, the error bound applies to certain time series generated by well-known classes of dynamical models, such as ARX models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.03036v1"
	},
	{
		"title": "Online Active Learning of Reject Option Classifiers ",
		"abstract": "Active learning is an important technique to reduce the number of labeled examples in supervised learning. Active learning for binary classification has been well addressed in machine learning. However, active learning of the reject option classifier remains unaddressed. In this paper, we propose novel algorithms for active learning of reject option classifiers. We develop an active learning algorithm using double ramp loss function. We provide mistake bounds for this algorithm. We also propose a new loss function called double sigmoid loss function for reject option and corresponding active learning algorithm. We offer a convergence guarantee for this algorithm. We provide extensive experimental results to show the effectiveness of the proposed algorithms. The proposed algorithms efficiently reduce the number of label examples required.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.06166v2"
	},
	{
		"title": "Interpretable and Differentially Private Predictions ",
		"abstract": "Interpretable predictions, where it is clear why a machine learning model has made a particular decision, can compromise privacy by revealing the characteristics of individual data points. This raises the central question addressed in this paper: Can models be interpretable without compromising privacy? For complex big data fit by correspondingly rich models, balancing privacy and explainability is particularly challenging, such that this question has remained largely unexplored. In this paper, we propose a family of simple models in the aim of approximating complex models using several locally linear maps per class to provide high classification accuracy, as well as differentially private explanations on the classification. We illustrate the usefulness of our approach on several image benchmark datasets as well as a medical dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.02004v4"
	},
	{
		"title": "On Measuring and Mitigating Biased Inferences of Word Embeddings ",
		"abstract": "Word embeddings carry stereotypical connotations from the text they are trained on, which can lead to invalid inferences in downstream models that rely on them. We use this observation to design a mechanism for measuring stereotypes using the task of natural language inference. We demonstrate a reduction in invalid inferences via bias mitigation strategies on static word embeddings (GloVe). Further, we show that for gender bias, these techniques extend to contextualized embeddings when applied selectively only to the static components of contextualized embeddings (ELMo, BERT).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.09369v3"
	},
	{
		"title": "Persuading Voters: It’s Easy to Whisper, It’s Hard to Speak Loud ",
		"abstract": "We focus on the following natural question: is it possible to influence the outcome of a voting process through the strategic provision of information to voters who update their beliefs rationally? We investigate whether it is computationally tractable to design a signaling scheme maximizing the probability with which the sender's preferred candidate is elected. We focus on the model recently introduced by Arieli and Babichenko (2019) (i.e., without inter-agent externalities), and consider, as explanatory examples, $k$-voting rule and plurality voting. There is a sharp contrast between the case in which private signals are allowed and the more restrictive setting in which only public signals are allowed. In the former, we show that an optimal signaling scheme can be computed efficiently both under a $k$-voting rule and plurality voting. In establishing these results, we provide two general (i.e., applicable to settings beyond voting) contributions. Specifically, we extend a well known result by Dughmi and Xu (2017) to more general settings, and prove that, when the sender's utility function is anonymous, computing an optimal signaling scheme is fixed parameter tractable w.r.t. the number of receivers' actions. In the public signaling case, we show that the sender's optimal expected return cannot be approximated to within any factor under a $k$-voting rule. This negative result easily extends to plurality voting and problems where utility functions are anonymous.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.10620v2"
	},
	{
		"title": "Private Bayesian Persuasion with Sequential Games ",
		"abstract": "We study an information-structure design problem (a.k.a. persuasion) with a single sender and multiple receivers with actions of a priori unknown types, independently drawn from action-specific marginal distributions. As in the standard Bayesian persuasion model, the sender has access to additional information regarding the action types, which she can exploit when committing to a (noisy) signaling scheme through which she sends a private signal to each receiver. The novelty of our model is in considering the case where the receivers interact in a sequential game with imperfect information, with utilities depending on the game outcome and the realized action types. After formalizing the notions of ex ante and ex interim persuasiveness (which differ in the time at which the receivers commit to following the sender's signaling scheme), we investigate the continuous optimization problem of computing a signaling scheme which maximizes the sender's expected revenue. We show that computing an optimal ex ante persuasive signaling scheme is NP-hard when there are three or more receivers. In contrast with previous hardness results for ex interim persuasion, we show that, for games with two receivers, an optimal ex ante persuasive signaling scheme can be computed in polynomial time thanks to a novel algorithm based on the ellipsoid method which we propose.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.00877v1"
	},
	{
		"title": "Deep Bayesian Nonparametric Learning of Rules and Plans from Demonstrations with a Learned Automaton Prior ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Modeling Dialogues with Hashcode Representations: A Nonparametric Approach ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Weighted Automata Extraction from Recurrent Neural Networks via Regression on State Spaces ",
		"abstract": "We present a method to extract a weighted finite automaton (WFA) from a recurrent neural network (RNN). Our algorithm is based on the WFA learning algorithm by Balle and Mohri, which is in turn an extension of Angluin's classic \\lstar algorithm. Our technical novelty is in the use of \\emph{regression} methods for the so-called equivalence queries, thus exploiting the internal state space of an RNN to prioritize counterexample candidates. This way we achieve a quantitative/weighted extension of the recent work by Weiss, Goldberg and Yahav that extracts DFAs. We experimentally evaluate the accuracy, expressivity and efficiency of the extracted WFAs.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.02931v3"
	},
	{
		"title": "Transductive Ensemble Learning for Neural Machine Translation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FET‐GAN: Font Effect Transfer via K‐shot Adaptive Instance Normalization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Finding Needles in a Moving Haystack: Prioritizing Alerts with Adversarial Reinforcement Learning ",
		"abstract": "Detection of malicious behavior is a fundamental problem in security. One of the major challenges in using detection systems in practice is in dealing with an overwhelming number of alerts that are triggered by normal behavior (the so-called false positives), obscuring alerts resulting from actual malicious activity. While numerous methods for reducing the scope of this issue have been proposed, ultimately one must still decide how to prioritize which alerts to investigate, and most existing prioritization methods are heuristic, for example, based on suspiciousness or priority scores. We introduce a novel approach for computing a policy for prioritizing alerts using adversarial reinforcement learning. Our approach assumes that the attackers know the full state of the detection system and dynamically choose an optimal attack as a function of this state, as well as of the alert prioritization policy. The first step of our approach is to capture the interaction between the defender and attacker in a game theoretic model. To tackle the computational complexity of solving this game to obtain a dynamic stochastic alert prioritization policy, we propose an adversarial reinforcement learning framework. In this framework, we use neural reinforcement learning to compute best response policies for both the defender and the adversary to an arbitrary stochastic policy of the other. We then use these in a double-oracle framework to obtain an approximate equilibrium of the game, which in turn yields a robust stochastic policy for the defender. Extensive experiments using case studies in fraud and intrusion detection demonstrate that our approach is effective in creating robust alert prioritization policies.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.08805v1"
	},
	{
		"title": "HirePeer: Impartial Peer‐Assessed Hiring at Scale in Expert Crowdsourcing Markets ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Contiguous Cake Cutting: Hardness Results and Approximation Algorithms ",
		"abstract": "We study the fair allocation of a cake, which serves as a metaphor for a divisible resource, under the requirement that each agent should receive a contiguous piece of the cake. While it is known that no finite envy-free algorithm exists in this setting, we exhibit efficient algorithms that produce allocations with low envy among the agents. We then establish NP-hardness results for various decision problems on the existence of envy-free allocations, such as when we fix the ordering of the agents or constrain the positions of certain cuts. In addition, we consider a discretized setting where indivisible items lie on a line and show a number of hardness results extending and strengthening those from prior work. Finally, we investigate connections between approximate and exact envy-freeness, as well as between continuous and discrete cake cutting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05416v2"
	},
	{
		"title": "Image‐Adaptive GAN based Reconstruction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Unified Framework for Knowledge Intensive Gradient Boosting: Leveraging Human Experts for Noisy Sparse Domains ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Swap Stability in Schelling Games on Graphs ",
		"abstract": "We study a recently introduced class of strategic games that is motivated by and generalizes Schelling's well-known residential segregation model. These games are played on undirected graphs, with the set of agents partitioned into multiple types; each agent either occupies a node of the graph and never moves away or aims to maximize the fraction of her neighbors who are of her own type. We consider a variant of this model that we call swap Schelling games, where the number of agents is equal to the number of nodes of the graph, and agents may {\\em swap} positions with other agents to increase their utility. We study the existence, computational complexity and quality of equilibrium assignments in these games, both from a social welfare perspective and from a diversity perspective.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02421v3"
	},
	{
		"title": "What Makes A Good Story? Designing Composite Rewards for Visual Storytelling ",
		"abstract": "Previous storytelling approaches mostly focused on optimizing traditional metrics such as BLEU, ROUGE and CIDEr. In this paper, we re-examine this problem from a different angle, by looking deep into what defines a realistically-natural and topically-coherent story. To this end, we propose three assessment criteria: relevance, coherence and expressiveness, which we observe through empirical analysis could constitute a \"high-quality\" story to the human eye. Following this quality guideline, we propose a reinforcement learning framework, ReCo-RL, with reward functions designed to capture the essence of these quality criteria. Experiments on the Visual Storytelling Dataset (VIST) with both automatic and human evaluations demonstrate that our ReCo-RL model achieves better performance than state-of-the-art baselines on both traditional metrics and the proposed new criteria.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05316v2"
	},
	{
		"title": "Expressing Objects just like Words: Recurrent Visual Embedding for Image‐Text Matching ",
		"abstract": "Existing image-text matching approaches typically infer the similarity of an image-text pair by capturing and aggregating the affinities between the text and each independent object of the image. However, they ignore the connections between the objects that are semantically related. These objects may collectively determine whether the image corresponds to a text or not. To address this problem, we propose a Dual Path Recurrent Neural Network (DP-RNN) which processes images and sentences symmetrically by recurrent neural networks (RNN). In particular, given an input image-text pair, our model reorders the image objects based on the positions of their most related words in the text. In the same way as extracting the hidden features from word embeddings, the model leverages RNN to extract high-level object features from the reordered object inputs. We validate that the high-level object features contain useful joint information of semantically related objects, which benefit the retrieval task. To compute the image-text similarity, we incorporate a Multi-attention Cross Matching Model into DP-RNN. It aggregates the affinity between objects and words with cross-modality guided attention and self-attention. Our model achieves the state-of-the-art performance on Flickr30K dataset and competitive performance on MS-COCO dataset. Extensive experiments demonstrate the effectiveness of our model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.08510v1"
	},
	{
		"title": "Improving Question Generation with Sentence‐level Semantic Matching and Answer Position Inferring ",
		"abstract": "Taking an answer and its context as input, sequence-to-sequence models have made considerable progress on question generation. However, we observe that these approaches often generate wrong question words or keywords and copy answer-irrelevant words from the input. We believe that lacking global question semantics and exploiting answer position-awareness not well are the key root causes. In this paper, we propose a neural question generation model with two concrete modules: sentence-level semantic matching and answer position inferring. Further, we enhance the initial state of the decoder by leveraging the answer-aware gated fusion mechanism. Experimental results demonstrate that our model outperforms the state-of-the-art (SOTA) models on SQuAD and MARCO datasets. Owing to its generality, our work also improves the existing models significantly.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00879v3"
	},
	{
		"title": "AdaFilter: Adaptive Filter Fine‐tuning for Deep Transfer Learning ",
		"abstract": "There is an increasing number of pre-trained deep neural network models. However, it is still unclear how to effectively use these models for a new task. Transfer learning, which aims to transfer knowledge from source tasks to a target task, is an effective solution to this problem. Fine-tuning is a popular transfer learning technique for deep neural networks where a few rounds of training are applied to the parameters of a pre-trained model to adapt them to a new task. Despite its popularity, in this paper, we show that fine-tuning suffers from several drawbacks. We propose an adaptive fine-tuning approach, called AdaFilter, which selects only a part of the convolutional filters in the pre-trained model to optimize on a per-example basis. We use a recurrent gated network to selectively fine-tune convolutional filters based on the activations of the previous layer. We experiment with 7 public image classification datasets and the results show that AdaFilter can reduce the average classification error of the standard fine-tuning by 2.54%.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09659v2"
	},
	{
		"title": "Hard Examples for Common Variable Decision Heuristics ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Toward A Thousand Lights: Decentralized Deep Reinforcement Learning for Large‐Scale Traffic Signal Control ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Leveraging Title‐Abstract Attentive Semantics for Paper Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Near‐Optimal Change‐Detection Based Algorithm for Piecewise‐Stationary Combinatorial Semi‐Bandits ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Graph‐Driven Generative Models for Heterogeneous Multi‐Task Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Pairwise Fairness for Ranking and Regression ",
		"abstract": "We present pairwise fairness metrics for ranking models and regression models that form analogues of statistical fairness notions such as equal opportunity, equal accuracy, and statistical parity. Our pairwise formulation supports both discrete protected groups, and continuous protected attributes. We show that the resulting training problems can be efficiently and effectively solved using existing constrained optimization and robust optimization techniques developed for fair classification. Experiments illustrate the broad applicability and trade-offs of these methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.05330v3"
	},
	{
		"title": "The HSIC Bottleneck: Deep Learning without Back‐Propagation ",
		"abstract": "We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for training deep neural networks. The HSIC bottleneck is an alternative to the conventional cross-entropy loss and backpropagation that has a number of distinct advantages. It mitigates exploding and vanishing gradients, resulting in the ability to learn very deep networks without skip connections. There is no requirement for symmetric feedback or update locking. We find that the HSIC bottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification comparable to backpropagation with a cross-entropy target, even when the system is not encouraged to make the output resemble the classification labels. Appending a single layer trained with SGD (without backpropagation) to reformat the information further improves performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.01580v3"
	},
	{
		"title": "Decoupled Attention Network for Text Recognition ",
		"abstract": "Text recognition has attracted considerable research interests because of its various applications. The cutting-edge text recognition methods are based on attention mechanisms. However, most of attention methods usually suffer from serious alignment problem due to its recurrency alignment operation, where the alignment relies on historical decoding results. To remedy this issue, we propose a decoupled attention network (DAN), which decouples the alignment operation from using historical decoding results. DAN is an effective, flexible and robust end-to-end text recognizer, which consists of three components: 1) a feature encoder that extracts visual features from the input image; 2) a convolutional alignment module that performs the alignment operation based on visual features from the encoder; and 3) a decoupled text decoder that makes final prediction by jointly using the feature map and attention maps. Experimental results show that DAN achieves state-of-the-art performance on multiple text recognition tasks, including offline handwritten text recognition and regular/irregular scene text recognition.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10205v1"
	},
	{
		"title": "Infinity Learning: Learning Markov Chains from Aggregate Steady‐State Observations ",
		"abstract": "We consider the task of learning a parametric Continuous Time Markov Chain (CTMC) sequence model without examples of sequences, where the training data consists entirely of aggregate steady-state statistics. Making the problem harder, we assume that the states we wish to predict are unobserved in the training data. Specifically, given a parametric model over the transition rates of a CTMC and some known transition rates, we wish to extrapolate its steady state distribution to states that are unobserved. A technical roadblock to learn a CTMC from its steady state has been that the chain rule to compute gradients will not work over the arbitrarily long sequences necessary to reach steady state ---from where the aggregate statistics are sampled. To overcome this optimization challenge, we propose $\\infty$-SGD, a principled stochastic gradient descent method that uses randomly-stopped estimators to avoid infinite sums required by the steady state computation, while learning even when only a subset of the CTMC states can be observed. We apply $\\infty$-SGD to a real-world testbed and synthetic experiments showcasing its accuracy, ability to extrapolate the steady state distribution to unobserved states under unobserved conditions (heavy loads, when training under light loads), and succeeding in difficult scenarios where even a tailor-made extension of existing methods fails.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.04186v1"
	},
	{
		"title": "Replicate, Walk, and Stop on Syntax: an Effective Neural Network Model for Aspect‐Level Sentiment Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Repetitive Reprediction Deep Decipher for Semi‐Supervised Learning ",
		"abstract": "Most recent semi-supervised deep learning (deep SSL) methods used a similar paradigm: use network predictions to update pseudo-labels and use pseudo-labels to update network parameters iteratively. However, they lack theoretical support and cannot explain why predictions are good candidates for pseudo-labels. In this paper, we propose a principled end-to-end framework named deep decipher (D2) for SSL. Within the D2 framework, we prove that pseudo-labels are related to network predictions by an exponential link function, which gives a theoretical support for using predictions as pseudo-labels. Furthermore, we demonstrate that updating pseudo-labels by network predictions will make them uncertain. To mitigate this problem, we propose a training strategy called repetitive reprediction (R2). Finally, the proposed R2-D2 method is tested on the large-scale ImageNet dataset and outperforms state-of-the-art methods by 5 percentage points.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.04345v2"
	},
	{
		"title": "Reliable and Efficient Anytime Skeleton Learning  ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Semi‐supervised Multi‐modal Learning with Balanced Spectral Decomposition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "When Radiology Report Generation meets Knowledge Graph ",
		"abstract": "Automatic radiology report generation has been an attracting research problem towards computer-aided diagnosis to alleviate the workload of doctors in recent years. Deep learning techniques for natural image captioning are successfully adapted to generating radiology reports. However, radiology image reporting is different from the natural image captioning task in two aspects: 1) the accuracy of positive disease keyword mentions is critical in radiology image reporting in comparison to the equivalent importance of every single word in a natural image caption; 2) the evaluation of reporting quality should focus more on matching the disease keywords and their associated attributes instead of counting the occurrence of N-gram. Based on these concerns, we propose to utilize a pre-constructed graph embedding module (modeled with a graph convolutional neural network) on multiple disease findings to assist the generation of reports in this work. The incorporation of knowledge graph allows for dedicated feature learning for each disease finding and the relationship modeling between them. In addition, we proposed a new evaluation metric for radiology image reporting with the assistance of the same composed graph. Experimental results demonstrate the superior performance of the methods integrated with the proposed graph embedding module on a publicly accessible dataset (IU-RR) of chest radiographs compared with previous approaches using both the conventional evaluation metrics commonly adopted for image captioning and our proposed ones.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.08277v1"
	},
	{
		"title": "CoCoX: Generating Conceptual and Counterfactual Explanations via Fault‐Lines ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Visual Domain Adaptation by Consensus‐based Transfer to Intermediate Domain ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Unsupervised Interlingual Semantic Representations from Sentence Embeddings for Zero‐Shot Cross‐Lingual Transfer ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Training‐Time‐Friendly Network for Real‐Time Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "IntroVNMT: An Introspective Model for Variational Neural Machine Translation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Annotated Corpus of Reference Resolution for Interpreting Common Grounding ",
		"abstract": "Common grounding is the process of creating, repairing and updating mutual understandings, which is a fundamental aspect of natural language conversation. However, interpreting the process of common grounding is a challenging task, especially under continuous and partially-observable context where complex ambiguity, uncertainty, partial understandings and misunderstandings are introduced. Interpretation becomes even more challenging when we deal with dialogue systems which still have limited capability of natural language understanding and generation. To address this problem, we consider reference resolution as the central subtask of common grounding and propose a new resource to study its intermediate process. Based on a simple and general annotation schema, we collected a total of 40,172 referring expressions in 5,191 dialogues curated from an existing corpus, along with multiple judgements of referent interpretations. We show that our annotation is highly reliable, captures the complexity of common grounding through a natural degree of reasonable disagreements, and allows for more detailed and quantitative analyses of common grounding strategies. Finally, we demonstrate the advantages of our annotation for interpreting, analyzing and improving common grounding in baseline dialogue systems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07588v1"
	},
	{
		"title": "P‐SIF: Document Embeddings Using Partition Averaging ",
		"abstract": "Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.09069v1"
	},
	{
		"title": "Segment‐then‐Rank: Non‐factoid Question Answering on Instructional Videos ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Student Networks with Few Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐channel Reverse Dictionary Model ",
		"abstract": "A reverse dictionary takes the description of a target word as input and outputs the target word together with other words that match the description. Existing reverse dictionary methods cannot deal with highly variable input queries and low-frequency target words successfully. Inspired by the description-to-word inference process of humans, we propose the multi-channel reverse dictionary model, which can mitigate the two problems simultaneously. Our model comprises a sentence encoder and multiple predictors. The predictors are expected to identify different characteristics of the target word from the input query. We evaluate our model on English and Chinese datasets including both dictionary definitions and human-written descriptions. Experimental results show that our model achieves the state-of-the-art performance, and even outperforms the most popular commercial reverse dictionary system on the human-written description dataset. We also conduct quantitative analyses and a case study to demonstrate the effectiveness and robustness of our model. All the code and data of this work can be obtained on https://github.com/thunlp/MultiRD.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08441v2"
	},
	{
		"title": "Towards Fine‐Grained Temporal Network Representation via Time‐Reinforced Random Walk ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Regularized Fine‐grained Meta Face Anti‐spoofing ",
		"abstract": "Face presentation attacks have become an increasingly critical concern when face recognition is widely applied. Many face anti-spoofing methods have been proposed, but most of them ignore the generalization ability to unseen attacks. To overcome the limitation, this work casts face anti-spoofing as a domain generalization (DG) problem, and attempts to address this problem by developing a new meta-learning framework called Regularized Fine-grained Meta-learning. To let our face anti-spoofing model generalize well to unseen attacks, the proposed framework trains our model to perform well in the simulated domain shift scenarios, which is achieved by finding generalized learning directions in the meta-learning process. Specifically, the proposed framework incorporates the domain knowledge of face anti-spoofing as the regularization so that meta-learning is conducted in the feature space regularized by the supervision of domain knowledge. This enables our model more likely to find generalized learning directions with the regularized meta-learning for face anti-spoofing task. Besides, to further enhance the generalization ability of our model, the proposed framework adopts a fine-grained learning strategy that simultaneously conducts meta-learning in a variety of domain shift scenarios in each iteration. Extensive experiments on four public datasets validate the effectiveness of the proposed method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10771v1"
	},
	{
		"title": "Fast Learning of Temporal Action Proposal via Dense Boundary Generator ",
		"abstract": "Generating temporal action proposals remains a very challenging problem, where the main issue lies in predicting precise temporal proposal boundaries and reliable action confidence in long and untrimmed real-world videos. In this paper, we propose an efficient and unified framework to generate temporal action proposals named Dense Boundary Generator (DBG), which draws inspiration from boundary-sensitive methods and implements boundary classification and action completeness regression for densely distributed proposals. In particular, the DBG consists of two modules: Temporal boundary classification (TBC) and Action-aware completeness regression (ACR). The TBC aims to provide two temporal boundary confidence maps by low-level two-stream features, while the ACR is designed to generate an action completeness score map by high-level action-aware features. Moreover, we introduce a dual stream BaseNet (DSB) to encode RGB and optical flow information, which helps to capture discriminative boundary and actionness features. Extensive experiments on popular benchmarks ActivityNet-1.3 and THUMOS14 demonstrate the superiority of DBG over the state-of-the-art proposal generator (e.g., MGG and BMN). Our code will be made available upon publication.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04127v1"
	},
	{
		"title": "A Restricted Black‐box Adversarial Framework Towards Attacking Graph Embedding Models ",
		"abstract": "With the great success of graph embedding model on both academic and industry area, the robustness of graph embedding against adversarial attack inevitably becomes a central problem in graph learning domain. Regardless of the fruitful progress, most of the current works perform the attack in a white-box fashion: they need to access the model predictions and labels to construct their adversarial loss. However, the inaccessibility of model predictions in real systems makes the white-box attack impractical to real graph learning system. This paper promotes current frameworks in a more general and flexible sense -- we demand to attack various kinds of graph embedding model with black-box driven. To this end, we begin by investigating the theoretical connections between graph signal processing and graph embedding models in a principled way and formulate the graph embedding model as a general graph signal process with corresponding graph filter. As such, a generalized adversarial attacker: GF-Attack is constructed by the graph filter and feature matrix. Instead of accessing any knowledge of the target classifiers used in graph embedding, GF-Attack performs the attack only on the graph filter in a black-box attack fashion. To validate the generalization of GF-Attack, we construct the attacker on four popular graph embedding models. Extensive experimental results validate the effectiveness of our attacker on several benchmark datasets. Particularly by using our attack, even small graph perturbations like one-edge flip is able to consistently make a strong attack in performance to different graph embedding models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.01297v5"
	},
	{
		"title": "Temporally Grounding Language Queries in Videos by Contextual Boundary‐aware Prediction ",
		"abstract": "The task of temporally grounding language queries in videos is to temporally localize the best matched video segment corresponding to a given language (sentence). It requires certain models to simultaneously perform visual and linguistic understandings. Previous work predominantly ignores the precision of segment localization. Sliding window based methods use predefined search window sizes, which suffer from redundant computation, while existing anchor-based approaches fail to yield precise localization. We address this issue by proposing an end-to-end boundary-aware model, which uses a lightweight branch to predict semantic boundaries corresponding to the given linguistic information. To better detect semantic boundaries, we propose to aggregate contextual information by explicitly modeling the relationship between the current element and its neighbors. The most confident segments are subsequently selected based on both anchor and boundary predictions at the testing stage. The proposed model, dubbed Contextual Boundary-aware Prediction (CBP), outperforms its competitors with a clear margin on three public datasets. All codes are available on https://github.com/JaywongWang/CBP .",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05010v2"
	},
	{
		"title": "Sentence Generation for Entity Description with Content‐plan Attention ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Recurrent Nested Model for Sequence Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Spatial Classification With Limited Observations Based On Physics‐Aware Structural Constraint ",
		"abstract": "Spatial classification with limited feature observations has been a challenging problem in machine learning. The problem exists in applications where only a subset of sensors are deployed at certain spots or partial responses are collected in field surveys. Existing research mostly focuses on addressing incomplete or missing data, e.g., data cleaning and imputation, classification models that allow for missing feature values or model missing features as hidden variables in the EM algorithm. These methods, however, assume that incomplete feature observations only happen on a small subset of samples, and thus cannot solve problems where the vast majority of samples have missing feature observations. To address this issue, we recently proposed a new approach that incorporates physics-aware structural constraint into the model representation. Our approach assumes that a spatial contextual feature is observed for all sample locations and establishes spatial structural constraint from the underlying spatial contextual feature map. We design efficient algorithms for model parameter learning and class inference. This paper extends our recent approach by allowing feature values of samples in each class to follow a multi-modal distribution. We propose learning algorithms for the extended model with multi-modal distribution. Evaluations on real-world hydrological applications show that our approach significantly outperforms baseline methods in classification accuracy, and the multi-modal extension is more robust than our early single-modal version especially when feature distribution in training samples is multi-modal. Computational experiments show that the proposed solution is computationally efficient on large datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2009.01072v1"
	},
	{
		"title": "Generate (non‐software) Bugs to Fool Classifiers ",
		"abstract": "In adversarial attacks intended to confound deep learning models, most studies have focused on limiting the magnitude of the modification so that humans do not notice the attack. On the other hand, during an attack against autonomous cars, for example, most drivers would not find it strange if a small insect image were placed on a stop sign, or they may overlook it. In this paper, we present a systematic approach to generate natural adversarial examples against classification models by employing such natural-appearing perturbations that imitate a certain object or signal. We first show the feasibility of this approach in an attack against an image classifier by employing generative adversarial networks that produce image patches that have the appearance of a natural object to fool the target model. We also introduce an algorithm to optimize placement of the perturbation in accordance with the input image, which makes the generation of adversarial examples fast and likely to succeed. Moreover, we experimentally show that the proposed approach can be extended to the audio domain, for example, to generate perturbations that sound like the chirping of birds to fool a speech classifier.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08644v1"
	},
	{
		"title": "Translation‐based Matching Adversarial Network for Cross‐lingual Natural Language Inference ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Incorporate Structure Knowledge for Image Inpainting ",
		"abstract": "This paper develops a multi-task learning framework that attempts to incorporate the image structure knowledge to assist image inpainting, which is not well explored in previous works. The primary idea is to train a shared generator to simultaneously complete the corrupted image and corresponding structures --- edge and gradient, thus implicitly encouraging the generator to exploit relevant structure knowledge while inpainting. In the meantime, we also introduce a structure embedding scheme to explicitly embed the learned structure features into the inpainting process, thus to provide possible preconditions for image completion. Specifically, a novel pyramid structure loss is proposed to supervise structure learning and embedding. Moreover, an attention mechanism is developed to further exploit the recurrent structures and patterns in the image to refine the generated structures and contents. Through multi-task learning, structure embedding besides with attention, our framework takes advantage of the structure knowledge and outperforms several state-of-the-art methods on benchmark datasets quantitatively and qualitatively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.04170v2"
	},
	{
		"title": "Fact‐aware Sentence Split and Rephrase with Permutation Invariant Training ",
		"abstract": "Sentence Split and Rephrase aims to break down a complex sentence into several simple sentences with its meaning preserved. Previous studies tend to address the issue by seq2seq learning from parallel sentence pairs, which takes a complex sentence as input and sequentially generates a series of simple sentences. However, the conventional seq2seq learning has two limitations for this task: (1) it does not take into account the facts stated in the long sentence; As a result, the generated simple sentences may miss or inaccurately state the facts in the original sentence. (2) The order variance of the simple sentences to be generated may confuse the seq2seq model during training because the simple sentences derived from the long source sentence could be in any order.   To overcome the challenges, we first propose the Fact-aware Sentence Encoding, which enables the model to learn facts from the long sentence and thus improves the precision of sentence split; then we introduce Permutation Invariant Training to alleviate the effects of order variance in seq2seq learning for this task. Experiments on the WebSplit-v1.0 benchmark dataset show that our approaches can largely improve the performance over the previous seq2seq learning approaches. Moreover, an extrinsic evaluation on oie-benchmark verifies the effectiveness of our approaches by an observation that splitting long sentences with our state-of-the-art model as preprocessing is helpful for improving OpenIE performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.11383v2"
	},
	{
		"title": "Adversarial Transformations for Semi‐Supervised Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "3D Human Pose Estimation via Explicit Compositional Depth Maps ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Shared Generative Latent Representation Learning for Multi‐view Clustering ",
		"abstract": "Clustering multi-view data has been a fundamental research topic in the computer vision community. It has been shown that a better accuracy can be achieved by integrating information of all the views than just using one view individually. However, the existing methods often struggle with the issues of dealing with the large-scale datasets and the poor performance in reconstructing samples. This paper proposes a novel multi-view clustering method by learning a shared generative latent representation that obeys a mixture of Gaussian distributions. The motivation is based on the fact that the multi-view data share a common latent embedding despite the diversity among the views. Specifically, benefited from the success of the deep generative learning, the proposed model not only can extract the nonlinear features from the views, but render a powerful ability in capturing the correlations among all the views. The extensive experimental results, on several datasets with different scales, demonstrate that the proposed method outperforms the state-of-the-art methods under a range of performance criteria.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.09747v1"
	},
	{
		"title": "Modelling and Solving Online Optimisation Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Latent‐Variable Non‐Autoregressive Neural Machine Translation with Deterministic Inference Using a Delta Posterior ",
		"abstract": "Although neural machine translation models reached high translation quality, the autoregressive nature makes inference difficult to parallelize and leads to high translation latency. Inspired by recent refinement-based approaches, we propose LaNMT, a latent-variable non-autoregressive model with continuous latent variables and deterministic inference procedure. In contrast to existing approaches, we use a deterministic inference algorithm to find the target sequence that maximizes the lowerbound to the log-probability. During inference, the length of translation automatically adapts itself. Our experiments show that the lowerbound can be greatly increased by running the inference algorithm, resulting in significantly improved translation quality. Our proposed model closes the performance gap between non-autoregressive and autoregressive approaches on ASPEC Ja-En dataset with 8.6x faster decoding. On WMT'14 En-De dataset, our model narrows the gap with autoregressive baseline to 2.0 BLEU points with 12.5x speedup. By decoding multiple initial latent variables in parallel and rescore using a teacher model, the proposed model further brings the gap down to 1.0 BLEU point on WMT'14 En-De task with 6.8x speedup.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.07181v5"
	},
	{
		"title": "Active Learning with Query Generation for Cost‐Effective Text Classiﬁcation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Monte‐Carlo Tree Search in Continuous Action Spaces with Value Gradients ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RTN: Reparameterized Ternary Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Patch Proposal Network for Fast Semantic Segmentation of High‐Resolution Images ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Federated Latent Dirichlet Allocation: A Local Differential Privacy Based Framework ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer ",
		"abstract": "Effective modeling of electronic health records (EHR) is rapidly becoming an important topic in both academia and industry. A recent study showed that using the graphical structure underlying EHR data (e.g. relationship between diagnoses and treatments) improves the performance of prediction tasks such as heart failure prediction. However, EHR data do not always contain complete structure information. Moreover, when it comes to claims data, structure information is completely unavailable to begin with. Under such circumstances, can we still do better than just treating EHR data as a flat-structured bag-of-features? In this paper, we study the possibility of jointly learning the hidden structure of EHR while performing supervised prediction tasks on EHR data. Specifically, we discuss that Transformer is a suitable basis model to learn the hidden EHR structure, and propose Graph Convolutional Transformer, which uses data statistics to guide the structure learning process. The proposed model consistently outperformed previous approaches empirically, on both synthetic data and publicly available EHR data, for various prediction tasks such as graph reconstruction and readmission prediction, indicating that it can serve as an effective general-purpose representation learning algorithm for EHR data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.04716v3"
	},
	{
		"title": "Span‐based Neural Buffer: Towards Efficient and Effective Utilization of Long‐Distance Context for Neural Sequence Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cross‐Modality Attention Network for Temporal Inconsistent Audio‐Visual Event Localization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GTNet: Generative Transfer Network for Zero‐Shot Object Detection ",
		"abstract": "We propose a Generative Transfer Network (GTNet) for zero shot object detection (ZSD). GTNet consists of an Object Detection Module and a Knowledge Transfer Module. The Object Detection Module can learn large-scale seen domain knowledge. The Knowledge Transfer Module leverages a feature synthesizer to generate unseen class features, which are applied to train a new classification layer for the Object Detection Module. In order to synthesize features for each unseen class with both the intra-class variance and the IoU variance, we design an IoU-Aware Generative Adversarial Network (IoUGAN) as the feature synthesizer, which can be easily integrated into GTNet. Specifically, IoUGAN consists of three unit models: Class Feature Generating Unit (CFU), Foreground Feature Generating Unit (FFU), and Background Feature Generating Unit (BFU). CFU generates unseen features with the intra-class variance conditioned on the class semantic embeddings. FFU and BFU add the IoU variance to the results of CFU, yielding class-specific foreground and background features, respectively. We evaluate our method on three public datasets and the results demonstrate that our method performs favorably against the state-of-the-art ZSD approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06812v2"
	},
	{
		"title": "Automated Spectral Kernel Learning ",
		"abstract": "The generalization performance of kernel methods is largely determined by the kernel, but common kernels are stationary thus input-independent and output-independent, that limits their applications on complicated tasks. In this paper, we propose a powerful and efficient spectral kernel learning framework and learned kernels are dependent on both inputs and outputs, by using non-stationary spectral kernels and flexibly learning the spectral measure from the data. Further, we derive a data-dependent generalization error bound based on Rademacher complexity, which estimates the generalization ability of the learning framework and suggests two regularization terms to improve performance. Extensive experimental results validate the effectiveness of the proposed algorithm and confirm our theoretical results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.04894v2"
	},
	{
		"title": "A Simple and Efficient Tensor Calculus ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TEINet: Towards an Efficient Architecture for Video Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Heuristic Black‐box Adversarial Attacks on Video Recognition Models ",
		"abstract": "We study the problem of attacking video recognition models in the black-box setting, where the model information is unknown and the adversary can only make queries to detect the predicted top-1 class and its probability. Compared with the black-box attack on images, attacking videos is more challenging as the computation cost for searching the adversarial perturbations on a video is much higher due to its high dimensionality. To overcome this challenge, we propose a heuristic black-box attack model that generates adversarial perturbations only on the selected frames and regions. More specifically, a heuristic-based algorithm is proposed to measure the importance of each frame in the video towards generating the adversarial examples. Based on the frames' importance, the proposed algorithm heuristically searches a subset of frames where the generated adversarial example has strong adversarial attack ability while keeps the perturbations lower than the given bound. Besides, to further boost the attack efficiency, we propose to generate the perturbations only on the salient regions of the selected frames. In this way, the generated perturbations are sparse in both temporal and spatial domains. Experimental results of attacking two mainstream video recognition methods on the UCF-101 dataset and the HMDB-51 dataset demonstrate that the proposed heuristic black-box adversarial attack method can significantly reduce the computation cost and lead to more than 28\\% reduction in query numbers for the untargeted attack on both datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09449v1"
	},
	{
		"title": "Time‐inconsistent Planning: Simple Motivation Is Hard to Find ",
		"abstract": "With the introduction of the graph-theoretic time-inconsistent planning model due to Kleinberg and Oren, it has been possible to investigate the computational complexity of how a task designer best can support a present-biased agent in completing the task. In this paper, we study the complexity of finding a choice reduction for the agent; that is, how to remove edges and vertices from the task graph such that a present-biased agent will remain motivated to reach his target even for a limited reward. While this problem is NP-complete in general, this is not necessarily true for instances which occur in practice, or for solutions which are of interest to task designers. For instance, a task designer may desire to find the best task graph which is not too complicated.   We therefore investigate the problem of finding simple motivating subgraphs. These are structures where the agent will modify his plan at most $k$ times along the way. We quantify this simplicity in the time-inconsistency model as a structural parameter: The number of branching vertices (vertices with out-degree at least $2$) in a minimal motivating subgraph.   Our results are as follows: We give a linear algorithm for finding an optimal motivating path, i.e. when $k=0$. On the negative side, we show that finding a simple motivating subgraph is NP-complete even if we allow only a single branching vertex --- revealing that simple motivating subgraphs are indeed hard to find. However, we give a pseudo-polynomial algorithm for the case when $k$ is fixed and edge weights are rationals, which might be a reasonable assumption in practice.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07536v1"
	},
	{
		"title": "Conclusion‐Supplement Answer Generation for Non‐Factoid Questions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dynamic Graph Representation for Occlusion Handling in Biometrics ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adversarial Fence Patrolling: Non‐Uniform Policies for Asymmetric Environments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improving Neural Relation Extraction with Positive and Unlabeled Learning ",
		"abstract": "We present a novel approach to improve the performance of distant supervision relation extraction with Positive and Unlabeled (PU) Learning. This approach first applies reinforcement learning to decide whether a sentence is positive to a given relation, and then positive and unlabeled bags are constructed. In contrast to most previous studies, which mainly use selected positive instances only, we make full use of unlabeled instances and propose two new representations for positive and unlabeled bags. These two representations are then combined in an appropriate way to make bag-level prediction. Experimental results on a widely used real-world dataset demonstrate that this new approach indeed achieves significant and consistent improvements as compared to several competitive baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12556v1"
	},
	{
		"title": "Zero‐Shot Learning from Adversarial Feature Residual to Compact Visual Feature ",
		"abstract": "Recently, many zero-shot learning (ZSL) methods focused on learning discriminative object features in an embedding feature space, however, the distributions of the unseen-class features learned by these methods are prone to be partly overlapped, resulting in inaccurate object recognition. Addressing this problem, we propose a novel adversarial network to synthesize compact semantic visual features for ZSL, consisting of a residual generator, a prototype predictor, and a discriminator. The residual generator is to generate the visual feature residual, which is integrated with a visual prototype predicted via the prototype predictor for synthesizing the visual feature. The discriminator is to distinguish the synthetic visual features from the real ones extracted from an existing categorization CNN. Since the generated residuals are generally numerically much smaller than the distances among all the prototypes, the distributions of the unseen-class features synthesized by the proposed network are less overlapped. In addition, considering that the visual features from categorization CNNs are generally inconsistent with their semantic features, a simple feature selection strategy is introduced for extracting more compact semantic visual features. Extensive experimental results on six benchmark datasets demonstrate that our method could achieve a significantly better performance than existing state-of-the-art methods by 1.2-13.2% in most cases.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.12962v1"
	},
	{
		"title": "Resilient Logic Programs: Answer Set Programs Challenged by Ontologies ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Few Shot Network Compression via Cross Distillation ",
		"abstract": "Model compression has been widely adopted to obtain light-weighted deep neural networks. Most prevalent methods, however, require fine-tuning with sufficient training data to ensure accuracy, which could be challenged by privacy and security issues. As a compromise between privacy and performance, in this paper we investigate few shot network compression: given few samples per class, how can we effectively compress the network with negligible performance drop? The core challenge of few shot network compression lies in high estimation errors from the original network during inference, since the compressed network can easily over-fits on the few training instances. The estimation errors could propagate and accumulate layer-wisely and finally deteriorate the network output. To address the problem, we propose cross distillation, a novel layer-wise knowledge distillation approach. By interweaving hidden layers of teacher and student network, layer-wisely accumulated estimation errors can be effectively reduced.The proposed method offers a general framework compatible with prevalent network compression techniques such as pruning. Extensive experiments on benchmark datasets demonstrate that cross distillation can significantly improve the student network's accuracy when only a few training instances are available.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09450v2"
	},
	{
		"title": "Empirical Bounds on Linear Regions of Deep Rectifier Networks ",
		"abstract": "We can compare the expressiveness of neural networks that use rectified linear units (ReLUs) by the number of linear regions, which reflect the number of pieces of the piecewise linear functions modeled by such networks. However, enumerating these regions is prohibitive and the known analytical bounds are identical for networks with same dimensions. In this work, we approximate the number of linear regions through empirical bounds based on features of the trained network and probabilistic inference. Our first contribution is a method to sample the activation patterns defined by ReLUs using universal hash functions. This method is based on a Mixed-Integer Linear Programming (MILP) formulation of the network and an algorithm for probabilistic lower bounds of MILP solution sets that we call MIPBound, which is considerably faster than exact counting and reaches values in similar orders of magnitude. Our second contribution is a tighter activation-based bound for the maximum number of linear regions, which is particularly stronger in networks with narrow layers. Combined, these bounds yield a fast proxy for the number of linear regions of a deep neural network.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1810.03370v3"
	},
	{
		"title": "SPAN: A Stochastic Projected Approximate Newton Method ",
		"abstract": "Second-order optimization methods have desirable convergence properties. However, the exact Newton method requires expensive computation for the Hessian and its inverse. In this paper, we propose SPAN, a novel approximate and fast Newton method. SPAN computes the inverse of the Hessian matrix via low-rank approximation and stochastic Hessian-vector products. Our experiments on multiple benchmark datasets demonstrate that SPAN outperforms existing first-order and second-order optimization methods in terms of the convergence wall-clock time. Furthermore, we provide a theoretical analysis of the per-iteration complexity, the approximation error, and the convergence rate. Both the theoretical analysis and experimental results show that our proposed method achieves a better trade-off between the convergence rate and the per-iteration efficiency.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03687v2"
	},
	{
		"title": "Fine‐Grained Machine Teaching with Attention Modeling ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Reinforcement Learning for Active Human Pose Estimation ",
		"abstract": "Most 3d human pose estimation methods assume that input -- be it images of a scene collected from one or several viewpoints, or from a video -- is given. Consequently, they focus on estimates leveraging prior knowledge and measurement by fusing information spatially and/or temporally, whenever available. In this paper we address the problem of an active observer with freedom to move and explore the scene spatially -- in `time-freeze' mode -- and/or temporally, by selecting informative viewpoints that improve its estimation accuracy. Towards this end, we introduce Pose-DRL, a fully trainable deep reinforcement learning-based active pose estimation architecture which learns to select appropriate views, in space and time, to feed an underlying monocular pose estimator. We evaluate our model using single- and multi-target estimators with strong result in both settings. Our system further learns automatic stopping conditions in time and transition functions to the next temporal processing step in videos. In extensive experiments with the Panoptic multi-view setup, and for complex scenes containing multiple people, we show that our model learns to select viewpoints that yield significantly more accurate pose estimates compared to strong multi-view baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.02024v2"
	},
	{
		"title": "Robust Tensor Decomposition via Orientation Invariant Tubal Nuclear Norms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Model Watermarking for Image Processing Networks ",
		"abstract": "Deep learning has achieved tremendous success in numerous industrial applications. As training a good model often needs massive high-quality data and computation resources, the learned models often have significant business values. However, these valuable deep models are exposed to a huge risk of infringements. For example, if the attacker has the full information of one target model including the network structure and weights, the model can be easily finetuned on new datasets. Even if the attacker can only access the output of the target model, he/she can still train another similar surrogate model by generating a large scale of input-output training pairs. How to protect the intellectual property of deep models is a very important but seriously under-researched problem. There are a few recent attempts at classification network protection only. In this paper, we propose the first model watermarking framework for protecting image processing models. To achieve this goal, we leverage the spatial invisible watermarking mechanism. Specifically, given a black-box target model, a unified and invisible watermark is hidden into its outputs, which can be regarded as a special task-agnostic barrier. In this way, when the attacker trains one surrogate model by using the input-output pairs of the target model, the hidden watermark will be learned and extracted afterward. To enable watermarks from binary bits to high-resolution images, both traditional and deep spatial invisible watermarking mechanism are considered. Experiments demonstrate the robustness of the proposed watermarking mechanism, which can resist surrogate models learned with different network structures and objective functions. Besides deep models, the proposed method is also easy to be extended to protect data and traditional image processing algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.11088v1"
	},
	{
		"title": "Learning Multi‐level Dependencies for Robust Word Recognition ",
		"abstract": "Robust language processing systems are becoming increasingly important given the recent awareness of dangerous situations where brittle machine learning models can be easily broken with the presence of noises. In this paper, we introduce a robust word recognition framework that captures multi-level sequential dependencies in noised sentences. The proposed framework employs a sequence-to-sequence model over characters of each word, whose output is given to a word-level bi-directional recurrent neural network. We conduct extensive experiments to verify the effectiveness of the framework. The results show that the proposed framework outperforms state-of-the-art methods by a large margin and they also suggest that character-level dependencies can play an important role in word recognition.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09789v1"
	},
	{
		"title": "Tracklet Self‐Supervised Learning for Unsupervised Person Re‐Identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning from Easy to Complex: Adaptive Multi‐curricula Learning for Neural Dialogue Generation ",
		"abstract": "Current state-of-the-art neural dialogue systems are mainly data-driven and are trained on human-generated responses. However, due to the subjectivity and open-ended nature of human conversations, the complexity of training dialogues varies greatly. The noise and uneven complexity of query-response pairs impede the learning efficiency and effects of the neural dialogue generation models. What is more, so far, there are no unified dialogue complexity measurements, and the dialogue complexity embodies multiple aspects of attributes---specificity, repetitiveness, relevance, etc. Inspired by human behaviors of learning to converse, where children learn from easy dialogues to complex ones and dynamically adjust their learning progress, in this paper, we first analyze five dialogue attributes to measure the dialogue complexity in multiple perspectives on three publicly available corpora. Then, we propose an adaptive multi-curricula learning framework to schedule a committee of the organized curricula. The framework is established upon the reinforcement learning paradigm, which automatically chooses different curricula at the evolving learning process according to the learning status of the neural dialogue generation model. Extensive experiments conducted on five state-of-the-art models demonstrate its learning efficiency and effectiveness with respect to 13 automatic evaluation metrics and human judgments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00639v2"
	},
	{
		"title": "Efficient Neural Architecture Search via Proximal Iterations ",
		"abstract": "Neural architecture search (NAS) recently attracts much research attention because of its ability to identify better architectures than handcrafted ones. However, many NAS methods, which optimize the search process in a discrete search space, need many GPU days for convergence. Recently, DARTS, which constructs a differentiable search space and then optimizes it by gradient descent, can obtain high-performance architecture and reduces the search time to several days. However, DARTS is still slow as it updates an ensemble of all operations and keeps only one after convergence. Besides, DARTS can converge to inferior architectures due to the strong correlation among operations. In this paper, we propose a new differentiable Neural Architecture Search method based on Proximal gradient descent (denoted as NASP). Different from DARTS, NASP reformulates the search process as an optimization problem with a constraint that only one operation is allowed to be updated during forward and backward propagation. Since the constraint is hard to deal with, we propose a new algorithm inspired by proximal iterations to solve it. Experiments on various tasks demonstrate that NASP can obtain high-performance architectures with 10 times of speedup on the computational time than DARTS.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.13577v3"
	},
	{
		"title": "FD‐GAN: Generative Adversarial Networks with Fusion‐discriminator for Single Image Dehazing ",
		"abstract": "Recently, convolutional neural networks (CNNs) have achieved great improvements in single image dehazing and attained much attention in research. Most existing learning-based dehazing methods are not fully end-to-end, which still follow the traditional dehazing procedure: first estimate the medium transmission and the atmospheric light, then recover the haze-free image based on the atmospheric scattering model. However, in practice, due to lack of priors and constraints, it is hard to precisely estimate these intermediate parameters. Inaccurate estimation further degrades the performance of dehazing, resulting in artifacts, color distortion and insufficient haze removal. To address this, we propose a fully end-to-end Generative Adversarial Networks with Fusion-discriminator (FD-GAN) for image dehazing. With the proposed Fusion-discriminator which takes frequency information as additional priors, our model can generator more natural and realistic dehazed images with less color distortion and fewer artifacts. Moreover, we synthesize a large-scale training dataset including various indoor and outdoor hazy images to boost the performance and we reveal that for learning-based dehazing methods, the performance is strictly influenced by the training data. Experiments have shown that our method reaches state-of-the-art performance on both public synthetic datasets and real-world images with more visually pleasing dehazed results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06968v2"
	},
	{
		"title": "Multi‐instance Multi‐label Action Recognition and Localization Based on Spatio‐Temporal Pre‐trimming for Untrimmed Videos ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Incorporating Expert‐based Investment Opinion Signals in Stock Prediction: A Deep Learning Framework ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Index Tracking with Cardinality Constraints: A Stochastic Neural Networks Approach ",
		"abstract": "Partial (replication) index tracking is a popular passive investment strategy. It aims to replicate the performance of a given index by constructing a tracking portfolio which contains some constituents of the index. The tracking error optimisation is quadratic and NP-hard when taking the L0 constraint into account so it is usually solved by heuristic methods such as evolutionary algorithms. This paper introduces a simple, efficient and scalable connectionist model as an alternative. We propose a novel reparametrisation method and then solve the optimisation problem with stochastic neural networks. The proposed approach is examined with S&P 500 index data for more than 10 years and compared with widely used index tracking approaches such as forward and backward selection and the largest market capitalisation methods. The empirical results show our model achieves excellent performance. Compared with the benchmarked models, our model has the lowest tracking error, across a range of portfolio sizes. Meanwhile it offers comparable performance to the others on secondary criteria such as volatility, Sharpe ratio and maximum drawdown.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05052v2"
	},
	{
		"title": "An Operational Semantics for True Concurrency in BDI Agent Systems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Be Relevant, Non‐redundant, Timely: Deep Reinforcement Learning for Real‐time Event Summarization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Simultaneous Learning of Pivots and Representations for Cross‐Domain Sentiment Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Agent Actor‐Critic with Hierarchical Graph Attention Network ",
		"abstract": "Most previous studies on multi-agent reinforcement learning focus on deriving decentralized and cooperative policies to maximize a common reward and rarely consider the transferability of trained policies to new tasks. This prevents such policies from being applied to more complex multi-agent tasks. To resolve these limitations, we propose a model that conducts both representation learning for multiple agents using hierarchical graph attention network and policy learning using multi-agent actor-critic. The hierarchical graph attention network is specially designed to model the hierarchical relationships among multiple agents that either cooperate or compete with each other to derive more advanced strategic policies. Two attention networks, the inter-agent and inter-group attention layers, are used to effectively model individual and group level interactions, respectively. The two attention networks have been proven to facilitate the transfer of learned policies to new tasks with different agent compositions and allow one to interpret the learned strategies. Empirically, we demonstrate that the proposed model outperforms existing methods in several mixed cooperative and competitive tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.12557v2"
	},
	{
		"title": "Interactive Dual Generative Adversarial Networks for Image Captioning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Empirical Study of Content Understanding in Conversational Question Answering ",
		"abstract": "With a lot of work about context-free question answering systems, there is an emerging trend of conversational question answering models in the natural language processing field. Thanks to the recently collected datasets, including QuAC and CoQA, there has been more work on conversational question answering, and recent work has achieved competitive performance on both datasets. However, to best of our knowledge, two important questions for conversational comprehension research have not been well studied: 1) How well can the benchmark dataset reflect models' content understanding? 2) Do the models well utilize the conversation content when answering questions? To investigate these questions, we design different training settings, testing settings, as well as an attack to verify the models' capability of content understanding on QuAC and CoQA. The experimental results indicate some potential hazards in the benchmark datasets, QuAC and CoQA, for conversational comprehension research. Our analysis also sheds light on both what models may learn and how datasets may bias the models. With deep investigation of the task, it is believed that this work can benefit the future progress of conversation comprehension. The source code is available at https://github.com/MiuLab/CQA-Study.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10743v2"
	},
	{
		"title": "Learning Triple Embeddings from Knowledge Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Unified Graph and Low‐rank Tensor Learning for Multi‐view Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Relatedness and TBox‐Driven Rule Learning in Large Knowledge Bases ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Algorithms for Manipulating Sequential Allocation ",
		"abstract": "Sequential allocation is a simple and widely studied mechanism to allocate indivisible items in turns to agents according to a pre-specified picking sequence of agents. At each turn, the current agent in the picking sequence picks its most preferred item among all items having not been allocated yet. This problem is well-known to be not strategyproof, i.e., an agent may get more utility by reporting an untruthful preference ranking of items. It arises the problem: how to find the best response of an agent?   It is known that this problem is polynomially solvable for only two agents and NP-complete for arbitrary number of agents.   The computational complexity of this problem with three agents was left as an open problem. In this paper, we give a novel algorithm that solves the problem in polynomial time for each fixed number of agents. We also show that an agent can always get at least half of its optimal utility by simply using its truthful preference as the response.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.06747v1"
	},
	{
		"title": "ElixirNet: Relation‐aware Network Architecture Adaptation for Medical Lesion Detection ",
		"abstract": "Most advances in medical lesion detection network are limited to subtle modification on the conventional detection network designed for natural images. However, there exists a vast domain gap between medical images and natural images where the medical image detection often suffers from several domain-specific challenges, such as high lesion/background similarity, dominant tiny lesions, and severe class imbalance. Is a hand-crafted detection network tailored for natural image undoubtedly good enough over a discrepant medical lesion domain? Is there more powerful operations, filters, and sub-networks that better fit the medical lesion detection problem to be discovered? In this paper, we introduce a novel ElixirNet that includes three components: 1) TruncatedRPN balances positive and negative data for false positive reduction; 2) Auto-lesion Block is automatically customized for medical images to incorporate relation-aware operations among region proposals, and leads to more suitable and efficient classification and localization. 3) Relation transfer module incorporates the semantic relationship and transfers the relevant contextual information with an interpretable the graph thus alleviates the problem of lack of annotations for all types of lesions. Experiments on DeepLesion and Kits19 prove the effectiveness of ElixirNet, achieving improvement of both sensitivity and precision over FPN with fewer parameters.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.08770v1"
	},
	{
		"title": "Thinking Globally, Acting Locally: Distantly Supervised Global‐to‐Local Knowledge Selection for Background Based Conversation ",
		"abstract": "Background Based Conversations (BBCs) have been introduced to help conversational systems avoid generating overly generic responses. In a BBC, the conversation is grounded in a knowledge source. A key challenge in BBCs is Knowledge Selection (KS): given a conversational context, try to find the appropriate background knowledge (a text fragment containing related facts or comments, etc.) based on which to generate the next response. Previous work addresses KS by employing attention and/or pointer mechanisms. These mechanisms use a local perspective, i.e., they select a token at a time based solely on the current decoding state. We argue for the adoption of a global perspective, i.e., pre-selecting some text fragments from the background knowledge that could help determine the topic of the next response. We enhance KS in BBCs by introducing a Global-to-Local Knowledge Selection (GLKS) mechanism. Given a conversational context and background knowledge, we first learn a topic transition vector to encode the most likely text fragments to be used in the next response, which is then used to guide the local KS at each decoding timestamp. In order to effectively learn the topic transition vector, we propose a distantly supervised learning schema. Experimental results show that the GLKS model significantly outperforms state-of-the-art methods in terms of both automatic and human evaluation. More importantly, GLKS achieves this without requiring any extra annotations, which demonstrates its high degree of scalability.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.09528v2"
	},
	{
		"title": "Efficient Residual Dense Block Search for Image Super‐Resolution ",
		"abstract": "Although remarkable progress has been made on single image super-resolution due to the revival of deep convolutional neural networks, deep learning methods are confronted with the challenges of computation and memory consumption in practice, especially for mobile devices. Focusing on this issue, we propose an efficient residual dense block search algorithm with multiple objectives to hunt for fast, lightweight and accurate networks for image super-resolution. Firstly, to accelerate super-resolution network, we exploit the variation of feature scale adequately with the proposed efficient residual dense blocks. In the proposed evolutionary algorithm, the locations of pooling and upsampling operator are searched automatically. Secondly, network architecture is evolved with the guidance of block credits to acquire accurate super-resolution network. The block credit reflects the effect of current block and is earned during model evaluation process. It guides the evolution by weighing the sampling probability of mutation to favor admirable blocks. Extensive experimental results demonstrate the effectiveness of the proposed searching method and the found efficient super-resolution models achieve better performance than the state-of-the-art methods with limited number of parameters and FLOPs.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.11409v3"
	},
	{
		"title": "Improving Knowledge‐aware Dialogue Generation via Knowledge Base Question Answering ",
		"abstract": "Neural network models usually suffer from the challenge of incorporating commonsense knowledge into the open-domain dialogue systems. In this paper, we propose a novel knowledge-aware dialogue generation model (called TransDG), which transfers question representation and knowledge matching abilities from knowledge base question answering (KBQA) task to facilitate the utterance understanding and factual knowledge selection for dialogue generation. In addition, we propose a response guiding attention and a multi-step decoding strategy to steer our model to focus on relevant features for response generation. Experiments on two benchmark datasets demonstrate that our model has robust superiority over compared methods in generating informative and fluent dialogues. Our code is available at https://github.com/siat-nlp/TransDG.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07491v1"
	},
	{
		"title": "ParamE: Regarding Neural Network Parameters as Relation Embeddings for Knowledge Graph Completion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Variational Perturbative Approach to Planning in Graph‐based Markov Decision Processes ",
		"abstract": "Coordinating multiple interacting agents to achieve a common goal is a difficult task with huge applicability. This problem remains hard to solve, even when limiting interactions to be mediated via a static interaction-graph. We present a novel approximate solution method for multi-agent Markov decision problems on graphs, based on variational perturbation theory. We adopt the strategy of planning via inference, which has been explored in various prior works. We employ a non-trivial extension of a novel high-order variational method that allows for approximate inference in large networks and has been shown to surpass the accuracy of existing variational methods. To compare our method to two state-of-the-art methods for multi-agent planning on graphs, we apply the method different standard GMDP problems. We show that in cases, where the goal is encoded as a non-local cost function, our method performs well, while state-of-the-art methods approach the performance of random guess. In a final experiment, we demonstrate that our method brings significant improvement for synchronization tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01849v2"
	},
	{
		"title": "DGCN: Dynamic Graph Convolutional Network for Efficient Multi‐Person Pose Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Tale of Two‐Timescale Reinforcement Learning with the Tightest Finite‐Time Bound ",
		"abstract": "Policy evaluation in reinforcement learning is often conducted using two-timescale stochastic approximation, which results in various gradient temporal difference methods such as GTD(0), GTD2, and TDC. Here, we provide convergence rate bounds for this suite of algorithms. Algorithms such as these have two iterates, $\\theta_n$ and $w_n,$ which are updated using two distinct stepsize sequences, $\\alpha_n$ and $\\beta_n,$ respectively. Assuming $\\alpha_n = n^{-\\alpha}$ and $\\beta_n = n^{-\\beta}$ with $1 > \\alpha > \\beta > 0,$ we show that, with high probability, the two iterates converge to their respective solutions $\\theta^*$ and $w^*$ at rates given by $\\|\\theta_n - \\theta^*\\| = \\tilde{O}( n^{-\\alpha/2})$ and $\\|w_n - w^*\\| = \\tilde{O}(n^{-\\beta/2});$ here, $\\tilde{O}$ hides logarithmic terms. Via comparable lower bounds, we show that these bounds are, in fact, tight. To the best of our knowledge, ours is the first finite-time analysis which achieves these rates. While it was known that the two timescale components decouple asymptotically, our results depict this phenomenon more explicitly by showing that it in fact happens from some finite time onwards. Lastly, compared to existing works, our result applies to a broader family of stepsizes, including non-square summable ones.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09157v2"
	},
	{
		"title": "Do not have enough data? Deep learning to the rescue! ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Visualizing Deep Networks by Optimizing with Integrated Gradients ",
		"abstract": "Understanding and interpreting the decisions made by deep learning models is valuable in many domains. In computer vision, computing heatmaps from a deep network is a popular approach for visualizing and understanding deep networks. However, heatmaps that do not correlate with the network may mislead human, hence the performance of heatmaps in providing a faithful explanation to the underlying deep network is crucial. In this paper, we propose I-GOS, which optimizes for a heatmap so that the classification scores on the masked image would maximally decrease. The main novelty of the approach is to compute descent directions based on the integrated gradients instead of the normal gradient, which avoids local optima and speeds up convergence. Compared with previous approaches, our method can flexibly compute heatmaps at any resolution for different user needs. Extensive experiments on several benchmark datasets show that the heatmaps produced by our approach are more correlated with the decision of the underlying deep network, in comparison with other state-of-the-art approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.00954v2"
	},
	{
		"title": "Diversity Transfer Network for Few‐Shot Learning ",
		"abstract": "Few-shot learning is a challenging task that aims at training a classifier for unseen classes with only a few training examples. The main difficulty of few-shot learning lies in the lack of intra-class diversity within insufficient training samples. To alleviate this problem, we propose a novel generative framework, Diversity Transfer Network (DTN), that learns to transfer latent diversities from known categories and composite them with support features to generate diverse samples for novel categories in feature space. The learning problem of the sample generation (i.e., diversity transfer) is solved via minimizing an effective meta-classification loss in a single-stage network, instead of the generative loss in previous works.   Besides, an organized auxiliary task co-training over known categories is proposed to stabilize the meta-training process of DTN. We perform extensive experiments and ablation studies on three datasets, i.e., \\emph{mini}ImageNet, CIFAR100 and CUB. The results show that DTN, with single-stage training and faster convergence speed, obtains the state-of-the-art results among the feature generation based few-shot learning methods. Code and supplementary material are available at: \\texttt{https://github.com/Yuxin-CV/DTN}",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.13182v1"
	},
	{
		"title": "Pyramid Attention Aggregation Network for Semantic Segmentation of Surgical Instruments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Apprenticeship Learning via Frank‐Wolfe ",
		"abstract": "We consider the applications of the Frank-Wolfe (FW) algorithm for Apprenticeship Learning (AL). In this setting, we are given a Markov Decision Process (MDP) without an explicit reward function. Instead, we observe an expert that acts according to some policy, and the goal is to find a policy whose feature expectations are closest to those of the expert policy. We formulate this problem as finding the projection of the feature expectations of the expert on the feature expectations polytope -- the convex hull of the feature expectations of all the deterministic policies in the MDP. We show that this formulation is equivalent to the AL objective and that solving this problem using the FW algorithm is equivalent well-known Projection method of Abbeel and Ng (2004). This insight allows us to analyze AL with tools from convex optimization literature and derive tighter convergence bounds on AL. Specifically, we show that a variation of the FW method that is based on taking \"away steps\" achieves a linear rate of convergence when applied to AL and that a stochastic version of the FW algorithm can be used to avoid precise estimation of feature expectations. We also experimentally show that this version outperforms the FW baseline. To the best of our knowledge, this is the first work that shows linear convergence rates for AL.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.01679v2"
	},
	{
		"title": "Gait Recognition for Co‐existing Multiple People Using Millimeter Wave Sensing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Variational Adversarial Kernel Learned Imitation Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "AWR: Adaptive Weighting Regression for 3D Hand Pose Estimation ",
		"abstract": "In this paper, we propose an adaptive weighting regression (AWR) method to leverage the advantages of both detection-based and regression-based methods. Hand joint coordinates are estimated as discrete integration of all pixels in dense representation, guided by adaptive weight maps. This learnable aggregation process introduces both dense and joint supervision that allows end-to-end training and brings adaptability to weight maps, making the network more accurate and robust. Comprehensive exploration experiments are conducted to validate the effectiveness and generality of AWR under various experimental settings, especially its usefulness for different types of dense representation and input modality. Our method outperforms other state-of-the-art methods on four publicly available datasets, including NYU, ICVL, MSRA and HANDS 2017 dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2007.09590v1"
	},
	{
		"title": "Human Synthesis and Scene Compositing ",
		"abstract": "Generating good quality and geometrically plausible synthetic images of humans with the ability to control appearance, pose and shape parameters, has become increasingly important for a variety of tasks ranging from photo editing, fashion virtual try-on, to special effects and image compression. In this paper, we propose HUSC, a HUman Synthesis and Scene Compositing framework for the realistic synthesis of humans with different appearance, in novel poses and scenes. Central to our formulation is 3d reasoning for both people and scenes, in order to produce realistic collages, by correctly modeling perspective effects and occlusion, by taking into account scene semantics and by adequately handling relative scales. Conceptually our framework consists of three components: (1) a human image synthesis model with controllable pose and appearance, based on a parametric representation, (2) a person insertion procedure that leverages the geometry and semantics of the 3d scene, and (3) an appearance compositing process to create a seamless blending between the colors of the scene and the generated human image, and avoid visual artifacts. The performance of our framework is supported by both qualitative and quantitative results, in particular state-of-the art synthesis scores for the DeepFashion dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10307v2"
	},
	{
		"title": "Bidding in Smart Grid PDAs: Theory, Analysis and Strategy ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Part Generation and Assembly for Structure‐aware Shape Synthesis ",
		"abstract": "Learning powerful deep generative models for 3D shape synthesis is largely hindered by the difficulty in ensuring plausibility encompassing correct topology and reasonable geometry. Indeed, learning the distribution of plausible 3D shapes seems a daunting task for the holistic approaches, given the significant topological variations of 3D objects even within the same category. Enlightened by the fact that 3D shape structure is characterized as part composition and placement, we propose to model 3D shape variations with a part-aware deep generative network, coined as PAGENet. The network is composed of an array of per-part VAE-GANs, generating semantic parts composing a complete shape, followed by a part assembly module that estimates a transformation for each part to correlate and assemble them into a plausible structure. Through delegating the learning of part composition and part placement into separate networks, the difficulty of modeling structural variations of 3D shapes is greatly reduced. We demonstrate through both qualitative and quantitative evaluations that PAGENet generates 3D shapes with plausible, diverse and detailed structure, and show two applications, i.e., semantic shape segmentation and part-based shape editing.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.06693v4"
	},
	{
		"title": "Consistent Video Style Transfer via Compound Regularization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Shape‐Oriented Convolution Neural Network for Point Cloud Analysis ",
		"abstract": "Point cloud is a principal data structure adopted for 3D geometric information encoding. Unlike other conventional visual data, such as images and videos, these irregular points describe the complex shape features of 3D objects, which makes shape feature learning an essential component of point cloud analysis. To this end, a shape-oriented message passing scheme dubbed ShapeConv is proposed to focus on the representation learning of the underlying shape formed by each local neighboring point. Despite this intra-shape relationship learning, ShapeConv is also designed to incorporate the contextual effects from the inter-shape relationship through capturing the long-ranged dependencies between local underlying shapes. This shape-oriented operator is stacked into our hierarchical learning architecture, namely Shape-Oriented Convolutional Neural Network (SOCNN), developed for point cloud analysis. Extensive experiments have been performed to evaluate its significance in the tasks of point cloud classification and part segmentation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.09411v1"
	},
	{
		"title": "A Three‐Level Optimization Model for Nonlinearly Separable Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "EHSOD: CAM‐Guided End‐to‐end Hybrid‐Supervised Object Detection with Cascade Refinement ",
		"abstract": "Object detectors trained on fully-annotated data currently yield state of the art performance but require expensive manual annotations. On the other hand, weakly-supervised detectors have much lower performance and cannot be used reliably in a realistic setting. In this paper, we study the hybrid-supervised object detection problem, aiming to train a high quality detector with only a limited amount of fullyannotated data and fully exploiting cheap data with imagelevel labels. State of the art methods typically propose an iterative approach, alternating between generating pseudo-labels and updating a detector. This paradigm requires careful manual hyper-parameter tuning for mining good pseudo labels at each round and is quite time-consuming. To address these issues, we present EHSOD, an end-to-end hybrid-supervised object detection system which can be trained in one shot on both fully and weakly-annotated data. Specifically, based on a two-stage detector, we proposed two modules to fully utilize the information from both kinds of labels: 1) CAMRPN module aims at finding foreground proposals guided by a class activation heat-map; 2) hybrid-supervised cascade module further refines the bounding-box position and classification with the help of an auxiliary head compatible with image-level data. Extensive experiments demonstrate the effectiveness of the proposed method and it achieves comparable results on multiple object detection benchmarks with only 30% fully-annotated data, e.g. 37.5% mAP on COCO. We will release the code and the trained models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07421v1"
	},
	{
		"title": "SM‐NAS: Structural‐to‐Modular Neural Architecture Search for Object Detection ",
		"abstract": "The state-of-the-art object detection method is complicated with various modules such as backbone, feature fusion neck, RPN and RCNN head, where each module may have different designs and structures. How to leverage the computational cost and accuracy trade-off for the structural combination as well as the modular selection of multiple modules? Neural architecture search (NAS) has shown great potential in finding an optimal solution. Existing NAS works for object detection only focus on searching better design of a single module such as backbone or feature fusion neck, while neglecting the balance of the whole system. In this paper, we present a two-stage coarse-to-fine searching strategy named Structural-to-Modular NAS (SM-NAS) for searching a GPU-friendly design of both an efficient combination of modules and better modular-level architecture for object detection. Specifically, Structural-level searching stage first aims to find an efficient combination of different modules; Modular-level searching stage then evolves each specific module and pushes the Pareto front forward to a faster task-specific network. We consider a multi-objective search where the search space covers many popular designs of detection methods. We directly search a detection backbone without pre-trained models or any proxy task by exploring a fast training from scratch strategy. The resulting architectures dominate state-of-the-art object detection systems in both inference time and accuracy and demonstrate the effectiveness on multiple detection datasets, e.g. halving the inference time with additional 1% mAP improvement compared to FPN and reaching 46% mAP with the similar inference time of MaskRCNN.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09929v2"
	},
	{
		"title": "HoMM: Higher‐order Moment Matching for Unsupervised Domain Adaptation ",
		"abstract": "Minimizing the discrepancy of feature distributions between different domains is one of the most promising directions in unsupervised domain adaptation. From the perspective of distribution matching, most existing discrepancy-based methods are designed to match the second-order or lower statistics, which however, have limited expression of statistical characteristic for non-Gaussian distributions. In this work, we explore the benefits of using higher-order statistics (mainly refer to third-order and fourth-order statistics) for domain matching. We propose a Higher-order Moment Matching (HoMM) method, and further extend the HoMM into reproducing kernel Hilbert spaces (RKHS). In particular, our proposed HoMM can perform arbitrary-order moment tensor matching, we show that the first-order HoMM is equivalent to Maximum Mean Discrepancy (MMD) and the second-order HoMM is equivalent to Correlation Alignment (CORAL). Moreover, the third-order and the fourth-order moment tensor matching are expected to perform comprehensive domain alignment as higher-order statistics can approximate more complex, non-Gaussian distributions. Besides, we also exploit the pseudo-labeled target samples to learn discriminative representations in the target domain, which further improves the transfer performance. Extensive experiments are conducted, showing that our proposed HoMM consistently outperforms the existing moment matching methods by a large margin. Codes are available at \\url{https://github.com/chenchao666/HoMM-Master}",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11976v1"
	},
	{
		"title": "Residual Continual Learning ",
		"abstract": "We propose a novel continual learning method called Residual Continual Learning (ResCL). Our method can prevent the catastrophic forgetting phenomenon in sequential learning of multiple tasks, without any source task information except the original network. ResCL reparameterizes network parameters by linearly combining each layer of the original network and a fine-tuned network; therefore, the size of the network does not increase at all. To apply the proposed method to general convolutional neural networks, the effects of batch normalization layers are also considered. By utilizing residual-learning-like reparameterization and a special weight decay loss, the trade-off between source and target performance is effectively controlled. The proposed method exhibits state-of-the-art performance in various continual learning scenarios.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06774v1"
	},
	{
		"title": "Beyond Trees: Analysis and Convergence of Belief Propagation in Graphs with Multiple Cycles ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dynamic Embedding on Textual Networks via a Gaussian Process ",
		"abstract": "Textual network embedding aims to learn low-dimensional representations of text-annotated nodes in a graph. Prior work in this area has typically focused on fixed graph structures; however, real-world networks are often dynamic. We address this challenge with a novel end-to-end node-embedding model, called Dynamic Embedding for Textual Networks with a Gaussian Process (DetGP). After training, DetGP can be applied efficiently to dynamic graphs without re-training or backpropagation. The learned representation of each node is a combination of textual and structural embeddings. Because the structure is allowed to be dynamic, our method uses the Gaussian process to take advantage of its non-parametric properties. To use both local and global graph structures, diffusion is used to model multiple hops between neighbors. The relative importance of global versus local structure for the embeddings is learned automatically. With the non-parametric nature of the Gaussian process, updating the embeddings for a changed graph structure requires only a forward pass through the learned model. Considering link prediction and node classification, experiments demonstrate the empirical effectiveness of our method compared to baseline approaches. We further show that DetGP can be straightforwardly and efficiently applied to dynamic textual networks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.02187v3"
	},
	{
		"title": "Unicoder‐VL: A Universal Encoder for Vision and Language by Cross‐modal Pre‐training ",
		"abstract": "We propose Unicoder-VL, a universal encoder that aims to learn joint representations of vision and language in a pre-training manner. Borrow ideas from cross-lingual pre-trained models, such as XLM and Unicoder, both visual and linguistic contents are fed into a multi-layer Transformer for the cross-modal pre-training, where three pre-trained tasks are employed, including Masked Language Modeling (MLM), Masked Object Classification (MOC) and Visual-linguistic Matching (VLM). The first two tasks learn context-aware representations for input tokens based on linguistic and visual contents jointly. The last task tries to predict whether an image and a text describe each other. After pretraining on large-scale image-caption pairs, we transfer Unicoder-VL to caption-based image-text retrieval and visual commonsense reasoning, with just one additional output layer. We achieve state-of-the-art or comparable results on both two tasks and show the powerful ability of the cross-modal pre-training.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.06066v3"
	},
	{
		"title": "Reinforcement Learning with Perturbed Rewards ",
		"abstract": "Recent studies have shown that reinforcement learning (RL) models are vulnerable in various noisy scenarios. For instance, the observed reward channel is often subject to noise in practice (e.g., when rewards are collected through sensors), and is therefore not credible. In addition, for applications such as robotics, a deep reinforcement learning (DRL) algorithm can be manipulated to produce arbitrary errors by receiving corrupted rewards. In this paper, we consider noisy RL problems with perturbed rewards, which can be approximated with a confusion matrix. We develop a robust RL framework that enables agents to learn in noisy environments where only perturbed rewards are observed. Our solution framework builds on existing RL/DRL algorithms and firstly addresses the biased noisy reward setting without any assumptions on the true distribution (e.g., zero-mean Gaussian noise as made in previous works). The core ideas of our solution include estimating a reward confusion matrix and defining a set of unbiased surrogate rewards. We prove the convergence and sample complexity of our approach. Extensive experiments on different DRL platforms show that trained policies based on our estimated surrogate reward can achieve higher expected rewards, and converge faster than existing baselines. For instance, the state-of-the-art PPO algorithm is able to obtain 84.6% and 80.8% improvements on average score for five Atari games, with error rates as 10% and 30% respectively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1810.01032v4"
	},
	{
		"title": "Efficient Inference of Optimal Decision Trees ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Zone Unit for Recurrent Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Proportional Belief Merging ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Correcting Predictions for Approximate Bayesian Inference ",
		"abstract": "Bayesian models quantify uncertainty and facilitate optimal decision-making in downstream applications. For most models, however, practitioners are forced to use approximate inference techniques that lead to sub-optimal decisions due to incorrect posterior predictive distributions. We present a novel approach that corrects for inaccuracies in posterior inference by altering the decision-making process. We train a separate model to make optimal decisions under the approximate posterior, combining interpretable Bayesian modeling with optimization of direct predictive accuracy in a principled fashion. The solution is generally applicable as a plug-in module for predictive decision-making for arbitrary probabilistic programs, irrespective of the posterior inference strategy. We demonstrate the approach empirically in several problems, confirming its potential.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.04919v1"
	},
	{
		"title": "Efficiently Enumerating Substrings with Statistically Significant Frequencies of Locally Optimal Occurrences in Gigantic String ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Visual Dialogue State Tracking for Question Generation ",
		"abstract": "GuessWhat?! is a visual dialogue task between a guesser and an oracle. The guesser aims to locate an object supposed by the oracle oneself in an image by asking a sequence of Yes/No questions. Asking proper questions with the progress of dialogue is vital for achieving successful final guess. As a result, the progress of dialogue should be properly represented and tracked. Previous models for question generation pay less attention on the representation and tracking of dialogue states, and therefore are prone to asking low quality questions such as repeated questions. This paper proposes visual dialogue state tracking (VDST) based method for question generation. A visual dialogue state is defined as the distribution on objects in the image as well as representations of objects. Representations of objects are updated with the change of the distribution on objects. An object-difference based attention is used to decode new question. The distribution on objects is updated by comparing the question-answer pair and objects. Experimental results on GuessWhat?! dataset show that our model significantly outperforms existing methods and achieves new state-of-the-art performance. It is also noticeable that our model reduces the rate of repeated questions from more than 50% to 21.9% compared with previous state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07928v2"
	},
	{
		"title": "Representing Closed Transformation Paths in Encoded Network Latent Space ",
		"abstract": "Deep generative networks have been widely used for learning mappings from a low-dimensional latent space to a high-dimensional data space. In many cases, data transformations are defined by linear paths in this latent space. However, the Euclidean structure of the latent space may be a poor match for the underlying latent structure in the data. In this work, we incorporate a generative manifold model into the latent space of an autoencoder in order to learn the low-dimensional manifold structure from the data and adapt the latent space to accommodate this structure. In particular, we focus on applications in which the data has closed transformation paths which extend from a starting point and return to nearly the same point. Through experiments on data with natural closed transformation paths, we show that this model introduces the ability to learn the latent dynamics of complex systems, generate transformation paths, and classify samples that belong on the same transformation path.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.02644v1"
	},
	{
		"title": "CG‐GAN: An Interactive Evolutionary GAN‐based Approach for Facial Composite Generation ",
		"abstract": "Facial composites are graphical representations of an eyewitness's memory of a face. Many digital systems are available for the creation of such composites but are either unable to reproduce features unless previously designed or do not allow holistic changes to the image. In this paper, we improve the efficiency of composite creation by removing the reliance on expert knowledge and letting the system learn to represent faces from examples. The novel approach, Composite Generating GAN (CG-GAN), applies generative and evolutionary computation to allow casual users to easily create facial composites. Specifically, CG-GAN utilizes the generator network of a pg-GAN to create high-resolution human faces. Users are provided with several functions to interactively breed and edit faces. CG-GAN offers a novel way of generating and handling static and animated photo-realistic facial composites, with the possibility of combining multiple representations of the same perpetrator, generated by different eyewitnesses.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05020v1"
	},
	{
		"title": "Efficient Querying from Weighted Binary Codes ",
		"abstract": "Binary codes are widely used to represent the data due to their small storage and efficient computation. However, there exists an ambiguity problem that lots of binary codes share the same Hamming distance to a query. To alleviate the ambiguity problem, weighted binary codes assign different weights to each bit of binary codes and compare the binary codes by the weighted Hamming distance. Till now, performing the querying from the weighted binary codes efficiently is still an open issue. In this paper, we propose a new method to rank the weighted binary codes and return the nearest weighted binary codes of the query efficiently. In our method, based on the multi-index hash tables, two algorithms, the table bucket finding algorithm and the table merging algorithm, are proposed to select the nearest weighted binary codes of the query in a non-exhaustive and accurate way. The proposed algorithms are justified by proving their theoretic properties. The experiments on three large-scale datasets validate both the search efficiency and the search accuracy of our method. Especially for the number of weighted binary codes up to one billion, our method shows a great improvement of more than 1000 times faster than the linear scan.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05006v2"
	},
	{
		"title": "Likelihood Ratios and Generative Classifiers for Unsupervised Out‐of‐Domain Detection In Task Oriented Dialog ",
		"abstract": "The task of identifying out-of-domain (OOD) input examples directly at test-time has seen renewed interest recently due to increased real world deployment of models. In this work, we focus on OOD detection for natural language sentence inputs to task-based dialog systems. Our findings are three-fold: First, we curate and release ROSTD (Real Out-of-Domain Sentences From Task-oriented Dialog) - a dataset of 4K OOD examples for the publicly available dataset from (Schuster et al. 2019). In contrast to existing settings which synthesize OOD examples by holding out a subset of classes, our examples were authored by annotators with apriori instructions to be out-of-domain with respect to the sentences in an existing dataset. Second, we explore likelihood ratio based approaches as an alternative to currently prevalent paradigms. Specifically, we reformulate and apply these approaches to natural language inputs. We find that they match or outperform the latter on all datasets, with larger improvements on non-artificial OOD benchmarks such as our dataset. Our ablations validate that specifically using likelihood ratios rather than plain likelihood is necessary to discriminate well between OOD and in-domain data. Third, we propose learning a generative classifier and computing a marginal likelihood (ratio) for OOD detection. This allows us to use a principled likelihood while at the same time exploiting training-time labels. We find that this approach outperforms both simple likelihood (ratio) based and other prior approaches. We are hitherto the first to investigate the use of generative classifiers for OOD detection at test-time.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.12800v1"
	},
	{
		"title": "Multi‐Fidelity Multi‐Objective Bayesian Optimization:  An Output Space Entropy Search Approach ",
		"abstract": "We study the novel problem of blackbox optimization of multiple objectives via multi-fidelity function evaluations that vary in the amount of resources consumed and their accuracy. The overall goal is to approximate the true Pareto set of solutions by minimizing the resources consumed for function evaluations. For example, in power system design optimization, we need to find designs that trade-off cost, size, efficiency, and thermal tolerance using multi-fidelity simulators for design evaluations. In this paper, we propose a novel approach referred as Multi-Fidelity Output Space Entropy Search for Multi-objective Optimization (MF-OSEMO) to solve this problem. The key idea is to select the sequence of candidate input and fidelity-vector pairs that maximize the information gained about the true Pareto front per unit resource cost. Our experiments on several synthetic and real-world benchmark problems show that MF-OSEMO, with both approximations, significantly improves over the state-of-the-art single-fidelity algorithms for multi-objective optimization.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2011.01542v1"
	},
	{
		"title": "Hierarchically Clustered Representation Learning ",
		"abstract": "The joint optimization of representation learning and clustering in the embedding space has experienced a breakthrough in recent years. In spite of the advance, clustering with representation learning has been limited to flat-level categories, which often involves cohesive clustering with a focus on instance relations. To overcome the limitations of flat clustering, we introduce hierarchically-clustered representation learning (HCRL), which simultaneously optimizes representation learning and hierarchical clustering in the embedding space. Compared with a few prior works, HCRL firstly attempts to consider a generation of deep embeddings from every component of the hierarchy, not just leaf components. In addition to obtaining hierarchically clustered embeddings, we can reconstruct data by the various abstraction levels, infer the intrinsic hierarchical structure, and learn the level-proportion features. We conducted evaluations with image and text domains, and our quantitative analyses showed competent likelihoods and the best accuracies compared with the baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.09906v2"
	},
	{
		"title": "Deep Conservative Policy Iteration ",
		"abstract": "Conservative Policy Iteration (CPI) is a founding algorithm of Approximate Dynamic Programming (ADP). Its core principle is to stabilize greediness through stochastic mixtures of consecutive policies. It comes with strong theoretical guarantees, and inspired approaches in deep Reinforcement Learning (RL). However, CPI itself has rarely been implemented, never with neural networks, and only experimented on toy problems. In this paper, we show how CPI can be practically combined with deep RL with discrete actions. We also introduce adaptive mixture rates inspired by the theory. We experiment thoroughly the resulting algorithm on the simple Cartpole problem, and validate the proposed method on a representative subset of Atari games. Overall, this work suggests that revisiting classic ADP may lead to improved and more stable deep RL algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.09784v2"
	},
	{
		"title": "Real‐Time Emotion Recognition via Attention Gated Hierarchical Memory Network ",
		"abstract": "Real-time emotion recognition (RTER) in conversations is significant for developing emotionally intelligent chatting machines. Without the future context in RTER, it becomes critical to build the memory bank carefully for capturing historical context and summarize the memories appropriately to retrieve relevant information. We propose an Attention Gated Hierarchical Memory Network (AGHMN) to address the problems of prior work: (1) Commonly used convolutional neural networks (CNNs) for utterance feature extraction are less compatible in the memory modules; (2) Unidirectional gated recurrent units (GRUs) only allow each historical utterance to have context before it, preventing information propagation in the opposite direction; (3) The Soft Attention for summarizing loses the positional and ordering information of memories, regardless of how the memory bank is built. Particularly, we propose a Hierarchical Memory Network (HMN) with a bidirectional GRU (BiGRU) as the utterance reader and a BiGRU fusion layer for the interaction between historical utterances. For memory summarizing, we propose an Attention GRU (AGRU) where we utilize the attention weights to update the internal state of GRU. We further promote the AGRU to a bidirectional variant (BiAGRU) to balance the contextual information from recent memories and that from distant memories. We conduct experiments on two emotion conversation datasets with extensive analysis, demonstrating the efficacy of our AGHMN models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09075v1"
	},
	{
		"title": "Exploratory Combinatorial Optimization with Reinforcement Learning ",
		"abstract": "Many real-world problems can be reduced to combinatorial optimization on a graph, where the subset or ordering of vertices that maximize some objective function must be found. With such tasks often NP-hard and analytically intractable, reinforcement learning (RL) has shown promise as a framework with which efficient heuristic methods to tackle these problems can be learned. Previous works construct the solution subset incrementally, adding one element at a time, however, the irreversible nature of this approach prevents the agent from revising its earlier decisions, which may be necessary given the complexity of the optimization task. We instead propose that the agent should seek to continuously improve the solution by learning to explore at test time. Our approach of exploratory combinatorial optimization (ECO-DQN) is, in principle, applicable to any combinatorial problem that can be defined on a graph. Experimentally, we show our method to produce state-of-the-art RL performance on the Maximum Cut problem. Moreover, because ECO-DQN can start from any arbitrary configuration, it can be combined with other search methods to further improve performance, which we demonstrate using a simple random search.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.04063v2"
	},
	{
		"title": "Privacy Enhanced Multimodal Neural Representations for Emotion Recognition ",
		"abstract": "Many mobile applications and virtual conversational agents now aim to recognize and adapt to emotions. To enable this, data are transmitted from users' devices and stored on central servers. Yet, these data contain sensitive information that could be used by mobile applications without user's consent or, maliciously, by an eavesdropping adversary. In this work, we show how multimodal representations trained for a primary task, here emotion recognition, can unintentionally leak demographic information, which could override a selected opt-out option by the user. We analyze how this leakage differs in representations obtained from textual, acoustic, and multimodal data. We use an adversarial learning paradigm to unlearn the private information present in a representation and investigate the effect of varying the strength of the adversarial component on the primary task and on the privacy metric, defined here as the inability of an attacker to predict specific demographic information. We evaluate this paradigm on multiple datasets and show that we can improve the privacy metric while not significantly impacting the performance on the primary task. To the best of our knowledge, this is the first work to analyze how the privacy metric differs across modalities and how multiple privacy concerns can be tackled while still maintaining performance on emotion recognition.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.13212v1"
	},
	{
		"title": "Election Control in Social Networks via Edge Addition or Removal ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Algorithmic Improvements for Deep Reinforcement Learning applied to Interactive Fiction ",
		"abstract": "Text-based games are a natural challenge domain for deep reinforcement learning algorithms. Their state and action spaces are combinatorially large, their reward function is sparse, and they are partially observable: the agent is informed of the consequences of its actions through textual feedback. In this paper we emphasize this latter point and consider the design of a deep reinforcement learning agent that can play from feedback alone. Our design recognizes and takes advantage of the structural characteristics of text-based games. We first propose a contextualisation mechanism, based on accumulated reward, which simplifies the learning problem and mitigates partial observability. We then study different methods that rely on the notion that most actions are ineffectual in any given situation, following Zahavy et al.'s idea of an admissible action. We evaluate these techniques in a series of text-based games of increasing difficulty based on the TextWorld framework, as well as the iconic game Zork. Empirically, we find that these techniques improve the performance of a baseline deep reinforcement learning agent applied to text-based games.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12511v1"
	},
	{
		"title": "Rare Words: A Major Problem for Contextualized Embeddings and How to Fix it by Attentive Mimicking ",
		"abstract": "Pretraining deep neural network architectures with a language modeling objective has brought large improvements for many natural language processing tasks. Exemplified by BERT, a recently proposed such architecture, we demonstrate that despite being trained on huge amounts of data, deep language models still struggle to understand rare words. To fix this problem, we adapt Attentive Mimicking, a method that was designed to explicitly learn embeddings for rare words, to deep language models. In order to make this possible, we introduce one-token approximation, a procedure that enables us to use Attentive Mimicking even when the underlying language model uses subword-based tokenization, i.e., it does not assign embeddings to all words. To evaluate our method, we create a novel dataset that tests the ability of language models to capture semantic properties of words without any task-specific fine-tuning. Using this dataset, we show that adding our adapted version of Attentive Mimicking to BERT does indeed substantially improve its understanding of rare words.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.06707v4"
	},
	{
		"title": "On the Problem of Covering a 3‐D Terrain ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adaptive Activation Network and Functional Regularization for Efficient and Flexible Deep Multi‐Task Learning ",
		"abstract": "Multi-task learning (MTL) is a common paradigm that seeks to improve the generalization performance of task learning by training related tasks simultaneously. However, it is still a challenging problem to search the flexible and accurate architecture that can be shared among multiple tasks. In this paper, we propose a novel deep learning model called Task Adaptive Activation Network (TAAN) that can automatically learn the optimal network architecture for MTL. The main principle of TAAN is to derive flexible activation functions for different tasks from the data with other parameters of the network fully shared. We further propose two functional regularization methods that improve the MTL performance of TAAN. The improved performance of both TAAN and the regularization methods is demonstrated by comprehensive experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08065v1"
	},
	{
		"title": "Robust Market Equilibria with Uncertain Preferences ",
		"abstract": "The problem of allocating scarce items to individuals is an important practical question in market design. An increasingly popular set of mechanisms for this task uses the concept of market equilibrium: individuals report their preferences, have a budget of real or fake currency, and a set of prices for items and allocations is computed that sets demand equal to supply. An important real world issue with such mechanisms is that individual valuations are often only imperfectly known. In this paper, we show how concepts from classical market equilibrium can be extended to reflect such uncertainty. We show that in linear, divisible Fisher markets a robust market equilibrium (RME) always exists; this also holds in settings where buyers may retain unspent money. We provide theoretical analysis of the allocative properties of RME in terms of envy and regret. Though RME are hard to compute for general uncertainty sets, we consider some natural and tractable uncertainty sets which lead to well behaved formulations of the problem that can be solved via modern convex programming methods. Finally, we show that very mild uncertainty about valuations can cause RME allocations to outperform those which take estimates as having no underlying uncertainty.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.04867v1"
	},
	{
		"title": "Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy ",
		"abstract": "While maximizing expected return is the goal in most reinforcement learning approaches, risk-sensitive objectives such as conditional value at risk (CVaR) are more suitable for many high-stakes applications. However, relatively little is known about how to explore to quickly learn policies with good CVaR. In this paper, we present the first algorithm for sample-efficient learning of CVaR-optimal policies in Markov decision processes based on the optimism in the face of uncertainty principle. This method relies on a novel optimistic version of the distributional Bellman operator that moves probability mass from the lower to the upper tail of the return distribution. We prove asymptotic convergence and optimism of this operator for the tabular policy evaluation case. We further demonstrate that our algorithm finds CVaR-optimal policies substantially faster than existing baselines in several simulated environments with discrete and continuous state spaces.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.01546v2"
	},
	{
		"title": "Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement Learning Agents ",
		"abstract": "Robustness of Deep Reinforcement Learning (DRL) algorithms towards adversarial attacks in real world applications such as those deployed in cyber-physical systems (CPS) are of increasing concern. Numerous studies have investigated the mechanisms of attacks on the RL agent's state space. Nonetheless, attacks on the RL agent's action space (AS) (corresponding to actuators in engineering systems) are equally perverse; such attacks are relatively less studied in the ML literature. In this work, we first frame the problem as an optimization problem of minimizing the cumulative reward of an RL agent with decoupled constraints as the budget of attack. We propose a white-box Myopic Action Space (MAS) attack algorithm that distributes the attacks across the action space dimensions. Next, we reformulate the optimization problem above with the same objective function, but with a temporally coupled constraint on the attack budget to take into account the approximated dynamics of the agent. This leads to the white-box Look-ahead Action Space (LAS) attack algorithm that distributes the attacks across the action and temporal dimensions. Our results shows that using the same amount of resources, the LAS attack deteriorates the agent's performance significantly more than the MAS attack. This reveals the possibility that with limited resource, an adversary can utilize the agent's dynamics to malevolently craft attacks that causes the agent to fail. Additionally, we leverage these attack strategies as a possible tool to gain insights on the potential vulnerabilities of DRL agents.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02583v2"
	},
	{
		"title": "Ensembles of Locally Independent Prediction Models ",
		"abstract": "Ensembles depend on diversity for improved performance. Many ensemble training methods, therefore, attempt to optimize for diversity, which they almost always define in terms of differences in training set predictions. In this paper, however, we demonstrate the diversity of predictions on the training set does not necessarily imply diversity under mild covariate shift, which can harm generalization in practical settings. To address this issue, we introduce a new diversity metric and associated method of training ensembles of models that extrapolate differently on local patches of the data manifold. Across a variety of synthetic and real-world tasks, we find that our method improves generalization and diversity in qualitatively novel ways, especially under data limits and covariate shift.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.01291v3"
	},
	{
		"title": "Learning Counterfactual Representations for Estimating Individual Dose‐Response Curves ",
		"abstract": "Estimating what would be an individual's potential response to varying levels of exposure to a treatment is of high practical relevance for several important fields, such as healthcare, economics and public policy. However, existing methods for learning to estimate counterfactual outcomes from observational data are either focused on estimating average dose-response curves, or limited to settings with only two treatments that do not have an associated dosage parameter. Here, we present a novel machine-learning approach towards learning counterfactual representations for estimating individual dose-response curves for any number of treatments with continuous dosage parameters with neural networks. Building on the established potential outcomes framework, we introduce performance metrics, model selection criteria, model architectures, and open benchmarks for estimating individual dose-response curves. Our experiments show that the methods developed in this work set a new state-of-the-art in estimating individual dose-response.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.00981v3"
	},
	{
		"title": "Modelling Sentence Pairs via Reinforcement Learning: An Actor‐Critic Approach to Learn the Irrelevant Words ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "When AWGN‐based Denoiser Meets Real Noises ",
		"abstract": "Discriminative learning-based image denoisers have achieved promising performance on synthetic noises such as Additive White Gaussian Noise (AWGN). The synthetic noises adopted in most previous work are pixel-independent, but real noises are mostly spatially/channel-correlated and spatially/channel-variant. This domain gap yields unsatisfied performance on images with real noises if the model is only trained with AWGN. In this paper, we propose a novel approach to boost the performance of a real image denoiser which is trained only with synthetic pixel-independent noise data dominated by AWGN. First, we train a deep model that consists of a noise estimator and a denoiser with mixed AWGN and Random Value Impulse Noise (RVIN). We then investigate Pixel-shuffle Down-sampling (PD) strategy to adapt the trained model to real noises. Extensive experiments demonstrate the effectiveness and generalization of the proposed approach. Notably, our method achieves state-of-the-art performance on real sRGB images in the DND benchmark among models trained with synthetic noises. Codes are available at https://github.com/yzhouas/PD-Denoising-pytorch.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.03485v2"
	},
	{
		"title": "Deep Reservoir Computing Meets 5G MIMO‐OFDM Systems in Symbol Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improving Context‐Aware Neural Machine Translation Using Self‐Attentive Sentence Embedding ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Event‐Driven Continuous Time Bayesian Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Forgetting an Argument ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Asking the Right Questions to the Right Users: Active Learning with Imperfect Oracles ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improving Policies via Search in Cooperative Partially‐Observable Games ",
		"abstract": "Recent superhuman results in games have largely been achieved in a variety of zero-sum settings, such as Go and Poker, in which agents need to compete against others. However, just like humans, real-world AI systems have to coordinate and communicate with other agents in cooperative partially observable environments as well. These settings commonly require participants to both interpret the actions of others and to act in a way that is informative when being interpreted. Those abilities are typically summarized as theory f mind and are seen as crucial for social interactions. In this paper we propose two different search techniques that can be applied to improve an arbitrary agreed-upon policy in a cooperative partially observable game. The first one, single-agent search, effectively converts the problem into a single agent setting by making all but one of the agents play according to the agreed-upon policy. In contrast, in multi-agent search all agents carry out the same common-knowledge search procedure whenever doing so is computationally feasible, and fall back to playing according to the agreed-upon policy otherwise. We prove that these search procedures are theoretically guaranteed to at least maintain the original performance of the agreed-upon policy (up to a bounded approximation error). In the benchmark challenge problem of Hanabi, our search technique greatly improves the performance of every agent we tested and when applied to a policy trained using RL achieves a new state-of-the-art score of 24.61 / 25 in the game, compared to a previous-best of 24.08 / 25.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.02318v1"
	},
	{
		"title": "Gromov‐Wasserstein Factorization Models for Graph Clustering ",
		"abstract": "We propose a new nonlinear factorization model for graphs that are with topological structures, and optionally, node attributes. This model is based on a pseudometric called Gromov-Wasserstein (GW) discrepancy, which compares graphs in a relational way. It estimates observed graphs as GW barycenters constructed by a set of atoms with different weights. By minimizing the GW discrepancy between each observed graph and its GW barycenter-based estimation, we learn the atoms and their weights associated with the observed graphs. The model achieves a novel and flexible factorization mechanism under GW discrepancy, in which both the observed graphs and the learnable atoms can be unaligned and with different sizes. We design an effective approximate algorithm for learning this Gromov-Wasserstein factorization (GWF) model, unrolling loopy computations as stacked modules and computing gradients with backpropagation. The stacked modules can be with two different architectures, which correspond to the proximal point algorithm (PPA) and Bregman alternating direction method of multipliers (BADMM), respectively. Experiments show that our model obtains encouraging results on clustering graphs.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08530v1"
	},
	{
		"title": "HDDL: An Extension to PDDL for Expressing Hierarchical Planning Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Message Passing on Sets ",
		"abstract": "Modern methods for learning over graph input data have shown the fruitfulness of accounting for relationships among elements in a collection. However, most methods that learn over set input data use only rudimentary approaches to exploit intra-collection relationships. In this work we introduce Deep Message Passing on Sets (DMPS), a novel method that incorporates relational learning for sets. DMPS not only connects learning on graphs with learning on sets via deep kernel learning, but it also bridges message passing on sets and traditional diffusion dynamics commonly used in denoising models. Based on these connections, we develop two new blocks for relational learning on sets: the set-denoising block and the set-residual block. The former is motivated by the connection between message passing on general graphs and diffusion-based denoising models, whereas the latter is inspired by the well-known residual network. In addition to demonstrating the interpretability of our model by learning the true underlying relational structure experimentally, we also show the effectiveness of our approach on both synthetic and real-world datasets by achieving results that are competitive with or outperform the state-of-the-art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.09877v1"
	},
	{
		"title": "Embedding Compression with Isotropic Iterative Quantization ",
		"abstract": "Continuous representation of words is a standard component in deep learning-based NLP models. However, representing a large vocabulary requires significant memory, which can cause problems, particularly on resource-constrained platforms. Therefore, in this paper we propose an isotropic iterative quantization (IIQ) approach for compressing embedding vectors into binary ones, leveraging the iterative quantization technique well established for image retrieval, while satisfying the desired isotropic property of PMI based models. Experiments with pre-trained embeddings (i.e., GloVe and HDC) demonstrate a more than thirty-fold compression ratio with comparable and sometimes even improved performance over the original real-valued embedding vectors.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.05314v2"
	},
	{
		"title": "Controlling Neural Machine Translation Formality with Synthetic Supervision ",
		"abstract": "This work aims to produce translations that convey source language content at a formality level that is appropriate for a particular audience. Framing this problem as a neural sequence-to-sequence task ideally requires training triplets consisting of a bilingual sentence pair labeled with target language formality. However, in practice, available training examples are limited to English sentence pairs of different styles, and bilingual parallel sentences of unknown formality. We introduce a novel training scheme for multi-task models that automatically generates synthetic training triplets by inferring the missing element on the fly, thus enabling end-to-end training. Comprehensive automatic and human assessments show that our best model outperforms existing models by producing translations that better match desired formality levels while preserving the source meaning.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08706v2"
	},
	{
		"title": "Optimizing Discrete Spaces via Expensive Evaluations: A Learning to Search Framework ",
		"abstract": "We consider the problem of optimizing expensive black-box functions over discrete spaces (e.g., sets, sequences, graphs). The key challenge is to select a sequence of combinatorial structures to evaluate, in order to identify high-performing structures as quickly as possible. Our main contribution is to introduce and evaluate a new learning-to-search framework for this problem called L2S-DISCO. The key insight is to employ search procedures guided by control knowledge at each step to select the next structure and to improve the control knowledge as new function evaluations are observed. We provide a concrete instantiation of L2S-DISCO for local search procedure and empirically evaluate it on diverse real-world benchmarks. Results show the efficacy of L2S-DISCO over state-of-the-art algorithms in solving complex optimization problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2012.07320v1"
	},
	{
		"title": "Grammar Filtering For Syntax‐Guided Synthesis ",
		"abstract": "Programming-by-example (PBE) is a synthesis paradigm that allows users to generate functions by simply providing input-output examples. While a promising interaction paradigm, synthesis is still too slow for realtime interaction and more widespread adoption. Existing approaches to PBE synthesis have used automated reasoning tools, such as SMT solvers, as well as works applying machine learning techniques. At its core, the automated reasoning approach relies on highly domain specific knowledge of programming languages. On the other hand, the machine learning approaches utilize the fact that when working with program code, it is possible to generate arbitrarily large training datasets. In this work, we propose a system for using machine learning in tandem with automated reasoning techniques to solve Syntax Guided Synthesis (SyGuS) style PBE problems. By preprocessing SyGuS PBE problems with a neural network, we can use a data driven approach to reduce the size of the search space, then allow automated reasoning-based solvers to more quickly find a solution analytically. Our system is able to run atop existing SyGuS PBE synthesis tools, decreasing the runtime of the winner of the 2019 SyGuS Competition for the PBE Strings track by 47.65% to outperform all of the competing tools.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.02884v1"
	},
	{
		"title": "A Meta Learning Method Leveraging Multiple Domain Data for Low Resource Machine Translation ",
		"abstract": "Manipulating training data leads to robust neural models for MT.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05467v1"
	},
	{
		"title": "Deception through Half‐Truths ",
		"abstract": "Deception is a fundamental issue across a diverse array of settings, from cybersecurity, where decoys (e.g., honeypots) are an important tool, to politics that can feature politically motivated \"leaks\" and fake news about candidates.Typical considerations of deception view it as providing false information.However, just as important but less frequently studied is a more tacit form where information is strategically hidden or leaked.We consider the problem of how much an adversary can affect a principal's decision by \"half-truths\", that is, by masking or hiding bits of information, when the principal is oblivious to the presence of the adversary. The principal's problem can be modeled as one of predicting future states of variables in a dynamic Bayes network, and we show that, while theoretically the principal's decisions can be made arbitrarily bad, the optimal attack is NP-hard to approximate, even under strong assumptions favoring the attacker. However, we also describe an important special case where the dependency of future states on past states is additive, in which we can efficiently compute an approximately optimal attack. Moreover, in networks with a linear transition function we can solve the problem optimally in polynomial time.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05885v1"
	},
	{
		"title": "Dempster‐Shafer Theoretic Learning of Indirect Speech Act Comprehension Norms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Active learning on the geometric block model ",
		"abstract": "The geometric block model is a recently proposed generative model for random graphs that is able to capture the inherent geometric properties of many community detection problems, providing more accurate characterizations of practical community structures compared with the popular stochastic block model. Galhotra et al. recently proposed a motif-counting algorithm for unsupervised community detection in the geometric block model that is proved to be near-optimal. They also characterized the regimes of the model parameters for which the proposed algorithm can achieve exact recovery. In this work, we initiate the study of active learning in the geometric block model. That is, we are interested in the problem of exactly recovering the community structure of random graphs following the geometric block model under arbitrary model parameters, by possibly querying the labels of a limited number of chosen nodes. We propose two active learning algorithms that combine the idea of motif-counting with two different label query policies. Our main contribution is to show that sampling the labels of a vanishingly small fraction of nodes (sub-linear in the total number of nodes) is sufficient to achieve exact recovery in the regimes under which the state-of-the-art unsupervised method fails. We validate the superior performance of our algorithms via numerical simulations on both real and synthetic datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06570v1"
	},
	{
		"title": "Self‐Supervised Learning for Generalizable Out‐of‐Distribution Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Motif‐matching based Subgraph‐level Attentional Convolution Network for Graph Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "The Surprising Power of Hiding Information in Facility Location ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": " Zero Shot Learning with the Isoperimetric Loss ",
		"abstract": "We introduce the isoperimetric loss as a regularization criterion for learning the map from a visual representation to a semantic embedding, to be used to transfer knowledge to unknown classes in a zero-shot learning setting. We use a pre-trained deep neural network model as a visual representation of image data, a Word2Vec embedding of class labels, and linear maps between the visual and semantic embedding spaces. However, the spaces themselves are not linear, and we postulate the sample embedding to be populated by noisy samples near otherwise smooth manifolds. We exploit the graph structure defined by the sample points to regularize the estimates of the manifolds by inferring the graph connectivity using a generalization of the isoperimetric inequalities from Riemannian geometry to graphs. Surprisingly, this regularization alone, paired with the simplest baseline model, outperforms the state-of-the-art among fully automated methods in zero-shot learning benchmarks such as AwA and CUB. This improvement is achieved solely by learning the structure of the underlying spaces by imposing regularity.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.06781v2"
	},
	{
		"title": "Adaptive Double Exploration Tradeoff for Outlier Detection ",
		"abstract": "We study a variant of the thresholding bandit problem (TBP) in the context of outlier detection, where the objective is to identify the outliers whose rewards are above a threshold. Distinct from the traditional TBP, the threshold is defined as a function of the rewards of all the arms, which is motivated by the criterion for identifying outliers. The learner needs to explore the rewards of the arms as well as the threshold. We refer to this problem as \"double exploration for outlier detection\". We construct an adaptively updated confidence interval for the threshold, based on the estimated value of the threshold in the previous rounds. Furthermore, by automatically trading off exploring the individual arms and exploring the outlier threshold, we provide an efficient algorithm in terms of the sample complexity. Experimental results on both synthetic datasets and real-world datasets demonstrate the efficiency of our algorithm.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.06092v1"
	},
	{
		"title": "IPO: Interior‐point Policy Optimization under Constraints ",
		"abstract": "In this paper, we study reinforcement learning (RL) algorithms to solve real-world decision problems with the objective of maximizing the long-term reward as well as satisfying cumulative constraints. We propose a novel first-order policy optimization method, Interior-point Policy Optimization (IPO), which augments the objective with logarithmic barrier functions, inspired by the interior-point method. Our proposed method is easy to implement with performance guarantees and can handle general types of cumulative multiconstraint settings. We conduct extensive evaluations to compare our approach with state-of-the-art baselines. Our algorithm outperforms the baseline algorithms, in terms of reward maximization and constraint satisfaction.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.09615v1"
	},
	{
		"title": "Can We Predict the Election Outcome from Sampled Votes? ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TBCNs: Taylor Binary Convolutional Networks for Enhancing the Performance of 1‐bit DCNNs ",
		"abstract": "Training 1-bit deep convolutional neural networks (DCNNs) is one of the most challenging problems in computer vision, because it is much easier to get trapped into local minima than conventional DCNNs. The reason lies in that the binarized kernels and activations of 1-bit DCNNs cause a significant accuracy loss and training inefficiency. To address this problem, we propose Genetic Binary Convolutional Networks (GBCNs) to optimize 1-bit DCNNs, by introducing a new balanced Genetic Algorithm (BGA) to improve the representational ability in an end-to-end framework. The BGA method is proposed to modify the binary process of GBCNs to alleviate the local minima problem, which can significantly improve the performance of 1-bit DCNNs. We develop a new BGA module that is generic and flexible, and can be easily incorporated into existing DCNNs, such asWideResNets and ResNets. Extensive experiments on the object classification tasks (CIFAR, ImageNet) validate the effectiveness of the proposed method. To highlight, our method shows strong generalization on the object recognition task, i.e., face recognition, facial and person re-identification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11634v2"
	},
	{
		"title": "GaSPing for Utility ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Factorized Inference in Deep Markov Models for Incomplete Multimodal Time Series ",
		"abstract": "Integrating deep learning with latent state space models has the potential to yield temporal models that are powerful, yet tractable and interpretable. Unfortunately, current models are not designed to handle missing data or multiple data modalities, which are both prevalent in real-world data. In this work, we introduce a factorized inference method for Multimodal Deep Markov Models (MDMMs), allowing us to filter and smooth in the presence of missing data, while also performing uncertainty-aware multimodal fusion. We derive this method by factorizing the posterior p(z|x) for non-linear state space models, and develop a variational backward-forward algorithm for inference. Because our method handles incompleteness over both time and modalities, it is capable of interpolation, extrapolation, conditional generation, label prediction, and weakly supervised learning of multimodal time series. We demonstrate these capabilities on both synthetic and real-world multimodal data under high levels of data deletion. Our method performs well even with more than 50% missing data, and outperforms existing deep approaches to inference in latent time series.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.13570v3"
	},
	{
		"title": "M3ER: Multiplicative Multimodal Emotion Recognition Using Facial, Textual, and Speech Cues ",
		"abstract": "We present M3ER, a learning-based method for emotion recognition from multiple input modalities. Our approach combines cues from multiple co-occurring modalities (such as face, text, and speech) and also is more robust than other methods to sensor noise in any of the individual modalities. M3ER models a novel, data-driven multiplicative fusion method to combine the modalities, which learn to emphasize the more reliable cues and suppress others on a per-sample basis. By introducing a check step which uses Canonical Correlational Analysis to differentiate between ineffective and effective modalities, M3ER is robust to sensor noise. M3ER also generates proxy features in place of the ineffectual modalities. We demonstrate the efficiency of our network through experimentation on two benchmark datasets, IEMOCAP and CMU-MOSEI. We report a mean accuracy of 82.7% on IEMOCAP and 89.0% on CMU-MOSEI, which, collectively, is an improvement of about 5% over prior work.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05659v2"
	},
	{
		"title": "CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi‐Task Learning ",
		"abstract": "Joint extraction of entities and relations has received significant attention due to its potential of providing higher performance for both tasks. Among existing methods, CopyRE is effective and novel, which uses a sequence-to-sequence framework and copy mechanism to directly generate the relation triplets. However, it suffers from two fatal problems. The model is extremely weak at differing the head and tail entity, resulting in inaccurate entity extraction. It also cannot predict multi-token entities (e.g. \\textit{Steven Jobs}). To address these problems, we give a detailed analysis of the reasons behind the inaccurate entity extraction problem, and then propose a simple but extremely effective model structure to solve this problem. In addition, we propose a multi-task learning framework equipped with copy mechanism, called CopyMTL, to allow the model to predict multi-token entities. Experiments reveal the problems of CopyRE and show that our model achieves significant improvement over the current state-of-the-art method by 9% in NYT and 16% in WebNLG (F1 score). Our code is available at https://github.com/WindChimeRan/CopyMTL",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10438v2"
	},
	{
		"title": "Exploiting Cross‐Lingual Subword Similarities in Low‐Resource Document Classification ",
		"abstract": "Text classification must sometimes be applied in a low-resource language with no labeled training data. However, training data may be available in a related language. We investigate whether character-level knowledge transfer from a related language helps text classification. We present a cross-lingual document classification framework (CACO) that exploits cross-lingual subword similarity by jointly training a character-based embedder and a word-based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. We use a joint character representation for both the source language and the target language, which allows the embedder to generalize knowledge about source language words to target language words with similar forms. We propose a multi-task objective that can further improve the model if additional cross-lingual or monolingual resources are available. Experiments confirm that character-level knowledge transfer is more data-efficient than word-level transfer between related languages.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1812.09617v4"
	},
	{
		"title": "The Choice Function Framework for Online Policy Improvement ",
		"abstract": "There are notable examples of online search improving over hand-coded or learned policies (e.g. AlphaZero) for sequential decision making. It is not clear, however, whether or not policy improvement is guaranteed for many of these approaches, even when given a perfect evaluation function and transition model. Indeed, simple counter examples show that seemingly reasonable online search procedures can hurt performance compared to the original policy. To address this issue, we introduce the choice function framework for analyzing online search procedures for policy improvement. A choice function specifies the actions to be considered at every node of a search tree, with all other actions being pruned. Our main contribution is to give sufficient conditions for stationary and non-stationary choice functions to guarantee that the value achieved by online search is no worse than the original policy. In addition, we describe a general parametric class of choice functions that satisfy those conditions and present an illustrative use case of the framework's empirical utility.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.00614v2"
	},
	{
		"title": "LATTE: Latent Type Modeling for Biomedical Entity Linking ",
		"abstract": "Entity linking is the task of linking mentions of named entities in natural language text, to entities in a curated knowledge-base. This is of significant importance in the biomedical domain, where it could be used to semantically annotate a large volume of clinical records and biomedical literature, to standardized concepts described in an ontology such as Unified Medical Language System (UMLS). We observe that with precise type information, entity disambiguation becomes a straightforward task. However, fine-grained type information is usually not available in biomedical domain. Thus, we propose LATTE, a LATent Type Entity Linking model, that improves entity linking by modeling the latent fine-grained type information about mentions and entities. Unlike previous methods that perform entity linking directly between the mentions and the entities, LATTE jointly does entity disambiguation, and latent fine-grained type learning, without direct supervision. We evaluate our model on two biomedical datasets: MedMentions, a large scale public dataset annotated with UMLS concepts, and a de-identified corpus of dictated doctor's notes that has been annotated with ICD concepts. Extensive experimental evaluation shows our model achieves significant performance improvements over several state-of-the-art techniques.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09787v2"
	},
	{
		"title": "Discriminative Adversarial Domain Adaptation ",
		"abstract": "Given labeled instances on a source domain and unlabeled ones on a target domain, unsupervised domain adaptation aims to learn a task classifier that can well classify target instances. Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, these methods are limited in aligning the joint distributions of feature and category across domains. To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance. We show that under practical conditions, it defines a minimax game that can promote the joint distribution alignment. Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation. Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three settings on benchmark datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12036v2"
	},
	{
		"title": "Evaluating the Cross‐Lingual Effectiveness of Massively Multilingual Neural Machine Translation ",
		"abstract": "The recently proposed massively multilingual neural machine translation (NMT) system has been shown to be capable of translating over 100 languages to and from English within a single model. Its improved translation performance on low resource languages hints at potential cross-lingual transfer capability for downstream tasks. In this paper, we evaluate the cross-lingual effectiveness of representations from the encoder of a massively multilingual NMT model on 5 downstream classification and sequence labeling tasks covering a diverse set of over 50 languages. We compare against a strong baseline, multilingual BERT (mBERT), in different cross-lingual transfer learning scenarios and show gains in zero-shot transfer in 4 out of these 5 tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.00437v1"
	},
	{
		"title": "3D Human Pose Estimation using Spatio‐Temporal Networks with Explicit Occlusion Training ",
		"abstract": "Estimating 3D poses from a monocular video is still a challenging task, despite the significant progress that has been made in recent years. Generally, the performance of existing methods drops when the target person is too small/large, or the motion is too fast/slow relative to the scale and speed of the training data. Moreover, to our knowledge, many of these methods are not designed or trained under severe occlusion explicitly, making their performance on handling occlusion compromised. Addressing these problems, we introduce a spatio-temporal network for robust 3D human pose estimation. As humans in videos may appear in different scales and have various motion speeds, we apply multi-scale spatial features for 2D joints or keypoints prediction in each individual frame, and multi-stride temporal convolutional net-works (TCNs) to estimate 3D joints or keypoints. Furthermore, we design a spatio-temporal discriminator based on body structures as well as limb motions to assess whether the predicted pose forms a valid pose and a valid movement. During training, we explicitly mask out some keypoints to simulate various occlusion cases, from minor to severe occlusion, so that our network can learn better and becomes robust to various degrees of occlusion. As there are limited 3D ground-truth data, we further utilize 2D video data to inject a semi-supervised learning capability to our network. Experiments on public datasets validate the effectiveness of our method, and our ablation studies show the strengths of our network\\'s individual submodules.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.11822v1"
	},
	{
		"title": "COBRA: Context‐Aware Bernoulli Neural Networks for Reputation Assessment ",
		"abstract": "Trust and reputation management (TRM) plays an increasingly important role in large-scale online environments such as multi-agent systems (MAS) and the Internet of Things (IoT). One main objective of TRM is to achieve accurate trust assessment of entities such as agents or IoT service providers. However, this encounters an accuracy-privacy dilemma as we identify in this paper, and we propose a framework called Context-aware Bernoulli Neural Network based Reputation Assessment (COBRA) to address this challenge. COBRA encapsulates agent interactions or transactions, which are prone to privacy leak, in machine learning models, and aggregates multiple such models using a Bernoulli neural network to predict a trust score for an agent. COBRA preserves agent privacy and retains interaction contexts via the machine learning models, and achieves more accurate trust prediction than a fully-connected neural network alternative. COBRA is also robust to security attacks by agents who inject fake machine learning models; notably, it is resistant to the 51-percent attack. The performance of COBRA is validated by our experiments using a real dataset, and by our simulations, where we also show that COBRA outperforms other state-of-the-art TRM systems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08446v2"
	},
	{
		"title": "Subset Selection by Pareto Optimization with Recombination ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MixedAD: A Scalable Algorithm for Detecting Mixed Anomalies in Attributed Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neural Snowball for Few‐Shot Relation Learning ",
		"abstract": "Knowledge graphs typically undergo open-ended growth of new relations. This cannot be well handled by relation extraction that focuses on pre-defined relations with sufficient training data. To address new relations with few-shot instances, we propose a novel bootstrapping approach, Neural Snowball, to learn new relations by transferring semantic knowledge about existing relations. More specifically, we use Relational Siamese Networks (RSN) to learn the metric of relational similarities between instances based on existing relations and their labeled data. Afterwards, given a new relation and its few-shot instances, we use RSN to accumulate reliable instances from unlabeled corpora; these instances are used to train a relation classifier, which can further identify new facts of the new relation. The process is conducted iteratively like a snowball. Experiments show that our model can gather high-quality instances for better few-shot relation learning and achieves significant improvement compared to baselines. Codes and datasets are released on https://github.com/thunlp/Neural-Snowball.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.11007v2"
	},
	{
		"title": "Diversified Interactive Recommendation with Implicit Feedback ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Transfer Reinforcement Learning using Output‐Gated Working Memory ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bivariate Beta‐LSTM ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Communication, Distortion, and Randomness in Metric Voting ",
		"abstract": "In distortion-based analysis of social choice rules over metric spaces, one assumes that all voters and candidates are jointly embedded in a common metric space. Voters rank candidates by non-decreasing distance. The mechanism, receiving only this ordinal (comparison) information, should select a candidate approximately minimizing the sum of distances from all voters. It is known that while the Copeland rule and related rules guarantee distortion at most 5, many other standard voting rules, such as Plurality, Veto, or $k$-approval, have distortion growing unboundedly in the number $n$ of candidates.   Plurality, Veto, or $k$-approval with small $k$ require less communication from the voters than all deterministic social choice rules known to achieve constant distortion. This motivates our study of the tradeoff between the distortion and the amount of communication in deterministic social choice rules.   We show that any one-round deterministic voting mechanism in which each voter communicates only the candidates she ranks in a given set of $k$ positions must have distortion at least $\\frac{2n-k}{k}$; we give a mechanism achieving an upper bound of $O(n/k)$, which matches the lower bound up to a constant. For more general communication-bounded voting mechanisms, in which each voter communicates $b$ bits of information about her ranking, we show a slightly weaker lower bound of $\\Omega(n/b)$ on the distortion.   For randomized mechanisms, it is known that Random Dictatorship achieves expected distortion strictly smaller than 3, almost matching a lower bound of $3-\\frac{2}{n}$ for any randomized mechanism that only receives each voter's top choice. We close this gap, by giving a simple randomized social choice rule which only uses each voter's first choice, and achieves expected distortion $3-\\frac{2}{n}$.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08129v2"
	},
	{
		"title": "Adversarially Robust Distillation ",
		"abstract": "Knowledge distillation is effective for producing small, high-performance neural networks for classification, but these small networks are vulnerable to adversarial attacks. This paper studies how adversarial robustness transfers from teacher to student during knowledge distillation. We find that a large amount of robustness may be inherited by the student even when distilled on only clean images. Second, we introduce Adversarially Robust Distillation (ARD) for distilling robustness onto student networks. In addition to producing small models with high test accuracy like conventional distillation, ARD also passes the superior robustness of large networks onto the student. In our experiments, we find that ARD student models decisively outperform adversarially trained networks of identical architecture in terms of robust accuracy, surpassing state-of-the-art methods on standard robustness benchmarks. Finally, we adapt recent fast adversarial training methods to ARD for accelerated robust distillation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.09747v2"
	},
	{
		"title": "Asymptotically Unambitious Artificial General Intelligence ",
		"abstract": "General intelligence, the ability to solve arbitrary solvable problems, is supposed by many to be artificially constructible. Narrow intelligence, the ability to solve a given particularly difficult problem, has seen impressive recent development. Notable examples include self-driving cars, Go engines, image classifiers, and translators. Artificial General Intelligence (AGI) presents dangers that narrow intelligence does not: if something smarter than us across every domain were indifferent to our concerns, it would be an existential threat to humanity, just as we threaten many species despite no ill will. Even the theory of how to maintain the alignment of an AGI's goals with our own has proven highly elusive. We present the first algorithm we are aware of for asymptotically unambitious AGI, where \"unambitiousness\" includes not seeking arbitrary power. Thus, we identify an exception to the Instrumental Convergence Thesis, which is roughly that by default, an AGI would seek power, including over us.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.12186v4"
	},
	{
		"title": "Mining Unfollow Behavior in Large‐Scale Online Social Networks via Spatial‐Temporal Interaction ",
		"abstract": "Online Social Networks (OSNs) evolve through two pervasive behaviors: follow and unfollow, which respectively signify relationship creation and relationship dissolution. Researches on social network evolution mainly focus on the follow behavior, while the unfollow behavior has largely been ignored. Mining unfollow behavior is challenging because user's decision on unfollow is not only affected by the simple combination of user's attributes like informativeness and reciprocity, but also affected by the complex interaction among them. Meanwhile, prior datasets seldom contain sufficient records for inferring such complex interaction. To address these issues, we first construct a large-scale real-world Weibo dataset, which records detailed post content and relationship dynamics of 1.8 million Chinese users. Next, we define user's attributes as two categories: spatial attributes (e.g., social role of user) and temporal attributes (e.g., post content of user). Leveraging the constructed dataset, we systematically study how the interaction effects between user's spatial and temporal attributes contribute to the unfollow behavior. Afterwards, we propose a novel unified model with heterogeneous information (UMHI) for unfollow prediction. Specifically, our UMHI model: 1) captures user's spatial attributes through social network structure; 2) infers user's temporal attributes through user-posted content and unfollow history; and 3) models the interaction between spatial and temporal attributes by the nonlinear MLP layers. Comprehensive evaluations on the constructed dataset demonstrate that the proposed UMHI model outperforms baseline methods by 16.44% on average in terms of precision. In addition, factor analyses verify that both spatial attributes and temporal attributes are essential for mining unfollow behavior.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07156v1"
	},
	{
		"title": "RoboCoDraw: Robotic Avatar Drawing with GAN‐based Style Transfer and Time‐efficient Path Optimization ",
		"abstract": "Robotic drawing has become increasingly popular as an entertainment and interactive tool. In this paper we present RoboCoDraw, a real-time collaborative robot-based drawing system that draws stylized human face sketches interactively in front of human users, by using the Generative Adversarial Network (GAN)-based style transfer and a Random-Key Genetic Algorithm (RKGA)-based path optimization. The proposed RoboCoDraw system takes a real human face image as input, converts it to a stylized avatar, then draws it with a robotic arm. A core component in this system is the Avatar-GAN proposed by us, which generates a cartoon avatar face image from a real human face. AvatarGAN is trained with unpaired face and avatar images only and can generate avatar images of much better likeness with human face images in comparison with the vanilla CycleGAN. After the avatar image is generated, it is fed to a line extraction algorithm and converted to sketches. An RKGA-based path optimization algorithm is applied to find a time-efficient robotic drawing path to be executed by the robotic arm. We demonstrate the capability of RoboCoDraw on various face images using a lightweight, safe collaborative robot UR5.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05099v1"
	},
	{
		"title": "Generative Continual Concept Learning ",
		"abstract": "After learning a concept, humans are also able to continually generalize their learned concepts to new domains by observing only a few labeled instances without any interference with the past learned knowledge. In contrast, learning concepts efficiently in a continual learning setting remains an open challenge for current Artificial Intelligence algorithms as persistent model retraining is necessary. Inspired by the Parallel Distributed Processing learning and the Complementary Learning Systems theories, we develop a computational model that is able to expand its previously learned concepts efficiently to new domains using a few labeled samples. We couple the new form of a concept to its past learned forms in an embedding space for effective continual learning. Doing so, a generative distribution is learned such that it is shared across the tasks in the embedding space and models the abstract concepts. This procedure enables the model to generate pseudo-data points to replay the past experience to tackle catastrophic forgetting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.03744v2"
	},
	{
		"title": "Reinforcement‐Learning based Portfolio Management with Augmented Asset Movement Prediction States ",
		"abstract": "Portfolio management (PM) is a fundamental financial planning task that aims to achieve investment goals such as maximal profits or minimal risks. Its decision process involves continuous derivation of valuable information from various data sources and sequential decision optimization, which is a prospective research direction for reinforcement learning (RL). In this paper, we propose SARL, a novel State-Augmented RL framework for PM. Our framework aims to address two unique challenges in financial PM: (1) data heterogeneity -- the collected information for each asset is usually diverse, noisy and imbalanced (e.g., news articles); and (2) environment uncertainty -- the financial market is versatile and non-stationary. To incorporate heterogeneous data and enhance robustness against environment uncertainty, our SARL augments the asset information with their price movement prediction as additional states, where the prediction can be solely based on financial data (e.g., asset prices) or derived from alternative sources such as news. Experiments on two real-world datasets, (i) Bitcoin market and (ii) HighTech stock market with 7-year Reuters news articles, validate the effectiveness of SARL over existing PM approaches, both in terms of accumulated profits and risk-adjusted profits. Moreover, extensive simulations are conducted to demonstrate the importance of our proposed state augmentation, providing new insights and boosting performance significantly over standard RL-based PM method and other baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.05780v1"
	},
	{
		"title": "CSPN++: Learning Context and Resource Aware Convolutional Spatial Propagation Networks for Depth Completion ",
		"abstract": "Depth Completion deals with the problem of converting a sparse depth map to a dense one, given the corresponding color image. Convolutional spatial propagation network (CSPN) is one of the state-of-the-art (SoTA) methods of depth completion, which recovers structural details of the scene. In this paper, we propose CSPN++, which further improves its effectiveness and efficiency by learning adaptive convolutional kernel sizes and the number of iterations for the propagation, thus the context and computational resources needed at each pixel could be dynamically assigned upon requests. Specifically, we formulate the learning of the two hyper-parameters as an architecture selection problem where various configurations of kernel sizes and numbers of iterations are first defined, and then a set of soft weighting parameters are trained to either properly assemble or select from the pre-defined configurations at each pixel. In our experiments, we find weighted assembling can lead to significant accuracy improvements, which we referred to as \"context-aware CSPN\", while weighted selection, \"resource-aware CSPN\" can reduce the computational resource significantly with similar or better accuracy. Besides, the resource needed for CSPN++ can be adjusted w.r.t. the computational budget automatically. Finally, to avoid the side effects of noise or inaccurate sparse depths, we embed a gated network inside CSPN++, which further improves the performance. We demonstrate the effectiveness of CSPN++on the KITTI depth completion benchmark, where it significantly improves over CSPN and other SoTA methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05377v2"
	},
	{
		"title": "Learning Fair Naive Bayes Classifiers by Discovering and Eliminating Discrimination Patterns ",
		"abstract": "As machine learning is increasingly used to make real-world decisions, recent research efforts aim to define and ensure fairness in algorithmic decision making. Existing methods often assume a fixed set of observable features to define individuals, but lack a discussion of certain features not being observed at test time. In this paper, we study fairness of naive Bayes classifiers, which allow partial observations. In particular, we introduce the notion of a discrimination pattern, which refers to an individual receiving different classifications depending on whether some sensitive attributes were observed. Then a model is considered fair if it has no such pattern. We propose an algorithm to discover and mine for discrimination patterns in a naive Bayes classifier, and show how to learn maximum likelihood parameters subject to these fairness constraints. Our approach iteratively discovers and eliminates discrimination patterns until a fair model is learned. An empirical evaluation on three real-world datasets demonstrates that we can remove exponentially many discrimination patterns by only adding a small fraction of them as constraints.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.03843v2"
	},
	{
		"title": "Robust Self‐weighted Multi‐view Projection Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Differentiable Reasoning on Large Knowledge Bases and Natural Language ",
		"abstract": "Reasoning with knowledge expressed in natural language and Knowledge Bases (KBs) is a major challenge for Artificial Intelligence, with applications in machine reading, dialogue, and question answering. General neural architectures that jointly learn representations and transformations of text are very data-inefficient, and it is hard to analyse their reasoning process. These issues are addressed by end-to-end differentiable reasoning systems such as Neural Theorem Provers (NTPs), although they can only be used with small-scale symbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension to NTPs addressing their complexity and scalability limitations, thus making them applicable to real-world datasets. This result is achieved by dynamically constructing the computation graph of NTPs and including only the most promising proof paths during inference, thus obtaining orders of magnitude more efficient models. Then, we propose a novel approach for jointly reasoning over KBs and textual mentions, by embedding logic facts and natural language sentences in a shared embedding space. We show that GNTPs perform on par with NTPs at a fraction of their cost while achieving competitive link prediction results on large datasets, providing explanations for predictions, and inducing interpretable models. Source code, datasets, and supplementary material are available online at https://github.com/uclnlp/gntp.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10824v1"
	},
	{
		"title": "EC‐GAN: Inferring Brain Effective Connectivity via Generative Adversarial Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Alternating Language Modeling for Cross‐Lingual Pre‐Training ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CGD: Multi‐view Clustering via Cross‐view Graph Diffusion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Tweedie‐Hawkes Processes: Interpreting the Phenomena of Outbreaks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐type Self‐attention Guided Degraded Saliency Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RIS‐GAN: Explore Residual and Illumination with Generative Adversarial Networks for Shadow Removal ",
		"abstract": "Residual images and illumination estimation have been proved very helpful in image enhancement. In this paper, we propose a general and novel framework RIS-GAN which explores residual and illumination with Generative Adversarial Networks for shadow removal. Combined with the coarse shadow-removal image, the estimated negative residual images and inverse illumination maps can be used to generate indirect shadow-removal images to refine the coarse shadow-removal result to the fine shadow-free image in a coarse-to-fine fashion. Three discriminators are designed to distinguish whether the predicted negative residual images, shadow-removal images, and the inverse illumination maps are real or fake jointly compared with the corresponding ground-truth information. To our best knowledge, we are the first one to explore residual and illumination for shadow removal. We evaluate our proposed method on two benchmark datasets, i.e., SRD and ISTD, and the extensive experiments demonstrate that our proposed method achieves the superior performance to state-of-the-arts, although we have no particular shadow-aware components designed in our generators.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09178v2"
	},
	{
		"title": "Auto‐GAN: Self‐Supervised Collaborative Learning for Medical Image Synthesis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Online Knowledge Distillation with Diverse Peers ",
		"abstract": "Distillation is an effective knowledge-transfer technique that uses predicted distributions of a powerful teacher model as soft targets to train a less-parameterized student model. A pre-trained high capacity teacher, however, is not always available. Recently proposed online variants use the aggregated intermediate predictions of multiple student models as targets to train each student model. Although group-derived targets give a good recipe for teacher-free distillation, group members are homogenized quickly with simple aggregation functions, leading to early saturated solutions. In this work, we propose Online Knowledge Distillation with Diverse peers (OKDDip), which performs two-level distillation during training with multiple auxiliary peers and one group leader. In the first-level distillation, each auxiliary peer holds an individual set of aggregation weights generated with an attention-based mechanism to derive its own targets from predictions of other auxiliary peers. Learning from distinct target distributions helps to boost peer diversity for effectiveness of group-based distillation. The second-level distillation is performed to transfer the knowledge in the ensemble of auxiliary peers further to the group leader, i.e., the model used for inference. Experimental results show that the proposed framework consistently gives better performance than state-of-the-art approaches without sacrificing training or inference complexity, demonstrating the effectiveness of the proposed two-level distillation framework.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00350v2"
	},
	{
		"title": "Rule‐Guided Compositional Representation Learning on Knowledge Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Feature Deformation Meta‐Networks in Image Captioning of Novel Objects ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Co‐GCN for Multi‐View Semi‐Supervised Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Object‐Oriented Dynamics Learning through Multi‐Level Abstraction ",
		"abstract": "Object-based approaches for learning action-conditioned dynamics has demonstrated promise for generalization and interpretability. However, existing approaches suffer from structural limitations and optimization difficulties for common environments with multiple dynamic objects. In this paper, we present a novel self-supervised learning framework, called Multi-level Abstraction Object-oriented Predictor (MAOP), which employs a three-level learning architecture that enables efficient object-based dynamics learning from raw visual observations. We also design a spatial-temporal relational reasoning mechanism for MAOP to support instance-level dynamics learning and handle partial observability. Our results show that MAOP significantly outperforms previous methods in terms of sample efficiency and generalization over novel environments for learning environment models. We also demonstrate that learned dynamics models enable efficient planning in unseen environments, comparable to true environment models. In addition, MAOP learns semantically and visually interpretable disentangled representations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.07482v4"
	},
	{
		"title": "Pyramid Constrained Self‐Attention Network for Fast Video Salient Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Explicit Sentence Compression for Neural Machine Translation ",
		"abstract": "State-of-the-art Transformer-based neural machine translation (NMT) systems still follow a standard encoder-decoder framework, in which source sentence representation can be well done by an encoder with self-attention mechanism. Though Transformer-based encoder may effectively capture general information in its resulting source sentence representation, the backbone information, which stands for the gist of a sentence, is not specifically focused on. In this paper, we propose an explicit sentence compression method to enhance the source sentence representation for NMT. In practice, an explicit sentence compression goal used to learn the backbone information in a sentence. We propose three ways, including backbone source-side fusion, target-side fusion, and both-side fusion, to integrate the compressed sentence into NMT. Our empirical tests on the WMT English-to-French and English-to-German translation tasks show that the proposed sentence compression method significantly improves the translation performances over strong baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11980v1"
	},
	{
		"title": "Online Second Price Auction with Semi‐bandit Feedback Under the Non‐Stationary Setting ",
		"abstract": "In this paper, we study the non-stationary online second price auction problem. We assume that the seller is selling the same type of items in $T$ rounds by the second price auction, and she can set the reserve price in each round. In each round, the bidders draw their private values from a joint distribution unknown to the seller. Then, the seller announced the reserve price in this round. Next, bidders with private values higher than the announced reserve price in that round will report their values to the seller as their bids. The bidder with the highest bid larger than the reserved price would win the item and she will pay to the seller the price equal to the second-highest bid or the reserve price, whichever is larger. The seller wants to maximize her total revenue during the time horizon $T$ while learning the distribution of private values over time. The problem is more challenging than the standard online learning scenario since the private value distribution is non-stationary, meaning that the distribution of bidders' private values may change over time, and we need to use the \\emph{non-stationary regret} to measure the performance of our algorithm. To our knowledge, this paper is the first to study the repeated auction in the non-stationary setting theoretically. Our algorithm achieves the non-stationary regret upper bound $\\tilde{\\mathcal{O}}(\\min\\{\\sqrt{\\mathcal S T}, \\bar{\\mathcal{V}}^{\\frac{1}{3}}T^{\\frac{2}{3}}\\})$, where $\\mathcal S$ is the number of switches in the distribution, and $\\bar{\\mathcal{V}}$ is the sum of total variation, and $\\mathcal S$ and $\\bar{\\mathcal{V}}$ are not needed to be known by the algorithm. We also prove regret lower bounds $\\Omega(\\sqrt{\\mathcal S T})$ in the switching case and $\\Omega(\\bar{\\mathcal{V}}^{\\frac{1}{3}}T^{\\frac{2}{3}})$ in the dynamic case, showing that our algorithm has nearly optimal \\emph{non-stationary regret}.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05949v1"
	},
	{
		"title": "Gradient Method for Continuous Influence Maximization with Budget‐Saving Considerations ",
		"abstract": "Continuous influence maximization (CIM) generalizes the original influence maximization by incorporating general marketing strategies: a marketing strategy mix is a vector $\\boldsymbol x = (x_1,\\dots,x_d)$ such that for each node $v$ in a social network, $v$ could be activated as a seed of diffusion with probability $h_v(\\boldsymbol x)$, where $h_v$ is a strategy activation function satisfying DR-submodularity. CIM is the task of selecting a strategy mix $\\boldsymbol x$ with constraint $\\sum_i x_i \\le k$ where $k$ is a budget constraint, such that the total number of activated nodes after the diffusion process, called influence spread and denoted as $g(\\boldsymbol x)$, is maximized. In this paper, we extend CIM to consider budget saving, that is, each strategy mix $\\boldsymbol x$ has a cost $c(\\boldsymbol x)$ where $c$ is a convex cost function, we want to maximize the balanced sum $g(\\boldsymbol x) + \\lambda(k - c(\\boldsymbol x))$ where $\\lambda$ is a balance parameter, subject to the constraint of $c(\\boldsymbol x) \\le k$. We denote this problem as CIM-BS. The objective function of CIM-BS is neither monotone, nor DR-submodular or concave, and thus neither the greedy algorithm nor the standard result on gradient method could be directly applied. Our key innovation is the combination of the gradient method with reverse influence sampling to design algorithms that solve CIM-BS: For the general case, we give an algorithm that achieves $\\left(\\frac{1}{2}-\\varepsilon\\right)$-approximation, and for the case of independent strategy activations, we present an algorithm that achieves $\\left(1-\\frac{1}{e}-\\varepsilon\\right)$ approximation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09100v1"
	},
	{
		"title": "Universal Adversarial Training ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Visual Relationship Detection with Low Rank Non‐Negative Tensor Decomposition ",
		"abstract": "We address the problem of Visual Relationship Detection (VRD) which aims to describe the relationships between pairs of objects in the form of triplets of (subject, predicate, object). We observe that given a pair of bounding box proposals, objects often participate in multiple relations implying the distribution of triplets is multimodal. We leverage the strong correlations within triplets to learn the joint distribution of triplet variables conditioned on the image and the bounding box proposals, doing away with the hitherto used independent distribution of triplets. To make learning the triplet joint distribution feasible, we introduce a novel technique of learning conditional triplet distributions in the form of their normalized low rank non-negative tensor decompositions. Normalized tensor decompositions take form of mixture distributions of discrete variables and thus are able to capture multimodality. This allows us to efficiently learn higher order discrete multimodal distributions and at the same time keep the parameter size manageable. We further model the probability of selecting an object proposal pair and include a relation triplet prior in our model. We show that each part of the model improves performance and the combination outperforms state-of-the-art score on the Visual Genome (VG) and Visual Relationship Detection (VRD) datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09895v1"
	},
	{
		"title": "Differentiable Algorithm for Marginalising Changepoints ",
		"abstract": "We present an algorithm for marginalising changepoints in time-series models that assume a fixed number of unknown changepoints. Our algorithm is differentiable with respect to its inputs, which are the values of latent random variables other than changepoints. Also, it runs in time O(mn) where n is the number of time steps and m the number of changepoints, an improvement over a naive marginalisation method with O(n^m) time complexity. We derive the algorithm by identifying quantities related to this marginalisation problem, showing that these quantities satisfy recursive relationships, and transforming the relationships to an algorithm via dynamic programming. Since our algorithm is differentiable, it can be applied to convert a model non-differentiable due to changepoints to a differentiable one, so that the resulting models can be analysed using gradient-based inference or learning techniques. We empirically show the effectiveness of our algorithm in this application by tackling the posterior inference problem on synthetic and real-world data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09839v1"
	},
	{
		"title": "Graph‐propagation based Correlation Learning for Weakly Supervised Fine‐grained Image Classification  ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Kinematic‐Structure‐Preserved Representation for Unsupervised 3D Human Pose Estimation ",
		"abstract": "Estimation of 3D human pose from monocular image has gained considerable attention, as a key step to several human-centric applications. However, generalizability of human pose estimation models developed using supervision on large-scale in-studio datasets remains questionable, as these models often perform unsatisfactorily on unseen in-the-wild environments. Though weakly-supervised models have been proposed to address this shortcoming, performance of such models relies on availability of paired supervision on some related tasks, such as 2D pose or multi-view image pairs. In contrast, we propose a novel kinematic-structure-preserved unsupervised 3D pose estimation framework, which is not restrained by any paired or unpaired weak supervisions. Our pose estimation framework relies on a minimal set of prior knowledge that defines the underlying kinematic 3D structure, such as skeletal joint connectivity information with bone-length ratios in a fixed canonical scale. The proposed model employs three consecutive differentiable transformations named as forward-kinematics, camera-projection and spatial-map transformation. This design not only acts as a suitable bottleneck stimulating effective pose disentanglement but also yields interpretable latent pose representations avoiding training of an explicit latent embedding to pose mapper. Furthermore, devoid of unstable adversarial setup, we re-utilize the decoder to formalize an energy-based loss, which enables us to learn from in-the-wild videos, beyond laboratory settings. Comprehensive experiments demonstrate our state-of-the-art unsupervised and weakly-supervised pose estimation performance on both Human3.6M and MPI-INF-3DHP datasets. Qualitative results on unseen environments further establish our superior generalization ability.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.14107v1"
	},
	{
		"title": "Generating Well‐formed Answers by Machine Reading with Stochastic Selector Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Revision in Continuous Space: Unsupervised Text Style Transfer without Adversarial Learning ",
		"abstract": "Typical methods for unsupervised text style transfer often rely on two key ingredients: 1) seeking the explicit disentanglement of the content and the attributes, and 2) troublesome adversarial learning. In this paper, we show that neither of these components is indispensable. We propose a new framework that utilizes the gradients to revise the sentence in a continuous space during inference to achieve text style transfer. Our method consists of three key components: a variational auto-encoder (VAE), some attribute predictors (one for each attribute), and a content predictor. The VAE and the two types of predictors enable us to perform gradient-based optimization in the continuous space, which is mapped from sentences in a discrete space, to find the representation of a target sentence with the desired attributes and preserved content. Moreover, the proposed method naturally has the ability to simultaneously manipulate multiple fine-grained attributes, such as sentence length and the presence of specific words, when performing text style transfer tasks. Compared with previous adversarial learning based methods, the proposed method is more interpretable, controllable and easier to train. Extensive experimental studies on three popular text style transfer tasks show that the proposed method significantly outperforms five state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.12304v3"
	},
	{
		"title": "Graph Representation Learning via Ladder Gamma Variational Autoencoders ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Question‐driven Purchasing Propensity Analysis for Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Zero‐shot Ingredient Recognition by Multi‐Relational Graph Convolutional Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FISR: Deep Joint Frame Interpolation and Super‐Resolution with A Multi‐scale Temporal Loss ",
		"abstract": "Super-resolution (SR) has been widely used to convert low-resolution legacy videos to high-resolution (HR) ones, to suit the increasing resolution of displays (e.g. UHD TVs). However, it becomes easier for humans to notice motion artifacts (e.g. motion judder) in HR videos being rendered on larger-sized display devices. Thus, broadcasting standards support higher frame rates for UHD (Ultra High Definition) videos (4K@60 fps, 8K@120 fps), meaning that applying SR only is insufficient to produce genuine high quality videos. Hence, to up-convert legacy videos for realistic applications, not only SR but also video frame interpolation (VFI) is necessitated. In this paper, we first propose a joint VFI-SR framework for up-scaling the spatio-temporal resolution of videos from 2K 30 fps to 4K 60 fps. For this, we propose a novel training scheme with a multi-scale temporal loss that imposes temporal regularization on the input video sequence, which can be applied to any general video-related task. The proposed structure is analyzed in depth with extensive experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07213v1"
	},
	{
		"title": "A Simultaneous Discover‐Identify Approach to Causal Inference in Linear Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Modeling Electrical Motor Dynamics using Encoder‐Decoder with Recurrent Skip Connection ",
		"abstract": "Electrical motors are the most important source of mechanical energy in the industrial world. Their modeling traditionally relies on a physics-based approach, which aims at taking their complex internal dynamics into account. In this paper, we explore the feasibility of modeling the dynamics of an electrical motor by following a data-driven approach, which uses only its inputs and outputs and does not make any assumption on its internal behaviour. We propose a novel encoder-decoder architecture which benefits from recurrent skip connections. We also propose a novel loss function that takes into account the complexity of electrical motor quantities and helps in avoiding model bias. We show that the proposed architecture can achieve a good learning performance on our high-frequency high-variance datasets. Two datasets are considered: the first one is generated using a simulator based on the physics of an induction motor and the second one is recorded from an industrial electrical motor. We benchmark our solution using variants of traditional neural networks like feedforward, convolutional, and recurrent networks. We evaluate various design choices of our architecture and compare it to the baselines. We show the domain adaptation capability of our model to learn dynamics just from simulated data by testing it on the raw sensor data. We finally show the effect of signal complexity on the proposed method ability to model temporal dynamics.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2010.05771v1"
	},
	{
		"title": "MuMod: A Micro‐unit Connection Approach for Hybrid‐order Community Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Task‐Aware Monocular Depth Estimation for 3D Object Detection ",
		"abstract": "Monocular depth estimation enables 3D perception from a single 2D image, thus attracting much research attention for years. Almost all methods treat foreground and background regions (\"things and stuff\") in an image equally. However, not all pixels are equal. Depth of foreground objects plays a crucial role in 3D object recognition and localization. To date how to boost the depth prediction accuracy of foreground objects is rarely discussed. In this paper, we first analyse the data distributions and interaction of foreground and background, then propose the foreground-background separated monocular depth estimation (ForeSeE) method, to estimate the foreground depth and background depth using separate optimization objectives and depth decoders. Our method significantly improves the depth estimation performance on foreground objects. Applying ForeSeE to 3D object detection, we achieve 7.5 AP gains and set new state-of-the-art results among other monocular methods. Code will be available at: https://github.com/WXinlong/ForeSeE.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07701v2"
	},
	{
		"title": "MOSS: End‐to‐End Dialog System Framework with Modular Supervision ",
		"abstract": "A major bottleneck in training end-to-end task-oriented dialog system is the lack of data. To utilize limited training data more efficiently, we propose Modular Supervision Network (MOSS), an encoder-decoder training framework that could incorporate supervision from various intermediate dialog system modules including natural language understanding, dialog state tracking, dialog policy learning, and natural language generation. With only 60% of the training data, MOSS-all (i.e., MOSS with supervision from all four dialog modules) outperforms state-of-the-art models on CamRest676. Moreover, introducing modular supervision has even bigger benefits when the dialog task has a more complex dialog state and action space. With only 40% of the training data, MOSS-all outperforms the state-of-the-art model on a complex laptop network troubleshooting dataset, LaptopNetwork, that we introduced. LaptopNetwork consists of conversations between real customers and customer service agents in Chinese. Moreover, MOSS framework can accommodate dialogs that have supervision from different dialog modules at both the framework level and model level. Therefore, MOSS is extremely flexible to update in a real-world deployment.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05528v1"
	},
	{
		"title": "Trading Convergence Rate with Computational Budget in High Dimensional Bayesian Optimization ",
		"abstract": "Scaling Bayesian optimisation (BO) to high-dimensional search spaces is a active and open research problems particularly when no assumptions are made on function structure. The main reason is that at each iteration, BO requires to find global maximisation of acquisition function, which itself is a non-convex optimization problem in the original search space. With growing dimensions, the computational budget for this maximisation gets increasingly short leading to inaccurate solution of the maximisation. This inaccuracy adversely affects both the convergence and the efficiency of BO. We propose a novel approach where the acquisition function only requires maximisation on a discrete set of low dimensional subspaces embedded in the original high-dimensional search space. Our method is free of any low dimensional structure assumption on the function unlike many recent high-dimensional BO methods. Optimising acquisition function in low dimensional subspaces allows our method to obtain accurate solutions within limited computational budget. We show that in spite of this convenience, our algorithm remains convergent. In particular, cumulative regret of our algorithm only grows sub-linearly with the number of iterations. More importantly, as evident from our regret bounds, our algorithm provides a way to trade the convergence rate with the number of subspaces used in the optimisation. Finally, when the number of subspaces is \"sufficiently large\", our algorithm's cumulative regret is at most $\\mathcal{O}^{*}(\\sqrt{T\\gamma_T})$ as opposed to $\\mathcal{O}^{*}(\\sqrt{DT\\gamma_T})$ for the GP-UCB of Srinivas et al. (2012), reducing a crucial factor $\\sqrt{D}$ where $D$ being the dimensional number of input space.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11950v2"
	},
	{
		"title": "Attention‐Informed Mixed‐Language Training for Zero‐shot Cross‐lingual Task‐oriented Dialogue Systems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Channel Attention Is All You Need for Video Frame Interpolation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neuron Interaction Based Representation Composition for Neural Machine Translation ",
		"abstract": "Recent NLP studies reveal that substantial linguistic information can be attributed to single neurons, i.e., individual dimensions of the representation vectors. We hypothesize that modeling strong interactions among neurons helps to better capture complex information by composing the linguistic properties embedded in individual neurons. Starting from this intuition, we propose a novel approach to compose representations learned by different components in neural machine translation (e.g., multi-layer networks or multi-head attention), based on modeling strong interactions among neurons in the representation vectors. Specifically, we leverage bilinear pooling to model pairwise multiplicative interactions among individual neurons, and a low-rank approximation to make the model computationally feasible. We further propose extended bilinear pooling to incorporate first-order representations. Experiments on WMT14 English-German and English-French translation tasks show that our model consistently improves performances over the SOTA Transformer baseline. Further analyses demonstrate that our approach indeed captures more syntactic and semantic information as expected.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09877v1"
	},
	{
		"title": "Enhancing Nearest Neighbor Based Entropy Estimator for High Dimensional Distributions via Bootstrapping Local Ellipsoid ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Least General Generalizations in Description Logic: Verification and Existence ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Speaker Video Dialog with Frame‐Level Temporal Localization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bridging the Gap between Pre‐Training and Fine‐Tuning for End‐to‐End Speech Translation ",
		"abstract": "End-to-end speech translation, a hot topic in recent years, aims to translate a segment of audio into a specific language with an end-to-end model. Conventional approaches employ multi-task learning and pre-training methods for this task, but they suffer from the huge gap between pre-training and fine-tuning. To address these issues, we propose a Tandem Connectionist Encoding Network (TCEN) which bridges the gap by reusing all subnets in fine-tuning, keeping the roles of subnets consistent, and pre-training the attention module. Furthermore, we propose two simple but effective methods to guarantee the speech encoder outputs and the MT encoder inputs are consistent in terms of semantic representation and sequence length. Experimental results show that our model outperforms baselines 2.2 BLEU on a large benchmark dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07575v3"
	},
	{
		"title": "SGAP‐Net: Semantic‐Guided Attentive Prototypes Network for Few‐Shot Human‐Object Interaction Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GDFace: Gated Deformation for Multi‐view Face Image Synthesis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "D2D‐LSTM: LSTM‐based Path Prediction of Content Diffusion Tree in Device‐to‐Device Social Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Graph Convolutional Networks with Markov Random Field Reasoning for Social Spammer Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Reinforcement Learning for General Game Playing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Hiding in Multilayer Networks ",
		"abstract": "Multilayer networks allow for modeling complex relationships, where individuals are embedded in multiple social networks at the same time. Given the ubiquity of such relationships, these networks have been increasingly gaining attention in the literature. This paper presents the first analysis of the robustness of centrality measures against strategic manipulation in multilayer networks. More specifically, we consider an \"evader\" who strategically chooses which connections to form in a multilayer network in order to obtain a low centrality-based ranking-thereby reducing the chance of being highlighted as a key figure in the network-while ensuring that she remains connected to a certain group of people. We prove that determining an optimal way to \"hide\" is NP-complete and hard to approximate for most centrality measures considered in our study. Moreover, we empirically evaluate a number of heuristics that the evader can use. Our results suggest that the centrality measures that are functions of the entire network topology are more robust to such a strategic evader than their counterparts which consider each layer separately.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05947v1"
	},
	{
		"title": "FPETS : Fully Parallel End‐to‐End Text‐to‐Speech System ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Time‐Stream Framework for Click‐Through Rate Prediction by Tracking Interest Evolution ",
		"abstract": "Click-through rate (CTR) prediction is an essential task in industrial applications such as video recommendation. Recently, deep learning models have been proposed to learn the representation of users' overall interests, while ignoring the fact that interests may dynamically change over time. We argue that it is necessary to consider the continuous-time information in CTR models to track user interest trend from rich historical behaviors. In this paper, we propose a novel Deep Time-Stream framework (DTS) which introduces the time information by an ordinary differential equations (ODE). DTS continuously models the evolution of interests using a neural network, and thus is able to tackle the challenge of dynamically representing users' interests based on their historical behaviors. In addition, our framework can be seamlessly applied to any existing deep CTR models by leveraging the additional Time-Stream Module, while no changes are made to the original CTR models. Experiments on public dataset as well as real industry dataset with billions of samples demonstrate the effectiveness of proposed approaches, which achieve superior performance compared with existing methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.03025v1"
	},
	{
		"title": "Fatigue‐aware Bandits for Dependent Click Models ",
		"abstract": "As recommender systems send a massive amount of content to keep users engaged, users may experience fatigue which is contributed by 1) an overexposure to irrelevant content, 2) boredom from seeing too many similar recommendations. To address this problem, we consider an online learning setting where a platform learns a policy to recommend content that takes user fatigue into account. We propose an extension of the Dependent Click Model (DCM) to describe users' behavior. We stipulate that for each piece of content, its attractiveness to a user depends on its intrinsic relevance and a discount factor which measures how many similar contents have been shown. Users view the recommended content sequentially and click on the ones that they find attractive. Users may leave the platform at any time, and the probability of exiting is higher when they do not like the content. Based on user's feedback, the platform learns the relevance of the underlying content as well as the discounting effect due to content fatigue. We refer to this learning task as \"fatigue-aware DCM Bandit\" problem. We consider two learning scenarios depending on whether the discounting effect is known. For each scenario, we propose a learning algorithm which simultaneously explores and exploits, and characterize its regret bound.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.09733v1"
	},
	{
		"title": "Multi‐View Spectral Clustering with Optimal Neighborhood Laplacian Matrix ",
		"abstract": "Multi-view spectral clustering can effectively reveal the intrinsic cluster structure among data by performing clustering on the learned optimal embedding across views. Though demonstrating promising performance in various applications, most of existing methods usually linearly combine a group of pre-specified first-order Laplacian matrices to construct the optimal Laplacian matrix, which may result in limited representation capability and insufficient information exploitation. Also, storing and implementing complex operations on the $n\\times n$ Laplacian matrices incurs intensive storage and computation complexity. To address these issues, this paper first proposes a multi-view spectral clustering algorithm that learns a high-order optimal neighborhood Laplacian matrix, and then extends it to the late fusion version for accurate and efficient multi-view clustering. Specifically, our proposed algorithm generates the optimal Laplacian matrix by searching the neighborhood of the linear combination of both the first-order and high-order base Laplacian matrices simultaneously. By this way, the representative capacity of the learned optimal Laplacian matrix is enhanced, which is helpful to better utilize the hidden high-order connection information among data, leading to improved clustering performance. We design an efficient algorithm with proved convergence to solve the resultant optimization problem. Extensive experimental results on nine datasets demonstrate the superiority of our algorithm against state-of-the-art methods, which verifies the effectiveness and advantages of the proposed algorithm.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.13539v1"
	},
	{
		"title": "Joint Adversarial Learning for Domain Adaptation in Semantic Segmentation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Bayesian Approach for Estimating Causal Effects from Observational Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Progressive Boundary Refinement Network for Temporal Action Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "AATEAM: Achieving the Ad Hoc Teamwork by Employing the Attention Mechanism ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Image Enhanced Event Detection in News Articles ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "iFAN: Image‐Instance Full Alignment Networks for Adaptive Object Detection ",
		"abstract": "Training an object detector on a data-rich domain and applying it to a data-poor one with limited performance drop is highly attractive in industry, because it saves huge annotation cost. Recent research on unsupervised domain adaptive object detection has verified that aligning data distributions between source and target images through adversarial learning is very useful. The key is when, where and how to use it to achieve best practice. We propose Image-Instance Full Alignment Networks (iFAN) to tackle this problem by precisely aligning feature distributions on both image and instance levels: 1) Image-level alignment: multi-scale features are roughly aligned by training adversarial domain classifiers in a hierarchically-nested fashion. 2) Full instance-level alignment: deep semantic information and elaborate instance representations are fully exploited to establish a strong relationship among categories and domains. Establishing these correlations is formulated as a metric learning problem by carefully constructing instance pairs. Above-mentioned adaptations can be integrated into an object detector (e.g. Faster RCNN), resulting in an end-to-end trainable framework where multiple alignments can work collaboratively in a coarse-tofine manner. In two domain adaptation tasks: synthetic-to-real (SIM10K->Cityscapes) and normal-to-foggy weather (Cityscapes->Foggy Cityscapes), iFAN outperforms the state-of-the-art methods with a boost of 10%+ AP over the source-only baseline.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.04132v1"
	},
	{
		"title": "FAS‐Net: Construct Effective Features Adaptively for Multi‐Scale Object Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dynamic Malware Analysis with Feature Engineering and Feature Learning ",
		"abstract": "Dynamic malware analysis executes the program in an isolated environment and monitors its run-time behaviour (e.g. system API calls) for malware detection. This technique has been proven to be effective against various code obfuscation techniques and newly released (\"zero-day\") malware. However, existing works typically only consider the API name while ignoring the arguments, or require complex feature engineering operations and expert knowledge to process the arguments. In this paper, we propose a novel and low-cost feature extraction approach, and an effective deep neural network architecture for accurate and fast malware detection. Specifically, the feature representation approach utilizes a feature hashing trick to encode the API call arguments associated with the API name. The deep neural network architecture applies multiple Gated-CNNs (convolutional neural networks) to transform the extracted features of each API call. The outputs are further processed through bidirectional LSTM (long-short term memory networks) to learn the sequential correlation among API calls. Experiments show that our solution outperforms baselines significantly on a large real dataset. Valuable insights about feature engineering and architecture design are derived from the ablation study.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.07352v5"
	},
	{
		"title": "Symbolic Top‐k Planning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MixPoet: Diverse Poetry Generation via Learning Controllable Mixed Latent Space ",
		"abstract": "As an essential step towards computer creativity, automatic poetry generation has gained increasing attention these years. Though recent neural models make prominent progress in some criteria of poetry quality, generated poems still suffer from the problem of poor diversity. Related literature researches show that different factors, such as life experience, historical background, etc., would influence composition styles of poets, which considerably contributes to the high diversity of human-authored poetry. Inspired by this, we propose MixPoet, a novel model that absorbs multiple factors to create various styles and promote diversity. Based on a semi-supervised variational autoencoder, our model disentangles the latent space into some subspaces, with each conditioned on one influence factor by adversarial training. In this way, the model learns a controllable latent variable to capture and mix generalized factor-related properties. Different factor mixtures lead to diverse styles and hence further differentiate generated poems from each other. Experiment results on Chinese poetry demonstrate that MixPoet improves both diversity and quality against three state-of-the-art models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.06094v1"
	},
	{
		"title": "Synthetic Depth Transfer for Monocular 3D Object Pose Estimation in the Wild ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Semi‐Supervised Streaming Learning with Emerging New Labels ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SensEmBERT: Context‐Enhanced Sense Embeddings for Multilingual Word Sense Disambiguation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bayesian Optimization for Categorical and Category‐Specific Continuous Inputs ",
		"abstract": "Many real-world functions are defined over both categorical and category-specific continuous variables and thus cannot be optimized by traditional Bayesian optimization (BO) methods. To optimize such functions, we propose a new method that formulates the problem as a multi-armed bandit problem, wherein each category corresponds to an arm with its reward distribution centered around the optimum of the objective function in continuous variables. Our goal is to identify the best arm and the maximizer of the corresponding continuous function simultaneously. Our algorithm uses a Thompson sampling scheme that helps connecting both multi-arm bandit and BO in a unified framework. We extend our method to batch BO to allow parallel optimization when multiple resources are available. We theoretically analyze our method for convergence and prove sub-linear regret bounds. We perform a variety of experiments: optimization of several benchmark functions, hyper-parameter tuning of a neural network, and automatic selection of the best machine learning model along with its optimal hyper-parameters (a.k.a automated machine learning). Comparisons with other methods demonstrate the effectiveness of our proposed method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12473v1"
	},
	{
		"title": "Incentive‐Compatible Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Hierarchical Modes Exploring in Generative Adversarial Networks ",
		"abstract": "In conditional Generative Adversarial Networks (cGANs), when two different initial noises are concatenated with the same conditional information, the distance between their outputs is relatively smaller, which makes minor modes likely to collapse into large modes. To prevent this happen, we proposed a hierarchical mode exploring method to alleviate mode collapse in cGANs by introducing a diversity measurement into the objective function as the regularization term. We also introduced the Expected Ratios of Expansion (ERE) into the regularization term, by minimizing the sum of differences between the real change of distance and ERE, we can control the diversity of generated images w.r.t specific-level features. We validated the proposed algorithm on four conditional image synthesis tasks including categorical generation, paired and un-paired image translation and text-to-image generation. Both qualitative and quantitative results show that the proposed method is effective in alleviating the mode collapse problem in cGANs, and can control the diversity of output images w.r.t specific-level features.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.08752v1"
	},
	{
		"title": "A Constraint‐Based Approach to Learning and Explanation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Softmax Dissection: Towards Understanding Intra‐ and Inter‐class Objective for Embedding Learning ",
		"abstract": "The softmax loss and its variants are widely used as objectives for embedding learning, especially in applications like face recognition. However, the intra- and inter-class objectives in the softmax loss are entangled, therefore a well-optimized inter-class objective leads to relaxation on the intra-class objective, and vice versa. In this paper, we propose to dissect the softmax loss into independent intra- and inter-class objective (D-Softmax). With D-Softmax as objective, we can have a clear understanding of both the intra- and inter-class objective, therefore it is straightforward to tune each part to the best state. Furthermore, we find the computation of the inter-class objective is redundant and propose two sampling-based variants of D-Softmax to reduce the computation cost. Training with regular-scale data, experiments in face verification show D-Softmax is favorably comparable to existing losses such as SphereFace and ArcFace. Training with massive-scale data, experiments show the fast variants of D-Softmax significantly accelerates the training process (such as 64x) with only a minor sacrifice in performance, outperforming existing acceleration methods of softmax in terms of both performance and efficiency.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.01281v2"
	},
	{
		"title": "Gated Convolutional Networks with Hybrid Connectivity for Image Classification ",
		"abstract": "We propose a simple yet effective method to reduce the redundancy of DenseNet by substantially decreasing the number of stacked modules by replacing the original bottleneck by our SMG module, which is augmented by local residual. Furthermore, SMG module is equipped with an efficient two-stage pipeline, which aims to DenseNet-like architectures that need to integrate all previous outputs, i.e., squeezing the incoming informative but redundant features gradually by hierarchical convolutions as a hourglass shape and then exciting it by multi-kernel depthwise convolutions, the output of which would be compact and hold more informative multi-scale features. We further develop a forget and an update gate by introducing the popular attention modules to implement the effective fusion instead of a simple addition between reused and new features. Due to the Hybrid Connectivity (nested combination of global dense and local residual) and Gated mechanisms, we called our network as the HCGNet. Experimental results on CIFAR and ImageNet datasets show that HCGNet is more prominently efficient than DenseNet, and can also significantly outperform state-of-the-art networks with less complexity. Moreover, HCGNet also shows the remarkable interpretability and robustness by network dissection and adversarial defense, respectively. On MS-COCO, HCGNet can consistently learn better features than popular backbones.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.09699v3"
	},
	{
		"title": "Enhanced Meta‐Learning for Cross‐lingual Named Entity Recognition with Minimal Resources ",
		"abstract": "For languages with no annotated resources, transferring knowledge from rich-resource languages is an effective solution for named entity recognition (NER). While all existing methods directly transfer from source-learned model to a target language, in this paper, we propose to fine-tune the learned model with a few similar examples given a test case, which could benefit the prediction by leveraging the structural and semantic information conveyed in such similar examples. To this end, we present a meta-learning algorithm to find a good model parameter initialization that could fast adapt to the given test case and propose to construct multiple pseudo-NER tasks for meta-training by computing sentence similarities. To further improve the model's generalization ability across different languages, we introduce a masking scheme and augment the loss function with an additional maximum term during meta-training. We conduct extensive experiments on cross-lingual named entity recognition with minimal resources over five target languages. The results show that our approach significantly outperforms existing state-of-the-art methods across the board.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06161v2"
	},
	{
		"title": "Global Greedy Dependency Parsing ",
		"abstract": "Most syntactic dependency parsing models may fall into one of two categories: transition- and graph-based models. The former models enjoy high inference efficiency with linear time complexity, but they rely on the stacking or re-ranking of partially-built parse trees to build a complete parse tree and are stuck with slower training for the necessity of dynamic oracle training. The latter, graph-based models, may boast better performance but are unfortunately marred by polynomial time inference. In this paper, we propose a novel parsing order objective, resulting in a novel dependency parsing model capable of both global (in sentence scope) feature extraction as in graph models and linear time inference as in transitional models. The proposed global greedy parser only uses two arc-building actions, left and right arcs, for projective parsing. When equipped with two extra non-projective arc-building actions, the proposed parser may also smoothly support non-projective parsing. Using multiple benchmark treebanks, including the Penn Treebank (PTB), the CoNLL-X treebanks, and the Universal Dependency Treebanks, we evaluate our parser and demonstrate that the proposed novel parser achieves good performance with faster training and decoding.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08673v3"
	},
	{
		"title": "Point2Node: Correlation Learning of Dynamic‐Node for Point Cloud Feature Modeling ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Partial Multi‐label Learning with Noisy Label Identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Query‐Driven Multi‐Instance Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Stealthy and Efficient Adversarial Attacks against Deep Reinforcement Learning ",
		"abstract": "Adversarial attacks against conventional Deep Learning (DL) systems and algorithms have been widely studied, and various defenses were proposed. However, the possibility and feasibility of such attacks against Deep Reinforcement Learning (DRL) are less explored. As DRL has achieved great success in various complex tasks, designing effective adversarial attacks is an indispensable prerequisite towards building robust DRL algorithms. In this paper, we introduce two novel adversarial attack techniques to \\emph{stealthily} and \\emph{efficiently} attack the DRL agents. These two techniques enable an adversary to inject adversarial samples in a minimal set of critical moments while causing the most severe damage to the agent. The first technique is the \\emph{critical point attack}: the adversary builds a model to predict the future environmental states and agent's actions, assesses the damage of each possible attack strategy, and selects the optimal one. The second technique is the \\emph{antagonist attack}: the adversary automatically learns a domain-agnostic model to discover the critical moments of attacking the agent in an episode. Experimental results demonstrate the effectiveness of our techniques. Specifically, to successfully attack the DRL agent, our critical point technique only requires 1 (TORCS) or 2 (Atari Pong and Breakout) steps, and the antagonist technique needs fewer than 5 steps (4 Mujoco tasks), which are significant improvements over state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.07099v1"
	},
	{
		"title": "A Variational Point Process Approach for Social Event Sequences ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Structural Decompositions of Epistemic Logic Programs ",
		"abstract": "Epistemic logic programs (ELPs) are a popular generalization of standard Answer Set Programming (ASP) providing means for reasoning over answer sets within the language. This richer formalism comes at the price of higher computational complexity reaching up to the fourth level of the polynomial hierarchy. However, in contrast to standard ASP, dedicated investigations towards tractability have not been undertaken yet. In this paper, we give first results in this direction and show that central ELP problems can be solved in linear time for ELPs exhibiting structural properties in terms of bounded treewidth. We also provide a full dynamic programming algorithm that adheres to these bounds. Finally, we show that applying treewidth to a novel dependency structure---given in terms of epistemic literals---allows to bound the number of ASP solver calls in typical ELP solving procedures.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.04219v1"
	},
	{
		"title": "Learning Conceptual‐Contextual Embeddings for Medical Text ",
		"abstract": "External knowledge is often useful for natural language understanding tasks. We introduce a contextual text representation model called Conceptual-Contextual (CC) embeddings, which incorporates structured knowledge into text representations. Unlike entity embedding methods, our approach encodes a knowledge graph into a context model. CC embeddings can be easily reused for a wide range of tasks just like pre-trained language models. Our model effectively encodes the huge UMLS database by leveraging semantic generalizability. Experiments on electronic health records (EHRs) and medical text processing benchmarks showed our model gives a major boost to the performance of supervised medical NLP tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.06203v3"
	},
	{
		"title": "Adapting to Smoothness: A More Universal Algorithm for Online Convex Optimization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improved Algorithms for Conservative Exploration in Bandits ",
		"abstract": "In many fields such as digital marketing, healthcare, finance, and robotics, it is common to have a well-tested and reliable baseline policy running in production (e.g., a recommender system). Nonetheless, the baseline policy is often suboptimal. In this case, it is desirable to deploy online learning algorithms (e.g., a multi-armed bandit algorithm) that interact with the system to learn a better/optimal policy under the constraint that during the learning process the performance is almost never worse than the performance of the baseline itself. In this paper, we study the conservative learning problem in the contextual linear bandit setting and introduce a novel algorithm, the Conservative Constrained LinUCB (CLUCB2). We derive regret bounds for CLUCB2 that match existing results and empirically show that it outperforms state-of-the-art conservative bandit algorithms in a number of synthetic and real-world problems. Finally, we consider a more realistic constraint where the performance is verified only at predefined checkpoints (instead of at every step) and show how this relaxed constraint favorably impacts the regret and empirical performance of CLUCB2.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03221v1"
	},
	{
		"title": "Fine‐Grained Fashion Similarity Learning by Attribute‐Specific Embedding Network ",
		"abstract": "This paper strives to learn fine-grained fashion similarity. In this similarity paradigm, one should pay more attention to the similarity in terms of a specific design/attribute among fashion items, which has potential values in many fashion related applications such as fashion copyright protection. To this end, we propose an Attribute-Specific Embedding Network (ASEN) to jointly learn multiple attribute-specific embeddings in an end-to-end manner, thus measure the fine-grained similarity in the corresponding space. With two attention modules, i.e., Attribute-aware Spatial Attention and Attribute-aware Channel Attention, ASEN is able to locate the related regions and capture the essential patterns under the guidance of the specified attribute, thus make the learned attribute-specific embeddings better reflect the fine-grained similarity. Extensive experiments on four fashion-related datasets show the effectiveness of ASEN for fine-grained fashion similarity learning and its potential for fashion reranking.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.02814v1"
	},
	{
		"title": "Multi‐view Clustering in Latent Embedding Space ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Simple, Fast, and Safe Mediator for Congestion Management ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Sequential Recommendation with Relation‐Aware Kernelized Self‐Attention ",
		"abstract": "Recent studies identified that sequential Recommendation is improved by the attention mechanism. By following this development, we propose Relation-Aware Kernelized Self-Attention (RKSA) adopting a self-attention mechanism of the Transformer with augmentation of a probabilistic model. The original self-attention of Transformer is a deterministic measure without relation-awareness. Therefore, we introduce a latent space to the self-attention, and the latent space models the recommendation context from relation as a multivariate skew-normal distribution with a kernelized covariance matrix from co-occurrences, item characteristics, and user information. This work merges the self-attention of the Transformer and the sequential recommendation by adding a probabilistic model of the recommendation task specifics. We experimented RKSA over the benchmark datasets, and RKSA shows significant improvements compared to the recent baseline models. Also, RKSA were able to produce a latent space model that answers the reasons for recommendation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06478v1"
	},
	{
		"title": "What Do You Mean `Why?': Resolving Sluices in Conversations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Match to Rank Model for Personalized Click‐Through Rate Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Distributed Machine Learning through Heterogeneous Edge Systems ",
		"abstract": "Many emerging AI applications request distributed machine learning (ML) among edge systems (e.g., IoT devices and PCs at the edge of the Internet), where data cannot be uploaded to a central venue for model training, due to their large volumes and/or security/privacy concerns. Edge devices are intrinsically heterogeneous in computing capacity, posing significant challenges to parameter synchronization for parallel training with the parameter server (PS) architecture. This paper proposes ADSP, a parameter synchronization scheme for distributed machine learning (ML) with heterogeneous edge systems. Eliminating the significant waiting time occurring with existing parameter synchronization models, the core idea of ADSP is to let faster edge devices continue training, while committing their model updates at strategically decided intervals. We design algorithms that decide time points for each worker to commit its model update, and ensure not only global model convergence but also faster convergence. Our testbed implementation and experiments show that ADSP outperforms existing parameter synchronization models significantly in terms of ML model convergence time, scalability and adaptability to large heterogeneity.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06949v1"
	},
	{
		"title": "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines ",
		"abstract": "Visual tracking problem demands to efficiently perform robust classification and accurate target state estimation over a given target at the same time. Former methods have proposed various ways of target state estimation, yet few of them took the particularity of the visual tracking problem itself into consideration. After a careful analysis, we propose a set of practical guidelines of target state estimation for high-performance generic object tracker design. Following these guidelines, we design our Fully Convolutional Siamese tracker++ (SiamFC++) by introducing both classification and target state estimation branch(G1), classification score without ambiguity(G2), tracking without prior knowledge(G3), and estimation quality score(G4). Extensive analysis and ablation studies demonstrate the effectiveness of our proposed guidelines. Without bells and whistles, our SiamFC++ tracker achieves state-of-the-art performance on five challenging benchmarks(OTB2015, VOT2018, LaSOT, GOT-10k, TrackingNet), which proves both the tracking and generalization ability of the tracker. Particularly, on the large-scale TrackingNet dataset, SiamFC++ achieves a previously unseen AUC score of 75.4 while running at over 90 FPS, which is far above the real-time requirement. Code and models are available at: https://github.com/MegviiDetection/video_analyst .",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06188v4"
	},
	{
		"title": "Aggregation of Perspectives Using the Constellations Approach  to Probabilistic Argumentation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement ",
		"abstract": "Identifying new user intents is an essential task in the dialogue system. However, it is hard to get satisfying clustering results since the definition of intents is strongly guided by prior knowledge. Existing methods incorporate prior knowledge by intensive feature engineering, which not only leads to overfitting but also makes it sensitive to the number of clusters. In this paper, we propose constrained deep adaptive clustering with cluster refinement (CDAC+), an end-to-end clustering method that can naturally incorporate pairwise constraints as prior knowledge to guide the clustering process. Moreover, we refine the clusters by forcing the model to learn from the high confidence assignments. After eliminating low confidence assignments, our approach is surprisingly insensitive to the number of clusters. Experimental results on the three benchmark datasets show that our method can yield significant improvements over strong baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08891v1"
	},
	{
		"title": "The Radial and Directional Posteriors for Bayesian Deep Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GSSNN: Graph Smoothing Splines Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DeGAN : Data‐Enriching GAN for Retrieving Representative Samples from a Trained Classifier ",
		"abstract": "In this era of digital information explosion, an abundance of data from numerous modalities is being generated as well as archived everyday. However, most problems associated with training Deep Neural Networks still revolve around lack of data that is rich enough for a given task. Data is required not only for training an initial model, but also for future learning tasks such as Model Compression and Incremental Learning. A diverse dataset may be used for training an initial model, but it may not be feasible to store it throughout the product life cycle due to data privacy issues or memory constraints. We propose to bridge the gap between the abundance of available data and lack of relevant data, for the future learning tasks of a given trained network. We use the available data, that may be an imbalanced subset of the original training dataset, or a related domain dataset, to retrieve representative samples from a trained classifier, using a novel Data-enriching GAN (DeGAN) framework. We demonstrate that data from a related domain can be leveraged to achieve state-of-the-art performance for the tasks of Data-free Knowledge Distillation and Incremental Learning on benchmark datasets. We further demonstrate that our proposed framework can enrich any data, even from unrelated domains, to make it more useful for the future learning tasks of a given network.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11960v1"
	},
	{
		"title": "Knowledge Graph Transfer Network for Few‐Shot Recognition ",
		"abstract": "Few-shot learning aims to learn novel categories from very few samples given some base categories with sufficient training samples. The main challenge of this task is the novel categories are prone to dominated by color, texture, shape of the object or background context (namely specificity), which are distinct for the given few training samples but not common for the corresponding categories (see Figure 1). Fortunately, we find that transferring information of the correlated based categories can help learn the novel concepts and thus avoid the novel concept being dominated by the specificity. Besides, incorporating semantic correlations among different categories can effectively regularize this information transfer. In this work, we represent the semantic correlations in the form of structured knowledge graph and integrate this graph into deep neural networks to promote few-shot learning by a novel Knowledge Graph Transfer Network (KGTN). Specifically, by initializing each node with the classifier weight of the corresponding category, a propagation mechanism is learned to adaptively propagate node message through the graph to explore node interaction and transfer classifier information of the base categories to those of the novel ones. Extensive experiments on the ImageNet dataset show significant performance improvement compared with current leading competitors. Furthermore, we construct an ImageNet-6K dataset that covers larger scale categories, i.e, 6,000 categories, and experiments on this dataset further demonstrate the effectiveness of our proposed model. Our codes and models are available at https://github.com/MyChocer/KGTN .",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09579v2"
	},
	{
		"title": "Towards Oracle Knowledge Distillation with Neural Architecture Search ",
		"abstract": "We present a novel framework of knowledge distillation that is capable of learning powerful and efficient student models from ensemble teacher networks. Our approach addresses the inherent model capacity issue between teacher and student and aims to maximize benefit from teacher models during distillation by reducing their capacity gap. Specifically, we employ a neural architecture search technique to augment useful structures and operations, where the searched network is appropriate for knowledge distillation towards student models and free from sacrificing its performance by fixing the network capacity. We also introduce an oracle knowledge distillation loss to facilitate model search and distillation using an ensemble-based teacher model, where a student network is learned to imitate oracle performance of the teacher. We perform extensive experiments on the image classification datasets---CIFAR-100 and TinyImageNet---using various networks. We also show that searching for a new student model is effective in both accuracy and memory size and that the searched models often outperform their teacher models thanks to neural architecture search with oracle knowledge distillation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.13019v1"
	},
	{
		"title": "LeDeepChef: Deep Reinforcement Learning Agent for Families of Text‐Based Games ",
		"abstract": "While Reinforcement Learning (RL) approaches lead to significant achievements in a variety of areas in recent history, natural language tasks remained mostly unaffected, due to the compositional and combinatorial nature that makes them notoriously hard to optimize. With the emerging field of Text-Based Games (TBGs), researchers try to bridge this gap. Inspired by the success of RL algorithms on Atari games, the idea is to develop new methods in a restricted game world and then gradually move to more complex environments. Previous work in the area of TBGs has mainly focused on solving individual games. We, however, consider the task of designing an agent that not just succeeds in a single game, but performs well across a whole family of games, sharing the same theme. In this work, we present our deep RL agent--LeDeepChef--that shows generalization capabilities to never-before-seen games of the same family with different environments and task descriptions. The agent participated in Microsoft Research's \"First TextWorld Problems: A Language and Reinforcement Learning Challenge\" and outperformed all but one competitor on the final test set. The games from the challenge all share the same theme, namely cooking in a modern house environment, but differ significantly in the arrangement of the rooms, the presented objects, and the specific goal (recipe to cook). To build an agent that achieves high scores across a whole family of games, we use an actor-critic framework and prune the action-space by using ideas from hierarchical reinforcement learning and a specialized module trained on a recipe database.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.01646v1"
	},
	{
		"title": "Implicit Coordination Using FOND Planning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks ",
		"abstract": "As Deep Neural Networks (DNNs) have demonstrated superhuman performance in a variety of fields, there is an increasing interest in understanding the complex internal mechanisms of DNNs. In this paper, we propose Relative Attributing Propagation (RAP), which decomposes the output predictions of DNNs with a new perspective of separating the relevant (positive) and irrelevant (negative) attributions according to the relative influence between the layers. The relevance of each neuron is identified with respect to its degree of contribution, separated into positive and negative, while preserving the conservation rule. Considering the relevance assigned to neurons in terms of relative priority, RAP allows each neuron to be assigned with a bi-polar importance score concerning the output: from highly relevant to highly irrelevant. Therefore, our method makes it possible to interpret DNNs with much clearer and attentive visualizations of the separated attributions than the conventional explaining methods. To verify that the attributions propagated by RAP correctly account for each meaning, we utilize the evaluation metrics: (i) Outside-inside relevance ratio, (ii) Segmentation mIOU and (iii) Region perturbation. In all experiments and metrics, we present a sizable gap in comparison to the existing literature. Our source code is available in \\url{https://github.com/wjNam/Relative_Attributing_Propagation}.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.00605v4"
	},
	{
		"title": "Effective Decoding in Graph Auto‐Encoder using Triadic Closure ",
		"abstract": "The (variational) graph auto-encoder and its variants have been popularly used for representation learning on graph-structured data. While the encoder is often a powerful graph convolutional network, the decoder reconstructs the graph structure by only considering two nodes at a time, thus ignoring possible interactions among edges. On the other hand, structured prediction, which considers the whole graph simultaneously, is computationally expensive. In this paper, we utilize the well-known triadic closure property which is exhibited in many real-world networks. We propose the triad decoder, which considers and predicts the three edges involved in a local triad together. The triad decoder can be readily used in any graph-based auto-encoder. In particular, we incorporate this to the (variational) graph auto-encoder. Experiments on link prediction, node clustering and graph generation show that the use of triads leads to more accurate prediction, clustering and better preservation of the graph characteristics.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11322v1"
	},
	{
		"title": "Revisiting Graph based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach ",
		"abstract": "Graph Convolutional Networks (GCNs) are state-of-the-art graph based representation learning models by iteratively stacking multiple layers of convolution aggregation operations and non-linear activation operations. Recently, in Collaborative Filtering (CF) based Recommender Systems (RS), by treating the user-item interaction behavior as a bipartite graph, some researchers model higher-layer collaborative signals with GCNs. These GCN based recommender models show superior performance compared to traditional works. However, these models suffer from training difficulty with non-linear activations for large user-item graphs. Besides, most GCN based models could not model deeper layers due to the over smoothing effect with the graph convolution operation. In this paper, we revisit GCN based CF models from two aspects. First, we empirically show that removing non-linearities would enhance recommendation performance, which is consistent with the theories in simple graph convolutional networks. Second, we propose a residual network structure that is specifically designed for CF with user-item interaction modeling, which alleviates the over smoothing problem in graph convolution aggregation operation with sparse user-item interaction data. The proposed model is a linear model and it is easy to train, scale to large datasets, and yield better efficiency and effectiveness on two real datasets. We publish the source code at https://github.com/newlei/LRGCCF.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.10167v1"
	},
	{
		"title": "Temporal Interlacing Network ",
		"abstract": "For a long time, the vision community tries to learn the spatio-temporal representation by combining convolutional neural network together with various temporal models, such as the families of Markov chain, optical flow, RNN and temporal convolution. However, these pipelines consume enormous computing resources due to the alternately learning process for spatial and temporal information. One natural question is whether we can embed the temporal information into the spatial one so the information in the two domains can be jointly learned once-only. In this work, we answer this question by presenting a simple yet powerful operator -- temporal interlacing network (TIN). Instead of learning the temporal features, TIN fuses the two kinds of information by interlacing spatial representations from the past to the future, and vice versa. A differentiable interlacing target can be learned to control the interlacing process. In this way, a heavy temporal model is replaced by a simple interlacing operator. We theoretically prove that with a learnable interlacing target, TIN performs equivalently to the regularized temporal convolution network (r-TCN), but gains 4% more accuracy with 6x less latency on 6 challenging benchmarks. These results push the state-of-the-art performances of video understanding by a considerable margin. Not surprising, the ensemble model of the proposed TIN won the $1^{st}$ place in the ICCV19 - Multi Moments in Time challenge. Code is made available to facilitate further research at https://github.com/deepcs233/TIN",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06499v1"
	},
	{
		"title": "JSI‐GAN: GAN‐Based Joint Super‐Resolution and Inverse Tone‐Mapping with Pixel‐Wise Task‐Specific Filters for UHD HDR Video ",
		"abstract": "Joint learning of super-resolution (SR) and inverse tone-mapping (ITM) has been explored recently, to convert legacy low resolution (LR) standard dynamic range (SDR) videos to high resolution (HR) high dynamic range (HDR) videos for the growing need of UHD HDR TV/broadcasting applications. However, previous CNN-based methods directly reconstruct the HR HDR frames from LR SDR frames, and are only trained with a simple L2 loss. In this paper, we take a divide-and-conquer approach in designing a novel GAN-based joint SR-ITM network, called JSI-GAN, which is composed of three task-specific subnets: an image reconstruction subnet, a detail restoration (DR) subnet and a local contrast enhancement (LCE) subnet. We delicately design these subnets so that they are appropriately trained for the intended purpose, learning a pair of pixel-wise 1D separable filters via the DR subnet for detail restoration and a pixel-wise 2D local filter by the LCE subnet for contrast enhancement. Moreover, to train the JSI-GAN effectively, we propose a novel detail GAN loss alongside the conventional GAN loss, which helps enhancing both local details and contrasts to reconstruct high quality HR HDR results. When all subnets are jointly trained well, the predicted HR HDR results of higher quality are obtained with at least 0.41 dB gain in PSNR over those generated by the previous methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.04391v2"
	},
	{
		"title": "Adversarial Disentanglement with Grouped Observations ",
		"abstract": "We consider the disentanglement of the representations of the relevant attributes of the data (content) from all other factors of variations (style) using Variational Autoencoders. Some recent works addressed this problem by utilizing grouped observations, where the content attributes are assumed to be common within each group, while there is no any supervised information on the style factors. In many cases, however, these methods fail to prevent the models from using the style variables to encode content related features as well. This work supplements these algorithms with a method that eliminates the content information in the style representations. For that purpose the training objective is augmented to minimize an appropriately defined mutual information term in an adversarial way. Experimental results and comparisons on image datasets show that the resulting method can efficiently separate the content and style related attributes and generalizes to unseen data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.04761v1"
	},
	{
		"title": "Learning The Value of Teamwork to Form Efficient Teams ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CatGAN: Category‐aware Generative Adversarial Networks with Hierarchical Evolutionary Learning for Category Text Generation ",
		"abstract": "Generating multiple categories of texts is a challenging task and draws more and more attention. Since generative adversarial nets (GANs) have shown competitive results on general text generation, they are extended for category text generation in some previous works. However, the complicated model structures and learning strategies limit their performance and exacerbate the training instability. This paper proposes a category-aware GAN (CatGAN) which consists of an efficient category-aware model for category text generation and a hierarchical evolutionary learning algorithm for training our model. The category-aware model directly measures the gap between real samples and generated samples on each category, then reducing this gap will guide the model to generate high-quality category samples. The Gumbel-Softmax relaxation further frees our model from complicated learning strategies for updating CatGAN on discrete data. Moreover, only focusing on the sample quality normally leads the mode collapse problem, thus a hierarchical evolutionary learning algorithm is introduced to stabilize the training procedure and obtain the trade-off between quality and diversity while training CatGAN. Experimental results demonstrate that CatGAN outperforms most of the existing state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06641v2"
	},
	{
		"title": "Sequential Mode Estimation with Oracle Queries ",
		"abstract": "We consider the problem of adaptively PAC-learning a probability distribution $\\mathcal{P}$'s mode by querying an oracle for information about a sequence of i.i.d. samples $X_1, X_2, \\ldots$ generated from $\\mathcal{P}$. We consider two different query models: (a) each query is an index $i$ for which the oracle reveals the value of the sample $X_i$, (b) each query is comprised of two indices $i$ and $j$ for which the oracle reveals if the samples $X_i$ and $X_j$ are the same or not. For these query models, we give sequential mode-estimation algorithms which, at each time $t$, either make a query to the corresponding oracle based on past observations, or decide to stop and output an estimate for the distribution's mode, required to be correct with a specified confidence. We analyze the query complexity of these algorithms for any underlying distribution $\\mathcal{P}$, and derive corresponding lower bounds on the optimal query complexity under the two querying models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08197v1"
	},
	{
		"title": "Achieving Fairness in the Stochastic Multi‐armed Bandit Problem ",
		"abstract": "We study an interesting variant of the stochastic multi-armed bandit problem, called the Fair-SMAB problem, where each arm is required to be pulled for at least a given fraction of the total available rounds. We investigate the interplay between learning and fairness in terms of a pre-specified vector denoting the fractions of guaranteed pulls. We define a fairness-aware regret, called $r$-Regret, that takes into account the above fairness constraints and naturally extends the conventional notion of regret. Our primary contribution is characterizing a class of Fair-SMAB algorithms by two parameters: the unfairness tolerance and the learning algorithm used as a black-box. We provide a fairness guarantee for this class that holds uniformly over time irrespective of the choice of the learning algorithm. In particular, when the learning algorithm is UCB1, we show that our algorithm achieves $O(\\ln T)$ $r$-Regret. Finally, we evaluate the cost of fairness in terms of the conventional notion of regret.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.10516v2"
	},
	{
		"title": "Incremental Fairness in Two‐Sided Market Platforms: On Smoothly Updating Recommendations ",
		"abstract": "Major online platforms today can be thought of as two-sided markets with producers and customers of goods and services. There have been concerns that over-emphasis on customer satisfaction by the platforms may affect the well-being of the producers. To counter such issues, few recent works have attempted to incorporate fairness for the producers. However, these studies have overlooked an important issue in such platforms -- to supposedly improve customer utility, the underlying algorithms are frequently updated, causing abrupt changes in the exposure of producers. In this work, we focus on the fairness issues arising out of such frequent updates, and argue for incremental updates of the platform algorithms so that the producers have enough time to adjust (both logistically and mentally) to the change. However, naive incremental updates may become unfair to the customers. Thus focusing on recommendations deployed on two-sided platforms, we formulate an ILP based online optimization to deploy changes incrementally in n steps, where we can ensure smooth transition of the exposure of items while guaranteeing a minimum utility for every customer. Evaluations over multiple real world datasets show that our proposed mechanism for platform updates can be efficient and fair to both the producers and the customers in two-sided platforms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10005v2"
	},
	{
		"title": "Weakly Supervised Learning Meets Ride‐Sharing User Experience Enhancement ",
		"abstract": "Weakly supervised learning aims at coping with scarce labeled data. Previous weakly supervised studies typically assume that there is only one kind of weak supervision in data. In many applications, however, raw data usually contains more than one kind of weak supervision at the same time. For example, in user experience enhancement from Didi, one of the largest online ride-sharing platforms, the ride comment data contains severe label noise (due to the subjective factors of passengers) and severe label distribution bias (due to the sampling bias). We call such a problem as \"compound weakly supervised learning\". In this paper, we propose the CWSL method to address this problem based on Didi ride-sharing comment data. Specifically, an instance reweighting strategy is employed to cope with severe label noise in comment data, where the weights for harmful noisy instances are small. Robust criteria like AUC rather than accuracy and the validation performance are optimized for the correction of biased data label. Alternating optimization and stochastic gradient methods accelerate the optimization on large-scale data. Experiments on Didi ride-sharing comment data clearly validate the effectiveness. We hope this work may shed some light on applying weakly supervised learning to complex real situations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.09027v1"
	},
	{
		"title": "Structure Learning for Headline Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Designing Committees for Mitigating Biases ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Background Suppression Network for Weakly‐supervised Temporal Action Localization ",
		"abstract": "Weakly-supervised temporal action localization is a very challenging problem because frame-wise labels are not given in the training stage while the only hint is video-level labels: whether each video contains action frames of interest. Previous methods aggregate frame-level class scores to produce video-level prediction and learn from video-level action labels. This formulation does not fully model the problem in that background frames are forced to be misclassified as action classes to predict video-level labels accurately. In this paper, we design Background Suppression Network (BaS-Net) which introduces an auxiliary class for background and has a two-branch weight-sharing architecture with an asymmetrical training strategy. This enables BaS-Net to suppress activations from background frames to improve localization performance. Extensive experiments demonstrate the effectiveness of BaS-Net and its superiority over the state-of-the-art methods on the most popular benchmarks - THUMOS'14 and ActivityNet. Our code and the trained model are available at https://github.com/Pilhyeon/BaSNet-pytorch.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09963v1"
	},
	{
		"title": "Distraction‐Aware Feature Learning for Human Attribute Recognition via Coarse‐to‐Fine Attention Mechanism ",
		"abstract": "Recently, Human Attribute Recognition (HAR) has become a hot topic due to its scientific challenges and application potentials, where localizing attributes is a crucial stage but not well handled. In this paper, we propose a novel deep learning approach to HAR, namely Distraction-aware HAR (Da-HAR). It enhances deep CNN feature learning by improving attribute localization through a coarse-to-fine attention mechanism. At the coarse step, a self-mask block is built to roughly discriminate and reduce distractions, while at the fine step, a masked attention branch is applied to further eliminate irrelevant regions. Thanks to this mechanism, feature learning is more accurate, especially when heavy occlusions and complex backgrounds exist. Extensive experiments are conducted on the WIDER-Attribute and RAP databases, and state-of-the-art results are achieved, demonstrating the effectiveness of the proposed approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11351v1"
	},
	{
		"title": "Multi‐spectral Salient Object Detection by Adversarial Domain Adaptation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Making Existing Clusterings Fairer: Algorithms, Complexity Results and Insights ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Attention‐based Graph Neural Network for Heterogeneous Structural Learning ",
		"abstract": "In this paper, we focus on graph representation learning of heterogeneous information network (HIN), in which various types of vertices are connected by various types of relations. Most of the existing methods conducted on HIN revise homogeneous graph embedding models via meta-paths to learn low-dimensional vector space of HIN. In this paper, we propose a novel Heterogeneous Graph Structural Attention Neural Network (HetSANN) to directly encode structural information of HIN without meta-path and achieve more informative representations. With this method, domain experts will not be needed to design meta-path schemes and the heterogeneous information can be processed automatically by our proposed model. Specifically, we implicitly represent heterogeneous information using the following two methods: 1) we model the transformation between heterogeneous vertices through a projection in low-dimensional entity spaces; 2) afterwards, we apply the graph neural network to aggregate multi-relational information of projected neighborhood by means of attention mechanism. We also present three extensions of HetSANN, i.e., voices-sharing product attention for the pairwise relationships in HIN, cycle-consistency loss to retain the transformation between heterogeneous entity spaces, and multi-task learning with full use of information. The experiments conducted on three public datasets demonstrate that our proposed models achieve significant and consistent improvements compared to state-of-the-art solutions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10832v1"
	},
	{
		"title": "Asymetric Co‐Teaching for Unsupervised Cross Domain Person Re‐Identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "RobuTrans: a Robust Transformer based Text‐to‐Speech Model ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bayes‐Adaptive Monte‐Carlo Planning and Learning for Goal‐Oriented Dialogues ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Guiding attention in Sequence‐to‐sequence models for Dialogue Act prediction ",
		"abstract": "The task of predicting dialog acts (DA) based on conversational dialog is a key component in the development of conversational agents. Accurately predicting DAs requires a precise modeling of both the conversation and the global tag dependencies. We leverage seq2seq approaches widely adopted in Neural Machine Translation (NMT) to improve the modelling of tag sequentiality. Seq2seq models are known to learn complex global dependencies while currently proposed approaches using linear conditional random fields (CRF) only model local tag dependencies. In this work, we introduce a seq2seq model tailored for DA classification using: a hierarchical encoder, a novel guided attention mechanism and beam search applied to both training and inference. Compared to the state of the art our model does not require handcrafted features and is trained end-to-end. Furthermore, the proposed approach achieves an unmatched accuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on MRDA.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.08801v2"
	},
	{
		"title": "Beyond the Grounding Bottleneck: Datalog Techniques for Inference in Probabilistic Logic Programs ",
		"abstract": "State-of-the-art inference approaches in probabilistic logic programming typically start by computing the relevant ground program with respect to the queries of interest, and then use this program for probabilistic inference using knowledge compilation and weighted model counting. We propose an alternative approach that uses efficient Datalog techniques to integrate knowledge compilation with forward reasoning with a non-ground program. This effectively eliminates the grounding bottleneck that so far has prohibited the application of probabilistic logic programming in query answering scenarios over knowledge graphs, while also providing fast approximations on classical benchmarks in the field.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07750v1"
	},
	{
		"title": "Induction of Subgoal Automata for Reinforcement Learning ",
		"abstract": "In this work we present ISA, a novel approach for learning and exploiting subgoals in reinforcement learning (RL). Our method relies on inducing an automaton whose transitions are subgoals expressed as propositional formulas over a set of observable events. A state-of-the-art inductive logic programming system is used to learn the automaton from observation traces perceived by the RL agent. The reinforcement learning and automaton learning processes are interleaved: a new refined automaton is learned whenever the RL agent generates a trace not recognized by the current automaton. We evaluate ISA in several gridworld problems and show that it performs similarly to a method for which automata are given in advance. We also show that the learned automata can be exploited to speed up convergence through reward shaping and transfer learning across multiple tasks. Finally, we analyze the running time and the number of traces that ISA needs to learn an automata, and the impact that the number of observable events has on the learner's performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.13152v1"
	},
	{
		"title": "A Proposal‐based Approach for Activity Image‐to‐Video Retrieval ",
		"abstract": "Activity image-to-video retrieval task aims to retrieve videos containing the similar activity as the query image, which is a challenging task because videos generally have many background segments irrelevant to the activity. In this paper, we utilize R-C3D model to represent a video by a bag of activity proposals, which can filter out background segments to some extent. However, there are still noisy proposals in each bag. Thus, we propose an Activity Proposal-based Image-to-Video Retrieval (APIVR) approach, which incorporates multi-instance learning into cross-modal retrieval framework to address the proposal noise issue. Specifically, we propose a Graph Multi-Instance Learning (GMIL) module with graph convolutional layer, and integrate this module with classification loss, adversarial loss, and triplet loss in our cross-modal retrieval framework. Moreover, we propose geometry-aware triplet loss based on point-to-subspace distance to preserve the structural information of activity proposals. Extensive experiments on three widely-used datasets verify the effectiveness of our approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10531v1"
	},
	{
		"title": "Progressive Bi‐C3D Pose Grammar for Human Pose Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Location‐aware Graph Convolutional Networks for Video Question Answering ",
		"abstract": "We addressed the challenging task of video question answering, which requires machines to answer questions about videos in a natural language form. Previous state-of-the-art methods attempt to apply spatio-temporal attention mechanism on video frame features without explicitly modeling the location and relations among object interaction occurred in videos. However, the relations between object interaction and their location information are very critical for both action recognition and question reasoning. In this work, we propose to represent the contents in the video as a location-aware graph by incorporating the location information of an object into the graph construction. Here, each node is associated with an object represented by its appearance and location features. Based on the constructed graph, we propose to use graph convolution to infer both the category and temporal locations of an action. As the graph is built on objects, our method is able to focus on the foreground action contents for better video question answering. Lastly, we leverage an attention mechanism to combine the output of graph convolution and encoded question features for final answer reasoning. Extensive experiments demonstrate the effectiveness of the proposed methods. Specifically, our method significantly outperforms state-of-the-art methods on TGIF-QA, Youtube2Text-QA, and MSVD-QA datasets. Code and pre-trained models are publicly available at: https://github.com/SunDoge/L-GCN",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.09105v1"
	},
	{
		"title": "Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering ",
		"abstract": "Community question answering (CQA) gains increasing popularity in both academy and industry recently. However, the redundancy and lengthiness issues of crowdsourced answers limit the performance of answer selection and lead to reading difficulties and misunderstandings for community users. To solve these problems, we tackle the tasks of answer selection and answer summary generation in CQA with a novel joint learning model. Specifically, we design a question-driven pointer-generator network, which exploits the correlation information between question-answer pairs to aid in attending the essential information when generating answer summaries. Meanwhile, we leverage the answer summaries to alleviate noise in original lengthy answers when ranking the relevancy degrees of question-answer pairs. In addition, we construct a new large-scale CQA corpus, WikiHowQA, which contains long answers for answer selection as well as reference summaries for answer summarization. The experimental results show that the joint learning method can effectively address the answer redundancy issue in CQA and achieves state-of-the-art results on both answer selection and text summarization tasks. Furthermore, the proposed model is shown to be of great transferring ability and applicability for resource-poor CQA tasks, which lack of reference answer summaries.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09801v1"
	},
	{
		"title": "Revisiting the Foundations of Abstract Argumentation ‐ Semantics Based on Weak Admissibility and Weak Defense ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Span Model for Open Information Extraction on Accurate Corpus ",
		"abstract": "Open information extraction (Open IE) is a challenging task especially due to its brittle data basis. Most of Open IE systems have to be trained on automatically built corpus and evaluated on inaccurate test set. In this work, we first alleviate this difficulty from both sides of training and test sets. For the former, we propose an improved model design to more sufficiently exploit training dataset. For the latter, we present our accurately re-annotated benchmark test set (Re-OIE6) according to a series of linguistic observation and analysis. Then, we introduce a span model instead of previous adopted sequence labeling formulization for n-ary Open IE. Our newly introduced model achieves new state-of-the-art performance on both benchmark evaluation datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.10879v6"
	},
	{
		"title": "DCR‐Net: A Deep Co‐Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classiﬁcation ",
		"abstract": "In dialog system, dialog act recognition and sentiment classification are two correlative tasks to capture speakers intentions, where dialog act and sentiment can indicate the explicit and the implicit intentions separately. Most of the existing systems either treat them as separate tasks or just jointly model the two tasks by sharing parameters in an implicit way without explicitly modeling mutual interaction and relation. To address this problem, we propose a Deep Co-Interactive Relation Network (DCR-Net) to explicitly consider the cross-impact and model the interaction between the two tasks by introducing a co-interactive relation layer. In addition, the proposed relation layer can be stacked to gradually capture mutual knowledge with multiple steps of interaction. Especially, we thoroughly study different relation layers and their effects. Experimental results on two public datasets (Mastodon and Dailydialog) show that our model outperforms the state-of-the-art joint model by 4.3% and 3.4% in terms of F1 score on dialog act recognition task, 5.7% and 12.4% on sentiment classification respectively. Comprehensive analysis empirically verifies the effectiveness of explicitly modeling the relation between the two tasks and the multi-steps interaction mechanism. Finally, we employ the Bidirectional Encoder Representation from Transformer (BERT) in our framework, which can further boost our performance in both tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.06914v1"
	},
	{
		"title": "Finding Action Tubes with a Sparse‐to‐Dense Framework ",
		"abstract": "The task of spatial-temporal action detection has attracted increasing attention among researchers. Existing dominant methods solve this problem by relying on short-term information and dense serial-wise detection on each individual frames or clips. Despite their effectiveness, these methods showed inadequate use of long-term information and are prone to inefficiency. In this paper, we propose for the first time, an efficient framework that generates action tube proposals from video streams with a single forward pass in a sparse-to-dense manner. There are two key characteristics in this framework: (1) Both long-term and short-term sampled information are explicitly utilized in our spatiotemporal network, (2) A new dynamic feature sampling module (DTS) is designed to effectively approximate the tube output while keeping the system tractable. We evaluate the efficacy of our model on the UCF101-24, JHMDB-21 and UCFSports benchmark datasets, achieving promising results that are competitive to state-of-the-art methods. The proposed sparse-to-dense strategy rendered our framework about 7.6 times more efficient than the nearest competitor.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.13196v1"
	},
	{
		"title": "Bounds and Complexity Results for Learning Coalition‐Based Interaction Functions in Networked Social Systems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FFA‐Net: Feature Fusion Attention Network for Single Image Dehazing ",
		"abstract": "In this paper, we propose an end-to-end feature fusion at-tention network (FFA-Net) to directly restore the haze-free image. The FFA-Net architecture consists of three key components:   1) A novel Feature Attention (FA) module combines Channel Attention with Pixel Attention mechanism, considering that different channel-wise features contain totally different weighted information and haze distribution is uneven on the different image pixels. FA treats different features and pixels unequally, which provides additional flexibility in dealing with different types of information, expanding the representational ability of CNNs. 2) A basic block structure consists of Local Residual Learning and Feature Attention, Local Residual Learning allowing the less important information such as thin haze region or low-frequency to be bypassed through multiple local residual connections, let main network architecture focus on more effective information. 3) An Attention-based different levels Feature Fusion (FFA) structure, the feature weights are adaptively learned from the Feature Attention (FA) module, giving more weight to important features. This structure can also retain the information of shallow layers and pass it into deep layers.   The experimental results demonstrate that our proposed FFA-Net surpasses previous state-of-the-art single image dehazing methods by a very large margin both quantitatively and qualitatively, boosting the best published PSNR metric from 30.23db to 36.39db on the SOTS indoor test dataset.   Code has been made available at GitHub.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07559v2"
	},
	{
		"title": "Realistic Face Reenactment via Self‐Supervised Disentangling of Identity and Pose ",
		"abstract": "Recent works have shown how realistic talking face images can be obtained under the supervision of geometry guidance, e.g., facial landmark or boundary. To alleviate the demand for manual annotations, in this paper, we propose a novel self-supervised hybrid model (DAE-GAN) that learns how to reenact face naturally given large amounts of unlabeled videos. Our approach combines two deforming autoencoders with the latest advances in the conditional generation. On the one hand, we adopt the deforming autoencoder to disentangle identity and pose representations. A strong prior in talking face videos is that each frame can be encoded as two parts: one for video-specific identity and the other for various poses. Inspired by that, we utilize a multi-frame deforming autoencoder to learn a pose-invariant embedded face for each video. Meanwhile, a multi-scale deforming autoencoder is proposed to extract pose-related information for each frame. On the other hand, the conditional generator allows for enhancing fine details and overall reality. It leverages the disentangled features to generate photo-realistic and pose-alike face images. We evaluate our model on VoxCeleb1 and RaFD dataset. Experiment results demonstrate the superior quality of reenacted images and the flexibility of transferring facial movements between identities.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.12957v1"
	},
	{
		"title": "ODSS: Efficient Hybridization for Optimal Coalition Structure Generation. ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Abstract Interpretation of Decision Tree Ensemble Classifiers ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Complexity and Expressive Power of Disjunction and Negation in Limit Datalog ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Effective Hard Thresholding Method based on Stochastic Variance Reduction for Nonconvex Sparse Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MRI Reconstruction with Interpretable Pixel‐Wise Operations Using Reinforcement Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multiple Positional Self‐Attention Network For Text Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Predicting AC‐Optimal Power Flows: Combining Deep Learning and Lagrangian Dual Methods ",
		"abstract": "The Optimal Power Flow (OPF) problem is a fundamental building block for the optimization of electrical power systems. It is nonlinear and nonconvex and computes the generator setpoints for power and voltage, given a set of load demands. It is often needed to be solved repeatedly under various conditions, either in real-time or in large-scale studies. This need is further exacerbated by the increasing stochasticity of power systems due to renewable energy sources in front and behind the meter. To address these challenges, this paper presents a deep learning approach to the OPF. The learning model exploits the information available in the prior states of the system (which is commonly available in practical applications), as well as a dual Lagrangian method to satisfy the physical and engineering constraints present in the OPF. The proposed model is evaluated on a large collection of realistic power systems. The experimental results show that its predictions are highly accurate with average errors as low as 0.2%. Additionally, the proposed approach is shown to improve the accuracy of widely adopted OPF linear DC approximation by at least two orders of magnitude.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10461v2"
	},
	{
		"title": "A New Burrows Wheeler Transform Markov Distance ",
		"abstract": "Prior work inspired by compression algorithms has described how the Burrows Wheeler Transform can be used to create a distance measure for bioinformatics problems. We describe issues with this approach that were not widely known, and introduce our new Burrows Wheeler Markov Distance (BWMD) as an alternative. The BWMD avoids the shortcomings of earlier efforts, and allows us to tackle problems in variable length DNA sequence clustering. BWMD is also more adaptable to other domains, which we demonstrate on malware classification tasks. Unlike other compression-based distance metrics known to us, BWMD works by embedding sequences into a fixed-length feature vector. This allows us to provide significantly improved clustering performance on larger malware corpora, a weakness of prior methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.13046v1"
	},
	{
		"title": "Adapting Stable Matchings to Evolving Preferences ",
		"abstract": "Adaptivity to changing environments and constraints is key to success in modern society. We address this by proposing \"incrementalized versions\" of Stable Marriage and Stable Roommates. That is, we try to answer the following question: for both problems, what is the computational cost of adapting an existing stable matching after some of the preferences of the agents have changed. While doing so, we also model the constraint that the new stable matching shall be not too different from the old one. After formalizing these incremental versions, we provide a fairly comprehensive picture of the computational complexity landscape of Incremental Stable Marriage and Incremental Stable Roommates. To this end, we exploit the parameters \"degree of change\" both in the input (difference between old and new preference profile) and in the output (difference between old and new stable matching). We obtain both hardness and tractability results, in particular showing a fixed-parameter tractability result with respect to the parameter \"distance between old and new stable matching\".",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.01375v2"
	},
	{
		"title": "Neural Simile Recognition with Cyclic Multitask Learning and Local Attention ",
		"abstract": "Simile recognition is to detect simile sentences and to extract simile components, i.e., tenors and vehicles. It involves two subtasks: {\\it simile sentence classification} and {\\it simile component extraction}. Recent work has shown that standard multitask learning is effective for Chinese simile recognition, but it is still uncertain whether the mutual effects between the subtasks have been well captured by simple parameter sharing. We propose a novel cyclic multitask learning framework for neural simile recognition, which stacks the subtasks and makes them into a loop by connecting the last to the first. It iteratively performs each subtask, taking the outputs of the previous subtask as additional inputs to the current one, so that the interdependence between the subtasks can be better explored. Extensive experiments show that our framework significantly outperforms the current state-of-the-art model and our carefully designed baselines, and the gains are still remarkable using BERT.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.09084v1"
	},
	{
		"title": "Learning and Reasoning for Robot Sequential Decision Making under Uncertainty ",
		"abstract": "Robots frequently face complex tasks that require more than one action, where sequential decision-making (SDM) capabilities become necessary. The key contribution of this work is a robot SDM framework, called LCORPP, that supports the simultaneous capabilities of supervised learning for passive state estimation, automated reasoning with declarative human knowledge, and planning under uncertainty toward achieving long-term goals. In particular, we use a hybrid reasoning paradigm to refine the state estimator, and provide informative priors for the probabilistic planner. In experiments, a mobile robot is tasked with estimating human intentions using their motion trajectories, declarative contextual knowledge, and human-robot interaction (dialog-based and motion-based). Results suggest that, in efficiency and accuracy, our framework performs better than its no-learning and no-reasoning counterparts in office environment.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.05322v3"
	},
	{
		"title": "Continuous Multiagent Control using Collective Behavior Entropy for Large‐Scale Home Energy Management ",
		"abstract": "With the increasing popularity of electric vehicles, distributed energy generation and storage facilities in smart grid systems, an efficient Demand-Side Management (DSM) is urgent for energy savings and peak loads reduction. Traditional DSM works focusing on optimizing the energy activities for a single household can not scale up to large-scale home energy management problems. Multi-agent Deep Reinforcement Learning (MA-DRL) shows a potential way to solve the problem of scalability, where modern homes interact together to reduce energy consumers consumption while striking a balance between energy cost and peak loads reduction. However, it is difficult to solve such an environment with the non-stationarity, and existing MA-DRL approaches cannot effectively give incentives for expected group behavior. In this paper, we propose a collective MA-DRL algorithm with continuous action space to provide fine-grained control on a large scale microgrid. To mitigate the non-stationarity of the microgrid environment, a novel predictive model is proposed to measure the collective market behavior. Besides, a collective behavior entropy is introduced to reduce the high peak loads incurred by the collective behaviors of all householders in the smart grid. Empirical results show that our approach significantly outperforms the state-of-the-art methods regarding power cost reduction and daily peak loads optimization.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.10000v1"
	},
	{
		"title": "The Value of Paraphrase for Knowledge Base Predicates ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Modelling Semantic Categories using Conceptual Neighborhood ",
		"abstract": "While many methods for learning vector space embeddings have been proposed in the field of Natural Language Processing, these methods typically do not distinguish between categories and individuals. Intuitively, if individuals are represented as vectors, we can think of categories as (soft) regions in the embedding space. Unfortunately, meaningful regions can be difficult to estimate, especially since we often have few examples of individuals that belong to a given category. To address this issue, we rely on the fact that different categories are often highly interdependent. In particular, categories often have conceptual neighbors, which are disjoint from but closely related to the given category (e.g.\\ fruit and vegetable). Our hypothesis is that more accurate category representations can be learned by relying on the assumption that the regions representing such conceptual neighbors should be adjacent in the embedding space. We propose a simple method for identifying conceptual neighbors and then show that incorporating these conceptual neighbors indeed leads to more accurate region based representations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01220v1"
	},
	{
		"title": "To Avoid the Pitfall of Missing Labels in Feature Selection: A Generative Model Gives the Answer ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Explainable Reinforcement Learning Through a Causal Lens ",
		"abstract": "Prevalent theories in cognitive science propose that humans understand and represent the knowledge of the world through causal relationships. In making sense of the world, we build causal models in our mind to encode cause-effect relations of events and use these to explain why new events happen. In this paper, we use causal models to derive causal explanations of behaviour of reinforcement learning agents. We present an approach that learns a structural causal model during reinforcement learning and encodes causal relationships between variables of interest. This model is then used to generate explanations of behaviour based on counterfactual analysis of the causal model. We report on a study with 120 participants who observe agents playing a real-time strategy game (Starcraft II) and then receive explanations of the agents' behaviour. We investigated: 1) participants' understanding gained by explanations through task prediction; 2) explanation satisfaction and 3) trust. Our results show that causal model explanations perform better on these measures compared to two other baseline explanation models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10958v2"
	},
	{
		"title": "Explanation vs Attention: A Two‐Player Game to Obtain Attention for VQA ",
		"abstract": "In this paper, we aim to obtain improved attention for a visual question answering (VQA) task. It is challenging to provide supervision for attention. An observation we make is that visual explanations as obtained through class activation mappings (specifically Grad-CAM) that are meant to explain the performance of various networks could form a means of supervision. However, as the distributions of attention maps and that of Grad-CAMs differ, it would not be suitable to directly use these as a form of supervision. Rather, we propose the use of a discriminator that aims to distinguish samples of visual explanation and attention maps. The use of adversarial training of the attention regions as a two-player game between attention and explanation serves to bring the distributions of attention maps and visual explanations closer. Significantly, we observe that providing such a means of supervision also results in attention maps that are more closely related to human attention resulting in a substantial improvement over baseline stacked attention network (SAN) models. It also results in a good improvement in rank correlation metric on the VQA task. This method can also be combined with recent MCB based methods and results in consistent improvement. We also provide comparisons with other means for learning distributions such as based on Correlation Alignment (Coral), Maximum Mean Discrepancy (MMD) and Mean Square Error (MSE) losses and observe that the adversarial loss outperforms the other forms of learning the attention maps. Visualization of the results also confirms our hypothesis that attention maps improve using this form of supervision.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08618v1"
	},
	{
		"title": "Enhancing Pointer Network for Sentence Ordering with Pairwise Ordering Predictions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Recurrent Model for Collective Entity Linking with Adaptive Features ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Inducing Relational Knowledge from BERT ",
		"abstract": "One of the most remarkable properties of word embeddings is the fact that they capture certain types of semantic and syntactic relationships. Recently, pre-trained language models such as BERT have achieved groundbreaking results across a wide range of Natural Language Processing tasks. However, it is unclear to what extent such models capture relational knowledge beyond what is already captured by standard word embeddings. To explore this question, we propose a methodology for distilling relational knowledge from a pre-trained language model. Starting from a few seed instances of a given relation, we first use a large text corpus to find sentences that are likely to express this relation. We then use a subset of these extracted sentences as templates. Finally, we fine-tune a language model to predict whether a given word pair is likely to be an instance of some relation, when given an instantiated template for that relation as input.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12753v1"
	},
	{
		"title": "Model Checking Temporal Epistemic Logic under Bounded Recall ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bounding Regret in Empirical Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Parameterized Algorithms for Finding a Collective Set of Items ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Exchangeable Generative Models with Flow Scans ",
		"abstract": "In this work, we develop a new approach to generative density estimation for exchangeable, non-i.i.d. data. The proposed framework, FlowScan, combines invertible flow transformations with a sorted scan to flexibly model the data while preserving exchangeability. Unlike most existing methods, FlowScan exploits the intradependencies within sets to learn both global and local structure. FlowScan represents the first approach that is able to apply sequential methods to exchangeable density estimation without resorting to averaging over all possible permutations. We achieve new state-of-the-art performance on point cloud and image set modeling.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.01967v3"
	},
	{
		"title": "AUC Optimization with a Reject Option ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ElGolog: A High‐Level Programming Language with Memory of the Execution History ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Latent Emotion Memory for Multi‐label Emotion Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Diversified Bayesian Nonnegative Matrix Factorization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Large‐scale Dataset for Argument Quality Ranking: Construction and Analysis ",
		"abstract": "Identifying the quality of free-text arguments has become an important task in the rapidly expanding field of computational argumentation. In this work, we explore the challenging task of argument quality ranking. To this end, we created a corpus of 30,497 arguments carefully annotated for point-wise quality, released as part of this work. To the best of our knowledge, this is the largest dataset annotated for point-wise argument quality, larger by a factor of five than previously released datasets. Moreover, we address the core issue of inducing a labeled score from crowd annotations by performing a comprehensive evaluation of different approaches to this problem. In addition, we analyze the quality dimensions that characterize this dataset. Finally, we present a neural method for argument quality ranking, which outperforms several baselines on our own dataset, as well as previous methods published for another dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11408v1"
	},
	{
		"title": "Seq2Sick: Evaluating the Robustness of Sequence‐to‐Sequence Models with Adversarial Examples ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Working Memory‐Driven Neural Networks with a Novel Knowledge Enhancement Paradigm for Implicit Discourse Relation Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CASTER: Predicting Drug Interactions with Chemical Substructure Representation ",
		"abstract": "Adverse drug-drug interactions (DDIs) remain a leading cause of morbidity and mortality. Identifying potential DDIs during the drug design process is critical for patients and society. Although several computational models have been proposed for DDI prediction, there are still limitations: (1) specialized design of drug representation for DDI predictions is lacking; (2) predictions are based on limited labelled data and do not generalize well to unseen drugs or DDIs; and (3) models are characterized by a large number of parameters, thus are hard to interpret. In this work, we develop a ChemicAl SubstrucTurE Representation (CASTER) framework that predicts DDIs given chemical structures of drugs.CASTER aims to mitigate these limitations via (1) a sequential pattern mining module rooted in the DDI mechanism to efficiently characterize functional sub-structures of drugs; (2) an auto-encoding module that leverages both labelled and unlabelled chemical structure data to improve predictive accuracy and generalizability; and (3) a dictionary learning module that explains the prediction via a small set of coefficients which measure the relevance of each input sub-structures to the DDI outcome. We evaluated CASTER on two real-world DDI datasets and showed that it performed better than state-of-the-art baselines and provided interpretable predictions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06446v2"
	},
	{
		"title": "K‐BERT: Enabling Language Representation With Knowledge Graph ",
		"abstract": "Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by equipped with a KG without pre-training by-self because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07606v1"
	},
	{
		"title": "Interpretable rumor detection in microblogs by attending to user interactions ",
		"abstract": "We address rumor detection by learning to differentiate between the community's response to real and fake claims in microblogs. Existing state-of-the-art models are based on tree models that model conversational trees. However, in social media, a user posting a reply might be replying to the entire thread rather than to a specific user. We propose a post-level attention model (PLAN) to model long distance interactions between tweets with the multi-head attention mechanism in a transformer network. We investigated variants of this model: (1) a structure aware self-attention model (StA-PLAN) that incorporates tree structure information in the transformer network, and (2) a hierarchical token and post-level attention model (StA-HiTPLAN) that learns a sentence representation with token-level self-attention. To the best of our knowledge, we are the first to evaluate our models on two rumor detection data sets: the PHEME data set as well as the Twitter15 and Twitter16 data sets. We show that our best models outperform current state-of-the-art models for both data sets. Moreover, the attention mechanism allows us to explain rumor detection predictions at both token-level and post-level.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.10667v1"
	},
	{
		"title": "Multi‐Question Learning for Visual Question Answering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TRENDNERT: A Benchmark for Trend and Downtrend Detection in a Scientific Domain ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Variational Metric Scaling for Metric‐Based Meta‐Learning ",
		"abstract": "Metric-based meta-learning has attracted a lot of attention due to its effectiveness and efficiency in few-shot learning. Recent studies show that metric scaling plays a crucial role in the performance of metric-based meta-learning algorithms. However, there still lacks a principled method for learning the metric scaling parameter automatically. In this paper, we recast metric-based meta-learning from a Bayesian perspective and develop a variational metric scaling framework for learning a proper metric scaling parameter. Firstly, we propose a stochastic variational method to learn a single global scaling parameter. To better fit the embedding space to a given data distribution, we extend our method to learn a dimensional scaling vector to transform the embedding space. Furthermore, to learn task-specific embeddings, we generate task-dependent dimensional scaling vectors with amortized variational inference. Our method is end-to-end without any pre-training and can be used as a simple plug-and-play module for existing metric-based meta-algorithms. Experiments on mini-ImageNet show that our methods can be used to consistently improve the performance of existing metric-based meta-algorithms including prototypical networks and TADAM. The source code can be downloaded from https://github.com/jiaxinchen666/variational-scaling.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11809v2"
	},
	{
		"title": "MIMAMO Net: Integrating Micro‐ and Macro‐motion for Video Emotion Recognition ",
		"abstract": "Spatial-temporal feature learning is of vital importance for video emotion recognition. Previous deep network structures often focused on macro-motion which extends over long time scales, e.g., on the order of seconds. We believe integrating structures capturing information about both micro- and macro-motion will benefit emotion prediction, because human perceive both micro- and macro-expressions. In this paper, we propose to combine micro- and macro-motion features to improve video emotion recognition with a two-stream recurrent network, named MIMAMO (Micro-Macro-Motion) Net. Specifically, smaller and shorter micro-motions are analyzed by a two-stream network, while larger and more sustained macro-motions can be well captured by a subsequent recurrent network. Assigning specific interpretations to the roles of different parts of the network enables us to make choice of parameters based on prior knowledge: choices that turn out to be optimal. One of the important innovations in our model is the use of interframe phase differences rather than optical flow as input to the temporal stream. Compared with the optical flow, phase differences require less computation and are more robust to illumination changes. Our proposed network achieves state of the art performance on two video emotion datasets, the OMG emotion dataset and the Aff-Wild dataset. The most significant gains are for arousal prediction, for which motion information is intuitively more informative. Source code is available at https://github.com/wtomin/MIMAMO-Net.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09784v1"
	},
	{
		"title": "Attention‐guide Walk Model in Heterogeneous Information Network for Multi‐style Recommendation Explanation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "The Efficiency of Human Cognition Reflects Planned Information Processing ",
		"abstract": "Planning is useful. It lets people take actions that have desirable long-term consequences. But, planning is hard. It requires thinking about consequences, which consumes limited computational and cognitive resources. Thus, people should plan their actions, but they should also be smart about how they deploy resources used for planning their actions. Put another way, people should also \"plan their plans\". Here, we formulate this aspect of planning as a meta-reasoning problem and formalize it in terms of a recursive Bellman objective that incorporates both task rewards and information-theoretic planning costs. Our account makes quantitative predictions about how people should plan and meta-plan as a function of the overall structure of a task, which we test in two experiments with human participants. We find that people's reaction times reflect a planned use of information processing, consistent with our account. This formulation of planning to plan provides new insight into the function of hierarchical planning, state abstraction, and cognitive control in both humans and machines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.05769v1"
	},
	{
		"title": "Fast and Deep Graph Neural Networks ",
		"abstract": "We address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (implemented through a recurrent neural network), and leverages a deep architectural organization of the recurrent units. Efficiency is gained by many aspects, including the use of small and very sparse networks, where the weights of the recurrent units are left untrained under the stability condition introduced in this work. This can be viewed as a way to study the intrinsic power of the architecture of a deep GNN, and also to provide insights for the set-up of more complex fully-trained models. Through experimental results, we show that even without training of the recurrent connections, the architecture of small deep GNN is surprisingly able to achieve or improve the state-of-the-art performance on a significant set of tasks in the field of graphs classification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08941v1"
	},
	{
		"title": "Planning with Abstract Learned Models While Learning Transferable Subtasks ",
		"abstract": "We introduce an algorithm for model-based hierarchical reinforcement learning to acquire self-contained transition and reward models suitable for probabilistic planning at multiple levels of abstraction. We call this framework Planning with Abstract Learned Models (PALM). By representing subtasks symbolically using a new formal structure, the lifted abstract Markov decision process (L-AMDP), PALM learns models that are independent and modular. Through our experiments, we show how PALM integrates planning and execution, facilitating a rapid and efficient learning of abstract, hierarchical models. We also demonstrate the increased potential for learned models to be transferred to new and related tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07544v2"
	},
	{
		"title": "Collaborative Sampling in Generative Adversarial Networks  ",
		"abstract": "The standard practice in Generative Adversarial Networks (GANs) discards the discriminator during sampling. However, this sampling method loses valuable information learned by the discriminator regarding the data distribution. In this work, we propose a collaborative sampling scheme between the generator and the discriminator for improved data generation. Guided by the discriminator, our approach refines the generated samples through gradient-based updates at a particular layer of the generator, shifting the generator distribution closer to the real data distribution. Additionally, we present a practical discriminator shaping method that can smoothen the loss landscape provided by the discriminator for effective sample refinement. Through extensive experiments on synthetic and image datasets, we demonstrate that our proposed method can improve generated samples both quantitatively and qualitatively, offering a new degree of freedom in GAN sampling.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.00813v3"
	},
	{
		"title": "Deep Spiking Delayed Feedback Reservoirs and Its Application in Spectrum Sensing of MIMO‐OFDM Dynamic Spectrum Sharing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ECGadv: Generating Adversarial Electrocardiogram to Misguide Arrhythmia Classification System ",
		"abstract": "Deep neural networks (DNNs)-powered Electrocardiogram (ECG) diagnosis systems recently achieve promising progress to take over tedious examinations by cardiologists. However, their vulnerability to adversarial attacks still lack comprehensive investigation. The existing attacks in image domain could not be directly applicable due to the distinct properties of ECGs in visualization and dynamic properties. Thus, this paper takes a step to thoroughly explore adversarial attacks on the DNN-powered ECG diagnosis system. We analyze the properties of ECGs to design effective attacks schemes under two attacks models respectively. Our results demonstrate the blind spots of DNN-powered diagnosis systems under adversarial attacks, which calls attention to adequate countermeasures.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.03808v4"
	},
	{
		"title": "Adaptive Greedy Versus Non‐adaptive Greedy for Influence Maximization ",
		"abstract": "We consider the \\emph{adaptive influence maximization problem}: given a network and a budget $k$, iteratively select $k$ seeds in the network to maximize the expected number of adopters. In the \\emph{full-adoption feedback model}, after selecting each seed, the seed-picker observes all the resulting adoptions. In the \\emph{myopic feedback model}, the seed-picker only observes whether each neighbor of the chosen seed adopts. Motivated by the extreme success of greedy-based algorithms/heuristics for influence maximization, we propose the concept of \\emph{greedy adaptivity gap}, which compares the performance of the adaptive greedy algorithm to its non-adaptive counterpart. Our first result shows that, for submodular influence maximization, the adaptive greedy algorithm can perform up to a $(1-1/e)$-fraction worse than the non-adaptive greedy algorithm, and that this ratio is tight. More specifically, on one side we provide examples where the performance of the adaptive greedy algorithm is only a $(1-1/e)$ fraction of the performance of the non-adaptive greedy algorithm in four settings: for both feedback models and both the \\emph{independent cascade model} and the \\emph{linear threshold model}. On the other side, we prove that in any submodular cascade, the adaptive greedy algorithm always outputs a $(1-1/e)$-approximation to the expected number of adoptions in the optimal non-adaptive seed choice. Our second result shows that, for the general submodular cascade model with full-adoption feedback, the adaptive greedy algorithm can outperform the non-adaptive greedy algorithm by an unbounded factor. Finally, we propose a risk-free variant of the adaptive greedy algorithm that always performs no worse than the non-adaptive greedy algorithm.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08164v1"
	},
	{
		"title": "Federated Patient Hashing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Online Planner Selection with Graph Neural Networks and Adaptive Scheduling ",
		"abstract": "Automated planning is one of the foundational areas of AI. Since no single planner can work well for all tasks and domains, portfolio-based techniques have become increasingly popular in recent years. In particular, deep learning emerges as a promising methodology for online planner selection. Owing to the recent development of structural graph representations of planning tasks, we propose a graph neural network (GNN) approach to selecting candidate planners. GNNs are advantageous over a straightforward alternative, the convolutional neural networks, in that they are invariant to node permutations and that they incorporate node labels for better inference.   Additionally, for cost-optimal planning, we propose a two-stage adaptive scheduling method to further improve the likelihood that a given task is solved in time. The scheduler may switch at halftime to a different planner, conditioned on the observed performance of the first one. Experimental results validate the effectiveness of the proposed method against strong baselines, both deep learning and non-deep learning based.   The code is available at \\url{https://github.com/matenure/GNN_planner}.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1811.00210v4"
	},
	{
		"title": "Stable Learning via Sample Reweighting ",
		"abstract": "We consider the problem of learning linear prediction models with model misspecification bias. In such case, the collinearity among input variables may inflate the error of parameter estimation, resulting in instability of prediction results when training and test distributions do not match. In this paper we theoretically analyze this fundamental problem and propose a sample reweighting method that reduces collinearity among input variables. Our method can be seen as a pretreatment of data to improve the condition of design matrix, and it can then be combined with any standard learning method for parameter estimation and variable selection. Empirical studies on both simulation and real datasets demonstrate the effectiveness of our method in terms of more stable performance across different distributed data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12580v1"
	},
	{
		"title": "Motion‐Based Generator Model: Unsupervised Disentanglement of Appearance, Trackable and Intrackable Motions in Dynamic Patterns ",
		"abstract": "Dynamic patterns are characterized by complex spatial and motion patterns. Understanding dynamic patterns requires a disentangled representational model that separates the factorial components. A commonly used model for dynamic patterns is the state space model, where the state evolves over time according to a transition model and the state generates the observed image frames according to an emission model. To model the motions explicitly, it is natural for the model to be based on the motions or the displacement fields of the pixels. Thus in the emission model, we let the hidden state generate the displacement field, which warps the trackable component in the previous image frame to generate the next frame while adding a simultaneously emitted residual image to account for the change that cannot be explained by the deformation. The warping of the previous image is about the trackable part of the change of image frame, while the residual image is about the intrackable part of the image. We use a maximum likelihood algorithm to learn the model that iterates between inferring latent noise vectors that drive the transition model and updating the parameters given the inferred latent vectors. Meanwhile we adopt a regularization term to penalize the norms of the residual images to encourage the model to explain the change of image frames by trackable motion. Unlike existing methods on dynamic patterns, we learn our model in unsupervised setting without ground truth displacement fields. In addition, our model defines a notion of intrackability by the separation of warped component and residual component in each image frame. We show that our method can synthesize realistic dynamic pattern, and disentangling appearance, trackable and intrackable motions. The learned models are useful for motion transfer, and it is natural to adopt it to define and measure intrackability of a dynamic pattern.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11294v1"
	},
	{
		"title": "Synchronous Speech Recognition and Speech‐to‐Text Translation with Interactive Decoding ",
		"abstract": "Speech-to-text translation (ST), which translates source language speech into target language text, has attracted intensive attention in recent years. Compared to the traditional pipeline system, the end-to-end ST model has potential benefits of lower latency, smaller model size, and less error propagation. However, it is notoriously difficult to implement such a model without transcriptions as intermediate. Existing works generally apply multi-task learning to improve translation quality by jointly training end-to-end ST along with automatic speech recognition (ASR). However, different tasks in this method cannot utilize information from each other, which limits the improvement. Other works propose a two-stage model where the second model can use the hidden state from the first one, but its cascade manner greatly affects the efficiency of training and inference process. In this paper, we propose a novel interactive attention mechanism which enables ASR and ST to perform synchronously and interactively in a single model. Specifically, the generation of transcriptions and translations not only relies on its previous outputs but also the outputs predicted in the other task. Experiments on TED speech translation corpora have shown that our proposed model can outperform strong baselines on the quality of speech translation and achieve better speech recognition performances as well.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07240v1"
	},
	{
		"title": "Learning Cross‐Aligned Latent Embeddings for Zero‐Shot Cross‐Modal Retrieval ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Communicate Implicitly by Actions ",
		"abstract": "In situations where explicit communication is limited, human collaborators act by learning to: (i) infer meaning behind their partner's actions, and (ii) convey private information about the state to their partner implicitly through actions. The first component of this learning process has been well-studied in multi-agent systems, whereas the second --- which is equally crucial for successful collaboration --- has not. To mimic both components mentioned above, thereby completing the learning process, we introduce a novel algorithm: Policy Belief Learning (PBL). PBL uses a belief module to model the other agent's private information and a policy module to form a distribution over actions informed by the belief module. Furthermore, to encourage communication by actions, we propose a novel auxiliary reward which incentivizes one agent to help its partner to make correct inferences about its private information. The auxiliary reward for communication is integrated into the learning of the policy module. We evaluate our approach on a set of environments including a matrix game, particle environment and the non-competitive bidding problem from contract bridge. We show empirically that this auxiliary reward is effective and easy to generalize. These results demonstrate that our PBL algorithm can produce strong pairs of agents in collaborative games where explicit communication is disabled.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1810.04444v4"
	},
	{
		"title": "System Identification with Time‐Aware Neural Sequence Models ",
		"abstract": "Established recurrent neural networks are well-suited to solve a wide variety of prediction tasks involving discrete sequences. However, they do not perform as well in the task of dynamical system identification, when dealing with observations from continuous variables that are unevenly sampled in time, for example due to missing observations. We show how such neural sequence models can be adapted to deal with variable step sizes in a natural way. In particular, we introduce a time-aware and stationary extension of existing models (including the Gated Recurrent Unit) that allows them to deal with unevenly sampled system observations by adapting to the observation times, while facilitating higher-order temporal behavior. We discuss the properties and demonstrate the validity of the proposed approach, based on samples from two industrial input/output processes.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09431v1"
	},
	{
		"title": "Shapley Q‐value: A Local Reward Approach to Solve Global Reward Games ",
		"abstract": "Cooperative game is a critical research area in the multi-agent reinforcement learning (MARL). Global reward game is a subclass of cooperative games, where all agents aim to maximize the global reward. Credit assignment is an important problem studied in the global reward game. Most of previous works stood by the view of non-cooperative-game theoretical framework with the shared reward approach, i.e., each agent being assigned a shared global reward directly. This, however, may give each agent an inaccurate reward on its contribution to the group, which could cause inefficient learning. To deal with this problem, we i) introduce a cooperative-game theoretical framework called extended convex game (ECG) that is a superset of global reward game, and ii) propose a local reward approach called Shapley Q-value. Shapley Q-value is able to distribute the global reward, reflecting each agent's own contribution in contrast to the shared reward approach. Moreover, we derive an MARL algorithm called Shapley Q-value deep deterministic policy gradient (SQDDPG), using Shapley Q-value as the critic for each agent. We evaluate SQDDPG on Cooperative Navigation, Prey-and-Predator and Traffic Junction, compared with the state-of-the-art algorithms, e.g., MADDPG, COMA, Independent DDPG and Independent A2C. In the experiments, SQDDPG shows a significant improvement on the convergence rate. Finally, we plot Shapley Q-value and validate the property of fair credit assignment.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.05707v5"
	},
	{
		"title": "CONAN: Complementary Pattern Augmentation for Rare Disease Detection ",
		"abstract": "Rare diseases affect hundreds of millions of people worldwide but are hard to detect since they have extremely low prevalence rates (varying from 1/1,000 to 1/200,000 patients) and are massively underdiagnosed. How do we reliably detect rare diseases with such low prevalence rates? How to further leverage patients with possibly uncertain diagnosis to improve detection? In this paper, we propose a Complementary pattern Augmentation (CONAN) framework for rare disease detection. CONAN combines ideas from both adversarial training and max-margin classification. It first learns self-attentive and hierarchical embedding for patient pattern characterization. Then, we develop a complementary generative adversarial networks (GAN) model to generate candidate positive and negative samples from the uncertain patients by encouraging a max-margin between classes. In addition, CONAN has a disease detector that serves as the discriminator during the adversarial training for identifying rare diseases. We evaluated CONAN on two disease detection tasks. For low prevalence inflammatory bowel disease (IBD) detection, CONAN achieved .96 precision recall area under the curve (PR-AUC) and 50.1% relative improvement over best baseline. For rare disease idiopathic pulmonary fibrosis (IPF) detection, CONAN achieves .22 PR-AUC with 41.3% relative improvement over the best baseline.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.13232v1"
	},
	{
		"title": "Deep Mixed Effect Model using Gaussian Processes: A Personalized and Reliable Prediction for Healthcare ",
		"abstract": "We present a personalized and reliable prediction model for healthcare, which can provide individually tailored medical services such as diagnosis, disease treatment, and prevention. Our proposed framework targets at making personalized and reliable predictions from time-series data, such as Electronic Health Records (EHR), by modeling two complementary components: i) a shared component that captures global trend across diverse patients and ii) a patient-specific component that models idiosyncratic variability for each patient. To this end, we propose a composite model of a deep neural network to learn complex global trends from the large number of patients, and Gaussian Processes (GP) to probabilistically model individual time-series given relatively small number of visits per patient. We evaluate our model on diverse and heterogeneous tasks from EHR datasets and show practical advantages over standard time-series deep models such as pure Recurrent Neural Network (RNN).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1806.01551v3"
	},
	{
		"title": "JEC‐QA: A Legal‐Domain Question Answering Dataset ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Weighted Model Integration Distributions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Integrating Linguistic Knowledge to Sentence Paraphrase Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Unsupervised Binary Coding Networks for Multivariate Time Series Retrieval ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Compressed Self‐Attention for Deep Metric Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Robust Adversarial Objects against Deep Learning Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Communication Learning via Backpropagation in Discrete Channels with Unknown Noise ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "TextNAS: A Neural Architecture Search Space tailored for Text Representation ",
		"abstract": "Learning text representation is crucial for text classification and other language related tasks. There are a diverse set of text representation networks in the literature, and how to find the optimal one is a non-trivial problem. Recently, the emerging Neural Architecture Search (NAS) techniques have demonstrated good potential to solve the problem. Nevertheless, most of the existing works of NAS focus on the search algorithms and pay little attention to the search space. In this paper, we argue that the search space is also an important human prior to the success of NAS in different applications. Thus, we propose a novel search space tailored for text representation. Through automatic search, the discovered network architecture outperforms state-of-the-art models on various public datasets on text classification and natural language inference tasks. Furthermore, some of the design principles found in the automatic network agree well with human intuition.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10729v1"
	},
	{
		"title": "Learning to Interactively Learn and Assist ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ConCare: Personalized Clinical Feature Embedding via Capturing the Healthcare Context ",
		"abstract": "Predicting the patient's clinical outcome from the historical electronic medical records (EMR) is a fundamental research problem in medical informatics. Most deep learning-based solutions for EMR analysis concentrate on learning the clinical visit embedding and exploring the relations between visits. Although those works have shown superior performances in healthcare prediction, they fail to explore the personal characteristics during the clinical visits thoroughly. Moreover, existing works usually assume that the more recent record weights more in the prediction, but this assumption is not suitable for all conditions. In this paper, we propose ConCare to handle the irregular EMR data and extract feature interrelationship to perform individualized healthcare prediction. Our solution can embed the feature sequences separately by modeling the time-aware distribution. ConCare further improves the multi-head self-attention via the cross-head decorrelation, so that the inter-dependencies among dynamic features and static baseline information can be effectively captured to form the personal health context. Experimental results on two real-world EMR datasets demonstrate the effectiveness of ConCare. The medical findings extracted by ConCare are also empirically confirmed by human experts and medical literature.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12216v1"
	},
	{
		"title": "On Adaptivity in Information‐Constrained Online Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Parameterized Complexity of Envy‐Free Resource Allocation in Social Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reinforcement Learning based Meta‐path Discovery in Large‐scale Heterogeneous Information Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Proximity Preserving Binary Code Using Signed Graph‐Cut ",
		"abstract": "We introduce a binary embedding framework, called Proximity Preserving Code (PPC), which learns similarity and dissimilarity between data points to create a compact and affinity-preserving binary code. This code can be used to apply fast and memory-efficient approximation to nearest-neighbor searches. Our framework is flexible, enabling different proximity definitions between data points. In contrast to previous methods that extract binary codes based on unsigned graph partitioning, our system models the attractive and repulsive forces in the data by incorporating positive and negative graph weights. The proposed framework is shown to boil down to finding the minimal cut of a signed graph, a problem known to be NP-hard. We offer an efficient approximation and achieve superior results by constructing the code bit after bit. We show that the proposed approximation is superior to the commonly used spectral methods with respect to both accuracy and complexity. Thus, it is useful for many other problems that can be translated into signed graph cut.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01793v1"
	},
	{
		"title": "Multi‐source Distilling Domain Adaptation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Hypergraph Label Propagation Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Chain Length and CSPs Learnable with Few Queries ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "On the Parameterized Complexity of Clustering Incomplete Data into Subspaces of Small Rank ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cakewalk Sampling ",
		"abstract": "We study the task of finding good local optima in combinatorial optimization problems. Although combinatorial optimization is NP-hard in general, locally optimal solutions are frequently used in practice. Local search methods however typically converge to a limited set of optima that depend on their initialization. Sampling methods on the other hand can access any valid solution, and thus can be used either directly or alongside methods of the former type as a way for finding good local optima. Since the effectiveness of this strategy depends on the sampling distribution, we derive a robust learning algorithm that adapts sampling distributions towards good local optima of arbitrary objective functions. As a first use case, we empirically study the efficiency in which sampling methods can recover locally maximal cliques in undirected graphs. Not only do we show how our adaptive sampler outperforms related methods, we also show how it can even approach the performance of established clique algorithms. As a second use case, we consider how greedy algorithms can be combined with our adaptive sampler, and we demonstrate how this leads to superior performance in k-medoid clustering. Together, these findings suggest that our adaptive sampler can provide an effective strategy to combinatorial optimization problems that arise in practice.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1802.09030v2"
	},
	{
		"title": "Relation Extraction with Convolutional Network over Learnable Syntax‐Transport Graph ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Feature Variance Regularization:  A Simple Way to Improve the Generalizability of Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Particle Swarm Based Algorithm for Functional Distributed Constraint Optimization Problems ",
		"abstract": "Distributed Constraint Optimization Problems (DCOPs) are a widely studied constraint handling framework. The objective of a DCOP algorithm is to optimize a global objective function that can be described as the aggregation of a number of distributed constraint cost functions. In a DCOP, each of these functions is defined by a set of discrete variables. However, in many applications, such as target tracking or sleep scheduling in sensor networks, continuous valued variables are more suited than the discrete ones. Considering this, Functional DCOPs (F-DCOPs) have been proposed that is able to explicitly model a problem containing continuous variables. Nevertheless, the state-of-the-art F-DCOPs approaches experience onerous memory or computation overhead. To address this issue, we propose a new F-DCOP algorithm, namely Particle Swarm Based F-DCOP (PFD), which is inspired by a meta-heuristic, Particle Swarm Optimization (PSO). Although it has been successfully applied to many continuous optimization problems, the potential of PSO has not been utilized in F-DCOPs. To be exact, PFD devises a distributed method of solution construction while significantly reducing the computation and memory requirements. Moreover, we theoretically prove that PFD is an anytime algorithm. Finally, our empirical results indicate that PFD outperforms the state-of-the-art approaches in terms of solution quality and computation overhead.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.06168v1"
	},
	{
		"title": "Optimizing Reachability Sets in Temporal Graphs by Delaying ",
		"abstract": "A temporal graph is a dynamic graph where every edge is assigned a set of integer time labels that indicate at which discrete time step the edge is available. In this paper, we study how changes of the time labels, corresponding to delays on the availability of the edges, affect the reachability sets from given sources. The questions about reachability sets are motivated by numerous applications of temporal graphs in network epidemiology, which aim to minimise the spread of infection, and scheduling problems in supply networks in manufacturing with the opposite objectives of maximising coverage and productivity. We introduce control mechanisms for reachability sets that are based on two natural operations of delaying. The first operation, termed merging, is global and batches together consecutive time labels into a single time label in the whole network simultaneously. This corresponds to postponing all events until a particular time. The second, imposes independent delays on the time labels of every edge of the graph. We provide a thorough investigation of the computational complexity of different objectives related to reachability sets when these operations are used. For the merging operation, i.e. global lockdown effect, we prove NP-hardness results for several minimization and maximization reachability objectives, even for very simple graph structures. For the second operation, independent delays, we prove that the minimization problems are NP-hard when the number of allowed delays is bounded. We complement this with a polynomial-time algorithm for minimising the reachability set in case of unbounded delays.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.05875v2"
	},
	{
		"title": "CAG: A Real‐time Low‐cost Improved‐Robustness High‐transferabilitiy Content‐aware Adversarial Attack Generator ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Integrating Overlapping Datasets Using Bivariate Causal Discovery ",
		"abstract": "Causal knowledge is vital for effective reasoning in science, as causal relations, unlike correlations, allow one to reason about the outcomes of interventions. Algorithms that can discover causal relations from observational data are based on the assumption that all variables have been jointly measured in a single dataset. In many cases this assumption fails. Previous approaches to overcoming this shortcoming devised algorithms that returned all joint causal structures consistent with the conditional independence information contained in each individual dataset. But, as conditional independence tests only determine causal structure up to Markov equivalence, the number of consistent joint structures returned by these approaches can be quite large. The last decade has seen the development of elegant algorithms for discovering causal relations beyond conditional independence, which can distinguish among Markov equivalent structures. In this work we adapt and extend these so-called bivariate causal discovery algorithms to the problem of learning consistent causal structures from multiple datasets with overlapping variables belonging to the same generating process, providing a sound and complete algorithm that outperforms previous approaches on synthetic and real data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.11356v2"
	},
	{
		"title": "Using approximation within Constraint Programming to solve the Parallel Machine Scheduling Problem with Additional Unit Resources ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Temporal Pyramid Recurrent Neural Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Go From the General to the Particular: Multi‐Domain Translation with Domain Transformation Networks ",
		"abstract": "The key challenge of multi-domain translation lies in simultaneously encoding both the general knowledge shared across domains and the particular knowledge distinctive to each domain in a unified model. Previous work shows that the standard neural machine translation (NMT) model, trained on mixed-domain data, generally captures the general knowledge, but misses the domain-specific knowledge. In response to this problem, we augment NMT model with additional domain transformation networks to transform the general representations to domain-specific representations, which are subsequently fed to the NMT decoder. To guarantee the knowledge transformation, we also propose two complementary supervision signals by leveraging the power of knowledge distillation and adversarial learning. Experimental results on several language pairs, covering both balanced and unbalanced multi-domain translation, demonstrate the effectiveness and universality of the proposed approach. Encouragingly, the proposed unified model achieves comparable results with the fine-tuning approach that requires multiple models to preserve the particular knowledge. Further analyses reveal that the domain transformation networks successfully capture the domain-specific knowledge as expected.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09912v1"
	},
	{
		"title": "Generalization Error Bounds of Gradient Descent for Learning Over‐parameterized Deep ReLU Networks ",
		"abstract": "Empirical studies show that gradient-based methods can learn deep neural networks (DNNs) with very good generalization performance in the over-parameterization regime, where DNNs can easily fit a random labeling of the training data. Very recently, a line of work explains in theory that with over-parameterization and proper random initialization, gradient-based methods can find the global minima of the training loss for DNNs. However, existing generalization error bounds are unable to explain the good generalization performance of over-parameterized DNNs. The major limitation of most existing generalization bounds is that they are based on uniform convergence and are independent of the training algorithm. In this work, we derive an algorithm-dependent generalization error bound for deep ReLU networks, and show that under certain assumptions on the data distribution, gradient descent (GD) with proper random initialization is able to train a sufficiently over-parameterized DNN to achieve arbitrarily small generalization error. Our work sheds light on explaining the good generalization performance of over-parameterized deep neural networks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.01384v4"
	},
	{
		"title": "Relation Extraction Exploiting Full Dependency Forests ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "End‐to‐End Game‐Focused Learning of Adversary Behavior in Security Games ",
		"abstract": "Stackelberg security games are a critical tool for maximizing the utility of limited defense resources to protect important targets from an intelligent adversary. Motivated by green security, where the defender may only observe an adversary's response to defense on a limited set of targets, we study the problem of learning a defense that generalizes well to a new set of targets with novel feature values and combinations. Traditionally, this problem has been addressed via a two-stage approach where an adversary model is trained to maximize predictive accuracy without considering the defender's optimization problem. We develop an end-to-end game-focused approach, where the adversary model is trained to maximize a surrogate for the defender's expected utility. We show both in theory and experimental results that our game-focused approach achieves higher defender expected utility than the two-stage alternative when there is limited data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.00958v2"
	},
	{
		"title": "PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for Real‐time Execution on Mobile Device ",
		"abstract": "Model compression techniques on Deep Neural Network (DNN) have been widely acknowledged as an effective way to achieve acceleration on a variety of platforms, and DNN weight pruning is a straightforward and effective method. There are currently two mainstreams of pruning methods representing two extremes of pruning regularity: non-structured, fine-grained pruning can achieve high sparsity and accuracy, but is not hardware friendly; structured, coarse-grained pruning exploits hardware-efficient structures in pruning, but suffers from accuracy drop when the pruning rate is high. In this paper, we introduce PCONV, comprising a new sparsity dimension, -- fine-grained pruning patterns inside the coarse-grained structures. PCONV comprises two types of sparsities, Sparse Convolution Patterns (SCP) which is generated from intra-convolution kernel pruning and connectivity sparsity generated from inter-convolution kernel pruning. Essentially, SCP enhances accuracy due to its special vision properties, and connectivity sparsity increases pruning rate while maintaining balanced workload on filter computation. To deploy PCONV, we develop a novel compiler-assisted DNN inference framework and execute PCONV models in real-time without accuracy compromise, which cannot be achieved in prior work. Our experimental results show that, PCONV outperforms three state-of-art end-to-end DNN frameworks, TensorFlow-Lite, TVM, and Alibaba Mobile Neural Network with speedup up to 39.2x, 11.4x, and 6.3x, respectively, with no accuracy loss. Mobile devices can achieve real-time inference on large-scale DNNs.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05073v4"
	},
	{
		"title": "A Graph Auto‐Encoder for Haplotype Assembly and Viral Quasispecies Reconstruction ",
		"abstract": "Reconstructing components of a genomic mixture from data obtained by means of DNA sequencing is a challenging problem encountered in a variety of applications including single individual haplotyping and studies of viral communities. High-throughput DNA sequencing platforms oversample mixture components to provide massive amounts of reads whose relative positions can be determined by mapping the reads to a known reference genome; assembly of the components, however, requires discovery of the reads' origin -- an NP-hard problem that the existing methods struggle to solve with the required level of accuracy. In this paper, we present a learning framework based on a graph auto-encoder designed to exploit structural properties of sequencing data. The algorithm is a neural network which essentially trains to ignore sequencing errors and infers the posteriori probabilities of the origin of sequencing reads. Mixture components are then reconstructed by finding consensus of the reads determined to originate from the same genomic component. Results on realistic synthetic as well as experimental data demonstrate that the proposed framework reliably assembles haplotypes and reconstructs viral communities, often significantly outperforming state-of-the-art techniques.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05316v1"
	},
	{
		"title": "Robust Named Entity Recognition with Truecasing Pretraining ",
		"abstract": "Although modern named entity recognition (NER) systems show impressive performance on standard datasets, they perform poorly when presented with noisy data. In particular, capitalization is a strong signal for entities in many languages, and even state of the art models overfit to this feature, with drastically lower performance on uncapitalized text. In this work, we address the problem of robustness of NER systems in data with noisy or uncertain casing, using a pretraining objective that predicts casing in text, or a truecaser, leveraging unlabeled data. The pretrained truecaser is combined with a standard BiLSTM-CRF model for NER by appending output distributions to character embeddings. In experiments over several datasets of varying domain and casing quality, we show that our new model improves performance in uncased text, even adding value to uncased BERT embeddings. Our method achieves a new state of the art on the WNUT17 shared task dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.07095v1"
	},
	{
		"title": "An Efficient Algorithm for Counting Markov Equivalent DAGs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reshaping Diverse Planning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fair Division Through Information Withholding ",
		"abstract": "Envy-freeness up to one good (EF1) is a well-studied fairness notion for indivisible goods that addresses pairwise envy by the removal of at most one good. In the worst case, each pair of agents might require the (hypothetical) removal of a different good, resulting in a weak aggregate guarantee. We study allocations that are nearly envy-free in aggregate, and define a novel fairness notion based on information withholding. Under this notion, an agent can withhold (or hide) some of the goods in its bundle and reveal the remaining goods to the other agents. We observe that in practice, envy-freeness can be achieved by withholding only a small number of goods overall. We show that finding allocations that withhold an optimal number of goods is computationally hard even for highly restricted classes of valuations. In contrast to the worst-case results, our experiments on synthetic and real-world preference data show that existing algorithms for finding EF1 allocations withhold close-to-optimal number of goods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.02583v3"
	},
	{
		"title": "Top‐Quality Planning: Finding Practically Useful Sets of Best Plans ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Non‐local U‐Nets for Biomedical Image Segmentation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adaptive Convolutional ReLUs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Polynomial Matrix Completion for Missing Data Imputation and Transductive Learning ",
		"abstract": "This paper develops new methods to recover the missing entries of a high-rank or even full-rank matrix when the intrinsic dimension of the data is low compared to the ambient dimension. Specifically, we assume that the columns of a matrix are generated by polynomials acting on a low-dimensional intrinsic variable, and wish to recover the missing entries under this assumption. We show that we can identify the complete matrix of minimum intrinsic dimension by minimizing the rank of the matrix in a high dimensional feature space. We develop a new formulation of the resulting problem using the kernel trick together with a new relaxation of the rank objective, and propose an efficient optimization method. We also show how to use our methods to complete data drawn from multiple nonlinear manifolds. Comparative studies on synthetic data, subspace clustering with missing data, motion capture data recovery, and transductive learning verify the superiority of our methods over the state-of-the-art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06989v1"
	},
	{
		"title": "Perpetual Voting: Fairness in Long‐Term Decision Making ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generalized Hidden Parameter MDPs: Transferable Model‐Based RL in a Handful of Trials ",
		"abstract": "There is broad interest in creating RL agents that can solve many (related) tasks and adapt to new tasks and environments after initial training. Model-based RL leverages learned surrogate models that describe dynamics and rewards of individual tasks, such that planning in a good surrogate can lead to good control of the true system. Rather than solving each task individually from scratch, hierarchical models can exploit the fact that tasks are often related by (unobserved) causal factors of variation in order to achieve efficient generalization, as in learning how the mass of an item affects the force required to lift it can generalize to previously unobserved masses. We propose Generalized Hidden Parameter MDPs (GHP-MDPs) that describe a family of MDPs where both dynamics and reward can change as a function of hidden parameters that vary across tasks. The GHP-MDP augments model-based RL with latent variables that capture these hidden parameters, facilitating transfer across tasks. We also explore a variant of the model that incorporates explicit latent structure mirroring the causal factors of variation across tasks (for instance: agent properties, environmental factors, and goals). We experimentally demonstrate state-of-the-art performance and sample-efficiency on a new challenging MuJoCo task using reward and dynamics latent spaces, while beating a previous state-of-the-art baseline with $>10\\times$ less data. Using test-time inference of the latent variables, our approach generalizes in a single episode to novel combinations of dynamics and reward, and to novel rewards.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03072v1"
	},
	{
		"title": "Pursuit of Low‐Rank Models of Time‐Varying Matrices Robust to Sparse and Measurement Noise ",
		"abstract": "In tracking of time-varying low-rank models of time-varying matrices, we present a method robust to both uniformly-distributed measurement noise and arbitrarily-distributed ``sparse'' noise. In theory, we bound the tracking error. In practice, our use of randomised coordinate descent is scalable and allows for encouraging results on changedetection net, a benchmark.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1809.03550v3"
	},
	{
		"title": "Shallow Feature based Dense Attention Network for Crowd Counting ",
		"abstract": "While the performance of crowd counting via deep learning has been improved dramatically in the recent years, it remains an ingrained problem due to cluttered backgrounds and varying scales of people within an image. In this paper, we propose a Shallow feature based Dense Attention Network (SDANet) for crowd counting from still images, which diminishes the impact of backgrounds via involving a shallow feature based attention model, and meanwhile, captures multi-scale information via densely connecting hierarchical image features. Specifically, inspired by the observation that backgrounds and human crowds generally have noticeably different responses in shallow features, we decide to build our attention model upon shallow-feature maps, which results in accurate background-pixel detection. Moreover, considering that the most representative features of people across different scales can appear in different layers of a feature extraction network, to better keep them all, we propose to densely connect hierarchical image features of different layers and subsequently encode them for estimating crowd density. Experimental results on three benchmark datasets clearly demonstrate the superiority of SDANet when dealing with different scenarios. Particularly, on the challenging UCF CC 50 dataset, our method outperforms other existing methods by a large margin, as is evident from a remarkable 11.9% Mean Absolute Error (MAE) drop of our SDANet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.09853v1"
	},
	{
		"title": "A General Approach to Fairness with Optimal Transport ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Inﬁnite ShapeOdds: Nonparametric Bayesian Models for Shape Representations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A  Multi‐Channel Neural Graphical Event Model with Negative Evidence ",
		"abstract": "Event datasets are sequences of events of various types occurring irregularly over the time-line, and they are increasingly prevalent in numerous domains. Existing work for modeling events using conditional intensities rely on either using some underlying parametric form to capture historical dependencies, or on non-parametric models that focus primarily on tasks such as prediction. We propose a non-parametric deep neural network approach in order to estimate the underlying intensity functions. We use a novel multi-channel RNN that optimally reinforces the negative evidence of no observable events with the introduction of fake event epochs within each consecutive inter-event interval. We evaluate our method against state-of-the-art baselines on model fitting tasks as gauged by log-likelihood. Through experiments on both synthetic and real-world datasets, we find that our proposed approach outperforms existing baselines on most of the datasets studied.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.09575v1"
	},
	{
		"title": "Generalized Transportability: Synthesis of Experiments from Heterogeneous Domains ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FourierSAT: A Fourier Expansion‐Based Algebraic Framework for Solving Hybrid Boolean Constraints ",
		"abstract": "The Boolean SATisfiability problem (SAT) is of central importance in computer science. Although SAT is known to be NP-complete, progress on the engineering side, especially that of Conflict-Driven Clause Learning (CDCL) and Local Search SAT solvers, has been remarkable. Yet, while SAT solvers aimed at solving industrial-scale benchmarks in Conjunctive Normal Form (CNF) have become quite mature, SAT solvers that are effective on other types of constraints, e.g., cardinality constraints and XORs, are less well studied; a general approach to handling non-CNF constraints is still lacking. In addition, previous work indicated that for specific classes of benchmarks, the running time of extant SAT solvers depends heavily on properties of the formula and details of encoding, instead of the scale of the benchmarks, which adds uncertainty to expectations of running time.   To address the issues above, we design FourierSAT, an incomplete SAT solver based on Fourier analysis of Boolean functions, a technique to represent Boolean functions by multilinear polynomials. By such a reduction to continuous optimization, we propose an algebraic framework for solving systems consisting of different types of constraints. The idea is to leverage gradient information to guide the search process in the direction of local improvements. Empirical results demonstrate that FourierSAT is more robust than other solvers on certain classes of benchmarks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01032v2"
	},
	{
		"title": "Tensor FISTA‐Net for Real‐Time Snapshot Compressive Imaging ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A New Framework for Online Testing of Heterogeneous Treatment Effect ",
		"abstract": "We propose a new framework for online testing of heterogeneous treatment effects. The proposed test, named sequential score test (SST), is able to control type I error under continuous monitoring and detect multi-dimensional heterogeneous treatment effects. We provide an online p-value calculation for SST, making it convenient for continuous monitoring, and extend our tests to online multiple testing settings by controlling the false discovery rate. We examine the empirical performance of the proposed tests and compare them with a state-of-art online test, named mSPRT using simulations and a real data. The results show that our proposed test controls type I error at any time, has higher detection power and allows quick inference on online A/B testing.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03277v1"
	},
	{
		"title": "Estimating Causal Effects Using Weighting‐Based Estimators ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Nonlinear Mixup: Out‐Of‐Manifold Data Augmentation for Text Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Linear Bandits with Feature Feedback ",
		"abstract": "This paper explores a new form of the linear bandit problem in which the algorithm receives the usual stochastic rewards as well as stochastic feedback about which features are relevant to the rewards, the latter feedback being the novel aspect. The focus of this paper is the development of new theory and algorithms for linear bandits with feature feedback. We show that linear bandits with feature feedback can achieve regret over time horizon $T$ that scales like $k\\sqrt{T}$, without prior knowledge of which features are relevant nor the number $k$ of relevant features. In comparison, the regret of traditional linear bandits is $d\\sqrt{T}$, where $d$ is the total number of (relevant and irrelevant) features, so the improvement can be dramatic if $k\\ll d$. The computational complexity of the new algorithm is proportional to $k$ rather than $d$, making it much more suitable for real-world applications compared to traditional linear bandits. We demonstrate the performance of the new algorithm with synthetic and real human-labeled data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.03705v2"
	},
	{
		"title": "Deciding the Loosely Guarded Fragment and Querying Its Horn Fragment Using Resolution ",
		"abstract": "We consider the following query answering problem: Given a Boolean conjunctive query and a theory in the Horn loosely guarded fragment, the aim is to determine whether the query is entailed by the theory. In this paper, we present a resolution decision procedure for the loosely guarded fragment, and use such a procedure to answer Boolean conjunctive queries against the Horn loosely guarded fragment. The Horn loosely guarded fragment subsumes classes of rules that are prevalent in ontology-based query answering, such as Horn ALCHOI and guarded existential rules. Additionally, we identify star queries and cloud queries, which using our procedure, can be answered against the loosely guarded fragment.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.03829v1"
	},
	{
		"title": "Deep Neural Network Approximated Dynamic Programming for Combinatorial Optimization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Just Add Functions: A Neural‐Symbolic Language Model ",
		"abstract": "Neural network language models (NNLMs) have achieved ever-improving accuracy due to more sophisticated architectures and increasing amounts of training data. However, the inductive bias of these models (formed by the distributional hypothesis of language), while ideally suited to modeling most running text, results in key limitations for today's models. In particular, the models often struggle to learn certain spatial, temporal, or quantitative relationships, which are commonplace in text and are second-nature for human readers. Yet, in many cases, these relationships can be encoded with simple mathematical or logical expressions. How can we augment today's neural models with such encodings?   In this paper, we propose a general methodology to enhance the inductive bias of NNLMs by incorporating simple functions into a neural architecture to form a hierarchical neural-symbolic language model (NSLM). These functions explicitly encode symbolic deterministic relationships to form probability distributions over words. We explore the effectiveness of this approach on numbers and geographic locations, and show that NSLMs significantly reduce perplexity in small-corpus language modeling, and that the performance improvement persists for rare tokens even on much larger corpora. The approach is simple and general, and we discuss how it can be applied to other word classes beyond numbers and geography.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05421v1"
	},
	{
		"title": "A Cardinal Improvement to Pseudo‐Boolean Solving ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Differentially Private and Fair Classification via Calibrated Functional Mechanism ",
		"abstract": "Machine learning is increasingly becoming a powerful tool to make decisions in a wide variety of applications, such as medical diagnosis and autonomous driving. Privacy concerns related to the training data and unfair behaviors of some decisions with regard to certain attributes (e.g., sex, race) are becoming more critical. Thus, constructing a fair machine learning model while simultaneously providing privacy protection becomes a challenging problem. In this paper, we focus on the design of classification model with fairness and differential privacy guarantees by jointly combining functional mechanism and decision boundary fairness. In order to enforce $\\epsilon$-differential privacy and fairness, we leverage the functional mechanism to add different amounts of Laplace noise regarding different attributes to the polynomial coefficients of the objective function in consideration of fairness constraint. We further propose an utility-enhancement scheme, called relaxed functional mechanism by adding Gaussian noise instead of Laplace noise, hence achieving $(\\epsilon,\\delta)$-differential privacy. Based on the relaxed functional mechanism, we can design $(\\epsilon,\\delta)$-differentially private and fair classification model. Moreover, our theoretical analysis and empirical results demonstrate that our two approaches achieve both fairness and differential privacy while preserving good utility and outperform the state-of-the-art algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.04958v2"
	},
	{
		"title": "Improved filtering for the Euclidean Traveling Salesperson Problem in CLP(FD) ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Learning‐powered Iterative Combinatorial Auctions ",
		"abstract": "In this paper, we study the design of deep learning-powered iterative combinatorial auctions (ICAs). We build on prior work where preference elicitation was done via kernelized support vector regressions (SVRs). However, the SVR-based approach has limitations because it requires solving a machine learning (ML)-based winner determination problem (WDP). With expressive kernels (like gaussians), the ML-based WDP cannot be solved for large domains. While linear or quadratic kernels have better computational scalability, these kernels have limited expressiveness. In this work, we address these shortcomings by using deep neural networks (DNNs) instead of SVRs. We first show how the DNN-based WDP can be reformulated into a mixed integer program (MIP). Second, we experimentally compare the prediction performance of DNNs against SVRs. Third, we present experimental evaluations in two medium-sized domains which show that even ICAs based on relatively small-sized DNNs lead to higher economic efficiency than ICAs based on kernelized SVRs. Finally, we show that our DNN-powered ICA also scales well to very large CA domains.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.05771v5"
	},
	{
		"title": "FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis ",
		"abstract": "Talking face synthesis has been widely studied in either appearance-based or warping-based methods. Previous works mostly utilize single face image as a source, and generate novel facial animations by merging other person's facial features. However, some facial regions like eyes or teeth, which may be hidden in the source image, can not be synthesized faithfully and stably. In this paper, We present a landmark driven two-stream network to generate faithful talking facial animation, in which more facial details are created, preserved and transferred from multiple source images instead of a single one. Specifically, we propose a network consisting of a learning and fetching stream. The fetching sub-net directly learns to attentively warp and merge facial regions from five source images of distinctive landmarks, while the learning pipeline renders facial organs from the training face space to compensate. Compared to baseline algorithms, extensive experiments demonstrate that the proposed method achieves a higher performance both quantitatively and qualitatively. Codes are at https://github.com/kgu3/FLNet_AAAI2020.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09224v1"
	},
	{
		"title": "Who did They Respond to? Conversation Structure Modeling using Masked Hierarchical Transformer ",
		"abstract": "Conversation structure is useful for both understanding the nature of conversation dynamics and for providing features for many downstream applications such as summarization of conversations. In this work, we define the problem of conversation structure modeling as identifying the parent utterance(s) to which each utterance in the conversation responds to. Previous work usually took a pair of utterances to decide whether one utterance is the parent of the other. We believe the entire ancestral history is a very important information source to make accurate prediction. Therefore, we design a novel masking mechanism to guide the ancestor flow, and leverage the transformer model to aggregate all ancestors to predict parent utterances. Our experiments are performed on the Reddit dataset (Zhang, Culbertson, and Paritosh 2017) and the Ubuntu IRC dataset (Kummerfeld et al. 2019). In addition, we also report experiments on a new larger corpus from the Reddit platform and release this dataset. We show that the proposed model, that takes into account the ancestral history of the conversation, significantly outperforms several strong baselines including the BERT model on all datasets",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10666v1"
	},
	{
		"title": "Local Regularizer Improves Generalization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Efficient Algorithms for Generating Provably Near‐Optimal Cluster Descriptors for Explainability ",
		"abstract": "Improving the explainability of the results from machine learning methods has become an important research goal. Here, we study the problem of making clusters more interpretable by extending a recent approach of [Davidson et al., NeurIPS 2018] for constructing succinct representations for clusters. Given a set of objects $S$, a partition $\\pi$ of $S$ (into clusters), and a universe $T$ of tags such that each element in $S$ is associated with a subset of tags, the goal is to find a representative set of tags for each cluster such that those sets are pairwise-disjoint and the total size of all the representatives is minimized. Since this problem is NP-hard in general, we develop approximation algorithms with provable performance guarantees for the problem. We also show applications to explain clusters from datasets, including clusters of genomic sequences that represent different threat levels.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.02487v1"
	},
	{
		"title": "An Implicit Form of Krasulina's k‐PCA Update without the Orthonormality Constraint ",
		"abstract": "We shed new insights on the two commonly used updates for the online $k$-PCA problem, namely, Krasulina's and Oja's updates. We show that Krasulina's update corresponds to a projected gradient descent step on the Stiefel manifold of the orthonormal $k$-frames, while Oja's update amounts to a gradient descent step using the unprojected gradient. Following these observations, we derive a more \\emph{implicit} form of Krasulina's $k$-PCA update, i.e. a version that uses the information of the future gradient as much as possible. Most interestingly, our implicit Krasulina update avoids the costly QR-decomposition step by bypassing the orthonormality constraint. We show that the new update in fact corresponds to an online EM step applied to a probabilistic $k$-PCA model. The probabilistic view of the updates allows us to combine multiple models in a distributed setting. We show experimentally that the implicit Krasulina update yields superior convergence while being significantly faster. We also give strong evidence that the new update can benefit from parallelism and is more stable w.r.t. tuning of the learning rate.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.04803v1"
	},
	{
		"title": "Predictive Student Modeling in Educational Games  with Multi‐Task Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Solving General Elliptical Mixture Models through an Approximate Wasserstein Manifold ",
		"abstract": "We address the estimation problem for general finite mixture models, with a particular focus on the elliptical mixture models (EMMs). Compared to the widely adopted Kullback-Leibler divergence, we show that the Wasserstein distance provides a more desirable optimisation space. We thus provide a stable solution to the EMMs that is both robust to initialisations and reaches a superior optimum by adaptively optimising along a manifold of an approximate Wasserstein distance. To this end, we first provide a unifying account of computable and identifiable EMMs, which serves as a basis to rigorously address the underpinning optimisation problem. Due to a probability constraint, solving this problem is extremely cumbersome and unstable, especially under the Wasserstein distance. To relieve this issue, we introduce an efficient optimisation method on a statistical manifold defined under an approximate Wasserstein distance, which allows for explicit metrics and computable operations, thus significantly stabilising and improving the EMM estimation. We further propose an adaptive method to accelerate the convergence. Experimental results demonstrate the excellent performance of the proposed EMM solver.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.03700v4"
	},
	{
		"title": "Dynamic Control of Probabilistic Simple Temporal Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Invariant Representations through Adversarial Forgetting ",
		"abstract": "We propose a novel approach to achieving invariance for deep neural networks in the form of inducing amnesia to unwanted factors of data through a new adversarial forgetting mechanism. We show that the forgetting mechanism serves as an information-bottleneck, which is manipulated by the adversarial training to learn invariance to unwanted factors. Empirical results show that the proposed framework achieves state-of-the-art performance at learning invariance in both nuisance and bias settings on a diverse collection of datasets and tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04060v2"
	},
	{
		"title": "Doctor2Vec: Dynamic Doctor Representation Learning for Clinical Trial Recruitment ",
		"abstract": "Massive electronic health records (EHRs) enable the success of learning accurate patient representations to support various predictive health applications. In contrast, doctor representation was not well studied despite that doctors play pivotal roles in healthcare. How to construct the right doctor representations? How to use doctor representation to solve important health analytic problems? In this work, we study the problem on {\\it clinical trial recruitment}, which is about identifying the right doctors to help conduct the trials based on the trial description and patient EHR data of those doctors. We propose doctor2vec which simultaneously learns 1) doctor representations from EHR data and 2) trial representations from the description and categorical information about the trials. In particular, doctor2vec utilizes a dynamic memory network where the doctor's experience with patients are stored in the memory bank and the network will dynamically assign weights based on the trial representation via an attention mechanism. Validated on large real-world trials and EHR data including 2,609 trials, 25K doctors and 430K patients, doctor2vec demonstrated improved performance over the best baseline by up to $8.7\\%$ in PR-AUC. We also demonstrated that the doctor2vec embedding can be transferred to benefit data insufficiency settings including trial recruitment in less populated/newly explored country with $13.7\\%$ improvement or for rare diseases with $8.1\\%$ improvement in PR-AUC.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10395v1"
	},
	{
		"title": "More accurate learning of k‐DNF reference classes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cost‐Accuracy Aware Adaptive Labeling for Active Learning ",
		"abstract": "Conventional active learning algorithms assume a single labeler that produces noiseless label at a given, fixed cost, and aim to achieve the best generalization performance for given classifier under a budget constraint. However, in many real settings, different labelers have different labeling costs and can yield different labeling accuracies. Moreover, a given labeler may exhibit different labeling accuracies for different instances. This setting can be referred to as active learning with diverse labelers with varying costs and accuracies, and it arises in many important real settings. It is therefore beneficial to understand how to effectively trade-off between labeling accuracy for different instances, labeling costs, as well as the informativeness of training instances, so as to achieve the best generalization performance at the lowest labeling cost. In this paper, we propose a new algorithm for selecting instances, labelers (and their corresponding costs and labeling accuracies), that employs generalization bound of learning with label noise to select informative instances and labelers so as to achieve higher generalization accuracy at a lower cost. Our proposed algorithm demonstrates state-of-the-art performance on five UCI and a real crowdsourcing dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2105.11418v1"
	},
	{
		"title": "Exponential Family Graph Embeddings ",
		"abstract": "Representing networks in a low dimensional latent space is a crucial task with many interesting applications in graph learning problems, such as link prediction and node classification. A widely applied network representation learning paradigm is based on the combination of random walks for sampling context nodes and the traditional \\textit{Skip-Gram} model to capture center-context node relationships. In this paper, we emphasize on exponential family distributions to capture rich interaction patterns between nodes in random walk sequences. We introduce the generic \\textit{exponential family graph embedding} model, that generalizes random walk-based network representation learning techniques to exponential family conditional distributions. We study three particular instances of this model, analyzing their properties and showing their relationship to existing unsupervised learning models. Our experimental evaluation on real-world datasets demonstrates that the proposed techniques outperform well-known baseline methods in two downstream machine learning tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09007v1"
	},
	{
		"title": "A Forest from the Trees: Generation through Neighborhoods ",
		"abstract": "In this work, we propose to learn a generative model using both learned features (through a latent space) and memories (through neighbors). Although human learning makes seamless use of both learned perceptual features and instance recall, current generative learning paradigms only make use of one of these two components. Take, for instance, flow models, which learn a latent space of invertible features that follow a simple distribution. Conversely, kernel density techniques use instances to shift a simple distribution into an aggregate mixture model. Here we propose multiple methods to enhance the latent space of a flow model with neighborhood information. Not only does our proposed framework represent a more human-like approach by leveraging both learned features and memories, but it may also be viewed as a step forward in non-parametric methods. The efficacy of our model is shown empirically with standard image datasets. We observe compelling results and a significant improvement over baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.01435v2"
	},
	{
		"title": "Strategy‐Proof and Non‐Wasteful Multi‐Unit Auction via Social Network ",
		"abstract": "Auctions via social network, pioneered by Li et al. (2017), have been attracting considerable attention in the literature of mechanism design for auctions. However, no known mechanism has satisfied strategy-proofness, non-deficit, non-wastefulness, and individual rationality for the multi-unit unit-demand auction, except for some naive ones. In this paper, we first propose a mechanism that satisfies all the above properties. We then make a comprehensive comparison with two naive mechanisms, showing that the proposed mechanism dominates them in social surplus, seller's revenue, and incentive of buyers for truth-telling. We also analyze the characteristics of the social surplus and the revenue achieved by the proposed mechanism, including the constant approximability of the worst-case efficiency loss and the complexity of optimizing revenue from the seller's perspective.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08809v1"
	},
	{
		"title": "ADDMC: Weighted Model Counting with Algebraic Decision Diagrams ",
		"abstract": "We present an algorithm to compute exact literal-weighted model counts of Boolean formulas in Conjunctive Normal Form. Our algorithm employs dynamic programming and uses Algebraic Decision Diagrams as the primary data structure. We implement this technique in ADDMC, a new model counter. We empirically evaluate various heuristics that can be used with ADDMC. We then compare ADDMC to state-of-the-art exact weighted model counters (Cachet, c2d, d4, and miniC2D) on 1914 standard model counting benchmarks and show that ADDMC significantly improves the virtual best solver.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.05000v2"
	},
	{
		"title": "Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical Bayes ",
		"abstract": "Stochastic variational inference for Bayesian deep neural network (DNN) requires specifying priors and approximate posterior distributions over neural network weights. Specifying meaningful weight priors is a challenging problem, particularly for scaling variational inference to deeper architectures involving high dimensional weight space. We propose MOdel Priors with Empirical Bayes using DNN (MOPED) method to choose informed weight priors in Bayesian neural networks. We formulate a two-stage hierarchical modeling, first find the maximum likelihood estimates of weights with DNN, and then set the weight priors using empirical Bayes approach to infer the posterior with variational inference. We empirically evaluate the proposed approach on real-world tasks including image classification, video activity recognition and audio classification with varying complex neural network architectures. We also evaluate our proposed approach on diabetic retinopathy diagnosis task and benchmark with the state-of-the-art Bayesian deep learning techniques. We demonstrate MOPED method enables scalable variational inference and provides reliable uncertainty quantification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.05323v3"
	},
	{
		"title": "On the convergence of model free learning in Mean Field Games ",
		"abstract": "Learning by experience in Multi-Agent Systems (MAS) is a difficult and exciting task, due to the lack of stationarity of the environment, whose dynamics evolves as the population learns. In order to design scalable algorithms for systems with a large population of interacting agents (e.g. swarms), this paper focuses on Mean Field MAS, where the number of agents is asymptotically infinite. Recently, a very active burgeoning field studies the effects of diverse reinforcement learning algorithms for agents with no prior information on a stationary Mean Field Game (MFG) and learn their policy through repeated experience. We adopt a high perspective on this problem and analyze in full generality the convergence of a fictitious iterative scheme using any single agent learning algorithm at each step. We quantify the quality of the computed approximate Nash equilibrium, in terms of the accumulated errors arising at each learning iteration step. Notably, we show for the first time convergence of model free learning algorithms towards non-stationary MFG equilibria, relying only on classical assumptions on the MFG dynamics. We illustrate our theoretical results with a numerical experiment in a continuous action-space environment, where the approximate best response of the iterative fictitious play scheme is computed with a deep RL algorithm.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.02633v3"
	},
	{
		"title": "Optimization of Chance‐Constrained Submodular Functions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Causal Discovery from Multiple Data Sets with Non‐Identical Variable Sets ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Lifelong Learning with a Changing Action Set ",
		"abstract": "In many real-world sequential decision making problems, the number of available actions (decisions) can vary over time. While problems like catastrophic forgetting, changing transition dynamics, changing rewards functions, etc. have been well-studied in the lifelong learning literature, the setting where the action set changes remains unaddressed. In this paper, we present an algorithm that autonomously adapts to an action set whose size changes over time. To tackle this open problem, we break it into two problems that can be solved iteratively: inferring the underlying, unknown, structure in the space of actions and optimizing a policy that leverages this structure. We demonstrate the efficiency of this approach on large-scale real-world lifelong learning problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.01770v3"
	},
	{
		"title": "Unsupervised Domain Adaptation via Structured Prediction Based Selective Pseudo‐Labeling ",
		"abstract": "Unsupervised domain adaptation aims to address the problem of classifying unlabeled samples from the target domain whilst labeled samples are only available from the source domain and the data distributions are different in these two domains. As a result, classifiers trained from labeled samples in the source domain suffer from significant performance drop when directly applied to the samples from the target domain. To address this issue, different approaches have been proposed to learn domain-invariant features or domain-specific classifiers. In either case, the lack of labeled samples in the target domain can be an issue which is usually overcome by pseudo-labeling. Inaccurate pseudo-labeling, however, could result in catastrophic error accumulation during learning. In this paper, we propose a novel selective pseudo-labeling strategy based on structured prediction. The idea of structured prediction is inspired by the fact that samples in the target domain are well clustered within the deep feature space so that unsupervised clustering analysis can be used to facilitate accurate pseudo-labeling. Experimental results on four datasets (i.e. Office-Caltech, Office31, ImageCLEF-DA and Office-Home) validate our approach outperforms contemporary state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07982v1"
	},
	{
		"title": "Reinforcement Learning When All Actions are Not Always Available ",
		"abstract": "The Markov decision process (MDP) formulation used to model many real-world sequential decision making problems does not efficiently capture the setting where the set of available decisions (actions) at each time step is stochastic. Recently, the stochastic action set Markov decision process (SAS-MDP) formulation has been proposed, which better captures the concept of a stochastic action set. In this paper we argue that existing RL algorithms for SAS-MDPs can suffer from potential divergence issues, and present new policy gradient algorithms for SAS-MDPs that incorporate variance reduction techniques unique to this setting, and provide conditions for their convergence. We conclude with experiments that demonstrate the practicality of our approaches on tasks inspired by real-life use cases wherein the action set is stochastic.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.01772v2"
	},
	{
		"title": "Logics for Sizes with Union or Intersection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Detecting semantic anomalies ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Meta‐Amortized Variational Inference and Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Gradient‐based Optimization for Bayesian Preference Elicitation ",
		"abstract": "Effective techniques for eliciting user preferences have taken on added importance as recommender systems (RSs) become increasingly interactive and conversational. A common and conceptually appealing Bayesian criterion for selecting queries is expected value of information (EVOI). Unfortunately, it is computationally prohibitive to construct queries with maximum EVOI in RSs with large item spaces. We tackle this issue by introducing a continuous formulation of EVOI as a differentiable network that can be optimized using gradient methods available in modern machine learning (ML) computational frameworks (e.g., TensorFlow, PyTorch). We exploit this to develop a novel, scalable Monte Carlo method for EVOI optimization, which is more scalable for large item spaces than methods requiring explicit enumeration of items. While we emphasize the use of this approach for pairwise (or k-wise) comparisons of items, we also demonstrate how our method can be adapted to queries involving subsets of item attributes or \"partial items,\" which are often more cognitively manageable for users. Experiments show that our gradient-based EVOI technique achieves state-of-the-art performance across several domains while scaling to large item spaces.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09153v1"
	},
	{
		"title": "Urban2Vec: Incorporating Street View Imagery and POIs for Multi‐Modal Urban Neighborhood Embedding ",
		"abstract": "Understanding intrinsic patterns and predicting spatiotemporal characteristics of cities require a comprehensive representation of urban neighborhoods. Existing works relied on either inter- or intra-region connectivities to generate neighborhood representations but failed to fully utilize the informative yet heterogeneous data within neighborhoods. In this work, we propose Urban2Vec, an unsupervised multi-modal framework which incorporates both street view imagery and point-of-interest (POI) data to learn neighborhood embeddings. Specifically, we use a convolutional neural network to extract visual features from street view images while preserving geospatial similarity. Furthermore, we model each POI as a bag-of-words containing its category, rating, and review information. Analog to document embedding in natural language processing, we establish the semantic similarity between neighborhood (\"document\") and the words from its surrounding POIs in the vector space. By jointly encoding visual, textual, and geospatial information into the neighborhood representation, Urban2Vec can achieve performances better than baseline models and comparable to fully-supervised methods in downstream prediction tasks. Extensive experiments on three U.S. metropolitan areas also demonstrate the model interpretability, generalization capability, and its value in neighborhood similarity analysis.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.11101v1"
	},
	{
		"title": "Weakly Supervised POS Taggers Perform Poorly on Truly Low‐Resource Languages ",
		"abstract": "Part-of-speech (POS) taggers for low-resource languages which are exclusively based on various forms of weak supervision - e.g., cross-lingual transfer, type-level supervision, or a combination thereof - have been reported to perform almost as well as supervised ones. However, weakly supervised POS taggers are commonly only evaluated on languages that are very different from truly low-resource languages, and the taggers use sources of information, like high-coverage and almost error-free dictionaries, which are likely not available for resource-poor languages. We train and evaluate state-of-the-art weakly supervised POS taggers for a typologically diverse set of 15 truly low-resource languages. On these languages, given a realistic amount of resources, even our best model gets only less than half of the words right. Our results highlight the need for new and different approaches to POS tagging for truly low-resource languages.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.13305v1"
	},
	{
		"title": "Scalable and Generalizable Social Bot Detection through Data Selection ",
		"abstract": "Efficient and reliable social bot classification is crucial for detecting information manipulation on social media. Despite rapid development, state-of-the-art bot detection models still face generalization and scalability challenges, which greatly limit their applications. In this paper we propose a framework that uses minimal account metadata, enabling efficient analysis that scales up to handle the full stream of public tweets of Twitter in real time. To ensure model accuracy, we build a rich collection of labeled datasets for training and validation. We deploy a strict validation system so that model performance on unseen datasets is also optimized, in addition to traditional cross-validation. We find that strategically selecting a subset of training data yields better model accuracy and generalization than exhaustively training on all available data. Thanks to the simplicity of the proposed model, its logic can be interpreted to provide insights into social bot characteristics.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09179v1"
	},
	{
		"title": "Q‐BERT: Hessian Based Ultra Low Precision Quantization of BERT ",
		"abstract": "Transformer based architectures have become de-facto models used for a range of Natural Language Processing tasks. In particular, the BERT based models achieved significant accuracy gain for GLUE tasks, CoNLL-03 and SQuAD. However, BERT based models have a prohibitive memory footprint and latency. As a result, deploying BERT based models in resource constrained environments has become a challenging task. In this work, we perform an extensive analysis of fine-tuned BERT models using second order Hessian information, and we use our results to propose a novel method for quantizing BERT models to ultra low precision. In particular, we propose a new group-wise quantization scheme, and we use a Hessian based mix-precision method to compress the model further. We extensively test our proposed method on BERT downstream tasks of SST-2, MNLI, CoNLL-03, and SQuAD. We can achieve comparable performance to baseline with at most $2.3\\%$ performance degradation, even with ultra-low precision quantization down to 2 bits, corresponding up to $13\\times$ compression of the model parameters, and up to $4\\times$ compression of the embedding table as well as activations. Among all tasks, we observed the highest performance loss for BERT fine-tuned on SQuAD. By probing into the Hessian based analysis as well as visualization, we show that this is related to the fact that current training/fine-tuning strategy of BERT does not converge for SQuAD.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05840v2"
	},
	{
		"title": "Inefficiency of K‐FAC for Large Batch Size Training ",
		"abstract": "In stochastic optimization, using large batch sizes during training can leverage parallel resources to produce faster wall-clock training times per training epoch. However, for both training loss and testing error, recent results analyzing large batch Stochastic Gradient Descent (SGD) have found sharp diminishing returns, beyond a certain critical batch size. In the hopes of addressing this, it has been suggested that the Kronecker-Factored Approximate Curvature (\\mbox{K-FAC}) method allows for greater scalability to large batch sizes, for non-convex machine learning problems such as neural network optimization, as well as greater robustness to variation in model hyperparameters. Here, we perform a detailed empirical analysis of large batch size training %of these two hypotheses, for both \\mbox{K-FAC} and SGD, evaluating performance in terms of both wall-clock time and aggregate computational cost. Our main results are twofold: first, we find that both \\mbox{K-FAC} and SGD doesn't have ideal scalability behavior beyond a certain batch size, and that \\mbox{K-FAC} does not exhibit improved large-batch scalability behavior, as compared to SGD; and second, we find that \\mbox{K-FAC}, in addition to requiring more hyperparameters to tune, suffers from similar hyperparameter sensitivity behavior as does SGD. We discuss extensive results using ResNet and AlexNet on \\mbox{CIFAR-10} and SVHN, respectively, as well as more general implications of our findings.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.06237v3"
	},
	{
		"title": "Information‐Theoretic Understanding of Population Risk Improvement with Model Compression ",
		"abstract": "We show that model compression can improve the population risk of a pre-trained model, by studying the tradeoff between the decrease in the generalization error and the increase in the empirical risk with model compression. We first prove that model compression reduces an information-theoretic bound on the generalization error; this allows for an interpretation of model compression as a regularization technique to avoid overfitting. We then characterize the increase in empirical risk with model compression using rate distortion theory. These results imply that the population risk could be improved by model compression if the decrease in generalization error exceeds the increase in empirical risk. We show through a linear regression example that such a decrease in population risk due to model compression is indeed possible. Our theoretical results further suggest that the Hessian-weighted $K$-means clustering compression approach can be improved by regularizing the distance between the clustering centers. We provide experiments with neural networks to support our theoretical assertions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.09421v1"
	},
	{
		"title": "Runtime Analysis of Somatic Contiguous Hypermutation Operators in MOEA/D Framework ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Rank Aggregation via Heterogeneous Thurstone Preference Models ",
		"abstract": "We propose the Heterogeneous Thurstone Model (HTM) for aggregating ranked data, which can take the accuracy levels of different users into account. By allowing different noise distributions, the proposed HTM model maintains the generality of Thurstone's original framework, and as such, also extends the Bradley-Terry-Luce (BTL) model for pairwise comparisons to heterogeneous populations of users. Under this framework, we also propose a rank aggregation algorithm based on alternating gradient descent to estimate the underlying item scores and accuracy levels of different users simultaneously from noisy pairwise comparisons. We theoretically prove that the proposed algorithm converges linearly up to a statistical error which matches that of the state-of-the-art method for the single-user BTL model. We evaluate the proposed HTM model and algorithm on both synthetic and real data, demonstrating that it outperforms existing methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01211v1"
	},
	{
		"title": "Nonlinear System Identification via Tensor Completion ",
		"abstract": "Function approximation from input and output data pairs constitutes a fundamental problem in supervised learning. Deep neural networks are currently the most popular method for learning to mimic the input-output relationship of a general nonlinear system, as they have proven to be very effective in approximating complex highly nonlinear functions. In this work, we show that identifying a general nonlinear function $y = f(x_1,\\ldots,x_N)$ from input-output examples can be formulated as a tensor completion problem and under certain conditions provably correct nonlinear system identification is possible. Specifically, we model the interactions between the $N$ input variables and the scalar output of a system by a single $N$-way tensor, and setup a weighted low-rank tensor completion problem with smoothness regularization which we tackle using a block coordinate descent algorithm. We extend our method to the multi-output setting and the case of partially observed data, which cannot be readily handled by neural networks. Finally, we demonstrate the effectiveness of the approach using several regression tasks including some standard benchmarks and a challenging student grade prediction task.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.05746v3"
	},
	{
		"title": "Relation Inference among Sensor Time Series in Smart Buildings with Metric Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bounded Incentives in Manipulating the Probabilistic Serial Rule ",
		"abstract": "The Probabilistic Serial mechanism is well-known for its desirable fairness and efficiency properties. It is one of the most prominent protocols for the random assignment problem. However, Probabilistic Serial is not incentive-compatible, thereby these desirable properties only hold for the agents' declared preferences, rather than their genuine preferences. A substantial utility gain through strategic behaviors would trigger self-interested agents to manipulate the mechanism and would subvert the very foundation of adopting the mechanism in practice. In this paper, we characterize the extent to which an individual agent can increase its utility by strategic manipulation. We show that the incentive ratio of the mechanism is $\\frac{3}{2}$. That is, no agent can misreport its preferences such that its utility becomes more than 1.5 times of what it is when reports truthfully. This ratio is a worst-case guarantee by allowing an agent to have complete information about other agents' reports and to figure out the best response strategy even if it is computationally intractable in general. To complement this worst-case study, we further evaluate an agent's utility gain on average by experiments. The experiments show that an agent' incentive in manipulating the rule is very limited. These results shed some light on the robustness of Probabilistic Serial against strategic manipulation, which is one step further than knowing that it is not incentive-compatible.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.10640v1"
	},
	{
		"title": "HAMNER: Headword Amplified Multi‐span Distantly Supervised Method for Domain Specific Named Entity Recognition ",
		"abstract": "To tackle Named Entity Recognition (NER) tasks, supervised methods need to obtain sufficient cleanly annotated data, which is labor and time consuming. On the contrary, distantly supervised methods acquire automatically annotated data using dictionaries to alleviate this requirement. Unfortunately, dictionaries hinder the effectiveness of distantly supervised methods for NER due to its limited coverage, especially in specific domains. In this paper, we aim at the limitations of the dictionary usage and mention boundary detection. We generalize the distant supervision by extending the dictionary with headword based non-exact matching. We apply a function to better weight the matched entity mentions. We propose a span-level model, which classifies all the possible spans then infers the selected spans with a proposed dynamic programming algorithm. Experiments on all three benchmark datasets demonstrate that our method outperforms previous state-of-the-art distantly supervised methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01731v1"
	},
	{
		"title": "Dialog State Tracking with Reinforced Data Augmentation ",
		"abstract": "Neural dialog state trackers are generally limited due to the lack of quantity and diversity of annotated training data. In this paper, we address this difficulty by proposing a reinforcement learning (RL) based framework for data augmentation that can generate high-quality data to improve the neural state tracker. Specifically, we introduce a novel contextual bandit generator to learn fine-grained augmentation policies that can generate new effective instances by choosing suitable replacements for the specific context. Moreover, by alternately learning between the generator and the state tracker, we can keep refining the generative policies to generate more high-quality training data for neural state tracker. Experimental results on the WoZ and MultiWoZ (restaurant) datasets demonstrate that the proposed framework significantly improves the performance over the state-of-the-art models, especially with limited training data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.07795v2"
	},
	{
		"title": "One‐Shot Image Classification by Learning to Restore Prototypes ",
		"abstract": "One-shot image classification aims to train image classifiers over the dataset with only one image per category. It is challenging for modern deep neural networks that typically require hundreds or thousands of images per class. In this paper, we adopt metric learning for this problem, which has been applied for few- and many-shot image classification by comparing the distance between the test image and the center of each class in the feature space. However, for one-shot learning, the existing metric learning approaches would suffer poor performance because the single training image may not be representative of the class. For example, if the image is far away from the class center in the feature space, the metric-learning based algorithms are unlikely to make correct predictions for the test images because the decision boundary is shifted by this noisy image. To address this issue, we propose a simple yet effective regression model, denoted by RestoreNet, which learns a class agnostic transformation on the image feature to move the image closer to the class center in the feature space. Experiments demonstrate that RestoreNet obtains superior performance over the state-of-the-art methods on a broad range of datasets. Moreover, RestoreNet can be easily combined with other methods to achieve further improvement.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.01234v1"
	},
	{
		"title": "Understanding Medical Conversations with Scattered Keyword Attention and Weak Supervision from Responses ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MarioNETte: Few‐shot Face Reenactment Preserving Identity of Unseen Targets ",
		"abstract": "When there is a mismatch between the target identity and the driver identity, face reenactment suffers severe degradation in the quality of the result, especially in a few-shot setting. The identity preservation problem, where the model loses the detailed information of the target leading to a defective output, is the most common failure mode. The problem has several potential sources such as the identity of the driver leaking due to the identity mismatch, or dealing with unseen large poses. To overcome such problems, we introduce components that address the mentioned problem: image attention block, target feature alignment, and landmark transformer. Through attending and warping the relevant features, the proposed architecture, called MarioNETte, produces high-quality reenactments of unseen identities in a few-shot setting. In addition, the landmark transformer dramatically alleviates the identity preservation problem by isolating the expression geometry through landmark disentanglement. Comprehensive experiments are performed to verify that the proposed framework can generate highly realistic faces, outperforming all other baselines, even under a significant mismatch of facial characteristics between the target and the driver.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08139v1"
	},
	{
		"title": "Dynamic Knowledge Routing Network For Target‐Guided Open‐Domain Conversation ",
		"abstract": "Target-guided open-domain conversation aims to proactively and naturally guide a dialogue agent or human to achieve specific goals, topics or keywords during open-ended conversations. Existing methods mainly rely on single-turn datadriven learning and simple target-guided strategy without considering semantic or factual knowledge relations among candidate topics/keywords. This results in poor transition smoothness and low success rate. In this work, we adopt a structured approach that controls the intended content of system responses by introducing coarse-grained keywords, attains smooth conversation transition through turn-level supervised learning and knowledge relations between candidate keywords, and drives an conversation towards an specified target with discourse-level guiding strategy. Specially, we propose a novel dynamic knowledge routing network (DKRN) which considers semantic knowledge relations among candidate keywords for accurate next topic prediction of next discourse. With the help of more accurate keyword prediction, our keyword-augmented response retrieval module can achieve better retrieval performance and more meaningful conversations. Besides, we also propose a novel dual discourse-level target-guided strategy to guide conversations to reach their goals smoothly with higher success rate. Furthermore, to push the research boundary of target-guided open-domain conversation to match real-world scenarios better, we introduce a new large-scale Chinese target-guided open-domain conversation dataset (more than 900K conversations) crawled from Sina Weibo. Quantitative and human evaluations show our method can produce meaningful and effective target-guided conversations, significantly improving over other state-of-the-art methods by more than 20% in success rate and more than 0.6 in average smoothness score.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01196v2"
	},
	{
		"title": "Rethinking Temporal Fusion for Video‐based Person Re‐identification on Semantic and Time Aspect ",
		"abstract": "Recently, the research interest of person re-identification (ReID) has gradually turned to video-based methods, which acquire a person representation by aggregating frame features of an entire video. However, existing video-based ReID methods do not consider the semantic difference brought by the outputs of different network stages, which potentially compromises the information richness of the person features. Furthermore, traditional methods ignore important relationship among frames, which causes information redundancy in fusion along the time axis. To address these issues, we propose a novel general temporal fusion framework to aggregate frame features on both semantic aspect and time aspect. As for the semantic aspect, a multi-stage fusion network is explored to fuse richer frame features at multiple semantic levels, which can effectively reduce the information loss caused by the traditional single-stage fusion. While, for the time axis, the existing intra-frame attention method is improved by adding a novel inter-frame attention module, which effectively reduces the information redundancy in temporal fusion by taking the relationship among frames into consideration. The experimental results show that our approach can effectively improve the video-based re-identification accuracy, achieving the state-of-the-art performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12512v1"
	},
	{
		"title": "Scalable Decision‐Theoretic Planning in Open and Typed Multiagent Systems ",
		"abstract": "In open agent systems, the set of agents that are cooperating or competing changes over time and in ways that are nontrivial to predict. For example, if collaborative robots were tasked with fighting wildfires, they may run out of suppressants and be temporarily unavailable to assist their peers. We consider the problem of planning in these contexts with the additional challenges that the agents are unable to communicate with each other and that there are many of them. Because an agent's optimal action depends on the actions of others, each agent must not only predict the actions of its peers, but, before that, reason whether they are even present to perform an action. Addressing openness thus requires agents to model each other's presence, which becomes computationally intractable with high numbers of agents. We present a novel, principled, and scalable method in this context that enables an agent to reason about others' presence in its shared environment and their actions. Our method extrapolates models of a few peers to the overall behavior of the many-agent system, and combines it with a generalization of Monte Carlo tree search to perform individual agent reasoning in many-agent open environments. Theoretical analyses establish the number of agents to model in order to achieve acceptable worst case bounds on extrapolation error, as well as regret bounds on the agent's utility from modeling only some neighbors. Simulations of multiagent wildfire suppression problems demonstrate our approach's efficacy compared with alternative baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08642v1"
	},
	{
		"title": "Graduate Employment Prediction with Bias ",
		"abstract": "The failure of landing a job for college students could cause serious social consequences such as drunkenness and suicide. In addition to academic performance, unconscious biases can become one key obstacle for hunting jobs for graduating students. Thus, it is necessary to understand these unconscious biases so that we can help these students at an early stage with more personalized intervention. In this paper, we develop a framework, i.e., MAYA (Multi-mAjor emploYment stAtus) to predict students' employment status while considering biases. The framework consists of four major components. Firstly, we solve the heterogeneity of student courses by embedding academic performance into a unified space. Then, we apply a generative adversarial network (GAN) to overcome the class imbalance problem. Thirdly, we adopt Long Short-Term Memory (LSTM) with a novel dropout mechanism to comprehensively capture sequential information among semesters. Finally, we design a bias-based regularization to capture the job market biases. We conduct extensive experiments on a large-scale educational dataset and the results demonstrate the effectiveness of our prediction framework.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.12012v1"
	},
	{
		"title": "Partial Multi‐Label Learning with Label Distribution ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Robust Stochastic Bandit Algorithms under Probabilistic Unbounded Adversarial Attack ",
		"abstract": "The multi-armed bandit formalism has been extensively studied under various attack models, in which an adversary can modify the reward revealed to the player. Previous studies focused on scenarios where the attack value either is bounded at each round or has a vanishing probability of occurrence. These models do not capture powerful adversaries that can catastrophically perturb the revealed reward. This paper investigates the attack model where an adversary attacks with a certain probability at each round, and its attack value can be arbitrary and unbounded if it attacks. Furthermore, the attack value does not necessarily follow a statistical distribution. We propose a novel sample median-based and exploration-aided UCB algorithm (called med-E-UCB) and a median-based $\\epsilon$-greedy algorithm (called med-$\\epsilon$-greedy). Both of these algorithms are provably robust to the aforementioned attack model. More specifically we show that both algorithms achieve $\\mathcal{O}(\\log T)$ pseudo-regret (i.e., the optimal regret without attacks). We also provide a high probability guarantee of $\\mathcal{O}(\\log T)$ regret with respect to random rewards and random occurrence of attacks. These bounds are achieved under arbitrary and unbounded reward perturbation as long as the attack probability does not exceed a certain constant threshold. We provide multiple synthetic simulations of the proposed algorithms to verify these claims and showcase the inability of existing techniques to achieve sublinear regret. We also provide experimental results of the algorithm operating in a cognitive radio setting using multiple software-defined radios.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07214v1"
	},
	{
		"title": "Multi‐Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting ",
		"abstract": "Traffic forecasting is of great importance to transportation management and public safety, and very challenging due to the complicated spatial-temporal dependency and essential uncertainty brought about by the road network and traffic conditions. Latest studies mainly focus on modeling the spatial dependency by utilizing graph convolutional networks (GCNs) throughout a fixed weighted graph. However, edges, i.e., the correlations between pair-wise nodes, are much more complicated and interact with each other. In this paper, we propose the Multi-Range Attentive Bicomponent GCN (MRA-BGCN), a novel deep learning model for traffic forecasting. We first build the node-wise graph according to the road network distance and the edge-wise graph according to various edge interaction patterns. Then, we implement the interactions of both nodes and edges using bicomponent graph convolution. The multi-range attention mechanism is introduced to aggregate information in different neighborhood ranges and automatically learn the importance of different ranges. Extensive experiments on two real-world road network traffic datasets, METR-LA and PEMS-BAY, show that our MRA-BGCN achieves the state-of-the-art results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12093v1"
	},
	{
		"title": "High‐Order Residual Network for Light Field Super‐Resolution ",
		"abstract": "Plenoptic cameras usually sacrifice the spatial resolution of their SAIs to acquire geometry information from different viewpoints. Several methods have been proposed to mitigate such spatio-angular trade-off, but seldom make use of the structural properties of the light field (LF) data efficiently. In this paper, we propose a novel high-order residual network to learn the geometric features hierarchically from the LF for reconstruction. An important component in the proposed network is the high-order residual block (HRB), which learns the local geometric features by considering the information from all input views. After fully obtaining the local features learned from each HRB, our model extracts the representative geometric features for spatio-angular upsampling through the global residual learning. Additionally, a refinement network is followed to further enhance the spatial details by minimizing a perceptual loss. Compared with previous work, our model is tailored to the rich structure inherent in the LF, and therefore can reduce the artifacts near non-Lambertian and occlusion regions. Experimental results show that our approach enables high-quality reconstruction even in challenging regions and outperforms state-of-the-art single image or LF reconstruction methods with both quantitative measurements and visual evaluation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.13094v1"
	},
	{
		"title": "Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets ",
		"abstract": "Time series modeling has attracted extensive research efforts; however, achieving both reliable efficiency and interpretability from a unified model still remains a challenging problem. Among the literature, shapelets offer interpretable and explanatory insights in the classification tasks, while most existing works ignore the differing representative power at different time slices, as well as (more importantly) the evolution pattern of shapelets. In this paper, we propose to extract time-aware shapelets by designing a two-level timing factor. Moreover, we define and construct the shapelet evolution graph, which captures how shapelets evolve over time and can be incorporated into the time series embeddings by graph embedding algorithms. To validate whether the representations obtained in this way can be applied effectively in various scenarios, we conduct experiments based on three public time series datasets, and two real-world datasets from different domains. Experimental results clearly show the improvements achieved by our approach compared with 17 state-of-the-art baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04143v2"
	},
	{
		"title": "Predictive Engagement: An Efficient Metric for Automatic Evaluation of Open‐Domain Dialogue Systems ",
		"abstract": "User engagement is a critical metric for evaluating the quality of open-domain dialogue systems. Prior work has focused on conversation-level engagement by using heuristically constructed features such as the number of turns and the total time of the conversation. In this paper, we investigate the possibility and efficacy of estimating utterance-level engagement and define a novel metric, {\\em predictive engagement}, for automatic evaluation of open-domain dialogue systems. Our experiments demonstrate that (1) human annotators have high agreement on assessing utterance-level engagement scores; (2) conversation-level engagement scores can be predicted from properly aggregated utterance-level engagement scores. Furthermore, we show that the utterance-level engagement scores can be learned from data. These scores can improve automatic evaluation metrics for open-domain dialogue systems, as shown by correlation with human judgements. This suggests that predictive engagement can be used as a real-time feedback for training better dialogue models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.01456v2"
	},
	{
		"title": "Alignment‐Enhanced Transformer for Constraining NMT with Pre‐Specified Translations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Independence Promoted Graph Disentangled Networks ",
		"abstract": "We address the problem of disentangled representation learning with independent latent factors in graph convolutional networks (GCNs). The current methods usually learn node representation by describing its neighborhood as a perceptual whole in a holistic manner while ignoring the entanglement of the latent factors. However, a real-world graph is formed by the complex interaction of many latent factors (e.g., the same hobby, education or work in social network). While little effort has been made toward exploring the disentangled representation in GCNs. In this paper, we propose a novel Independence Promoted Graph Disentangled Networks (IPGDN) to learn disentangled node representation while enhancing the independence among node representations. In particular, we firstly present disentangled representation learning by neighborhood routing mechanism, and then employ the Hilbert-Schmidt Independence Criterion (HSIC) to enforce independence between the latent representations, which is effectively integrated into a graph convolutional framework as a regularizer at the output layer. Experimental studies on real-world graphs validate our model and demonstrate that our algorithms outperform the state-of-the-arts by a wide margin in different network applications, including semi-supervised graph classification, graph clustering and graph visualization.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11430v1"
	},
	{
		"title": "Tensor Graph Convolutional Networks for Text Classification ",
		"abstract": "Compared to sequential learning models, graph-based neural networks exhibit some excellent properties, such as ability capturing global information. In this paper, we investigate graph-based neural networks for text classification problem. A new framework TensorGCN (tensor graph convolutional networks), is presented for this task. A text graph tensor is firstly constructed to describe semantic, syntactic, and sequential contextual information. Then, two kinds of propagation learning perform on the text graph tensor. The first is intra-graph propagation used for aggregating information from neighborhood nodes in a single graph. The second is inter-graph propagation used for harmonizing heterogeneous information between graphs. Extensive experiments are conducted on benchmark datasets, and the results illustrate the effectiveness of our proposed framework. Our proposed TensorGCN presents an effective way to harmonize and integrate heterogeneous information from different kinds of graphs.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.05313v1"
	},
	{
		"title": "Semi‐Supervised Hierarchical Recurrent Graph Neural Network for City‐Wide Parking Availability Prediction ",
		"abstract": "The ability to predict city-wide parking availability is crucial for the successful development of Parking Guidance and Information (PGI) systems. Indeed, the effective prediction of city-wide parking availability can improve parking efficiency, help urban planning, and ultimately alleviate city congestion. However, it is a non-trivial task for predicting citywide parking availability because of three major challenges: 1) the non-Euclidean spatial autocorrelation among parking lots, 2) the dynamic temporal autocorrelation inside of and between parking lots, and 3) the scarcity of information about real-time parking availability obtained from real-time sensors (e.g., camera, ultrasonic sensor, and GPS). To this end, we propose Semi-supervised Hierarchical Recurrent Graph Neural Network (SHARE) for predicting city-wide parking availability. Specifically, we first propose a hierarchical graph convolution structure to model non-Euclidean spatial autocorrelation among parking lots. Along this line, a contextual graph convolution block and a soft clustering graph convolution block are respectively proposed to capture local and global spatial dependencies between parking lots. Additionally, we adopt a recurrent neural network to incorporate dynamic temporal dependencies of parking lots. Moreover, we propose a parking availability approximation module to estimate missing real-time parking availabilities from both spatial and temporal domain. Finally, experiments on two real-world datasets demonstrate the prediction performance of SHARE outperforms seven state-of-the-art baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10516v1"
	},
	{
		"title": "A Pre‐training Based Personalized Dialogue Generation Model with Persona‐sparse Data ",
		"abstract": "Endowing dialogue systems with personas is essential to deliver more human-like conversations. However, this problem is still far from well explored due to the difficulties of both embodying personalities in natural languages and the persona sparsity issue observed in most dialogue corpora. This paper proposes a pre-training based personalized dialogue model that can generate coherent responses using persona-sparse dialogue data. In this method, a pre-trained language model is used to initialize an encoder and decoder, and personal attribute embeddings are devised to model richer dialogue contexts by encoding speakers' personas together with dialogue histories. Further, to incorporate the target persona in the decoding process and to balance its contribution, an attention routing structure is devised in the decoder to merge features extracted from the target persona and dialogue contexts using dynamically predicted weights. Our model can utilize persona-sparse dialogues in a unified manner during the training process, and can also control the amount of persona-related features to exhibit during the inference process. Both automatic and manual evaluation demonstrates that the proposed model outperforms state-of-the-art methods for generating more coherent and persona consistent responses with persona-sparse data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04700v1"
	},
	{
		"title": "One‐Shot Learning for Long‐Tail Visual Relation Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Simultaneously Linking Entities and Extracting Relations from Biomedical Text without Mention‐level Supervision ",
		"abstract": "Understanding the meaning of text often involves reasoning about entities and their relationships. This requires identifying textual mentions of entities, linking them to a canonical concept, and discerning their relationships. These tasks are nearly always viewed as separate components within a pipeline, each requiring a distinct model and training data. While relation extraction can often be trained with readily available weak or distant supervision, entity linkers typically require expensive mention-level supervision -- which is not available in many domains. Instead, we propose a model which is trained to simultaneously produce entity linking and relation decisions while requiring no mention-level annotations. This approach avoids cascading errors that arise from pipelined methods and more accurately predicts entity relationships from text. We show that our model outperforms a state-of-the art entity linking and relation extraction pipeline on two biomedical datasets and can drastically improve the overall recall of the system.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01070v1"
	},
	{
		"title": "Optimizing Nondecomposable Data Dependent Regularizers via Lagrangian Reparameterization offers Significant Performance and Efficiency Gains ",
		"abstract": "Data dependent regularization is known to benefit a wide variety of problems in machine learning. Often, these regularizers cannot be easily decomposed into a sum over a finite number of terms, e.g., a sum over individual example-wise terms. The $F_\\beta$ measure, Area under the ROC curve (AUCROC) and Precision at a fixed recall (P@R) are some prominent examples that are used in many applications. We find that for most medium to large sized datasets, scalability issues severely limit our ability in leveraging the benefits of such regularizers. Importantly, the key technical impediment despite some recent progress is that, such objectives remain difficult to optimize via backpropapagation procedures. While an efficient general-purpose strategy for this problem still remains elusive, in this paper, we show that for many data-dependent nondecomposable regularizers that are relevant in applications, sizable gains in efficiency are possible with minimal code-level changes; in other words, no specialized tools or numerical schemes are needed. Our procedure involves a reparameterization followed by a partial dualization -- this leads to a formulation that has provably cheap projection operators. We present a detailed analysis of runtime and convergence properties of our algorithm. On the experimental side, we show that a direct use of our scheme significantly improves the state of the art IOU measures reported for MSCOCO Stuff segmentation dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.12398v1"
	},
	{
		"title": "Recognizing Instagram Filtered Images with Feature De‐stylization ",
		"abstract": "Deep neural networks have been shown to suffer from poor generalization when small perturbations are added (like Gaussian noise), yet little work has been done to evaluate their robustness to more natural image transformations like photo filters. This paper presents a study on how popular pretrained models are affected by commonly used Instagram filters. To this end, we introduce ImageNet-Instagram, a filtered version of ImageNet, where 20 popular Instagram filters are applied to each image in ImageNet. Our analysis suggests that simple structure preserving filters which only alter the global appearance of an image can lead to large differences in the convolutional feature space. To improve generalization, we introduce a lightweight de-stylization module that predicts parameters used for scaling and shifting feature maps to \"undo\" the changes incurred by filters, inverting the process of style transfer tasks. We further demonstrate the module can be readily plugged into modern CNN architectures together with skip connections. We conduct extensive studies on ImageNet-Instagram, and show quantitatively and qualitatively, that the proposed module, among other things, can effectively improve generalization by simply learning normalization parameters without retraining the entire network, thus recovering the alterations in the feature space caused by the filters.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.13000v1"
	},
	{
		"title": "Infomax Neural Joint Source‐Channel Coding via Adversarial Bit Flip ",
		"abstract": "Although Shannon theory states that it is asymptotically optimal to separate the source and channel coding as two independent processes, in many practical communication scenarios this decomposition is limited by the finite bit-length and computational power for decoding. Recently, neural joint source-channel coding (NECST) is proposed to sidestep this problem. While it leverages the advancements of amortized inference and deep learning to improve the encoding and decoding process, it still cannot always achieve compelling results in terms of compression and error correction performance due to the limited robustness of its learned coding networks. In this paper, motivated by the inherent connections between neural joint source-channel coding and discrete representation learning, we propose a novel regularization method called Infomax Adversarial-Bit-Flip (IABF) to improve the stability and robustness of the neural joint source-channel coding scheme. More specifically, on the encoder side, we propose to explicitly maximize the mutual information between the codeword and data; while on the decoder side, the amortized reconstruction is regularized within an adversarial framework. Extensive experiments conducted on various real-world datasets evidence that our IABF can achieve state-of-the-art performances on both compression and error correction benchmarks and outperform the baselines by a significant margin.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.01454v1"
	},
	{
		"title": "On the learning property of logistic and softmax losses for deep neural networks ",
		"abstract": "Deep convolutional neural networks (CNNs) trained with logistic and softmax losses have made significant advancement in visual recognition tasks in computer vision. When training data exhibit class imbalances, the class-wise reweighted version of logistic and softmax losses are often used to boost performance of the unweighted version. In this paper, motivated to explain the reweighting mechanism, we explicate the learning property of those two loss functions by analyzing the necessary condition (e.g., gradient equals to zero) after training CNNs to converge to a local minimum. The analysis immediately provides us explanations for understanding (1) quantitative effects of the class-wise reweighting mechanism: deterministic effectiveness for binary classification using logistic loss yet indeterministic for multi-class classification using softmax loss; (2) disadvantage of logistic loss for single-label multi-class classification via one-vs.-all approach, which is due to the averaging effect on predicted probabilities for the negative class (e.g., non-target classes) in the learning process. With the disadvantage and advantage of logistic loss disentangled, we thereafter propose a novel reweighted logistic loss for multi-class classification. Our simple yet effective formulation improves ordinary logistic loss by focusing on learning hard non-target classes (target vs. non-target class in one-vs.-all) and turned out to be competitive with softmax loss. We evaluate our method on several benchmark datasets to demonstrate its effectiveness.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.02309v1"
	},
	{
		"title": "OF‐MSRN: Optical Flow‐Auxiliary Multi‐Task Regression Network for Direct Quantitative Measurement, Segmentation and Motion Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fast and efficient Boolean matrix factorization by geometric segmentation ",
		"abstract": "Boolean matrix has been used to represent digital information in many fields, including bank transaction, crime records, natural language processing, protein-protein interaction, etc. Boolean matrix factorization (BMF) aims to find an approximation of a binary matrix as the Boolean product of two low rank Boolean matrices, which could generate vast amount of information for the patterns of relationships between the features and samples. Inspired by binary matrix permutation theories and geometric segmentation, we developed a fast and efficient BMF approach called MEBF (Median Expansion for Boolean Factorization). Overall, MEBF adopted a heuristic approach to locate binary patterns presented as submatrices that are dense in 1's. At each iteration, MEBF permutates the rows and columns such that the permutated matrix is approximately Upper Triangular-Like (UTL) with so-called Simultaneous Consecutive-ones Property (SC1P). The largest submatrix dense in 1 would lies on the upper triangular area of the permutated matrix, and its location was determined based on a geometric segmentation of a triangular. We compared MEBF with other state of the art approaches on data scenarios with different sparsity and noise levels. MEBF demonstrated superior performances in lower reconstruction error, and higher computational efficiency, as well as more accurate sparse patterns than popular methods such as ASSO, PANDA and MP. We demonstrated the application of MEBF on both binary and non-binary data sets, and revealed its further potential in knowledge retrieving and data denoising.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03991v2"
	},
	{
		"title": "A New Dataset and Boundary‐Attention Semantic Segmentation for Face Parsing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Automatic Generation of Headlines for Online Math Questions ",
		"abstract": "Mathematical equations are an important part of dissemination and communication of scientific information. Students, however, often feel challenged in reading and understanding math content and equations. With the development of the Web, students are posting their math questions online. Nevertheless, constructing a concise math headline that gives a good description of the posted detailed math question is nontrivial. In this study, we explore a novel summarization task denoted as geNerating A concise Math hEadline from a detailed math question (NAME). Compared to conventional summarization tasks, this task has two extra and essential constraints: 1) Detailed math questions consist of text and math equations which require a unified framework to jointly model textual and mathematical information; 2) Unlike text, math equations contain semantic and structural features, and both of them should be captured together. To address these issues, we propose MathSum, a novel summarization model which utilizes a pointer mechanism combined with a multi-head attention mechanism for mathematical representation augmentation. The pointer mechanism can either copy textual tokens or math tokens from source questions in order to generate math headlines. The multi-head attention mechanism is designed to enrich the representation of math equations by modeling and integrating both its semantic and structural features. For evaluation, we collect and make available two sets of real-world detailed math questions along with human-written math headlines, namely EXEQ-300k and OFEQ-10k. Experimental results demonstrate that our model (MathSum) significantly outperforms state-of-the-art models for both the EXEQ-300k and OFEQ-10k datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00839v1"
	},
	{
		"title": "Regression Under Human Assistance ",
		"abstract": "Decisions are increasingly taken by both humans and machine learning models. However, machine learning models are currently trained for full automation -- they are not aware that some of the decisions may still be taken by humans. In this paper, we take a first step towards the development of machine learning models that are optimized to operate under different automation levels. More specifically, we first introduce the problem of ridge regression under human assistance and show that it is NP-hard. Then, we derive an alternative representation of the corresponding objective function as a difference of nondecreasing submodular functions. Building on this representation, we further show that the objective is nondecreasing and satisfies $\\alpha$-submodularity, a recently introduced notion of approximate submodularity. These properties allow a simple and efficient greedy algorithm to enjoy approximation guarantees at solving the problem. Experiments on synthetic and real-world data from two important applications -- medical diagnosis and content moderation-demonstrate that our algorithm outsources to humans those samples in which the prediction error of the ridge regression model would have been the highest if it had to make a prediction, it outperforms several competitive baselines, and its performance is robust with respect to several design choices and hyperparameters used in the experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02963v4"
	},
	{
		"title": "CircleNet for Hip Landmark Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Effective AER Object Classification Using Segmented Probability‐Maximization Learning in Spiking Neural Networks ",
		"abstract": "Address event representation (AER) cameras have recently attracted more attention due to the advantages of high temporal resolution and low power consumption, compared with traditional frame-based cameras. Since AER cameras record the visual input as asynchronous discrete events, they are inherently suitable to coordinate with the spiking neural network (SNN), which is biologically plausible and energy-efficient on neuromorphic hardware. However, using SNN to perform the AER object classification is still challenging, due to the lack of effective learning algorithms for this new representation. To tackle this issue, we propose an AER object classification model using a novel segmented probability-maximization (SPA) learning algorithm. Technically, 1) the SPA learning algorithm iteratively maximizes the probability of the classes that samples belong to, in order to improve the reliability of neuron responses and effectiveness of learning; 2) a peak detection (PD) mechanism is introduced in SPA to locate informative time points segment by segment, based on which information within the whole event stream can be fully utilized by the learning. Extensive experimental results show that, compared to state-of-the-art methods, not only our model is more effective, but also it requires less information to reach a certain level of accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06199v1"
	},
	{
		"title": "Asymmetrical Hierarchical Networks with Attentive Interactions for Interpretable Review‐Based Recommendation ",
		"abstract": "Recently, recommender systems have been able to emit substantially improved recommendations by leveraging user-provided reviews. Existing methods typically merge all reviews of a given user or item into a long document, and then process user and item documents in the same manner. In practice, however, these two sets of reviews are notably different: users' reviews reflect a variety of items that they have bought and are hence very heterogeneous in their topics, while an item's reviews pertain only to that single item and are thus topically homogeneous. In this work, we develop a novel neural network model that properly accounts for this important difference by means of asymmetric attentive modules. The user module learns to attend to only those signals that are relevant with respect to the target item, whereas the item module learns to extract the most salient contents with regard to properties of the item. Our multi-hierarchical paradigm accounts for the fact that neither are all reviews equally useful, nor are all sentences within each review equally pertinent. Extensive experimental results on a variety of real datasets demonstrate the effectiveness of our method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.04346v1"
	},
	{
		"title": "DARB: A Density‐Adaptive Regular‐Block Pruning for Deep Neural Networks ",
		"abstract": "The rapidly growing parameter volume of deep neural networks (DNNs) hinders the artificial intelligence applications on resource constrained devices, such as mobile and wearable devices. Neural network pruning, as one of the mainstream model compression techniques, is under extensive study to reduce the number of parameters and computations. In contrast to irregular pruning that incurs high index storage and decoding overhead, structured pruning techniques have been proposed as the promising solutions. However, prior studies on structured pruning tackle the problem mainly from the perspective of facilitating hardware implementation, without analyzing the characteristics of sparse neural networks. The neglect on the study of sparse neural networks causes inefficient trade-off between regularity and pruning ratio. Consequently, the potential of structurally pruning neural networks is not sufficiently mined.   In this work, we examine the structural characteristics of the irregularly pruned weight matrices, such as the diverse redundancy of different rows, the sensitivity of different rows to pruning, and the positional characteristics of retained weights. By leveraging the gained insights as a guidance, we first propose the novel block-max weight masking (BMWM) method, which can effectively retain the salient weights while imposing high regularity to the weight matrix. As a further optimization, we propose a density-adaptive regular-block (DARB) pruning that outperforms prior structured pruning work with high pruning ratio and decoding efficiency. Our experimental results show that DARB can achieve 13$\\times$ to 25$\\times$ pruning ratio, which are 2.8$\\times$ to 4.3$\\times$ improvements than the state-of-the-art counterparts on multiple neural network models and tasks. Moreover, DARB can achieve 14.3$\\times$ decoding efficiency than block pruning with higher pruning ratio.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08020v2"
	},
	{
		"title": "Reinforcement Mechanism Design: With Applications to Dynamic Pricing in Sponsored Search Auctions ",
		"abstract": "In this study, we apply reinforcement learning techniques and propose what we call reinforcement mechanism design to tackle the dynamic pricing problem in sponsored search auctions. In contrast to previous game-theoretical approaches that heavily rely on rationality and common knowledge among the bidders, we take a data-driven approach, and try to learn, over repeated interactions, the set of optimal reserve prices. We implement our approach within the current sponsored search framework of a major search engine: we first train a buyer behavior model, via a real bidding data set, that accurately predicts bids given information that bidders are aware of, including the game parameters disclosed by the search engine, as well as the bidders' KPI data from previous rounds. We then put forward a reinforcement/MDP (Markov Decision Process) based algorithm that optimizes reserve prices over time, in a GSP-like auction. Our simulations demonstrate that our framework outperforms static optimization strategies including the ones that are currently in use, as well as several other dynamic ones.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1711.10279v1"
	},
	{
		"title": "OMuLeT: Online Multi‐Lead Time Location Prediction for Hurricane Trajectory Forecasting ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐View Partial Multi‐label Learning with Graph‐based Disambiguation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Outlier Detection Ensemble with Embedded Feature Selection ",
		"abstract": "Feature selection places an important role in improving the performance of outlier detection, especially for noisy data. Existing methods usually perform feature selection and outlier scoring separately, which would select feature subsets that may not optimally serve for outlier detection, leading to unsatisfying performance. In this paper, we propose an outlier detection ensemble framework with embedded feature selection (ODEFS), to address this issue. Specifically, for each random sub-sampling based learning component, ODEFS unifies feature selection and outlier detection into a pairwise ranking formulation to learn feature subsets that are tailored for the outlier detection method. Moreover, we adopt the thresholded self-paced learning to simultaneously optimize feature selection and example selection, which is helpful to improve the reliability of the training set. After that, we design an alternate algorithm with proved convergence to solve the resultant optimization problem. In addition, we analyze the generalization error bound of the proposed framework, which provides theoretical guarantee on the method and insightful practical guidance. Comprehensive experimental results on 12 real-world datasets from diverse domains validate the superiority of the proposed ODEFS.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.05492v1"
	},
	{
		"title": "Learning Relationships between Text, Audio, and Video via Deep Canonical Correlation for Multimodal Language Analysis ",
		"abstract": "Multimodal language analysis often considers relationships between features based on text and those based on acoustical and visual properties. Text features typically outperform non-text features in sentiment analysis or emotion recognition tasks in part because the text features are derived from advanced language models or word embeddings trained on massive data sources while audio and video features are human-engineered and comparatively underdeveloped. Given that the text, audio, and video are describing the same utterance in different ways, we hypothesize that the multimodal sentiment analysis and emotion recognition can be improved by learning (hidden) correlations between features extracted from the outer product of text and audio (we call this text-based audio) and analogous text-based video. This paper proposes a novel model, the Interaction Canonical Correlation Network (ICCN), to learn such multimodal embeddings. ICCN learns correlations between all three modes via deep canonical correlation analysis (DCCA) and the proposed embeddings are then tested on several benchmark datasets and against other state-of-the-art multimodal embedding algorithms. Empirical results and ablation studies confirm the effectiveness of ICCN in capturing useful information from all three views.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05544v2"
	},
	{
		"title": "Video Face Super‐Resolution with Motion‐Adaptive Feedback Cell ",
		"abstract": "Video super-resolution (VSR) methods have recently achieved a remarkable success due to the development of deep convolutional neural networks (CNN). Current state-of-the-art CNN methods usually treat the VSR problem as a large number of separate multi-frame super-resolution tasks, at which a batch of low resolution (LR) frames is utilized to generate a single high resolution (HR) frame, and running a slide window to select LR frames over the entire video would obtain a series of HR frames. However, duo to the complex temporal dependency between frames, with the number of LR input frames increase, the performance of the reconstructed HR frames become worse. The reason is in that these methods lack the ability to model complex temporal dependencies and hard to give an accurate motion estimation and compensation for VSR process. Which makes the performance degrade drastically when the motion in frames is complex. In this paper, we propose a Motion-Adaptive Feedback Cell (MAFC), a simple but effective block, which can efficiently capture the motion compensation and feed it back to the network in an adaptive way. Our approach efficiently utilizes the information of the inter-frame motion, the dependence of the network on motion estimation and compensation method can be avoid. In addition, benefiting from the excellent nature of MAFC, the network can achieve better performance in the case of extremely complex motion scenarios. Extensive evaluations and comparisons validate the strengths of our approach, and the experimental results demonstrated that the proposed framework is outperform the state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06378v1"
	},
	{
		"title": "Story Realization: Expanding Plot Events into Sentences ",
		"abstract": "Neural network based approaches to automated story plot generation attempt to learn how to generate novel plots from a corpus of natural language plot summaries. Prior work has shown that a semantic abstraction of sentences called events improves neural plot generation and and allows one to decompose the problem into: (1) the generation of a sequence of events (event-to-event) and (2) the transformation of these events into natural language sentences (event-to-sentence). However, typical neural language generation approaches to event-to-sentence can ignore the event details and produce grammatically-correct but semantically-unrelated sentences. We present an ensemble-based model that generates natural language guided by events.We provide results---including a human subjects study---for a full end-to-end automated story generation system showing that our method generates more coherent and plausible stories than baseline approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03480v2"
	},
	{
		"title": "Facial Attribute Capsules for Noise Face Super Resolution ",
		"abstract": "Existing face super-resolution (SR) methods mainly assume the input image to be noise-free. Their performance degrades drastically when applied to real-world scenarios where the input image is always contaminated by noise. In this paper, we propose a Facial Attribute Capsules Network (FACN) to deal with the problem of high-scale super-resolution of noisy face image. Capsule is a group of neurons whose activity vector models different properties of the same entity. Inspired by the concept of capsule, we propose an integrated representation model of facial information, which named Facial Attribute Capsule (FAC). In the SR processing, we first generated a group of FACs from the input LR face, and then reconstructed the HR face from this group of FACs. Aiming to effectively improve the robustness of FAC to noise, we generate FAC in semantic, probabilistic and facial attributes manners by means of integrated learning strategy. Each FAC can be divided into two sub-capsules: Semantic Capsule (SC) and Probabilistic Capsule (PC). Them describe an explicit facial attribute in detail from two aspects of semantic representation and probability distribution. The group of FACs model an image as a combination of facial attribute information in the semantic space and probabilistic space by an attribute-disentangling way. The diverse FACs could better combine the face prior information to generate the face images with fine-grained semantic attributes. Extensive benchmark experiments show that our method achieves superior hallucination results and outperforms state-of-the-art for very low resolution (LR) noise face image super resolution.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06518v1"
	},
	{
		"title": "Neural Semantic Parsing in Low‐Resource Settings with Back‐Translation and Meta‐Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Long Short‐Term Sample Distillation ",
		"abstract": "In the past decade, there has been substantial progress at training increasingly deep neural networks. Recent advances within the teacher--student training paradigm have established that information about past training updates show promise as a source of guidance during subsequent training steps. Based on this notion, in this paper, we propose Long Short-Term Sample Distillation, a novel training policy that simultaneously leverages multiple phases of the previous training process to guide the later training updates to a neural network, while efficiently proceeding in just one single generation pass. With Long Short-Term Sample Distillation, the supervision signal for each sample is decomposed into two parts: a long-term signal and a short-term one. The long-term teacher draws on snapshots from several epochs ago in order to provide steadfast guidance and to guarantee teacher--student differences, while the short-term one yields more up-to-date cues with the goal of enabling higher-quality updates. Moreover, the teachers for each sample are unique, such that, overall, the model learns from a very diverse set of teachers. Comprehensive experimental results across a range of vision and NLP tasks demonstrate the effectiveness of this new training method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00739v1"
	},
	{
		"title": "Multi‐View Multiple Clusterings using Deep Matrix Factorization ",
		"abstract": "Multi-view clustering aims at integrating complementary information from multiple heterogeneous views to improve clustering results. Existing multi-view clustering solutions can only output a single clustering of the data. Due to their multiplicity, multi-view data, can have different groupings that are reasonable and interesting from different perspectives. However, how to find multiple, meaningful, and diverse clustering results from multi-view data is still a rarely studied and challenging topic in multi-view clustering and multiple clusterings. In this paper, we introduce a deep matrix factorization based solution (DMClusts) to discover multiple clusterings. DMClusts gradually factorizes multi-view data matrices into representational subspaces layer-by-layer and generates one clustering in each layer. To enforce the diversity between generated clusterings, it minimizes a new redundancy quantification term derived from the proximity between samples in these subspaces. We further introduce an iterative optimization procedure to simultaneously seek multiple clusterings with quality and diversity. Experimental results on benchmark datasets confirm that DMClusts outperforms state-of-the-art multiple clustering solutions.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11396v1"
	},
	{
		"title": " On the Role of Weight Sharing During Deep Option Learning  ",
		"abstract": "The options framework is a popular approach for building temporally extended actions in reinforcement learning. In particular, the option-critic architecture provides general purpose policy gradient theorems for learning actions from scratch that are extended in time. However, past work makes the key assumption that each of the components of option-critic has independent parameters. In this work we note that while this key assumption of the policy gradient theorems of option-critic holds in the tabular case, it is always violated in practice for the deep function approximation setting. We thus reconsider this assumption and consider more general extensions of option-critic and hierarchical option-critic training that optimize for the full architecture with each update. It turns out that not assuming parameter independence challenges a belief in prior work that training the policy over options can be disentangled from the dynamics of the underlying options. In fact, learning can be sped up by focusing the policy over options on states where options are actually likely to terminate. We put our new algorithms to the test in application to sample efficient learning of Atari games, and demonstrate significantly improved stability and faster convergence when learning long options.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.13408v2"
	},
	{
		"title": "Generating Realistic Stock Market Order Streams ",
		"abstract": "We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks (GANs). Our Stock-GAN model employs a conditional Wasserstein GAN to capture history dependence of orders. The generator design includes specially crafted aspects including components that approximate the market's auction mechanism, augmenting the order history with order-book constructions to improve the generation task. We perform an ablation study to verify the usefulness of aspects of our network structure. We provide a mathematical characterization of distribution learned by the generator. We also propose statistics to measure the quality of generated orders. We test our approach with synthetic and actual market data, compare to many baseline generative models, and find the generated data to be close to real data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.04212v1"
	},
	{
		"title": "Constructing Multiple Tasks for Augmentation: Improving Neural Image Classification With K‐means Features ",
		"abstract": "Multi-task learning (MTL) has received considerable attention, and numerous deep learning applications benefit from MTL with multiple objectives. However, constructing multiple related tasks is difficult, and sometimes only a single task is available for training in a dataset. To tackle this problem, we explored the idea of using unsupervised clustering to construct a variety of auxiliary tasks from unlabeled data or existing labeled data. We found that some of these newly constructed tasks could exhibit semantic meanings corresponding to certain human-specific attributes, but some were non-ideal. In order to effectively reduce the impact of non-ideal auxiliary tasks on the main task, we further proposed a novel meta-learning-based multi-task learning approach, which trained the shared hidden layers on auxiliary tasks, while the meta-optimization objective was to minimize the loss on the main task, ensuring that the optimizing direction led to an improvement on the main task. Experimental results across five image datasets demonstrated that the proposed method significantly outperformed existing single task learning, semi-supervised learning, and some data augmentation methods, including an improvement of more than 9% on the Omniglot dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07518v1"
	},
	{
		"title": "The Effectiveness of Peer Prediction in Long‐Term Forecasting ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generating Adversarial Examples for Holding Robustness of Source Code Processing Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Character‐Centric Neural Model for Automated Story Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Learning based Branch and Bound for Maximum Common Subgraph related Problems ",
		"abstract": "Branch-and-bound (BnB) algorithms are widely used to solve combinatorial problems, and the performance crucially depends on its branching heuristic.In this work, we consider a typical problem of maximum common subgraph (MCS), and propose a branching heuristic inspired from reinforcement learning with a goal of reaching a tree leaf as early as possible to greatly reduce the search tree size.Extensive experiments show that our method is beneficial and outperforms current best BnB algorithm for the MCS.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.05840v2"
	},
	{
		"title": "Graph Transformer for Graph‐to‐Sequence Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Accelerating Primal Solution Findings for Mixed Integer Programs Based on Solution Prediction ",
		"abstract": "Mixed Integer Programming (MIP) is one of the most widely used modeling techniques for combinatorial optimization problems. In many applications, a similar MIP model is solved on a regular basis, maintaining remarkable similarities in model structures and solution appearances but differing in formulation coefficients. This offers the opportunity for machine learning methods to explore the correlations between model structures and the resulting solution values. To address this issue, we propose to represent an MIP instance using a tripartite graph, based on which a Graph Convolutional Network (GCN) is constructed to predict solution values for binary variables. The predicted solutions are used to generate a local branching type cut which can be either treated as a global (invalid) inequality in the formulation resulting in a heuristic approach to solve the MIP, or as a root branching rule resulting in an exact approach. Computational evaluations on 8 distinct types of MIP problems show that the proposed framework improves the primal solution finding performance significantly on a state-of-the-art open-source MIP solver.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.09575v2"
	},
	{
		"title": "Temporal Network Embedding with High‐Order Nonlinear Information ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Auto Weight: Entirely Data‐driven and Highly Efficient Weighting Framework ",
		"abstract": "Example weighting algorithm is an effective solution to the training bias problem, however, most previous typical methods are usually limited to human knowledge and require laborious tuning of hyperparameters. In this paper, we propose a novel example weighting framework called Learning to Auto Weight (LAW). The proposed framework finds step-dependent weighting policies adaptively, and can be jointly trained with target networks without any assumptions or prior knowledge about the dataset. It consists of three key components: Stage-based Searching Strategy (3SM) is adopted to shrink the huge searching space in a complete training process; Duplicate Network Reward (DNR) gives more accurate supervision by removing randomness during the searching process; Full Data Update (FDU) further improves the updating efficiency. Experimental results demonstrate the superiority of weighting policy explored by LAW over standard training pipeline. Compared with baselines, LAW can find a better weighting schedule which achieves much more superior accuracy on both biased CIFAR and ImageNet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.11058v3"
	},
	{
		"title": "Relational Graph Neural Network with Hierarchical Attention for Knowledge Graph Completion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Narrative Planning Model Acquisition from Text Summaries and Descriptions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Attention‐based Multi‐modal Fusion Network for Semantic Scene Completion ",
		"abstract": "This paper presents an end-to-end 3D convolutional network named attention-based multi-modal fusion network (AMFNet) for the semantic scene completion (SSC) task of inferring the occupancy and semantic labels of a volumetric 3D scene from single-view RGB-D images. Compared with previous methods which use only the semantic features extracted from RGB-D images, the proposed AMFNet learns to perform effective 3D scene completion and semantic segmentation simultaneously via leveraging the experience of inferring 2D semantic segmentation from RGB-D images as well as the reliable depth cues in spatial dimension. It is achieved by employing a multi-modal fusion architecture boosted from 2D semantic segmentation and a 3D semantic completion network empowered by residual attention blocks. We validate our method on both the synthetic SUNCG-RGBD dataset and the real NYUv2 dataset and the results show that our method respectively achieves the gains of 2.5% and 2.6% on the synthetic SUNCG-RGBD dataset and the real NYUv2 dataset against the state-of-the-art method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.13910v2"
	},
	{
		"title": "Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of NER ",
		"abstract": "BiLSTM has been prevalently used as a core module for NER in a sequence-labeling setup. State-of-the-art approaches use BiLSTM with additional resources such as gazetteers, language-modeling, or multi-task supervision to further improve NER. This paper instead takes a step back and focuses on analyzing problems of BiLSTM itself and how exactly self-attention can bring improvements. We formally show the limitation of (CRF-)BiLSTM in modeling cross-context patterns for each word -- the XOR limitation. Then, we show that two types of simple cross-structures -- self-attention and Cross-BiLSTM -- can effectively remedy the problem. We test the practical impacts of the deficiency on real-world NER datasets, OntoNotes 5.0 and WNUT 2017, with clear and consistent improvements over the baseline, up to 8.7% on some of the multi-token entity mentions. We give in-depth analyses of the improvements across several aspects of NER, especially the identification of multi-token mentions. This study should lay a sound foundation for future improvements on sequence-labeling NER. (Source codes: https://github.com/jacobvsdanniel/cross-ner)",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.11046v3"
	},
	{
		"title": "Learning with Unsure Responses ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Query Inseparable ELH Ontologies ",
		"abstract": "We investigate the complexity of learning query inseparable ELH ontologies in a variant of Angluin's exact learning model. Given a fixed data instance A* and a query language Q, we are interested in computing an ontology H that entails the same queries as a target ontology T on A*, that is, H and T are inseparable w.r.t. A* and Q. The learner is allowed to pose two kinds of questions. The first is `Does (T,A)\\models q?', with A an arbitrary data instance and q and query in Q. An oracle replies this question with `yes' or `no'. In the second, the learner asks `Are H and T inseparable w.r.t. A* and Q?'. If so, the learning process finishes, otherwise, the learner receives (A*,q) with q in Q, (T,A*)\\models q and (H,A*)\\not\\models q (or vice-versa). Then, we analyse conditions in which query inseparability is preserved if A* changes. Finally, we consider the PAC learning model and a setting where the algorithms learn from a batch of classified data, limiting interactions with the oracles.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07229v5"
	},
	{
		"title": "Safe Linear Stochastic Bandits ",
		"abstract": "We introduce the safe linear stochastic bandit framework---a generalization of linear stochastic bandits---where, in each stage, the learner is required to select an arm with an expected reward that is no less than a predetermined (safe) threshold with high probability. We assume that the learner initially has knowledge of an arm that is known to be safe, but not necessarily optimal. Leveraging on this assumption, we introduce a learning algorithm that systematically combines known safe arms with exploratory arms to safely expand the set of safe arms over time, while facilitating safe greedy exploitation in subsequent stages. In addition to ensuring the satisfaction of the safety constraint at every stage of play, the proposed algorithm is shown to exhibit an expected regret that is no more than $O(\\sqrt{T}\\log (T))$ after $T$ stages of play.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09501v1"
	},
	{
		"title": "Incentivized Exploration for Multi‐Armed Bandits under Reward Drift ",
		"abstract": "We study incentivized exploration for the multi-armed bandit (MAB) problem where the players receive compensation for exploring arms other than the greedy choice and may provide biased feedback on reward. We seek to understand the impact of this drifted reward feedback by analyzing the performance of three instantiations of the incentivized MAB algorithm: UCB, $\\varepsilon$-Greedy, and Thompson Sampling. Our results show that they all achieve $\\mathcal{O}(\\log T)$ regret and compensation under the drifted reward, and are therefore effective in incentivizing exploration. Numerical examples are provided to complement the theoretical analysis.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05142v3"
	},
	{
		"title": "A Dataset for Low‐Resource Stylized Sequence‐to‐Sequence Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Maximizing Overall Diversity for Improved Uncertainty Estimates in Deep Ensembles ",
		"abstract": "The inaccuracy of neural network models on inputs that do not stem from the training data distribution is both problematic and at times unrecognized. Model uncertainty estimation can address this issue, where uncertainty estimates are often based on the variation in predictions produced by a diverse ensemble of models applied to the same input. Here we describe Maximize Overall Diversity (MOD), a straightforward approach to improve ensemble-based uncertainty estimates by encouraging larger overall diversity in ensemble predictions across all possible inputs that might be encountered in the future. When applied to various neural network ensembles, MOD significantly improves predictive performance for out-of-distribution test examples without sacrificing in-distribution performance on 38 Protein-DNA binding regression datasets, 9 UCI datasets, and the IMDB-Wiki image dataset. Across many Bayesian optimization tasks, the performance of UCB acquisition is also greatly improved by leveraging MOD uncertainty estimates.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.07380v2"
	},
	{
		"title": "Facial Action Unit Intensity Estimation via Semantic Correspondence Learning with Dynamic Graph Convolution ",
		"abstract": "The intensity estimation of facial action units (AUs) is challenging due to subtle changes in the person's facial appearance. Previous approaches mainly rely on probabilistic models or predefined rules for modeling co-occurrence relationships among AUs, leading to limited generalization. In contrast, we present a new learning framework that automatically learns the latent relationships of AUs via establishing semantic correspondences between feature maps. In the heatmap regression-based network, feature maps preserve rich semantic information associated with AU intensities and locations. Moreover, the AU co-occurring pattern can be reflected by activating a set of feature channels, where each channel encodes a specific visual pattern of AU. This motivates us to model the correlation among feature channels, which implicitly represents the co-occurrence relationship of AU intensity levels. Specifically, we introduce a semantic correspondence convolution (SCC) module to dynamically compute the correspondences from deep and low resolution feature maps, and thus enhancing the discriminability of features. The experimental results demonstrate the effectiveness and the superior performance of our method on two benchmark datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.09681v1"
	},
	{
		"title": "Complementary Auxiliary Classifiers for Label‐Conditional Text Generation  ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Robust Adversarial Training Approach to Machine Reading Comprehension ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deep Residual‐Dense Lattice Network for Speech Enhancement ",
		"abstract": "Convolutional neural networks (CNNs) with residual links (ResNets) and causal dilated convolutional units have been the network of choice for deep learning approaches to speech enhancement. While residual links improve gradient flow during training, feature diminution of shallow layer outputs can occur due to repetitive summations with deeper layer outputs. One strategy to improve feature re-usage is to fuse both ResNets and densely connected CNNs (DenseNets). DenseNets, however, over-allocate parameters for feature re-usage. Motivated by this, we propose the residual-dense lattice network (RDL-Net), which is a new CNN for speech enhancement that employs both residual and dense aggregations without over-allocating parameters for feature re-usage. This is managed through the topology of the RDL blocks, which limit the number of outputs used for dense aggregations. Our extensive experimental investigation shows that RDL-Nets are able to achieve a higher speech enhancement performance than CNNs that employ residual and/or dense aggregations. RDL-Nets also use substantially fewer parameters and have a lower computational requirement. Furthermore, we demonstrate that RDL-Nets outperform many state-of-the-art deep learning approaches to speech enhancement.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.12794v1"
	},
	{
		"title": "AlignFlow: Cycle Consistent Learning from Multiple Domains via Normalizing Flows ",
		"abstract": "Given datasets from multiple domains, a key challenge is to efficiently exploit these data sources for modeling a target domain. Variants of this problem have been studied in many contexts, such as cross-domain translation and domain adaptation. We propose AlignFlow, a generative modeling framework that models each domain via a normalizing flow. The use of normalizing flows allows for a) flexibility in specifying learning objectives via adversarial training, maximum likelihood estimation, or a hybrid of the two methods; and b) learning and exact inference of a shared representation in the latent space of the generative model. We derive a uniform set of conditions under which AlignFlow is marginally-consistent for the different learning objectives. Furthermore, we show that AlignFlow guarantees exact cycle consistency in mapping datapoints from a source domain to target and back to the source domain. Empirically, AlignFlow outperforms relevant baselines on image-to-image translation and unsupervised domain adaptation and can be used to simultaneously interpolate across the various domains using the learned representation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.12892v2"
	},
	{
		"title": "Just ask: An Interactive Learning Framework for Vision and Language Navigation ",
		"abstract": "In the vision and language navigation task, the agent may encounter ambiguous situations that are hard to interpret by just relying on visual information and natural language instructions. We propose an interactive learning framework to endow the agent with the ability to ask for users' help in such situations. As part of this framework, we investigate multiple learning approaches for the agent with different levels of complexity. The simplest model-confusion-based method lets the agent ask questions based on its confusion, relying on the predefined confidence threshold of a next action prediction model. To build on this confusion-based method, the agent is expected to demonstrate more sophisticated reasoning such that it discovers the timing and locations to interact with a human. We achieve this goal using reinforcement learning (RL) with a proposed reward shaping term, which enables the agent to ask questions only when necessary. The success rate can be boosted by at least 15% with only one question asked on average during the navigation. Furthermore, we show that the RL agent is capable of adjusting dynamically to noisy human responses. Finally, we design a continual learning strategy, which can be viewed as a data augmentation method, for the agent to improve further utilizing its interaction history with a human. We demonstrate the proposed strategy is substantially more realistic and data-efficient compared to previously proposed pre-exploration techniques.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00915v1"
	},
	{
		"title": "Learning Feature Interactions with Lorentzian Factorization Machine ",
		"abstract": "Learning representations for feature interactions to model user behaviors is critical for recommendation system and click-trough rate (CTR) predictions. Recent advances in this area are empowered by deep learning methods which could learn sophisticated feature interactions and achieve the state-of-the-art result in an end-to-end manner. These approaches require large number of training parameters integrated with the low-level representations, and thus are memory and computational inefficient. In this paper, we propose a new model named \"LorentzFM\" that can learn feature interactions embedded in a hyperbolic space in which the violation of triangle inequality for Lorentz distances is available. To this end, the learned representation is benefited by the peculiar geometric properties of hyperbolic triangles, and result in a significant reduction in the number of parameters (20\\% to 80\\%) because all the top deep learning layers are not required. With such a lightweight architecture, LorentzFM achieves comparable and even materially better results than the deep learning methods such as DeepFM, xDeepFM and Deep \\& Cross in both recommendation and CTR prediction tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09821v1"
	},
	{
		"title": "Robustness Certificates for Sparse Adversarial Attacks by Randomized Ablation ",
		"abstract": "Recently, techniques have been developed to provably guarantee the robustness of a classifier to adversarial perturbations of bounded L_1 and L_2 magnitudes by using randomized smoothing: the robust classification is a consensus of base classifications on randomly noised samples where the noise is additive. In this paper, we extend this technique to the L_0 threat model. We propose an efficient and certifiably robust defense against sparse adversarial attacks by randomly ablating input features, rather than using additive noise. Experimentally, on MNIST, we can certify the classifications of over 50% of images to be robust to any distortion of at most 8 pixels. This is comparable to the observed empirical robustness of unprotected classifiers on MNIST to modern L_0 attacks, demonstrating the tightness of the proposed robustness certificate. We also evaluate our certificate on ImageNet and CIFAR-10. Our certificates represent an improvement on those provided in a concurrent work (Lee et al. 2019) which uses random noise rather than ablation (median certificates of 8 pixels versus 4 pixels on MNIST; 16 pixels versus 1 pixel on ImageNet.) Additionally, we empirically demonstrate that our classifier is highly robust to modern sparse adversarial attacks on MNIST. Our classifications are robust, in median, to adversarial perturbations of up to 31 pixels, compared to 22 pixels reported as the state-of-the-art defense, at the cost of a slight decrease (around 2.3%) in the classification accuracy. Code is available at https://github.com/alevine0/randomizedAblation/.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09272v1"
	},
	{
		"title": "New Interpretations of Normalization Methods in Deep Learning ",
		"abstract": "In recent years, a variety of normalization methods have been proposed to help train neural networks, such as batch normalization (BN), layer normalization (LN), weight normalization (WN), group normalization (GN), etc. However, mathematical tools to analyze all these normalization methods are lacking. In this paper, we first propose a lemma to define some necessary tools. Then, we use these tools to make a deep analysis on popular normalization methods and obtain the following conclusions: 1) Most of the normalization methods can be interpreted in a unified framework, namely normalizing pre-activations or weights onto a sphere; 2) Since most of the existing normalization methods are scaling invariant, we can conduct optimization on a sphere with scaling symmetry removed, which can help stabilize the training of network; 3) We prove that training with these normalization methods can make the norm of weights increase, which could cause adversarial vulnerability as it amplifies the attack. Finally, a series of experiments are conducted to verify these claims.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.09104v1"
	},
	{
		"title": "Knowledge‐Enriched Visual Storytelling ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Building Calibrated Deep Models via Uncertainty Matching with Auxiliary Interval Predictors ",
		"abstract": "With rapid adoption of deep learning in critical applications, the question of when and how much to trust these models often arises, which drives the need to quantify the inherent uncertainties. While identifying all sources that account for the stochasticity of models is challenging, it is common to augment predictions with confidence intervals to convey the expected variations in a model's behavior. We require prediction intervals to be well-calibrated, reflect the true uncertainties, and to be sharp. However, existing techniques for obtaining prediction intervals are known to produce unsatisfactory results in at least one of these criteria. To address this challenge, we develop a novel approach for building calibrated estimators. More specifically, we use separate models for prediction and interval estimation, and pose a bi-level optimization problem that allows the former to leverage estimates from the latter through an \\textit{uncertainty matching} strategy. Using experiments in regression, time-series forecasting, and object localization, we show that our approach achieves significant improvements over existing uncertainty quantification methods, both in terms of model fidelity and calibration error.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.04079v2"
	},
	{
		"title": "CD‐UAP: Class Discriminative Universal Adversarial Perturbation ",
		"abstract": "A single universal adversarial perturbation (UAP) can be added to all natural images to change most of their predicted class labels. It is of high practical relevance for an attacker to have flexible control over the targeted classes to be attacked, however, the existing UAP method attacks samples from all classes. In this work, we propose a new universal attack method to generate a single perturbation that fools a target network to misclassify only a chosen group of classes, while having limited influence on the remaining classes. Since the proposed attack generates a universal adversarial perturbation that is discriminative to targeted and non-targeted classes, we term it class discriminative universal adversarial perturbation (CD-UAP). We propose one simple yet effective algorithm framework, under which we design and compare various loss function configurations tailored for the class discriminative universal attack. The proposed approach has been evaluated with extensive experiments on various benchmark datasets. Additionally, our proposed approach achieves state-of-the-art performance for the original task of UAP attacking all classes, which demonstrates the effectiveness of our approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2010.03300v1"
	},
	{
		"title": "A Human‐AI Loop Approach for Joint Keyword Discovery and Expectation Estimation in Micropost Event Detection ",
		"abstract": "Microblogging platforms such as Twitter are increasingly being used in event detection. Existing approaches mainly use machine learning models and rely on event-related keywords to collect the data for model training. These approaches make strong assumptions on the distribution of the relevant micro-posts containing the keyword -- referred to as the expectation of the distribution -- and use it as a posterior regularization parameter during model training. Such approaches are, however, limited as they fail to reliably estimate the informativeness of a keyword and its expectation for model training. This paper introduces a Human-AI loop approach to jointly discover informative keywords for model training while estimating their expectation. Our approach iteratively leverages the crowd to estimate both keyword specific expectation and the disagreement between the crowd and the model in order to discover new keywords that are most beneficial for model training. These keywords and their expectation not only improve the resulting performance but also make the model training process more transparent. We empirically demonstrate the merits of our approach, both in terms of accuracy and interpretability, on multiple real-world datasets and show that our approach improves the state of the art by 24.3%.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00667v1"
	},
	{
		"title": "Adversary for Social Good: Protecting Familial Privacy through Joint Adversarial Attacks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Entrainment2Vec: Embedding Entrainment  for Multi‐party Dialogues ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Metareasoning in Modular Software Systems: On‐the‐Fly Configuration Using Reinforcement Learning with Rich Contextual Representations ",
		"abstract": "Assemblies of modular subsystems are being pressed into service to perform sensing, reasoning, and decision making in high-stakes, time-critical tasks in such areas as transportation, healthcare, and industrial automation. We address the opportunity to maximize the utility of an overall computing system by employing reinforcement learning to guide the configuration of the set of interacting modules that comprise the system. The challenge of doing system-wide optimization is a combinatorial problem. Local attempts to boost the performance of a specific module by modifying its configuration often leads to losses in overall utility of the system's performance as the distribution of inputs to downstream modules changes drastically. We present metareasoning techniques which consider a rich representation of the input, monitor the state of the entire pipeline, and adjust the configuration of modules on-the-fly so as to maximize the utility of a system's operation. We show significant improvement in both real-world and synthetic pipelines across a variety of reinforcement learning techniques.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.05179v1"
	},
	{
		"title": "Long‐Term Loop Closure Detection through Visual‐Spatial Information Preserving Multi‐Order Graph Matching ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Localize, Assemble, and Predicate: Contextual Object Proposal Embedding for Visual Relation Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "To Signal or Not To Signal: Exploiting Uncertain Real‐Time Information in Signaling Games for Security and Sustainability ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐view Consistency for Relation Extraction via Mutual Information and Structure Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Tensor Completion for Weakly‐dependent Data on Graph for Metro Passenger Flow Prediction ",
		"abstract": "Low-rank tensor decomposition and completion have attracted significant interest from academia given the ubiquity of tensor data. However, the low-rank structure is a global property, which will not be fulfilled when the data presents complex and weak dependencies given specific graph structures. One particular application that motivates this study is the spatiotemporal data analysis. As shown in the preliminary study, weakly dependencies can worsen the low-rank tensor completion performance. In this paper, we propose a novel low-rank CANDECOMP / PARAFAC (CP) tensor decomposition and completion framework by introducing the $L_{1}$-norm penalty and Graph Laplacian penalty to model the weakly dependency on graph. We further propose an efficient optimization algorithm based on the Block Coordinate Descent for efficient estimation. A case study based on the metro passenger flow data in Hong Kong is conducted to demonstrate improved performance over the regular tensor completion methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05693v1"
	},
	{
		"title": "Optimal Contract with Heterogeneous Agents ",
		"abstract": "We consider the principal-agent problem with heterogeneous agents. Previous works assume that the principal signs independent incentive contracts with every agent to make them invest more efforts on the tasks. However, in many circumstances, these contracts need to be identical for the sake of fairness. We investigate the optimal common contract problem. To our knowledge, this is the first attempt to consider this natural and important generalization. We first show this problem is NP-complete. Then we provide a dynamic programming algorithm to compute the optimal contract in $O(n^2m)$ time, where $n,m$ are the number of agents and actions, under the assumption that the agents' cost functions obey increasing difference property. At last, we generalize the setting such that each agent can choose to directly produce a reward in $[0,1]$. We provide an $O(\\log n)$-approximate algorithm for this generalization.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04146v1"
	},
	{
		"title": "Age Progression and Regression with Spatial Attention Modules ",
		"abstract": "Age progression and regression refers to aesthetically render-ing a given face image to present effects of face aging and rejuvenation, respectively. Although numerous studies have been conducted in this topic, there are two major problems: 1) multiple models are usually trained to simulate different age mappings, and 2) the photo-realism of generated face images is heavily influenced by the variation of training images in terms of pose, illumination, and background. To address these issues, in this paper, we propose a framework based on conditional Generative Adversarial Networks (cGANs) to achieve age progression and regression simultaneously. Particularly, since face aging and rejuvenation are largely different in terms of image translation patterns, we model these two processes using two separate generators, each dedicated to one age changing process. In addition, we exploit spatial attention mechanisms to limit image modifications to regions closely related to age changes, so that images with high visual fidelity could be synthesized for in-the-wild cases. Experiments on multiple datasets demonstrate the ability of our model in synthesizing lifelike face images at desired ages with personalized features well preserved, and keeping age-irrelevant regions unchanged.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.02133v2"
	},
	{
		"title": "Tensorized LSTM with Adaptive Shared Memory for Learning Trends in Multivariate Time Series ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Using the Chase to Reason over Ontologies of Existential Rules with Equality ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MMM: Multi‐stage Multi‐task Learning for Multi‐choice Reading Comprehension ",
		"abstract": "Machine Reading Comprehension (MRC) for question answering (QA), which aims to answer a question given the relevant context passages, is an important way to test the ability of intelligence systems to understand human language. Multiple-Choice QA (MCQA) is one of the most difficult tasks in MRC because it often requires more advanced reading comprehension skills such as logical reasoning, summarization, and arithmetic operations, compared to the extractive counterpart where answers are usually spans of text within given passages. Moreover, most existing MCQA datasets are small in size, making the learning task even harder. We introduce MMM, a Multi-stage Multi-task learning framework for Multi-choice reading comprehension. Our method involves two sequential stages: coarse-tuning stage using out-of-domain datasets and multi-task learning stage using a larger in-domain dataset to help model generalize better with limited data. Furthermore, we propose a novel multi-step attention network (MAN) as the top-level classifier for this task. We demonstrate MMM significantly advances the state-of-the-art on four representative MCQA datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.00458v2"
	},
	{
		"title": "Learning Signed Network Embedding via Graph Attention ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Revisiting Probability Distribution Assumptions for Information Theoretic Feature Selection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Select Bi‐Aspect Information for Document‐Scale Text Content Manipulation ",
		"abstract": "In this paper, we focus on a new practical task, document-scale text content manipulation, which is the opposite of text style transfer and aims to preserve text styles while altering the content. In detail, the input is a set of structured records and a reference text for describing another recordset. The output is a summary that accurately describes the partial content in the source recordset with the same writing style of the reference. The task is unsupervised due to lack of parallel data, and is challenging to select suitable records and style words from bi-aspect inputs respectively and generate a high-fidelity long document. To tackle those problems, we first build a dataset based on a basketball game report corpus as our testbed, and present an unsupervised neural model with interactive attention mechanism, which is used for learning the semantic relationship between records and reference texts to achieve better content transfer and better style preservation. In addition, we also explore the effectiveness of the back-translation in our task for constructing some pseudo-training pairs. Empirical results show superiority of our approaches over competitive methods, and the models also yield a new state-of-the-art result on a sentence-level dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.10210v1"
	},
	{
		"title": "Adapting Language Models for Non‐Parallel Author‐Stylized Rewriting ",
		"abstract": "Given the recent progress in language modeling using Transformer-based neural models and an active interest in generating stylized text, we present an approach to leverage the generalization capabilities of a language model to rewrite an input text in a target author's style. Our proposed approach adapts a pre-trained language model to generate author-stylized text by fine-tuning on the author-specific corpus using a denoising autoencoder (DAE) loss in a cascaded encoder-decoder framework. Optimizing over DAE loss allows our model to learn the nuances of an author's style without relying on parallel data, which has been a severe limitation of the previous related works in this space. To evaluate the efficacy of our approach, we propose a linguistically-motivated framework to quantify stylistic alignment of the generated text to the target author at lexical, syntactic and surface levels. The evaluation framework is both interpretable as it leads to several insights about the model, and self-contained as it does not rely on external classifiers, e.g. sentiment or formality classifiers. Qualitative and quantitative assessment indicates that the proposed approach rewrites the input text with better alignment to the target style while preserving the original content better than state-of-the-art baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.09962v3"
	},
	{
		"title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment ",
		"abstract": "Machine learning algorithms are often vulnerable to adversarial examples that have imperceptible alterations from the original counterparts but can fool the state-of-the-art models. It is helpful to evaluate or even improve the robustness of these models by exposing the maliciously crafted adversarial examples. In this paper, we present TextFooler, a simple but strong baseline to generate natural adversarial text. By applying it to two fundamental natural language tasks, text classification and textual entailment, we successfully attacked three target models, including the powerful pre-trained BERT, and the widely used convolutional and recurrent neural networks. We demonstrate the advantages of this framework in three ways: (1) effective---it outperforms state-of-the-art attacks in terms of success rate and perturbation rate, (2) utility-preserving---it preserves semantic content and grammaticality, and remains correctly classified by humans, and (3) efficient---it generates adversarial text with computational complexity linear to the text length. *The code, pre-trained target models, and test examples are available at https://github.com/jind11/TextFooler.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.11932v6"
	},
	{
		"title": "Multi‐scale Anomaly Detection on Attributed Networks ",
		"abstract": "Many social and economic systems can be represented as attributed networks encoding the relations between entities who are themselves described by different node attributes. Finding anomalies in these systems is crucial for detecting abuses such as credit card frauds, web spams or network intrusions. Intuitively, anomalous nodes are defined as nodes whose attributes differ starkly from the attributes of a certain set of nodes of reference, called the context of the anomaly. While some methods have proposed to spot anomalies locally, globally or within a community context, the problem remain challenging due to the multi-scale composition of real networks and the heterogeneity of node metadata. Here, we propose a principled way to uncover outlier nodes simultaneously with the context with respect to which they are anomalous, at all relevant scales of the network. We characterize anomalous nodes in terms of the concentration retained for each node after smoothing specific signals localized on the vertices of the graph. Besides, we introduce a graph signal processing formulation of the Markov stability framework used in community detection, in order to find the context of anomalies. The performance of our method is assessed on synthetic and real-world attributed networks and shows superior results concerning state of the art algorithms. Finally, we show the scalability of our approach in large networks employing Chebychev polynomial approximations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.04144v1"
	},
	{
		"title": "MultiSumm: Towards a Unified Model for Multi‐Lingual Abstractive Summarization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Understanding the semantic content of sparse word embeddings using a commonsense knowledge base ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Order‐free Learning Alleviating Exposure Bias in Multi‐label Classification ",
		"abstract": "Multi-label classification (MLC) assigns multiple labels to each sample. Prior studies show that MLC can be transformed to a sequence prediction problem with a recurrent neural network (RNN) decoder to model the label dependency. However, training a RNN decoder requires a predefined order of labels, which is not directly available in the MLC specification. Besides, RNN thus trained tends to overfit the label combinations in the training set and have difficulty generating unseen label sequences. In this paper, we propose a new framework for MLC which does not rely on a predefined label order and thus alleviates exposure bias. The experimental results on three multi-label classification benchmark datasets show that our method outperforms competitive baselines by a large margin. We also find the proposed approach has a higher probability of generating label combinations not seen during training than the baseline models. The result shows that the proposed approach has better generalization capability.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03434v1"
	},
	{
		"title": "Reasoning with Heterogeneous Graph Alignment for Video Question Answering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Table2Analysis: Modeling and Recommendation of Common Analysis Patterns for Multi‐Dimensional Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Dynamic Programming for Predict+Optimise ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Practical Frank‐‐Wolfe Method with Decision Diagrams for Computing Wardrop Equilibrium of Combinatorial Congestion Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neural Inheritance Relation Guided One‐Shot Layer Assignment Search ",
		"abstract": "Layer assignment is seldom picked out as an independent research topic in neural architecture search. In this paper, for the first time, we systematically investigate the impact of different layer assignments to the network performance by building an architecture dataset of layer assignment on CIFAR-100. Through analyzing this dataset, we discover a neural inheritance relation among the networks with different layer assignments, that is, the optimal layer assignments for deeper networks always inherit from those for shallow networks. Inspired by this neural inheritance relation, we propose an efficient one-shot layer assignment search approach via inherited sampling. Specifically, the optimal layer assignment searched in the shallow network can be provided as a strong sampling priori to train and search the deeper ones in supernet, which extremely reduces the network search space. Comprehensive experiments carried out on CIFAR-100 illustrate the efficiency of our proposed method. Our search results are strongly consistent with the optimal ones directly selected from the architecture dataset. To further confirm the generalization of our proposed method, we also conduct experiments on Tiny-ImageNet and ImageNet. Our searched results are remarkably superior to the handcrafted ones under the unchanged computational budgets. The neural inheritance relation discovered in this paper can provide insights to the universal neural architecture search.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.12580v1"
	},
	{
		"title": "ActiveThief: Model Extraction Using Active Learning and Unannotated Public Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "New Efficient Multi‐Spike Learning for Fast Processing and Robust Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generalize Sentence Representation with Self‐Inference ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Representative Solutions for Bi‐Objective Optimisation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Neural Machine Translation with Joint Representation ",
		"abstract": "Though early successes of Statistical Machine Translation (SMT) systems are attributed in part to the explicit modelling of the interaction between any two source and target units, e.g., alignment, the recent Neural Machine Translation (NMT) systems resort to the attention which partially encodes the interaction for efficiency. In this paper, we employ Joint Representation that fully accounts for each possible interaction. We sidestep the inefficiency issue by refining representations with the proposed efficient attention operation. The resulting Reformer models offer a new Sequence-to- Sequence modelling paradigm besides the Encoder-Decoder framework and outperform the Transformer baseline in either the small scale IWSLT14 German-English, English-German and IWSLT15 Vietnamese-English or the large scale NIST12 Chinese-English translation tasks by about 1 BLEU point.We also propose a systematic model scaling approach, allowing the Reformer model to beat the state-of-the-art Transformer in IWSLT14 German-English and NIST12 Chinese-English with about 50% fewer parameters. The code is publicly available at https://github.com/lyy1994/reformer.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06546v2"
	},
	{
		"title": "Multi‐level Head‐wise Match and Aggregation in Transformer for Textual Sequence Matching ",
		"abstract": "Transformer has been successfully applied to many natural language processing tasks. However, for textual sequence matching, simple matching between the representation of a pair of sequences might bring in unnecessary noise. In this paper, we propose a new approach to sequence pair matching with Transformer, by learning head-wise matching representations on multiple levels. Experiments show that our proposed approach can achieve new state-of-the-art performance on multiple tasks that rely only on pre-computed sequence-vector-representation, such as SNLI, MNLI-match, MNLI-mismatch, QQP, and SQuAD-binary.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.07234v1"
	},
	{
		"title": "Observe Before Play: Multi‐armed Bandit with Pre‐observations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "AirNet: A Calibration Model for Low‐Cost Air Monitoring Sensors Using Dual Sequence Encoder Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Filling Conversation Ellipsis for Better Social Dialog Understanding ",
		"abstract": "The phenomenon of ellipsis is prevalent in social conversations. Ellipsis increases the difficulty of a series of downstream language understanding tasks, such as dialog act prediction and semantic role labeling. We propose to resolve ellipsis through automatic sentence completion to improve language understanding. However, automatic ellipsis completion can result in output which does not accurately reflect user intent. To address this issue, we propose a method which considers both the original utterance that has ellipsis and the automatically completed utterance in dialog act and semantic role labeling tasks. Specifically, we first complete user utterances to resolve ellipsis using an end-to-end pointer network model. We then train a prediction model using both utterances containing ellipsis and our automatically completed utterances. Finally, we combine the prediction results from these two utterances using a selection model that is guided by expert knowledge. Our approach improves dialog act prediction and semantic role labeling by 1.3% and 2.5% in F1 score respectively in social conversations. We also present an open-domain human-machine conversation dataset with manually completed user utterances and annotated semantic role labeling after manual completion.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10776v1"
	},
	{
		"title": "Functionality Discovery and Prediction of Physical Objects ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fine‐grained Recognition: Accounting for Subtle Differences between Similar Classes ",
		"abstract": "The main requisite for fine-grained recognition task is to focus on subtle discriminative details that make the subordinate classes different from each other. We note that existing methods implicitly address this requirement and leave it to a data-driven pipeline to figure out what makes a subordinate class different from the others. This results in two major limitations: First, the network focuses on the most obvious distinctions between classes and overlooks more subtle inter-class variations. Second, the chance of misclassifying a given sample in any of the negative classes is considered equal, while in fact, confusions generally occur among only the most similar classes. Here, we propose to explicitly force the network to find the subtle differences among closely related classes. In this pursuit, we introduce two key novelties that can be easily plugged into existing end-to-end deep learning pipelines. On one hand, we introduce diversification block which masks the most salient features for an input to force the network to use more subtle cues for its correct classification. Concurrently, we introduce a gradient-boosting loss function that focuses only on the confusing classes for each sample and therefore moves swiftly along the direction on the loss surface that seeks to resolve these ambiguities. The synergy between these two blocks helps the network to learn more effective feature representations. Comprehensive experiments are performed on five challenging datasets. Our approach outperforms existing methods using similar experimental setting on all five datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06842v1"
	},
	{
		"title": "An Efficient Explorative Sampling considering the Generative Boundaries of Deep Generative Neural Networks ",
		"abstract": "Deep generative neural networks (DGNNs) have achieved realistic and high-quality data generation. In particular, the adversarial training scheme has been applied to many DGNNs and has exhibited powerful performance. Despite of recent advances in generative networks, identifying the image generation mechanism still remains challenging. In this paper, we present an explorative sampling algorithm to analyze generation mechanism of DGNNs. Our method efficiently obtains samples with identical attributes from a query image in a perspective of the trained model. We define generative boundaries which determine the activation of nodes in the internal layer and probe inside the model with this information. To handle a large number of boundaries, we obtain the essential set of boundaries using optimization. By gathering samples within the region surrounded by generative boundaries, we can empirically reveal the characteristics of the internal layers of DGNNs. We also demonstrate that our algorithm can find more homogeneous, the model specific samples compared to the variations of {\\epsilon}-based sampling method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05827v1"
	},
	{
		"title": "Variational Inference for Sparse Gaussian Process Modulated Hawkes Process ",
		"abstract": "The Hawkes process (HP) has been widely applied to modeling self-exciting events including neuron spikes, earthquakes and tweets. To avoid designing parametric triggering kernel and to be able to quantify the prediction confidence, the non-parametric Bayesian HP has been proposed. However, the inference of such models suffers from unscalability or slow convergence. In this paper, we aim to solve both problems. Specifically, first, we propose a new non-parametric Bayesian HP in which the triggering kernel is modeled as a squared sparse Gaussian process. Then, we propose a novel variational inference schema for model optimization. We employ the branching structure of the HP so that maximization of evidence lower bound (ELBO) is tractable by the expectation-maximization algorithm. We propose a tighter ELBO which improves the fitting performance. Further, we accelerate the novel variational inference schema to linear time complexity by leveraging the stationarity of the triggering kernel. Different from prior acceleration methods, ours enjoys higher efficiency. Finally, we exploit synthetic data and two large social media datasets to evaluate our method. We show that our approach outperforms state-of-the-art non-parametric frequentist and Bayesian methods. We validate the efficiency of our accelerated variational inference schema and practical utility of our tighter ELBO for model selection. We observe that the tighter ELBO exceeds the common one in model selection.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10496v2"
	},
	{
		"title": "An End‐to‐End Visual‐Audio Attention Network for Emotion Recognition in User‐Generated Videos ",
		"abstract": "Emotion recognition in user-generated videos plays an important role in human-centered computing. Existing methods mainly employ traditional two-stage shallow pipeline, i.e. extracting visual and/or audio features and training classifiers. In this paper, we propose to recognize video emotions in an end-to-end manner based on convolutional neural networks (CNNs). Specifically, we develop a deep Visual-Audio Attention Network (VAANet), a novel architecture that integrates spatial, channel-wise, and temporal attentions into a visual 3D CNN and temporal attentions into an audio 2D CNN. Further, we design a special classification loss, i.e. polarity-consistent cross-entropy loss, based on the polarity-emotion hierarchy constraint to guide the attention generation. Extensive experiments conducted on the challenging VideoEmotion-8 and Ekman-6 datasets demonstrate that the proposed VAANet outperforms the state-of-the-art approaches for video emotion recognition. Our source code is released at: https://github.com/maysonma/VAANet.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.00832v1"
	},
	{
		"title": "Discriminative Sentence Modeling for Story Ending Prediction ",
		"abstract": "Story Ending Prediction is a task that needs to select an appropriate ending for the given story, which requires the machine to understand the story and sometimes needs commonsense knowledge. To tackle this task, we propose a new neural network called Diff-Net for better modeling the differences of each ending in this task. The proposed model could discriminate two endings in three semantic levels: contextual representation, story-aware representation, and discriminative representation. Experimental results on the Story Cloze Test dataset show that the proposed model siginificantly outperforms various systems by a large margin, and detailed ablation studies are given for better understanding our model. We also carefully examine the traditional and BERT-based models on both SCT v1.0 and v1.5 with interesting findings that may potentially help future studies.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.09008v1"
	},
	{
		"title": "Multi‐label Patent Categorization with Non‐local Attention‐based Graph Convolutional Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Cluster‐Weighted Kernel K‐Means Method for Multi‐View Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Joint Model for Definition Extraction with Syntactic Connection and Semantic Consistency ",
		"abstract": "Definition Extraction (DE) is one of the well-known topics in Information Extraction that aims to identify terms and their corresponding definitions in unstructured texts. This task can be formalized either as a sentence classification task (i.e., containing term-definition pairs or not) or a sequential labeling task (i.e., identifying the boundaries of the terms and definitions). The previous works for DE have only focused on one of the two approaches, failing to model the inter-dependencies between the two tasks. In this work, we propose a novel model for DE that simultaneously performs the two tasks in a single framework to benefit from their inter-dependencies. Our model features deep learning architectures to exploit the global structures of the input sentences as well as the semantic consistencies between the terms and the definitions, thereby improving the quality of the representation vectors for DE. Besides the joint inference between sentence classification and sequential labeling, the proposed model is fundamentally different from the prior work for DE in that the prior work has only employed the local structures of the input sentences (i.e., word-to-word relations), and not yet considered the semantic consistencies between terms and definitions. In order to implement these novel ideas, our model presents a multi-task learning framework that employs graph convolutional neural networks and predicts the dependency paths between the terms and the definitions. We also seek to enforce the consistency between the representations of the terms and definitions both globally (i.e., increasing semantic consistency between the representations of the entire sentences and the terms/definitions) and locally (i.e., promoting the similarity between the representations of the terms and the definitions).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.01678v4"
	},
	{
		"title": "Symmetric Metric Learning with Adaptive Margin for Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DefogGAN: Predicting Hidden Information in the StarCraft Fog of War with Generative Adversarial Nets ",
		"abstract": "We propose DefogGAN, a generative approach to the problem of inferring state information hidden in the fog of war for real-time strategy (RTS) games. Given a partially observed state, DefogGAN generates defogged images of a game as predictive information. Such information can lead to create a strategic agent for the game. DefogGAN is a conditional GAN variant featuring pyramidal reconstruction loss to optimize on multiple feature resolution scales.We have validated DefogGAN empirically using a large dataset of professional StarCraft replays. Our results indicate that DefogGAN can predict the enemy buildings and combat units as accurately as professional players do and achieves a superior performance among state-of-the-art defoggers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.01927v2"
	},
	{
		"title": "Deep Embedded Non‐Redundant Clustering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cross‐lingual Pre‐training Based Transfer for Zero‐shot Neural Machine Translation ",
		"abstract": "Transfer learning between different language pairs has shown its effectiveness for Neural Machine Translation (NMT) in low-resource scenario. However, existing transfer methods involving a common target language are far from success in the extreme scenario of zero-shot translation, due to the language space mismatch problem between transferor (the parent model) and transferee (the child model) on the source side. To address this challenge, we propose an effective transfer learning approach based on cross-lingual pre-training. Our key idea is to make all source languages share the same feature space and thus enable a smooth transition for zero-shot translation. To this end, we introduce one monolingual pre-training method and two bilingual pre-training methods to obtain a universal encoder for different languages. Once the universal encoder is constructed, the parent model built on such encoder is trained with large-scale annotated data and then directly applied in zero-shot translation scenario. Experiments on two public datasets show that our approach significantly outperforms strong pivot-based baseline and various multilingual NMT approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01214v1"
	},
	{
		"title": "Theory‐based Causal Transfer: Integrating Instance‐level Induction and Abstract‐level Structure Learning ",
		"abstract": "Learning transferable knowledge across similar but different settings is a fundamental component of generalized intelligence. In this paper, we approach the transfer learning challenge from a causal theory perspective. Our agent is endowed with two basic yet general theories for transfer learning: (i) a task shares a common abstract structure that is invariant across domains, and (ii) the behavior of specific features of the environment remain constant across domains. We adopt a Bayesian perspective of causal theory induction and use these theories to transfer knowledge between environments. Given these general theories, the goal is to train an agent by interactively exploring the problem space to (i) discover, form, and transfer useful abstract and structural knowledge, and (ii) induce useful knowledge from the instance-level attributes observed in the environment. A hierarchy of Bayesian structures is used to model abstract-level structural causal knowledge, and an instance-level associative learning scheme learns which specific objects can be used to induce state changes through interaction. This model-learning scheme is then integrated with a model-based planner to achieve a task in the OpenLock environment, a virtual ``escape room'' with a complex hierarchy that requires agents to reason about an abstract, generalized causal structure. We compare performances against a set of predominate model-free reinforcement learning(RL) algorithms. RL agents showed poor ability transferring learned knowledge across different trials. Whereas the proposed model revealed similar performance trends as human learners, and more importantly, demonstrated transfer behavior across trials and learning situations.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11185v1"
	},
	{
		"title": "Introducing Probabilistic Bézier Curves for N‐Step Sequence Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Transfer Value Iteration Networks ",
		"abstract": "Value iteration networks (VINs) have been demonstrated to have a good generalization ability for reinforcement learning tasks across similar domains. However, based on our experiments, a policy learned by VINs still fail to generalize well on the domain whose action space and feature space are not identical to those in the domain where it is trained. In this paper, we propose a transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such that a learned policy from a source domain can be generalized to a target domain with only limited training data, even if the source domain and the target domain have domain-specific actions and features. We empirically verify that our proposed TVINs outperform VINs when the source and the target domains have similar but not identical action and feature spaces. Furthermore, we show that the performance improvement is consistent across different environments, maze sizes, dataset sizes as well as different values of hyperparameters such as number of iteration and kernel size.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05701v2"
	},
	{
		"title": "Scalable Attentive Sentence‐Pair Modeling via Distilled Sentence Embedding ",
		"abstract": "Recent state-of-the-art natural language understanding models, such as BERT and XLNet, score a pair of sentences (A and B) using multiple cross-attention operations - a process in which each word in sentence A attends to all words in sentence B and vice versa. As a result, computing the similarity between a query sentence and a set of candidate sentences, requires the propagation of all query-candidate sentence-pairs throughout a stack of cross-attention layers. This exhaustive process becomes computationally prohibitive when the number of candidate sentences is large. In contrast, sentence embedding techniques learn a sentence-to-vector mapping and compute the similarity between the sentence vectors via simple elementary operations. In this paper, we introduce Distilled Sentence Embedding (DSE) - a model that is based on knowledge distillation from cross-attentive models, focusing on sentence-pair tasks. The outline of DSE is as follows: Given a cross-attentive teacher model (e.g. a fine-tuned BERT), we train a sentence embedding based student model to reconstruct the sentence-pair scores obtained by the teacher model. We empirically demonstrate the effectiveness of DSE on five GLUE sentence-pair tasks. DSE significantly outperforms several ELMO variants and other sentence embedding methods, while accelerating computation of the query-candidate sentence-pairs similarities by several orders of magnitude, with an average relative degradation of 4.6% compared to BERT. Furthermore, we show that DSE produces sentence embeddings that reach state-of-the-art performance on universal sentence representation benchmarks. Our code is made publicly available at https://github.com/microsoft/Distilled-Sentence-Embedding.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.05161v3"
	},
	{
		"title": "SemSUM: Semantic Dependency Guided Neural Abstractive Summarization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Skip‐connected Evolving Recurrent Neural Network for Data Stream Classification under Label Latency Scenario ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "On the Expressivity of ASK Queries in SPARQL ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Aggregated Gradient Langevin Dynamics ",
		"abstract": "In this paper, we explore a general Aggregated Gradient Langevin Dynamics framework (AGLD) for the Markov Chain Monte Carlo (MCMC) sampling. We investigate the nonasymptotic convergence of AGLD with a unified analysis for different data accessing (e.g. random access, cyclic access and random reshuffle) and snapshot updating strategies, under convex and nonconvex settings respectively. It is the first time that bounds for I/O friendly strategies such as cyclic access and random reshuffle have been established in the MCMC literature. The theoretic results also indicate that methods in AGLD possess the merits of both the low per-iteration computational complexity and the short mixture time. Empirical studies demonstrate that our framework allows to derive novel schemes to generate high-quality samples for large-scale Bayesian posterior learning tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.09223v1"
	},
	{
		"title": "TreeGen: A Tree‐Based Transformer Architecture for Code Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Not All Attention Is Needed: Gated Attention Network for Sequence Data ",
		"abstract": "Although deep neural networks generally have fixed network structures, the concept of dynamic mechanism has drawn more and more attention in recent years. Attention mechanisms compute input-dependent dynamic attention weights for aggregating a sequence of hidden states. Dynamic network configuration in convolutional neural networks (CNNs) selectively activates only part of the network at a time for different inputs. In this paper, we combine the two dynamic mechanisms for text classification tasks. Traditional attention mechanisms attend to the whole sequence of hidden states for an input sentence, while in most cases not all attention is needed especially for long sequences. We propose a novel method called Gated Attention Network (GA-Net) to dynamically select a subset of elements to attend to using an auxiliary network, and compute attention weights to aggregate the selected elements. It avoids a significant amount of unnecessary computation on unattended elements, and allows the model to pay attention to important parts of the sequence. Experiments in various datasets show that the proposed method achieves better performance compared with all baseline models with global or local attention while requiring less computation and achieving better interpretability. It is also promising to extend the idea to more complex attention-based models, such as transformers and seq-to-seq models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00349v1"
	},
	{
		"title": "Coordinated Reasoning for Cross‐Lingual Knowledge Graph Alignment ",
		"abstract": "Existing entity alignment methods mainly vary on the choices of encoding the knowledge graph, but they typically use the same decoding method, which independently chooses the local optimal match for each source entity. This decoding method may not only cause the \"many-to-one\" problem but also neglect the coordinated nature of this task, that is, each alignment decision may highly correlate to the other decisions. In this paper, we introduce two coordinated reasoning methods, i.e., the Easy-to-Hard decoding strategy and joint entity alignment algorithm. Specifically, the Easy-to-Hard strategy first retrieves the model-confident alignments from the predicted results and then incorporates them as additional knowledge to resolve the remaining model-uncertain alignments. To achieve this, we further propose an enhanced alignment model that is built on the current state-of-the-art baseline. In addition, to address the many-to-one problem, we propose to jointly predict entity alignments so that the one-to-one constraint can be naturally incorporated into the alignment prediction. Experimental results show that our model achieves the state-of-the-art performance and our reasoning methods can also significantly improve existing baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.08728v1"
	},
	{
		"title": "Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "End‐to‐End Argumentation Knowledge Graph Construction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adversarial Training Based Multi‐Source Unsupervised Domain Adaptation for Sentiment Analysis ",
		"abstract": "Multi-source unsupervised domain adaptation (MS-UDA) for sentiment analysis (SA) aims to leverage useful information in multiple source domains to help do SA in an unlabeled target domain that has no supervised information. Existing algorithms of MS-UDA either only exploit the shared features, i.e., the domain-invariant information, or based on some weak assumption in NLP, e.g., smoothness assumption. To avoid these problems, we propose two transfer learning frameworks based on the multi-source domain adaptation methodology for SA by combining the source hypotheses to derive a good target hypothesis. The key feature of the first framework is a novel Weighting Scheme based Unsupervised Domain Adaptation framework (WS-UDA), which combine the source classifiers to acquire pseudo labels for target instances directly. While the second framework is a Two-Stage Training based Unsupervised Domain Adaptation framework (2ST-UDA), which further exploits these pseudo labels to train a target private extractor. Importantly, the weights assigned to each source classifier are based on the relations between target instances and source domains, which measured by a discriminator through the adversarial training. Furthermore, through the same discriminator, we also fulfill the separation of shared features and private features. Experimental results on two SA datasets demonstrate the promising performance of our frameworks, which outperforms unsupervised state-of-the-art competitors.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.05602v1"
	},
	{
		"title": "Back to the Future ‐‐ Sequential Alignment of Text Representations ",
		"abstract": "Language evolves over time in many ways relevant to natural language processing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO' in publications refer to neural network architectures rather than persons. This type of temporal signal is typically overlooked, but is important if one aims to deploy a machine learning model over an extended period of time. In particular, language evolution causes data drift between time-steps in sequential decision-making tasks. Examples of such tasks include prediction of paper acceptance for yearly conferences (regular intervals) or author stance prediction for rumours on Twitter (irregular intervals). Inspired by successes in computer vision, we tackle data drift by sequentially aligning learned representations. We evaluate on three challenging tasks varying in terms of time-scales, linguistic units, and domains. These tasks show our method outperforming several strong baselines, including using all available data. We argue that, due to its low computational expense, sequential alignment is a practical solution to dealing with language evolution.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03464v3"
	},
	{
		"title": "Learning MAX‐SAT from Contextual Examples for Combinatorial Optimisation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GlobalTrack: A Simple and Strong Baseline for Long‐term Tracking ",
		"abstract": "A key capability of a long-term tracker is to search for targets in very large areas (typically the entire image) to handle possible target absences or tracking failures. However, currently there is a lack of such a strong baseline for global instance search. In this work, we aim to bridge this gap. Specifically, we propose GlobalTrack, a pure global instance search based tracker that makes no assumption on the temporal consistency of the target's positions and scales. GlobalTrack is developed based on two-stage object detectors, and it is able to perform full-image and multi-scale search of arbitrary instances with only a single query as the guide. We further propose a cross-query loss to improve the robustness of our approach against distractors. With no online learning, no punishment on position or scale changes, no scale smoothing and no trajectory refinement, our pure global instance search based tracker achieves comparable, sometimes much better performance on four large-scale tracking benchmarks (i.e., 52.1% AUC on LaSOT, 63.8% success rate on TLP, 60.3% MaxGM on OxUvA and 75.4% normalized precision on TrackingNet), compared to state-of-the-art approaches that typically require complex post-processing. More importantly, our tracker runs without cumulative errors, i.e., any type of temporary tracking failures will not affect its performance on future frames, making it ideal for long-term tracking. We hope this work will be a strong baseline for long-term tracking and will stimulate future works in this area. Code is available at https://github.com/huanglianghua/GlobalTrack.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08531v1"
	},
	{
		"title": "Hierarchical Contextualized Representation  for Named Entity Recognition ",
		"abstract": "Named entity recognition (NER) models are typically based on the architecture of Bi-directional LSTM (BiLSTM). The constraints of sequential nature and the modeling of single input prevent the full utilization of global information from larger scope, not only in the entire sentence, but also in the entire document (dataset). In this paper, we address these two deficiencies and propose a model augmented with hierarchical contextualized representation: sentence-level representation and document-level representation. In sentence-level, we take different contributions of words in a single sentence into consideration to enhance the sentence representation learned from an independent BiLSTM via label embedding attention mechanism. In document-level, the key-value memory network is adopted to record the document-aware information for each unique word which is sensitive to similarity of context information. Our two-level hierarchical contextualized representations are fused with each input token embedding and corresponding hidden state of BiLSTM, respectively. The experimental results on three benchmark NER datasets (CoNLL-2003 and Ontonotes 5.0 English datasets, CoNLL-2002 Spanish dataset) show that we establish new state-of-the-art results.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.02257v2"
	},
	{
		"title": "Multi‐source Domain Adaptation for Visual Sentiment Classification ",
		"abstract": "Existing domain adaptation methods on visual sentiment classification typically are investigated under the single-source scenario, where the knowledge learned from a source domain of sufficient labeled data is transferred to the target domain of loosely labeled or unlabeled data. However, in practice, data from a single source domain usually have a limited volume and can hardly cover the characteristics of the target domain. In this paper, we propose a novel multi-source domain adaptation (MDA) method, termed Multi-source Sentiment Generative Adversarial Network (MSGAN), for visual sentiment classification. To handle data from multiple source domains, it learns to find a unified sentiment latent space where data from both the source and target domains share a similar distribution. This is achieved via cycle consistent adversarial learning in an end-to-end manner. Extensive experiments conducted on four benchmark datasets demonstrate that MSGAN significantly outperforms the state-of-the-art MDA approaches for visual sentiment classification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.03886v1"
	},
	{
		"title": "Discretizing Continuous Action Space for On‐Policy Optimization ",
		"abstract": "In this work, we show that discretizing action space for continuous control is a simple yet powerful technique for on-policy optimization. The explosion in the number of discrete actions can be efficiently addressed by a policy with factorized distribution across action dimensions. We show that the discrete policy achieves significant performance gains with state-of-the-art on-policy optimization algorithms (PPO, TRPO, ACKTR) especially on high-dimensional tasks with complex dynamics. Additionally, we show that an ordinal parameterization of the discrete distribution can introduce the inductive bias that encodes the natural ordering between discrete actions. This ordinal architecture further significantly improves the performance of PPO/TRPO.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.10500v4"
	},
	{
		"title": "An Efficient Evolutionary Algorithm for Subset Selection with General Cost Constraints ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐task Learning for Metaphor Detection with Graph Convolutional Neural Networks and Word Sense Disambiguation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Semi‐supervised Learning for Maximizing the Partial AUC ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Feature Discrete Collaborative Filtering for Fast Cold‐start Recommendation ",
		"abstract": "Hashing is an effective technique to address the large-scale recommendation problem, due to its high computation and storage efficiency on calculating the user preferences on items. However, existing hashing-based recommendation methods still suffer from two important problems: 1) Their recommendation process mainly relies on the user-item interactions and single specific content feature. When the interaction history or the content feature is unavailable (the cold-start problem), their performance will be seriously deteriorated. 2) Existing methods learn the hash codes with relaxed optimization or adopt discrete coordinate descent to directly solve binary hash codes, which results in significant quantization loss or consumes considerable computation time. In this paper, we propose a fast cold-start recommendation method, called Multi-Feature Discrete Collaborative Filtering (MFDCF), to solve these problems. Specifically, a low-rank self-weighted multi-feature fusion module is designed to adaptively project the multiple content features into binary yet informative hash codes by fully exploiting their complementarity. Additionally, we develop a fast discrete optimization algorithm to directly compute the binary hash codes with simple operations. Experiments on two public recommendation datasets demonstrate that MFDCF outperforms the state-of-the-arts on various aspects.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.10719v1"
	},
	{
		"title": "Generating Interactive Worlds with Text ",
		"abstract": "Procedurally generating cohesive and interesting game environments is challenging and time-consuming. In order for the relationships between the game elements to be natural, common-sense has to be encoded into arrangement of the elements. In this work, we investigate a machine learning approach for world creation using content from the multi-player text adventure game environment LIGHT. We introduce neural network based models to compositionally arrange locations, characters, and objects into a coherent whole. In addition to creating worlds based on existing elements, our models can generate new game content. Humans can also leverage our models to interactively aid in worldbuilding. We show that the game environments created with our approach are cohesive, diverse, and preferred by human evaluators compared to other machine learning based world construction algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09194v2"
	},
	{
		"title": "Multi‐Component Graph Convolutional Collaborative Filtering ",
		"abstract": "The interactions of users and items in recommender system could be naturally modeled as a user-item bipartite graph. In recent years, we have witnessed an emerging research effort in exploring user-item graph for collaborative filtering methods. Nevertheless, the formation of user-item interactions typically arises from highly complex latent purchasing motivations, such as high cost performance or eye-catching appearance, which are indistinguishably represented by the edges. The existing approaches still remain the differences between various purchasing motivations unexplored, rendering the inability to capture fine-grained user preference. Therefore, in this paper we propose a novel Multi-Component graph convolutional Collaborative Filtering (MCCF) approach to distinguish the latent purchasing motivations underneath the observed explicit user-item interactions. Specifically, there are two elaborately designed modules, decomposer and combiner, inside MCCF. The former first decomposes the edges in user-item graph to identify the latent components that may cause the purchasing relationship; the latter then recombines these latent components automatically to obtain unified embeddings for prediction. Furthermore, the sparse regularizer and weighted random sample strategy are utilized to alleviate the overfitting problem and accelerate the optimization. Empirical results on three real datasets and a synthetic dataset not only show the significant performance gains of MCCF, but also well demonstrate the necessity of considering multiple components.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10699v1"
	},
	{
		"title": "Co‐Attention Hierarchical Network: Generating Coherent Long Distractors for Reading Comprehension ",
		"abstract": "In reading comprehension, generating sentence-level distractors is a significant task, which requires a deep understanding of the article and question. The traditional entity-centered methods can only generate word-level or phrase-level distractors. Although recently proposed neural-based methods like sequence-to-sequence (Seq2Seq) model show great potential in generating creative text, the previous neural methods for distractor generation ignore two important aspects. First, they didn't model the interactions between the article and question, making the generated distractors tend to be too general or not relevant to question context. Second, they didn't emphasize the relationship between the distractor and article, making the generated distractors not semantically relevant to the article and thus fail to form a set of meaningful options. To solve the first problem, we propose a co-attention enhanced hierarchical architecture to better capture the interactions between the article and question, thus guide the decoder to generate more coherent distractors. To alleviate the second problem, we add an additional semantic similarity loss to push the generated distractors more relevant to the article. Experimental results show that our model outperforms several strong baselines on automatic metrics, achieving state-of-the-art performance. Further human evaluation indicates that our generated distractors are more coherent and more educative compared with those distractors generated by baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08648v1"
	},
	{
		"title": "Two Birds with One Stone: Investigating Invertible Neural Networks for Inverse Problems in Morphology ",
		"abstract": "Most problems in natural language processing can be approximated as inverse problems such as analysis and generation at variety of levels from morphological (e.g., cat+Plural <-> cats) to semantic (e.g., (call + 1 2) <-> \"Calculate one plus two.\"). Although the tasks in both directions are closely related, general approach in the field has been to design separate models specific for each task. However, having one shared model for both tasks, would help the researchers exploit the common knowledge among these problems with reduced time and memory requirements. We investigate a specific class of neural networks, called Invertible Neural Networks (INNs) (Ardizzone et al. 2019) that enable simultaneous optimization in both directions, hence allow addressing of inverse problems via a single model. In this study, we investigate INNs on morphological problems casted as inverse problems. We apply INNs to various morphological tasks with varying ambiguity and show that they provide competitive performance in both directions. We show that they are able to recover the morphological input parameters, i.e., predicting the lemma (e.g., cat) or the morphological tags (e.g., Plural) when run in the reverse direction, without any significant performance drop in the forward direction, i.e., predicting the surface form (e.g., cats).",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05274v1"
	},
	{
		"title": "Distilling Knowledge from Well‐informed Soft Labels for Neural Relation Extraction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Filtration and Distillation: Enhancing Region Attention for Fine‐Grained Visual Categorization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Syntactically Look‐Ahead Attention Network for Sentence Compression ",
		"abstract": "Sentence compression is the task of compressing a long sentence into a short one by deleting redundant words. In sequence-to-sequence (Seq2Seq) based models, the decoder unidirectionally decides to retain or delete words. Thus, it cannot usually explicitly capture the relationships between decoded words and unseen words that will be decoded in the future time steps. Therefore, to avoid generating ungrammatical sentences, the decoder sometimes drops important words in compressing sentences. To solve this problem, we propose a novel Seq2Seq model, syntactically look-ahead attention network (SLAHAN), that can generate informative summaries by explicitly tracking both dependency parent and child words during decoding and capturing important words that will be decoded in the future. The results of the automatic evaluation on the Google sentence compression dataset showed that SLAHAN achieved the best kept-token-based-F1, ROUGE-1, ROUGE-2 and ROUGE-L scores of 85.5, 79.3, 71.3 and 79.1, respectively. SLAHAN also improved the summarization performance on longer sentences. Furthermore, in the human evaluation, SLAHAN improved informativeness without losing readability.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01145v2"
	},
	{
		"title": "A New Approach to Plan‐Space Explanation: Analyzing Plan‐Property Dependencies in Oversubscription Planning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Author Name Disambiguation on Heterogeneous Information Network with Adversarial Representation Learning ",
		"abstract": "Author name ambiguity causes inadequacy and inconvenience in academic information retrieval, which raises the necessity of author name disambiguation (AND). Existing AND methods can be divided into two categories: the models focusing on content information to distinguish whether two papers are written by the same author, the models focusing on relation information to represent information as edges on the network and to quantify the similarity among papers. However, the former requires adequate labeled samples and informative negative samples, and are also ineffective in measuring the high-order connections among papers, while the latter needs complicated feature engineering or supervision to construct the network. We propose a novel generative adversarial framework to grow the two categories of models together: (i) the discriminative module distinguishes whether two papers are from the same author, and (ii) the generative module selects possibly homogeneous papers directly from the heterogeneous information network, which eliminates the complicated feature engineering. In such a way, the discriminative module guides the generative module to select homogeneous papers, and the generative module generates high-quality negative samples to train the discriminative module to make it aware of high-order connections among papers. Furthermore, a self-training strategy for the discriminative module and a random walk based generating algorithm are designed to make the training stable and efficient. Extensive experiments on two real-world AND benchmarks demonstrate that our model provides significant performance improvement over the state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.09803v1"
	},
	{
		"title": "Fully Convolutional Network for Consistent Voxel‐wise Correspondence ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "D‐SPIDER‐SFO: A Decentralized Optimization Algorithm with Faster Convergence Rate for Nonconvex Problems ",
		"abstract": "Decentralized optimization algorithms have attracted intensive interests recently, as it has a balanced communication pattern, especially when solving large-scale machine learning problems. Stochastic Path Integrated Differential Estimator Stochastic First-Order method (SPIDER-SFO) nearly achieves the algorithmic lower bound in certain regimes for nonconvex problems. However, whether we can find a decentralized algorithm which achieves a similar convergence rate to SPIDER-SFO is still unclear. To tackle this problem, we propose a decentralized variant of SPIDER-SFO, called decentralized SPIDER-SFO (D-SPIDER-SFO). We show that D-SPIDER-SFO achieves a similar gradient computation cost---that is, $\\mathcal{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-approximate first-order stationary point---to its centralized counterpart. To the best of our knowledge, D-SPIDER-SFO achieves the state-of-the-art performance for solving nonconvex optimization problems on decentralized networks in terms of the computational cost. Experiments on different network configurations demonstrate the efficiency of the proposed method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12665v1"
	},
	{
		"title": "GraLSP: Graph Neural Networks with Local Structural Patterns ",
		"abstract": "It is not until recently that graph neural networks (GNNs) are adopted to perform graph representation learning, among which, those based on the aggregation of features within the neighborhood of a node achieved great success. However, despite such achievements, GNNs illustrate defects in identifying some common structural patterns which, unfortunately, play significant roles in various network phenomena. In this paper, we propose GraLSP, a GNN framework which explicitly incorporates local structural patterns into the neighborhood aggregation through random anonymous walks. Specifically, we capture local graph structures via random anonymous walks, powerful and flexible tools that represent structural patterns. The walks are then fed into the feature aggregation, where we design various mechanisms to address the impact of structural features, including adaptive receptive radius, attention and amplification. In addition, we design objectives that capture similarities between structures and are optimized jointly with node proximity objectives. With the adequate leverage of structural patterns, our model is able to outperform competitive counterparts in various prediction tasks in multiple datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07675v2"
	},
	{
		"title": "Modelling Diversity of Solutions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cross‐Lingual Low‐Resource Set‐to‐Description Retrieval for Global E‐Commerce ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adversarial Attack on Deep Product Quantization Network for Image Retrieval ",
		"abstract": "Deep product quantization network (DPQN) has recently received much attention in fast image retrieval tasks due to its efficiency of encoding high-dimensional visual features especially when dealing with large-scale datasets. Recent studies show that deep neural networks (DNNs) are vulnerable to input with small and maliciously designed perturbations (a.k.a., adversarial examples). This phenomenon raises the concern of security issues for DPQN in the testing/deploying stage as well. However, little effort has been devoted to investigating how adversarial examples affect DPQN. To this end, we propose product quantization adversarial generation (PQ-AG), a simple yet effective method to generate adversarial examples for product quantization based retrieval systems. PQ-AG aims to generate imperceptible adversarial perturbations for query images to form adversarial queries, whose nearest neighbors from a targeted product quantizaiton model are not semantically related to those from the original queries. Extensive experiments show that our PQ-AQ successfully creates adversarial examples to mislead targeted product quantization retrieval models. Besides, we found that our PQ-AG significantly degrades retrieval performance in both white-box and black-box settings.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.11374v1"
	},
	{
		"title": "Latent Opinions Transfer Network for Target‐Oriented Opinion Words Extraction ",
		"abstract": "Target-oriented opinion words extraction (TOWE) is a new subtask of ABSA, which aims to extract the corresponding opinion words for a given opinion target in a sentence. Recently, neural network methods have been applied to this task and achieve promising results. However, the difficulty of annotation causes the datasets of TOWE to be insufficient, which heavily limits the performance of neural models. By contrast, abundant review sentiment classification data are easily available at online review sites. These reviews contain substantial latent opinions information and semantic patterns. In this paper, we propose a novel model to transfer these opinions knowledge from resource-rich review sentiment classification datasets to low-resource task TOWE. To address the challenges in the transfer process, we design an effective transformation method to obtain latent opinions, then integrate them into TOWE. Extensive experimental results show that our model achieves better performance compared to other state-of-the-art methods and significantly outperforms the base model without transferring opinions knowledge. Further analysis validates the effectiveness of our model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.01989v1"
	},
	{
		"title": "Generating Diverse Translation by Manipulating Multi‐Head Attention ",
		"abstract": "Transformer model has been widely used on machine translation tasks and obtained state-of-the-art results. In this paper, we report an interesting phenomenon in its encoder-decoder multi-head attention: different attention heads of the final decoder layer align to different word translation candidates. We empirically verify this discovery and propose a method to generate diverse translations by manipulating heads. Furthermore, we make use of these diverse translations with the back-translation technique for better data augmentation. Experiment results show that our method generates diverse translations without severe drop in translation quality. Experiments also show that back-translation with these diverse translations could bring significant improvement on performance on translation tasks. An auxiliary experiment of conversation response generation task proves the effect of diversity as well.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09333v1"
	},
	{
		"title": "Geometry‐driven Self‐supervised Method for 3D Human Pose Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Deciding Acceptance in Incomplete Argumentation Frameworks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Heterogeneous Transfer Learning With Weighted Instance‐Correspondence Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Map Frequent Phrases to Sub‐Structures of Meaning Representation for Neural Semantic Parsing ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cut‐Based Graph Learning networks to Discover Compositional Structure of Sequential Video Data ",
		"abstract": "Conventional sequential learning methods such as Recurrent Neural Networks (RNNs) focus on interactions between consecutive inputs, i.e. first-order Markovian dependency. However, most of sequential data, as seen with videos, have complex dependency structures that imply variable-length semantic flows and their compositions, and those are hard to be captured by conventional methods. Here, we propose Cut-Based Graph Learning Networks (CB-GLNs) for learning video data by discovering these complex structures of the video. The CB-GLNs represent video data as a graph, with nodes and edges corresponding to frames of the video and their dependencies respectively. The CB-GLNs find compositional dependencies of the data in multilevel graph forms via a parameterized kernel with graph-cut and a message passing framework. We evaluate the proposed method on the two different tasks for video understanding: Video theme classification (Youtube-8M dataset) and Video Question and Answering (TVQA dataset). The experimental results show that our model efficiently learns the semantic compositional structure of video data. Furthermore, our model achieves the highest performance in comparison to other baseline methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.07613v1"
	},
	{
		"title": "Parallel AND/OR Search for Marginal MAP ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Ultrafast Photorealistic Style Transfer via Neural Architecture Search ",
		"abstract": "The key challenge in photorealistic style transfer is that an algorithm should faithfully transfer the style of a reference photo to a content photo while the generated image should look like one captured by a camera. Although several photorealistic style transfer algorithms have been proposed, they need to rely on post- and/or pre-processing to make the generated images look photorealistic. If we disable the additional processing, these algorithms would fail to produce plausible photorealistic stylization in terms of detail preservation and photorealism. In this work, we propose an effective solution to these issues. Our method consists of a construction step (C-step) to build a photorealistic stylization network and a pruning step (P-step) for acceleration. In the C-step, we propose a dense auto-encoder named PhotoNet based on a carefully designed pre-analysis. PhotoNet integrates a feature aggregation module (BFA) and instance normalized skip links (INSL). To generate faithful stylization, we introduce multiple style transfer modules in the decoder and INSLs. PhotoNet significantly outperforms existing algorithms in terms of both efficiency and effectiveness. In the P-step, we adopt a neural architecture search method to accelerate PhotoNet. We propose an automatic network pruning framework in the manner of teacher-student learning for photorealistic stylization. The network architecture named PhotoNAS resulted from the search achieves significant acceleration over PhotoNet while keeping the stylization effects almost intact. We conduct extensive experiments on both image and video transfer. The results show that our method can produce favorable results while achieving 20-30 times acceleration in comparison with the existing state-of-the-art approaches. It is worth noting that the proposed algorithm accomplishes better performance without any pre- or post-processing.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.02398v2"
	},
	{
		"title": "Synch‐Graph: Multisensory Emotion Recognition Through Neural Synchrony via Graph Convolutional Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fine‐Grained Argument Unit Recognition and Classification ",
		"abstract": "Prior work has commonly defined argument retrieval from heterogeneous document collections as a sentence-level classification task. Consequently, argument retrieval suffers both from low recall and from sentence segmentation errors making it difficult for humans and machines to consume the arguments. In this work, we argue that the task should be performed on a more fine-grained level of sequence labeling. For this, we define the task as Argument Unit Recognition and Classification (AURC). We present a dataset of arguments from heterogeneous sources annotated as spans of tokens within a sentence, as well as with a corresponding stance. We show that and how such difficult argument annotations can be effectively collected through crowdsourcing with high interannotator agreement. The new benchmark, AURC-8, contains up to 15% more arguments per topic as compared to annotations on the sentence level. We identify a number of methods targeted at AURC sequence labeling, achieving close to human performance on known domains. Further analysis also reveals that, contrary to previous approaches, our methods are more robust against sentence segmentation errors. We publicly release our code and the AURC-8 dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.09688v4"
	},
	{
		"title": "Word‐level Contextual Sentiment Analysis with Interpretability ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Stochastic Derivative‐Free Optimization Method with Importance Sampling: Theory and Learning to Control ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Joint Entity and Relation Extraction with a Hybrid Transformer and Reinforcement Learning Based Model ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Knowledge and Cross‐Pair Pattern Guided Semantic Matching for Question Answering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Efficient Framework for Dense Video Captioning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Integrating Deep Learning with Logic Fusion for Information Extraction ",
		"abstract": "Information extraction (IE) aims to produce structured information from an input text, e.g., Named Entity Recognition and Relation Extraction. Various attempts have been proposed for IE via feature engineering or deep learning. However, most of them fail to associate the complex relationships inherent in the task itself, which has proven to be especially crucial. For example, the relation between 2 entities is highly dependent on their entity types. These dependencies can be regarded as complex constraints that can be efficiently expressed as logical rules. To combine such logic reasoning capabilities with learning capabilities of deep neural networks, we propose to integrate logical knowledge in the form of first-order logic into a deep learning system, which can be trained jointly in an end-to-end manner. The integrated framework is able to enhance neural outputs with knowledge regularization via logic rules, and at the same time update the weights of logic rules to comply with the characteristics of the training data. We demonstrate the effectiveness and generalization of the proposed model on multiple IE tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.03041v1"
	},
	{
		"title": "Distance‐based Equilibria in Normal‐Form Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Masking Orchestration: Multi‐task Pretraining for Multi‐role Dialogue Representation Learning ",
		"abstract": "Multi-role dialogue understanding comprises a wide range of diverse tasks such as question answering, act classification, dialogue summarization etc. While dialogue corpora are abundantly available, labeled data, for specific learning tasks, can be highly scarce and expensive. In this work, we investigate dialogue context representation learning with various types unsupervised pretraining tasks where the training objectives are given naturally according to the nature of the utterance and the structure of the multi-role conversation. Meanwhile, in order to locate essential information for dialogue summarization/extraction, the pretraining process enables external knowledge integration. The proposed fine-tuned pretraining mechanism is comprehensively evaluated via three different dialogue datasets along with a number of downstream dialogue-mining tasks. Result shows that the proposed pretraining mechanism significantly contributes to all the downstream tasks without discrimination to different encoders.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.04994v1"
	},
	{
		"title": "Domain Adaptive Attention Learning for Unsupervised Person Re‐Identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Zero‐Resource Cross‐Lingual Named Entity Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "HS‐CAI: A Hybrid DCOP Algorithm via Combining Search with Context‐based Inference ",
		"abstract": "Search and inference are two main strategies for optimally solving Distributed Constraint Optimization Problems (DCOPs). Recently, several algorithms were proposed to combine their advantages. Unfortunately, such algorithms only use an approximated inference as a one-shot preprocessing phase to construct the initial lower bounds which lead to inefficient pruning under the limited memory budget. On the other hand, iterative inference algorithms (e.g., MB-DPOP) perform a context-based complete inference for all possible contexts but suffer from tremendous traffic overheads. In this paper, $(i)$ hybridizing search with context-based inference, we propose a complete algorithm for DCOPs, named {HS-CAI} where the inference utilizes the contexts derived from the search process to establish tight lower bounds while the search uses such bounds for efficient pruning and thereby reduces contexts for the inference. Furthermore, $(ii)$ we introduce a context evaluation mechanism to select the context patterns for the inference to further reduce the overheads incurred by iterative inferences. Finally, $(iii)$ we prove the correctness of our algorithm and the experimental results demonstrate its superiority over the state-of-the-art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12716v2"
	},
	{
		"title": "Planning and Acting with Non‐deterministic Events: Navigating between Safe States ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Social Influence Does Matter: User Action Prediction for In‐Feed Advertising ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Task‐Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context ",
		"abstract": "Conversations have an intrinsic one-to-many property, which means that multiple responses can be appropriate for the same dialog context. In task-oriented dialogs, this property leads to different valid dialog policies towards task completion. However, none of the existing task-oriented dialog generation approaches takes this property into account. We propose a Multi-Action Data Augmentation (MADA) framework to utilize the one-to-many property to generate diverse appropriate dialog responses. Specifically, we first use dialog states to summarize the dialog history, and then discover all possible mappings from every dialog state to its different valid system actions. During dialog system training, we enable the current dialog state to map to all valid system actions discovered in the previous process to create additional state-action pairs. By incorporating these additional pairs, the dialog policy learns a balanced action distribution, which further guides the dialog model to generate diverse responses. Experimental results show that the proposed framework consistently improves dialog policy diversity, and results in improved response diversity and appropriateness. Our model obtains state-of-the-art results on MultiWOZ.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10484v2"
	},
	{
		"title": "Reliable Multilabel Classiﬁcation: Prediction with Partial Abstention ",
		"abstract": "In contrast to conventional (single-label) classification, the setting of multilabel classification (MLC) allows an instance to belong to several classes simultaneously. Thus, instead of selecting a single class label, predictions take the form of a subset of all labels. In this paper, we study an extension of the setting of MLC, in which the learner is allowed to partially abstain from a prediction, that is, to deliver predictions on some but not necessarily all class labels. We propose a formalization of MLC with abstention in terms of a generalized loss minimization problem and present first results for the case of the Hamming loss, rank loss, and F-measure, both theoretical and experimental.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.09235v2"
	},
	{
		"title": "Actionable ethics through Neural Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reinforced Curriculum Learning on Pre‐trained Neural Machine Translation Models ",
		"abstract": "The competitive performance of neural machine translation (NMT) critically relies on large amounts of training data. However, acquiring high-quality translation pairs requires expert knowledge and is costly. Therefore, how to best utilize a given dataset of samples with diverse quality and characteristics becomes an important yet understudied question in NMT. Curriculum learning methods have been introduced to NMT to optimize a model's performance by prescribing the data input order, based on heuristics such as the assessment of noise and difficulty levels. However, existing methods require training from scratch, while in practice most NMT models are pre-trained on big data already. Moreover, as heuristics, they do not generalize well. In this paper, we aim to learn a curriculum for improving a pre-trained NMT model by re-selecting influential data samples from the original training set and formulate this task as a reinforcement learning problem. Specifically, we propose a data selection framework based on Deterministic Actor-Critic, in which a critic network predicts the expected change of model performance due to a certain sample, while an actor network learns to select the best sample out of a random batch of samples presented to it. Experiments on several translation datasets show that our method can further improve the performance of NMT when original batch training reaches its ceiling, without using additional new training data, and significantly outperforms several strong baseline methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.05757v1"
	},
	{
		"title": "Knowing What, How and Why: A Near Complete Solution for Aspect‐based Sentiment Analysis ",
		"abstract": "Target-based sentiment analysis or aspect-based sentiment analysis (ABSA) refers to addressing various sentiment analysis tasks at a fine-grained level, which includes but is not limited to aspect extraction, aspect sentiment classification, and opinion extraction. There exist many solvers of the above individual subtasks or a combination of two subtasks, and they can work together to tell a complete story, i.e. the discussed aspect, the sentiment on it, and the cause of the sentiment. However, no previous ABSA research tried to provide a complete solution in one shot. In this paper, we introduce a new subtask under ABSA, named aspect sentiment triplet extraction (ASTE). Particularly, a solver of this task needs to extract triplets (What, How, Why) from the inputs, which show WHAT the targeted aspects are, HOW their sentiment polarities are and WHY they have such polarities (i.e. opinion reasons). For instance, one triplet from \"Waiters are very friendly and the pasta is simply average\" could be ('Waiters', positive, 'friendly'). We propose a two-stage framework to address this task. The first stage predicts what, how and why in a unified model, and then the second stage pairs up the predicted what (how) and why from the first stage to output triplets. In the experiments, our framework has set a benchmark performance in this novel triplet extraction task. Meanwhile, it outperforms a few strong baselines adapted from state-of-the-art related methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.01616v4"
	},
	{
		"title": "Finding Most Compatible Phylogenetic Trees over Multi‐State Characters ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Frame‐Guided Region‐Aligned Representation for Video Person Re‐identification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Differentiable Meta‐learning Model for Few‐shot Semantic Segmentation ",
		"abstract": "To address the annotation scarcity issue in some cases of semantic segmentation, there have been a few attempts to develop the segmentation model in the few-shot learning paradigm. However, most existing methods only focus on the traditional 1-way segmentation setting (i.e., one image only contains a single object). This is far away from practical semantic segmentation tasks where the K-way setting (K>1) is usually required by performing the accurate multi-object segmentation. To deal with this issue, we formulate the few-shot semantic segmentation task as a learning-based pixel classification problem and propose a novel framework called MetaSegNet based on meta-learning. In MetaSegNet, an architecture of embedding module consisting of the global and local feature branches is developed to extract the appropriate meta-knowledge for the few-shot segmentation. Moreover, we incorporate a linear model into MetaSegNet as a base learner to directly predict the label of each pixel for the multi-object segmentation. Furthermore, our MetaSegNet can be trained by the episodic training mechanism in an end-to-end manner from scratch. Experiments on two popular semantic segmentation datasets, i.e., PASCAL VOC and COCO, reveal the effectiveness of the proposed MetaSegNet in the K-way few-shot semantic segmentation task.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10371v1"
	},
	{
		"title": "Unsupervised Metric Learning with Synthetic Examples ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Cross‐Lingual Natural Language Generation via Pre‐Training ",
		"abstract": "In this work we focus on transferring supervision signals of natural language generation (NLG) tasks between multiple languages. We propose to pretrain the encoder and the decoder of a sequence-to-sequence model under both monolingual and cross-lingual settings. The pre-training objective encourages the model to represent different languages in the shared space, so that we can conduct zero-shot cross-lingual transfer. After the pre-training procedure, we use monolingual data to fine-tune the pre-trained model on downstream NLG tasks. Then the sequence-to-sequence model trained in a single language can be directly evaluated beyond that language (i.e., accepting multi-lingual input and producing multi-lingual output). Experimental results on question generation and abstractive summarization show that our model outperforms the machine-translation-based pipeline methods for zero-shot cross-lingual generation. Moreover, cross-lingual transfer improves NLG performance of low-resource languages by leveraging rich-resource language data. Our implementation and data are available at https://github.com/CZWin32768/xnlg.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10481v3"
	},
	{
		"title": "Weighted Sampling for Combined Model Selection and Hyperparameter Tuning ",
		"abstract": "The combined algorithm selection and hyperparameter tuning (CASH) problem is characterized by large hierarchical hyperparameter spaces. Model-free hyperparameter tuning methods can explore such large spaces efficiently since they are highly parallelizable across multiple machines. When no prior knowledge or meta-data exists to boost their performance, these methods commonly sample random configurations following a uniform distribution. In this work, we propose a novel sampling distribution as an alternative to uniform sampling and prove theoretically that it has a better chance of finding the best configuration in a worst-case setting. In order to compare competing methods rigorously in an experimental setting, one must perform statistical hypothesis testing. We show that there is little-to-no agreement in the automated machine learning literature regarding which methods should be used. We contrast this disparity with the methods recommended by the broader statistics literature, and identify a suitable approach. We then select three popular model-free solutions to CASH and evaluate their performance, with uniform sampling as well as the proposed sampling scheme, across 67 datasets from the OpenML platform. We investigate the trade-off between exploration and exploitation across the three algorithms, and verify empirically that the proposed sampling distribution improves performance in all cases.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07140v3"
	},
	{
		"title": "Towards Making the Most of BERT in Neural Machine Translation ",
		"abstract": "GPT-2 and BERT demonstrate the effectiveness of using pre-trained language models (LMs) on various natural language processing tasks. However, LM fine-tuning often suffers from catastrophic forgetting when applied to resource-rich tasks. In this work, we introduce a concerted training framework (\\method) that is the key to integrate the pre-trained LMs to neural machine translation (NMT). Our proposed Cnmt consists of three techniques: a) asymptotic distillation to ensure that the NMT model can retain the previous pre-trained knowledge; b) a dynamic switching gate to avoid catastrophic forgetting of pre-trained knowledge; and c) a strategy to adjust the learning paces according to a scheduled policy. Our experiments in machine translation show \\method gains of up to 3 BLEU score on the WMT14 English-German language pair which even surpasses the previous state-of-the-art pre-training aided NMT by 1.4 BLEU score. While for the large WMT14 English-French task with 40 millions of sentence-pairs, our base model still significantly improves upon the state-of-the-art Transformer big model by more than 1 BLEU score.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.05672v4"
	},
	{
		"title": "Region‐Adaptive Dense Network for Efficient Motion Deblurring ",
		"abstract": "In this paper, we address the problem of dynamic scene deblurring in the presence of motion blur. Restoration of images affected by severe blur necessitates a network design with a large receptive field, which existing networks attempt to achieve through simple increment in the number of generic convolution layers, kernel-size, or the scales at which the image is processed. However, these techniques ignore the non-uniform nature of blur, and they come at the expense of an increase in model size and inference time. We present a new architecture composed of region adaptive dense deformable modules that implicitly discover the spatially varying shifts responsible for non-uniform blur in the input image and learn to modulate the filters. This capability is complemented by a self-attentive module which captures non-local spatial relationships among the intermediate features and enhances the spatially-varying processing capability. We incorporate these modules into a densely connected encoder-decoder design which utilizes pre-trained Densenet filters to further improve the performance. Our network facilitates interpretable modeling of the spatially-varying deblurring process while dispensing with multi-scale processing and large filters entirely. Extensive comparisons with prior art on benchmark dynamic scene deblurring datasets clearly demonstrate the superiority of the proposed networks via significant improvements in accuracy and speed, enabling almost real-time deblurring.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.11394v3"
	},
	{
		"title": "Can Embeddings Adequately Represent Medical Terminology? New Large‐Scale Medical Term Similarity Datasets Have the Answer! ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Decidability and Complexity of Action‐Based Temporal Planning over Dense Time ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fairness for Robust Log Loss Classification ",
		"abstract": "Developing classification methods with high accuracy that also avoid unfair treatment of different groups has become increasingly important for data-driven decision making in social applications. Many existing methods enforce fairness constraints on a selected classifier (e.g., logistic regression) by directly forming constrained optimizations. We instead re-derive a new classifier from the first principles of distributional robustness that incorporates fairness criteria into a worst-case logarithmic loss minimization. This construction takes the form of a minimax game and produces a parametric exponential family conditional distribution that resembles truncated logistic regression. We present the theoretical benefits of our approach in terms of its convexity and asymptotic convergence. We then demonstrate the practical advantages of our approach on three benchmark fairness datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.03910v4"
	},
	{
		"title": "Generalized Planning with Positive and Negative Examples ",
		"abstract": "Generalized planning aims at computing an algorithm-like structure (generalized plan) that solves a set of multiple planning instances. In this paper we define negative examples for generalized planning as planning instances that must not be solved by a generalized plan. With this regard the paper extends the notion of validation of a generalized plan as the problem of verifying that a given generalized plan solves the set of input positives instances while it fails to solve a given input set of negative examples. This notion of plan validation allows us to define quantitative metrics to asses the generalization capacity of generalized plans. The paper also shows how to incorporate this new notion of plan validation into a compilation for plan synthesis that takes both positive and negative instances as input. Experiments show that incorporating negative examples can accelerate plan synthesis in several domains and leverage quantitative metrics to evaluate the generalization capacity of the synthesized plans.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09365v1"
	},
	{
		"title": "Efficient Facial Feature Learning with Wide Ensemble‐based Convolutional Neural Networks ",
		"abstract": "Ensemble methods, traditionally built with independently trained de-correlated models, have proven to be efficient methods for reducing the remaining residual generalization error, which results in robust and accurate methods for real-world applications. In the context of deep learning, however, training an ensemble of deep networks is costly and generates high redundancy which is inefficient. In this paper, we present experiments on Ensembles with Shared Representations (ESRs) based on convolutional networks to demonstrate, quantitatively and qualitatively, their data processing efficiency and scalability to large-scale datasets of facial expressions. We show that redundancy and computational load can be dramatically reduced by varying the branching level of the ESR without loss of diversity and generalization power, which are both important for ensemble performance. Experiments on large-scale datasets suggest that ESRs reduce the remaining residual generalization error on the AffectNet and FER+ datasets, reach human-level performance, and outperform state-of-the-art methods on facial expression recognition in the wild using emotion and affect concepts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06338v1"
	},
	{
		"title": "Neural Question Generation with Answer Pivot ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets ",
		"abstract": "Existing analysis work in machine reading comprehension (MRC) is largely concerned with evaluating the capabilities of systems. However, the capabilities of datasets are not assessed for benchmarking language understanding precisely. We propose a semi-automated, ablation-based methodology for this challenge; By checking whether questions can be solved even after removing features associated with a skill requisite for language understanding, we evaluate to what degree the questions do not require the skill. Experiments on 10 datasets (e.g., CoQA, SQuAD v2.0, and RACE) with a strong baseline model show that, for example, the relative scores of a baseline model provided with content words only and with shuffled sentence words in the context are on average 89.2% and 78.5% of the original score, respectively. These results suggest that most of the questions already answered correctly by the model do not necessarily require grammatical and complex reasoning. For precise benchmarking, MRC datasets will need to take extra care in their design to ensure that questions can correctly evaluate the intended skills.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09241v1"
	},
	{
		"title": "Error‐Correcting and Verifiable Parallel Inference in Graphical Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Sentiment Classification in Customer Service Dialogue with Topic‐aware Multi‐task Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Viewpoint‐Aware Loss with Angular Regularization for Person Re‐Identification ",
		"abstract": "Although great progress in supervised person re-identification (Re-ID) has been made recently, due to the viewpoint variation of a person, Re-ID remains a massive visual challenge. Most existing viewpoint-based person Re-ID methods project images from each viewpoint into separated and unrelated sub-feature spaces. They only model the identity-level distribution inside an individual viewpoint but ignore the underlying relationship between different viewpoints. To address this problem, we propose a novel approach, called \\textit{Viewpoint-Aware Loss with Angular Regularization }(\\textbf{VA-reID}). Instead of one subspace for each viewpoint, our method projects the feature from different viewpoints into a unified hypersphere and effectively models the feature distribution on both the identity-level and the viewpoint-level. In addition, rather than modeling different viewpoints as hard labels used for conventional viewpoint classification, we introduce viewpoint-aware adaptive label smoothing regularization (VALSR) that assigns the adaptive soft label to feature representation. VALSR can effectively solve the ambiguity of the viewpoint cluster label assignment. Extensive experiments on the Market1501 and DukeMTMC-reID datasets demonstrated that our method outperforms the state-of-the-art supervised Re-ID methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01300v1"
	},
	{
		"title": "Generative Adversarial Zero‐Shot Relational Learning for Knowledge Graphs ",
		"abstract": "Large-scale knowledge graphs (KGs) are shown to become more important in current information systems. To expand the coverage of KGs, previous studies on knowledge graph completion need to collect adequate training instances for newly-added relations. In this paper, we consider a novel formulation, zero-shot learning, to free this cumbersome curation. For newly-added relations, we attempt to learn their semantic features from their text descriptions and hence recognize the facts of unseen relations with no examples being seen. For this purpose, we leverage Generative Adversarial Networks (GANs) to establish the connection between text and knowledge graph domain: The generator learns to generate the reasonable relation embeddings merely with noisy text descriptions. Under this setting, zero-shot learning is naturally converted to a traditional supervised classification task. Empirically, our method is model-agnostic that could be potentially applied to any version of KG embeddings, and consistently yields performance improvements on NELL and Wiki dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.02332v1"
	},
	{
		"title": "Generative Exploration and Exploitation ",
		"abstract": "Sparse reward is one of the biggest challenges in reinforcement learning (RL). In this paper, we propose a novel method called Generative Exploration and Exploitation (GENE) to overcome sparse reward. GENE automatically generates start states to encourage the agent to explore the environment and to exploit received reward signals. GENE can adaptively tradeoff between exploration and exploitation according to the varying distributions of states experienced by the agent as the learning progresses. GENE relies on no prior knowledge about the environment and can be combined with any RL algorithm, no matter on-policy or off-policy, single-agent or multi-agent. Empirically, we demonstrate that GENE significantly outperforms existing methods in three tasks with only binary rewards, including Maze, Maze Ant, and Cooperative Navigation. Ablation studies verify the emergence of progressive exploration and automatic reversing.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.09605v2"
	},
	{
		"title": "CF‐LSTM: Cascaded Feature‐Based Long Short‐Term Networks for Predicting Pedestrian Trajectory ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Modeling Fluency and Faithfulness for Diverse Neural Machine Translation ",
		"abstract": "Neural machine translation models usually adopt the teacher forcing strategy for training which requires the predicted sequence matches ground truth word by word and forces the probability of each prediction to approach a 0-1 distribution. However, the strategy casts all the portion of the distribution to the ground truth word and ignores other words in the target vocabulary even when the ground truth word cannot dominate the distribution. To address the problem of teacher forcing, we propose a method to introduce an evaluation module to guide the distribution of the prediction. The evaluation module accesses each prediction from the perspectives of fluency and faithfulness to encourage the model to generate the word which has a fluent connection with its past and future translation and meanwhile tends to form a translation equivalent in meaning to the source. The experiments on multiple translation tasks show that our method can achieve significant improvements over strong baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00178v1"
	},
	{
		"title": "Integrating Relation Constraints with Neural Relation Extractors ",
		"abstract": "Recent years have seen rapid progress in identifying predefined relationship between entity pairs using neural networks NNs. However, such models often make predictions for each entity pair individually, thus often fail to solve the inconsistency among different predictions, which can be characterized by discrete relation constraints. These constraints are often defined over combinations of entity-relation-entity triples, since there often lack of explicitly well-defined type and cardinality requirements for the relations. In this paper, we propose a unified framework to integrate relation constraints with NNs by introducing a new loss term, ConstraintLoss. Particularly, we develop two efficient methods to capture how well the local predictions from multiple instance pairs satisfy the relation constraints. Experiments on both English and Chinese datasets show that our approach can help NNs learn from discrete relation constraints to reduce inconsistency among local predictions, and outperform popular neural relation extraction NRE models even enhanced with extra post-processing. Our source code and datasets will be released at https://github.com/PKUYeYuan/Constraint-Loss-AAAI-2020.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11493v1"
	},
	{
		"title": "Biologically Plausible Sequence Learning with Spiking Neural Networks ",
		"abstract": "Motivated by the celebrated discrete-time model of nervous activity outlined by McCulloch and Pitts in 1943, we propose a novel continuous-time model, the McCulloch-Pitts network (MPN), for sequence learning in spiking neural networks. Our model has a local learning rule, such that the synaptic weight updates depend only on the information directly accessible by the synapse. By exploiting asymmetry in the connections between binary neurons, we show that MPN can be trained to robustly memorize multiple spatiotemporal patterns of binary vectors, generalizing the ability of the symmetric Hopfield network to memorize static spatial patterns. In addition, we demonstrate that the model can efficiently learn sequences of binary pictures as well as generative models for experimental neural spike-train data. Our learning rule is consistent with spike-timing-dependent plasticity (STDP), thus providing a theoretical ground for the systematic design of biologically inspired networks with large and robust long-range sequence storage capacity.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10943v1"
	},
	{
		"title": "Acquiring Knowledge from Pre‐trained Model to Neural Machine Translation ",
		"abstract": "Pre-training and fine-tuning have achieved great success in the natural language process field. The standard paradigm of exploiting them includes two steps: first, pre-training a model, e.g. BERT, with a large scale unlabeled monolingual data. Then, fine-tuning the pre-trained model with labeled data from downstream tasks. However, in neural machine translation (NMT), we address the problem that the training objective of the bilingual task is far different from the monolingual pre-trained model. This gap leads that only using fine-tuning in NMT can not fully utilize prior language knowledge. In this paper, we propose an APT framework for acquiring knowledge from the pre-trained model to NMT. The proposed approach includes two modules: 1). a dynamic fusion mechanism to fuse task-specific features adapted from general knowledge into NMT network, 2). a knowledge distillation paradigm to learn language knowledge continuously during the NMT training process. The proposed approach could integrate suitable knowledge from pre-trained models to improve the NMT. Experimental results on WMT English to German, German to English and Chinese to English machine translation tasks show that our model outperforms strong baselines and the fine-tuning counterparts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01774v1"
	},
	{
		"title": "GTC: Guided Training of CTC Towards Efficient and Accurate Scene Text Recognition ",
		"abstract": "Connectionist Temporal Classification (CTC) and attention mechanism are two main approaches used in recent scene text recognition works. Compared with attention-based methods, CTC decoder has a much shorter inference time, yet a lower accuracy. To design an efficient and effective model, we propose the guided training of CTC (GTC), where CTC model learns a better alignment and feature representations from a more powerful attentional guidance. With the benefit of guided training, CTC model achieves robust and accurate prediction for both regular and irregular scene text while maintaining a fast inference speed. Moreover, to further leverage the potential of CTC decoder, a graph convolutional network (GCN) is proposed to learn the local correlations of extracted features. Extensive experiments on standard benchmarks demonstrate that our end-to-end model achieves a new state-of-the-art for regular and irregular scene text recognition and needs 6 times shorter inference time than attentionbased methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01276v1"
	},
	{
		"title": "Towards Universal Languages for Tractable Ontology Mediated Query Answering ",
		"abstract": "An ontology language for ontology mediated query answering (OMQA-language) is universal for a family of OMQA-languages if it is the most expressive one among this family. In this paper, we focus on three families of tractable OMQA-languages, including first-order rewritable languages and languages whose data complexity of the query answering is in AC0 or PTIME. On the negative side, we prove that there is, in general, no universal language for each of these families of languages. On the positive side, we propose a novel property, the locality, to approximate the first-order rewritability, and show that there exists a language of disjunctive embedded dependencies that is universal for the family of OMQA-languages with locality. All of these results apply to OMQA with query languages such as conjunctive queries, unions of conjunctive queries and acyclic conjunctive queries.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11359v2"
	},
	{
		"title": "Approval‐Based Apportionment ",
		"abstract": "In the apportionment problem, a fixed number of seats must be distributed among parties in proportion to the number of voters supporting each party. We study a generalization of this setting, in which voters cast approval ballots over parties, such that each voter can support multiple parties. This approval-based apportionment setting generalizes traditional apportionment and is a natural restriction of approval-based multiwinner elections, where approval ballots range over individual candidates. Using techniques from both apportionment and multiwinner elections, we are able to provide representation guarantees that are currently out of reach in the general setting of multiwinner elections: First, we show that core-stable committees are guaranteed to exist and can be found in polynomial time. Second, we demonstrate that extended justified representation is compatible with committee monotonicity.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08365v1"
	},
	{
		"title": "Deep Attentive Ranking Networks for Learning to Order Sentences ",
		"abstract": "We present an attention-based ranking framework for learning to order sentences given a paragraph. Our framework is built on a bidirectional sentence encoder and a self-attention based transformer network to obtain an input order invariant representation of paragraphs. Moreover, it allows seamless training using a variety of ranking based loss functions, such as pointwise, pairwise, and listwise ranking. We apply our framework on two tasks: Sentence Ordering and Order Discrimination. Our framework outperforms various state-of-the-art methods on these tasks on a variety of evaluation metrics. We also show that it achieves better results when using pairwise and listwise ranking losses, rather than the pointwise ranking loss, which suggests that incorporating relative positions of two or more sentences in the loss function contributes to better learning.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.00056v1"
	},
	{
		"title": "Optimal Margin Distribution Learning in Dynamic Environments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces ",
		"abstract": "Distributional word vectors have recently been shown to encode many of the human biases, most notably gender and racial biases, and models for attenuating such biases have consequently been proposed. However, existing models and studies (1) operate on under-specified and mutually differing bias definitions, (2) are tailored for a particular bias (e.g., gender bias) and (3) have been evaluated inconsistently and non-rigorously. In this work, we introduce a general framework for debiasing word embeddings. We operationalize the definition of a bias by discerning two types of bias specification: explicit and implicit. We then propose three debiasing models that operate on explicit or implicit bias specifications and that can be composed towards more robust debiasing. Finally, we devise a full-fledged evaluation framework in which we couple existing bias metrics with newly proposed ones. Experimental findings across three embedding methods suggest that the proposed debiasing models are robust and widely applicable: they often completely remove the bias both implicitly and explicitly without degradation of semantic information encoded in any of the input distributional spaces. Moreover, we successfully transfer debiasing models, by means of cross-lingual embedding spaces, and remove or attenuate biases in distributional word vector spaces of languages that lack readily available bias specifications.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.06092v2"
	},
	{
		"title": "Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height‐Guided Depth Estimation ",
		"abstract": "Monocular 3D object detection task aims to predict the 3D bounding boxes of objects based on monocular RGB images. Since the location recovery in 3D space is quite difficult on account of absence of depth information, this paper proposes a novel unified framework which decomposes the detection problem into a structured polygon prediction task and a depth recovery task. Different from the widely studied 2D bounding boxes, the proposed novel structured polygon in the 2D image consists of several projected surfaces of the target object. Compared to the widely-used 3D bounding box proposals, it is shown to be a better representation for 3D detection. In order to inversely project the predicted 2D structured polygon to a cuboid in the 3D physical world, the following depth recovery task uses the object height prior to complete the inverse projection transformation with the given camera projection matrix. Moreover, a fine-grained 3D box refinement scheme is proposed to further rectify the 3D detection results. Experiments are conducted on the challenging KITTI benchmark, in which our method achieves state-of-the-art detection accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01619v1"
	},
	{
		"title": "Hearing Lips: Improving Lip Reading by Distilling Speech Recognizers ",
		"abstract": "Lip reading has witnessed unparalleled development in recent years thanks to deep learning and the availability of large-scale datasets. Despite the encouraging results achieved, the performance of lip reading, unfortunately, remains inferior to the one of its counterpart speech recognition, due to the ambiguous nature of its actuations that makes it challenging to extract discriminant features from the lip movement videos. In this paper, we propose a new method, termed as Lip by Speech (LIBS), of which the goal is to strengthen lip reading by learning from speech recognizers. The rationale behind our approach is that the features extracted from speech recognizers may provide complementary and discriminant clues, which are formidable to be obtained from the subtle movements of the lips, and consequently facilitate the training of lip readers. This is achieved, specifically, by distilling multi-granularity knowledge from speech recognizers to lip readers. To conduct this cross-modal knowledge distillation, we utilize an efficacious alignment scheme to handle the inconsistent lengths of the audios and videos, as well as an innovative filtering strategy to refine the speech recognizer's prediction. The proposed method achieves the new state-of-the-art performance on the CMLR and LRS2 datasets, outperforming the baseline by a margin of 7.66% and 2.75% in character error rate, respectively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11502v1"
	},
	{
		"title": "Two‐Level Transformer and Auxiliary Coherence Modeling for Improved Text Segmentation ",
		"abstract": "Breaking down the structure of long texts into semantically coherent segments makes the texts more readable and supports downstream applications like summarization and retrieval. Starting from an apparent link between text coherence and segmentation, we introduce a novel supervised model for text segmentation with simple but explicit coherence modeling. Our model -- a neural architecture consisting of two hierarchically connected Transformer networks -- is a multi-task learning model that couples the sentence-level segmentation objective with the coherence objective that differentiates correct sequences of sentences from corrupt ones. The proposed model, dubbed Coherence-Aware Text Segmentation (CATS), yields state-of-the-art segmentation performance on a collection of benchmark datasets. Furthermore, by coupling CATS with cross-lingual word embeddings, we demonstrate its effectiveness in zero-shot language transfer: it can successfully segment texts in languages unseen in training.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.00891v1"
	},
	{
		"title": "Rethinking Generalization of Neural Models: A Named Entity Recognition  Case Study ",
		"abstract": "While neural network-based models have achieved impressive performance on a large body of NLP tasks, the generalization behavior of different models remains poorly understood: Does this excellent performance imply a perfect generalization model, or are there still some limitations? In this paper, we take the NER task as a testbed to analyze the generalization behavior of existing models from different perspectives and characterize the differences of their generalization abilities through the lens of our proposed measures, which guides us to better design models and training methods. Experiments with in-depth analyses diagnose the bottleneck of existing neural NER models in terms of breakdown performance analysis, annotation errors, dataset bias, and category relationships, which suggest directions for improvement. We have released the datasets: (ReCoNLL, PLONER) for the future research at our project page: http://pfliu.com/InterpretNER/. As a by-product of this paper, we have open-sourced a project that involves a comprehensive summary of recent NER papers and classifies them into different research topics: https://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.03844v1"
	},
	{
		"title": "Attentive Experience Replay ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "SynSig2Vec: Learning Representations from Synthetic Dynamic Signatures for Real‐world Verification ",
		"abstract": "An open research problem in automatic signature verification is the skilled forgery attacks. However, the skilled forgeries are very difficult to acquire for representation learning. To tackle this issue, this paper proposes to learn dynamic signature representations through ranking synthesized signatures. First, a neuromotor inspired signature synthesis method is proposed to synthesize signatures with different distortion levels for any template signature. Then, given the templates, we construct a lightweight one-dimensional convolutional network to learn to rank the synthesized samples, and directly optimize the average precision of the ranking to exploit relative and fine-grained signature similarities. Finally, after training, fixed-length representations can be extracted from dynamic signatures of variable lengths for verification. One highlight of our method is that it requires neither skilled nor random forgeries for training, yet it surpasses the state-of-the-art by a large margin on two public benchmarks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05358v2"
	},
	{
		"title": "Favorite‐Candidate Voting for Eliminating the Least Popular Candidate in a Metric Space ",
		"abstract": "We study single-candidate voting embedded in a metric space, where both voters and candidates are points in the space, and the distances between voters and candidates specify the voters' preferences over candidates. In the voting, each voter is asked to submit her favorite candidate. Given the collection of favorite candidates, a mechanism for eliminating the least popular candidate finds a committee containing all candidates but the one to be eliminated. Each committee is associated with a social value that is the sum of the costs (utilities) it imposes (provides) to the voters. We design mechanisms for finding a committee to optimize the social value. We measure the quality of a mechanism by its distortion, defined as the worst-case ratio between the social value of the committee found by the mechanism and the optimal one. We establish new upper and lower bounds on the distortion of mechanisms in this single-candidate voting, for both general metrics and well-motivated special cases.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12109v1"
	},
	{
		"title": "Spatio‐Temporal Graph Structure Learning for Traffic Forecasting ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Robust Federated Learning via Collaborative Machine Teaching ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Instance‐wise Dynamic Sensor Selection for Human Activity Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Interactive Regret‐Based Genetic Algorithm for Solving Multi‐Objective Combinatorial Optimization Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "End‐to‐End Bootstrapping Neural Network for Entity Set Expansion ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "HLHLp: Quantized Neural Networks Training for Reaching Flat Minima in Loss Surface ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Scalable Inductive Logic Programming incorporating Domain‐specific Optimisation Criteria ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Experimental Design for Optimization of Orthogonal Projection Pursuit Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning to Reason: Leveraging Neural Networks for Approximate DNF Counting ",
		"abstract": "Weighted model counting (WMC) has emerged as a prevalent approach for probabilistic inference. In its most general form, WMC is #P-hard. Weighted DNF counting (weighted #DNF) is a special case, where approximations with probabilistic guarantees are obtained in O(nm), where n denotes the number of variables, and m the number of clauses of the input DNF, but this is not scalable in practice. In this paper, we propose a neural model counting approach for weighted #DNF that combines approximate model counting with deep learning, and accurately approximates model counts in linear time when width is bounded. We conduct experiments to validate our method, and show that our model learns and generalizes very well to large-scale #DNF instances.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.02688v5"
	},
	{
		"title": "Simplify‐then‐Translate: Automatic Preprocessing for Black‐Box Translation ",
		"abstract": "Black-box machine translation systems have proven incredibly useful for a variety of applications yet by design are hard to adapt, tune to a specific domain, or build on top of. In this work, we introduce a method to improve such systems via automatic pre-processing (APP) using sentence simplification. We first propose a method to automatically generate a large in-domain paraphrase corpus through back-translation with a black-box MT system, which is used to train a paraphrase model that \"simplifies\" the original sentence to be more conducive for translation. The model is used to preprocess source sentences of multiple low-resource language pairs. We show that this preprocessing leads to better translation performance as compared to non-preprocessed source sentences. We further perform side-by-side human evaluation to verify that translations of the simplified sentences are better than the original ones. Finally, we provide some guidance on recommended language pairs for generating the simplification model corpora by investigating the relationship between ease of translation of a language pair (as measured by BLEU) and quality of the resulting simplification model from back-translations of this language pair (as measured by SARI), and tie this into the downstream task of low-resource translation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.11197v2"
	},
	{
		"title": "Semi‐Supervised Text Simplification with Back‐Translation and Asymmetric Denoising Autoencoders ",
		"abstract": "Text simplification (TS) rephrases long sentences into simplified variants while preserving inherent semantics. Traditional sequence-to-sequence models heavily rely on the quantity and quality of parallel sentences, which limits their applicability in different languages and domains. This work investigates how to leverage large amounts of unpaired corpora in TS task. We adopt the back-translation architecture in unsupervised machine translation (NMT), including denoising autoencoders for language modeling and automatic generation of parallel data by iterative back-translation. However, it is non-trivial to generate appropriate complex-simple pair if we directly treat the set of simple and complex corpora as two different languages, since the two types of sentences are quite similar and it is hard for the model to capture the characteristics in different types of sentences. To tackle this problem, we propose asymmetric denoising methods for sentences with separate complexity. When modeling simple and complex sentences with autoencoders, we introduce different types of noise into the training process. Such a method can significantly improve the simplification performance. Our model can be trained in both unsupervised and semi-supervised manner. Automatic and human evaluations show that our unsupervised model outperforms the previous systems, and with limited supervision, our model can perform competitively with multiple state-of-the-art simplification systems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.14693v1"
	},
	{
		"title": "A Calculus for Stochastic Interventions: Causal Effect Identification and Surrogate Experiments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GAN‐Based Unpaired Chinese Character Image Translation via Skeleton Transformation and Stroke Rendering ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Electing Successive Committees: Complexity and Algorithms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Reinforcement Learning of Risk‐Constrained Policies in Markov Decision Processes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Spatial‐Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial‐Temporal Network Data Forecasting ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DASOT: A Unified Framework Integrating Data Association and Single Object Tracking for Online Multi‐Object Tracking ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Network as Regularization for Training Deep Neural Networks: Framework, Model and Performance ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DWM: A Decomposable Winograd Method for Convolution Acceleration ",
		"abstract": "Winograd's minimal filtering algorithm has been widely used in Convolutional Neural Networks (CNNs) to reduce the number of multiplications for faster processing. However, it is only effective on convolutions with kernel size as 3x3 and stride as 1, because it suffers from significantly increased FLOPs and numerical accuracy problem for kernel size larger than 3x3 and fails on convolution with stride larger than 1. In this paper, we propose a novel Decomposable Winograd Method (DWM), which breaks through the limitation of original Winograd's minimal filtering algorithm to a wide and general convolutions. DWM decomposes kernels with large size or large stride to several small kernels with stride as 1 for further applying Winograd method, so that DWM can reduce the number of multiplications while keeping the numerical accuracy. It enables the fast exploring of larger kernel size and larger stride value in CNNs for high performance and accuracy and even the potential for new CNNs. Comparing against the original Winograd, the proposed DWM is able to support all kinds of convolutions with a speedup of ~2, without affecting the numerical accuracy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.00552v1"
	},
	{
		"title": "Model‐Based Diagnosis with Uncertain Observations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Draft and Edit: Automatic Storytelling Through Multi‐Pass  Hierarchical Conditional Variational Autoencoder ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Capsule Routing via Variational Bayes ",
		"abstract": "Capsule networks are a recently proposed type of neural network shown to outperform alternatives in challenging shape recognition tasks. In capsule networks, scalar neurons are replaced with capsule vectors or matrices, whose entries represent different properties of objects. The relationships between objects and their parts are learned via trainable viewpoint-invariant transformation matrices, and the presence of a given object is decided by the level of agreement among votes from its parts. This interaction occurs between capsule layers and is a process called routing-by-agreement. In this paper, we propose a new capsule routing algorithm derived from Variational Bayes for fitting a mixture of transforming gaussians, and show it is possible transform our capsule network into a Capsule-VAE. Our Bayesian approach addresses some of the inherent weaknesses of MLE based models such as the variance-collapse by modelling uncertainty over capsule pose parameters. We outperform the state-of-the-art on smallNORB using 50% fewer capsules than previously reported, achieve competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous works.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.11455v3"
	},
	{
		"title": "Modality‐Balanced Models for Visual Dialogue ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Explainable Data Decompositions ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "LMLFM: Longitudinal Multi‐Level Factorization Machine ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DNNs as layers of cooperating classifiers ",
		"abstract": "A robust theoretical framework that can describe and predict the generalization ability of deep neural networks (DNNs) in general circumstances remains elusive. Classical attempts have produced complexity metrics that rely heavily on global measures of compactness and capacity with little investigation into the effects of sub-component collaboration. We demonstrate intriguing regularities in the activation patterns of the hidden nodes within fully-connected feedforward networks. By tracing the origin of these patterns, we show how such networks can be viewed as the combination of two information processing systems: one continuous and one discrete. We describe how these two systems arise naturally from the gradient-based optimization process, and demonstrate the classification ability of the two systems, individually and in collaboration. This perspective on DNN classification offers a novel way to think about generalization, in which different subsets of the training data are used to train distinct classifiers; those classifiers are then combined to perform the classification task, and their consistency is crucial for accurate classification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06178v1"
	},
	{
		"title": "Exploiting Spatial Invariance for Scalable Unsupervised Object Tracking ",
		"abstract": "The ability to detect and track objects in the visual world is a crucial skill for any intelligent agent, as it is a necessary precursor to any object-level reasoning process. Moreover, it is important that agents learn to track objects without supervision (i.e. without access to annotated training videos) since this will allow agents to begin operating in new environments with minimal human assistance. The task of learning to discover and track objects in videos, which we call \\textit{unsupervised object tracking}, has grown in prominence in recent years; however, most architectures that address it still struggle to deal with large scenes containing many objects. In the current work, we propose an architecture that scales well to the large-scene, many-object setting by employing spatially invariant computations (convolutions and spatial attention) and representations (a spatially local object specification scheme). In a series of experiments, we demonstrate a number of attractive features of our architecture; most notably, that it outperforms competing methods at tracking objects in cluttered scenes with many objects, and that it can generalize well to videos that are larger and/or contain more objects than videos encountered during training.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09033v1"
	},
	{
		"title": "Automatic Verification of Liveness Properties in the Situation Calculus ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Knowledge Distillation from Internal Representations ",
		"abstract": "Knowledge distillation is typically conducted by training a small model (the student) to mimic a large and cumbersome model (the teacher). The idea is to compress the knowledge from the teacher by using its output probabilities as soft-labels to optimize the student. However, when the teacher is considerably large, there is no guarantee that the internal knowledge of the teacher will be transferred into the student; even if the student closely matches the soft-labels, its internal representations may be considerably different. This internal mismatch can undermine the generalization capabilities originally intended to be transferred from the teacher to the student. In this paper, we propose to distill the internal representations of a large model such as BERT into a simplified version of it. We formulate two ways to distill such representations and various algorithms to conduct the distillation. We experiment with datasets from the GLUE benchmark and consistently show that adding knowledge distillation from internal representations is a more powerful method than only using soft-label distillation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.03723v2"
	},
	{
		"title": "Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug‐like Molecules ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Novel Learning Framework for Sampling‐Based Motion Planning in Autonomous Driving ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Robust Low‐Rank Discovery of Data‐Driven Partial Differential Equations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Posterior‐GAN: Towards Informative and Coherent Response Generation with Posterior Generative Adversarial Network ",
		"abstract": "Neural conversational models learn to generate responses by taking into account the dialog history. These models are typically optimized over the query-response pairs with a maximum likelihood estimation objective. However, the query-response tuples are naturally loosely coupled, and there exist multiple responses that can respond to a given query, which leads the conversational model learning burdensome. Besides, the general dull response problem is even worsened when the model is confronted with meaningless response training instances. Intuitively, a high-quality response not only responds to the given query but also links up to the future conversations, in this paper, we leverage the query-response-future turn triples to induce the generated responses that consider both the given context and the future conversations. To facilitate the modeling of these triples, we further propose a novel encoder-decoder based generative adversarial learning framework, Posterior Generative Adversarial Network (Posterior-GAN), which consists of a forward and a backward generative discriminator to cooperatively encourage the generated response to be informative and coherent by two complementary assessment perspectives. Experimental results demonstrate that our method effectively boosts the informativeness and coherence of the generated response on both automatic and human evaluation, which verifies the advantages of considering two assessment perspectives.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.02020v1"
	},
	{
		"title": "Manipulating Districts to Win Elections: Fine‐Grained Complexity ",
		"abstract": "Gerrymandering is a practice of manipulating district boundaries and locations in order to achieve a political advantage for a particular party. Lewenberg, Lev, and Rosenschein [AAMAS 2017] initiated the algorithmic study of a geographically-based manipulation problem, where voters must vote at the ballot box closest to them. In this variant of gerrymandering, for a given set of possible locations of ballot boxes and known political preferences of $n$ voters, the task is to identify locations for $k$ boxes out of $m$ possible locations to guarantee victory of a certain party in at least $l$ districts. Here integers $k$ and $l$ are some selected parameter.   It is known that the problem is NP-complete already for 4 political parties and prior to our work only heuristic algorithms for this problem were developed. We initiate the rigorous study of the gerrymandering problem from the perspectives of parameterized and fine-grained complexity and provide asymptotically matching lower and upper bounds on its computational complexity. We prove that the problem is W[1]-hard parameterized by $k+n$ and that it does not admit an $f(n,k)\\cdot m^{o(\\sqrt{k})}$ algorithm for any function $f$ of $k$ and $n$ only, unless Exponential Time Hypothesis (ETH) fails. Our lower bounds hold already for $2$ parties. On the other hand, we give an algorithm that solves the problem for a constant number of parties in time $(m+n)^{O(\\sqrt{k})}$.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.07607v1"
	},
	{
		"title": "Synthesizing Action Sequences for Modifying Model Decisions ",
		"abstract": "When a model makes a consequential decision, e.g., denying someone a loan, it needs to additionally generate actionable, realistic feedback on what the person can do to favorably change the decision. We cast this problem through the lens of program synthesis, in which our goal is to synthesize an optimal (realistically cheapest or simplest) sequence of actions that if a person executes successfully can change their classification. We present a novel and general approach that combines search-based program synthesis and test-time adversarial attacks to construct action sequences over a domain-specific set of actions. We demonstrate the effectiveness of our approach on a number of deep neural networks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.00057v3"
	},
	{
		"title": "Deep Model‐Based Reinforcement Learning via Estimated Uncertainty and Conservative Policy Optimization ",
		"abstract": "Model-based reinforcement learning algorithms tend to achieve higher sample efficiency than model-free methods. However, due to the inevitable errors of learned models, model-based methods struggle to achieve the same asymptotic performance as model-free methods.   In this paper, We propose a Policy Optimization method with Model-Based Uncertainty (POMBU)---a novel model-based approach---that can effectively improve the asymptotic performance using the uncertainty in Q-values. We derive an upper bound of the uncertainty, based on which we can approximate the uncertainty accurately and efficiently for model-based methods. We further propose an uncertainty-aware policy optimization algorithm that optimizes the policy conservatively to encourage performance improvement with high probability. This can significantly alleviate the overfitting of policy to inaccurate models.   Experiments show POMBU can outperform existing state-of-the-art policy optimization algorithms in terms of sample efficiency and asymptotic performance. Moreover, the experiments demonstrate the excellent robustness of POMBU compared to previous model-based approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12574v1"
	},
	{
		"title": "Accelerating and Improving AlphaZero Using Population Based Training ",
		"abstract": "AlphaZero has been very successful in many games. Unfortunately, it still consumes a huge amount of computing resources, the majority of which is spent in self-play. Hyperparameter tuning exacerbates the training cost since each hyperparameter configuration requires its own time to train one run, during which it will generate its own self-play records. As a result, multiple runs are usually needed for different hyperparameter configurations. This paper proposes using population based training (PBT) to help tune hyperparameters dynamically and improve strength during training time. Another significant advantage is that this method requires a single run only, while incurring a small additional time cost, since the time for generating self-play records remains unchanged though the time for optimization is increased following the AlphaZero training algorithm. In our experiments for 9x9 Go, the PBT method is able to achieve a higher win rate for 9x9 Go than the baselines, each with its own hyperparameter configuration and trained individually. For 19x19 Go, with PBT, we are able to obtain improvements in playing strength. Specifically, the PBT agent can obtain up to 74% win rate against ELF OpenGo, an open-source state-of-the-art AlphaZero program using a neural network of a comparable capacity. This is compared to a saturated non-PBT agent, which achieves a win rate of 47% against ELF OpenGo under the same circumstances.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.06212v1"
	},
	{
		"title": "How the Duration of the Learning Period Affects the Performance of Random Gradient Selection Hyper‐heuristics ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Quantized Compressive Sampling of Stochastic Gradients for Efficient Communication in Distributed Deep Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "M‐NAS: Meta Neural Architecture Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Translucent Answer Predictions in Multi‐Hop Reading Comprehension ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Visual Agreement Regularized Training for Multi‐Modal Machine Translation ",
		"abstract": "Multi-modal machine translation aims at translating the source sentence into a different language in the presence of the paired image. Previous work suggests that additional visual information only provides dispensable help to translation, which is needed in several very special cases such as translating ambiguous words. To make better use of visual information, this work presents visual agreement regularized training. The proposed approach jointly trains the source-to-target and target-to-source translation models and encourages them to share the same focus on the visual information when generating semantically equivalent visual words (e.g. \"ball\" in English and \"ballon\" in French). Besides, a simple yet effective multi-head co-attention model is also introduced to capture interactions between visual and textual features. The results show that our approaches can outperform competitive baselines by a large margin on the Multi30k dataset. Further analysis demonstrates that the proposed regularized training can effectively improve the agreement of attention on the image, leading to better use of visual information.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.12014v1"
	},
	{
		"title": "Indirect Stochastic Gradient Quantization and its Application in Distributed Deep Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Diverse Stochastic Human‐Action Generators by Learning Smooth Latent Transitions ",
		"abstract": "Human-motion generation is a long-standing challenging task due to the requirement of accurately modeling complex and diverse dynamic patterns. Most existing methods adopt sequence models such as RNN to directly model transitions in the original action space. Due to high dimensionality and potential noise, such modeling of action transitions is particularly challenging. In this paper, we focus on skeleton-based action generation and propose to model smooth and diverse transitions on a latent space of action sequences with much lower dimensionality. Conditioned on a latent sequence, actions are generated by a frame-wise decoder shared by all latent action-poses. Specifically, an implicit RNN is defined to model smooth latent sequences, whose randomness (diversity) is controlled by noise from the input. Different from standard action-prediction methods, our model can generate action sequences from pure noise without any conditional action poses. Remarkably, it can also generate unseen actions from mixed classes during training. Our model is learned with a bi-directional generative-adversarial-net framework, which not only can generate diverse action sequences of a particular class or mix classes, but also learns to classify action sequences within the same model. Experimental results show the superiority of our method in both diverse action-sequence generation and classification, relative to existing methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10150v1"
	},
	{
		"title": "Spatio‐Temporal Deformable Convolution for Compressed Video Quality Enhancement ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Controlling the Amount of Verbatim Copying in Abstractive Summarization ",
		"abstract": "An abstract must not change the meaning of the original text. A single most effective way to achieve that is to increase the amount of copying while still allowing for text abstraction. Human editors can usually exercise control over copying, resulting in summaries that are more extractive than abstractive, or vice versa. However, it remains poorly understood whether modern neural abstractive summarizers can provide the same flexibility, i.e., learning from single reference summaries to generate multiple summary hypotheses with varying degrees of copying. In this paper, we present a neural summarization model that, by learning from single human abstracts, can produce a broad spectrum of summaries ranging from purely extractive to highly generative ones. We frame the task of summarization as language modeling and exploit alternative mechanisms to generate summary hypotheses. Our method allows for control over copying during both training and decoding stages of a neural summarization model. Through extensive experiments we illustrate the significance of our proposed method on controlling the amount of verbatim copying and achieve competitive results over strong baselines. Our analysis further reveals interesting and unobvious facts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10390v1"
	},
	{
		"title": "Reinforcement Learning with Non‐Markovian Rewards ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations ",
		"abstract": "Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07979v3"
	},
	{
		"title": "A Multi‐unit Profit Competitive Mechanism for Cellular Traffic Offloading ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Open Domain Event Text Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Rumor Detection on Social Media with Bi‐Directional Graph Convolutional Networks ",
		"abstract": "Social media has been developing rapidly in public due to its nature of spreading new information, which leads to rumors being circulated. Meanwhile, detecting rumors from such massive information in social media is becoming an arduous challenge. Therefore, some deep learning methods are applied to discover rumors through the way they spread, such as Recursive Neural Network (RvNN) and so on. However, these deep learning methods only take into account the patterns of deep propagation but ignore the structures of wide dispersion in rumor detection. Actually, propagation and dispersion are two crucial characteristics of rumors. In this paper, we propose a novel bi-directional graph model, named Bi-Directional Graph Convolutional Networks (Bi-GCN), to explore both characteristics by operating on both top-down and bottom-up propagation of rumors. It leverages a GCN with a top-down directed graph of rumor spreading to learn the patterns of rumor propagation, and a GCN with an opposite directed graph of rumor diffusion to capture the structures of rumor dispersion. Moreover, the information from the source post is involved in each layer of GCN to enhance the influences from the roots of rumors. Encouraging empirical results on several benchmarks confirm the superiority of the proposed method over the state-of-the-art approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06362v1"
	},
	{
		"title": "Answering Conjunctive Queries with Inequalities in DL‐LiteR ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Query Rewriting for Ontology‐mediated Conditional Answers ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Improved Knowledge Distillation via Teacher Assistant ",
		"abstract": "Despite the fact that deep neural networks are powerful models and achieve appealing results on many tasks, they are too large to be deployed on edge devices like smartphones or embedded sensor nodes. There have been efforts to compress these networks, and a popular method is knowledge distillation, where a large (teacher) pre-trained network is used to train a smaller (student) network. However, in this paper, we show that the student network performance degrades when the gap between student and teacher is large. Given a fixed student network, one cannot employ an arbitrarily large teacher, or in other words, a teacher can effectively transfer its knowledge to students up to a certain size, not smaller. To alleviate this shortcoming, we introduce multi-step knowledge distillation, which employs an intermediate-sized network (teacher assistant) to bridge the gap between the student and the teacher. Moreover, we study the effect of teacher assistant size and extend the framework to multi-step distillation. Theoretical analysis and extensive experiments on CIFAR-10,100 and ImageNet datasets and on CNN and ResNet architectures substantiate the effectiveness of our proposed approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.03393v2"
	},
	{
		"title": "Evaluating Commonsense in Pre‐trained Language Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Gamma‐Nets: Generalizing Value Estimation Over Timescale ",
		"abstract": "We present $\\Gamma$-nets, a method for generalizing value function estimation over timescale. By using the timescale as one of the estimator's inputs we can estimate value for arbitrary timescales. As a result, the prediction target for any timescale is available and we are free to train on multiple timescales at each timestep. Here we empirically evaluate $\\Gamma$-nets in the policy evaluation setting. We first demonstrate the approach on a square wave and then on a robot arm using linear function approximation. Next, we consider the deep reinforcement learning setting using several Atari video games. Our results show that $\\Gamma$-nets can be effective for predicting arbitrary timescales, with only a small cost in accuracy as compared to learning estimators for fixed timescales. $\\Gamma$-nets provide a method for compactly making predictions at many timescales without requiring a priori knowledge of the task, making it a valuable contribution to ongoing work on model-based planning, representation learning, and lifelong learning algorithms.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07794v5"
	},
	{
		"title": "Semi‐Supervised Learning on Meta Structure: Multi‐Task Tagging and Parsing in Low‐Resource Scenarios ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting ",
		"abstract": "This work proposes a novel approach for multiple time series forecasting. At first, multi-way delay embedding transform (MDT) is employed to represent time series as low-rank block Hankel tensors (BHT). Then, the higher-order tensors are projected to compressed core tensors by applying Tucker decomposition. At the same time, the generalized tensor Autoregressive Integrated Moving Average (ARIMA) is explicitly used on consecutive core tensors to predict future samples. In this manner, the proposed approach tactically incorporates the unique advantages of MDT tensorization (to exploit mutual correlations) and tensor ARIMA coupled with low-rank Tucker decomposition into a unified framework. This framework exploits the low-rank structure of block Hankel tensors in the embedded space and captures the intrinsic correlations among multiple TS, which thus can improve the forecasting results, especially for multiple short time series. Experiments conducted on three public datasets and two industrial datasets verify that the proposed BHT-ARIMA effectively improves forecasting accuracy and reduces computational cost compared with the state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.12135v1"
	},
	{
		"title": "DMRM: A Dual‐channel Multi‐hop Reasoning Model for Visual Dialog ",
		"abstract": "Visual Dialog is a vision-language task that requires an AI agent to engage in a conversation with humans grounded in an image. It remains a challenging task since it requires the agent to fully understand a given question before making an appropriate response not only from the textual dialog history, but also from the visually-grounded information. While previous models typically leverage single-hop reasoning or single-channel reasoning to deal with this complex multimodal reasoning task, which is intuitively insufficient. In this paper, we thus propose a novel and more powerful Dual-channel Multi-hop Reasoning Model for Visual Dialog, named DMRM. DMRM synchronously captures information from the dialog history and the image to enrich the semantic representation of the question by exploiting dual-channel reasoning. Specifically, DMRM maintains a dual channel to obtain the question- and history-aware image features and the question- and image-aware dialog history features by a mulit-hop reasoning process in each channel. Additionally, we also design an effective multimodal attention to further enhance the decoder to generate more accurate responses. Experimental results on the VisDial v0.9 and v1.0 datasets demonstrate that the proposed model is effective and outperforms compared models by a significant margin.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08360v1"
	},
	{
		"title": "Shoreline: Data‐Driven Threshold Estimation of the Online Reserves of Cryptocurrency Trading Platforms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "The Impact of Selfishness in Hypergraph Hedonic Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Type‐aware Anchor Link Prediction across Heterogeneous Networks based on Graph Attention Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Robust Conditional GAN from Uncertainty‐Aware Pairwise Comparisons ",
		"abstract": "Conditional generative adversarial networks have shown exceptional generation performance over the past few years. However, they require large numbers of annotations. To address this problem, we propose a novel generative adversarial network utilizing weak supervision in the form of pairwise comparisons (PC-GAN) for image attribute editing. In the light of Bayesian uncertainty estimation and noise-tolerant adversarial training, PC-GAN can estimate attribute rating efficiently and demonstrate robust performance in noise resistance. Through extensive experiments, we show both qualitatively and quantitatively that PC-GAN performs comparably with fully-supervised methods and outperforms unsupervised baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09298v2"
	},
	{
		"title": "Joint Parsing and Generation for Abstractive Summarization ",
		"abstract": "Sentences produced by abstractive summarization systems can be ungrammatical and fail to preserve the original meanings, despite being locally fluent. In this paper we propose to remedy this problem by jointly generating a sentence and its syntactic dependency parse while performing abstraction. If generating a word can introduce an erroneous relation to the summary, the behavior must be discouraged. The proposed method thus holds promise for producing grammatical sentences and encouraging the summary to stay true-to-original. Our contributions of this work are twofold. First, we present a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder in a synchronized manner to generate a summary sentence and its syntactic parse. Secondly, we describe a novel human evaluation protocol to assess if, and to what extent, a summary remains true to its original meanings. We evaluate our method on a number of summarization datasets and demonstrate competitive results against strong baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10389v1"
	},
	{
		"title": "Learning to Crawl ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Mask & Focus: Conversation Modelling by Learning Concepts ",
		"abstract": "Sequence to sequence models attempt to capture the correlation between all the words in the input and output sequences. While this is quite useful for machine translation where the correlation among the words is indeed quite strong, it becomes problematic for conversation modelling where the correlation is often at a much abstract level. In contrast, humans tend to focus on the essential concepts discussed in the conversation context and generate responses accordingly. In this paper, we attempt to mimic this response generating mechanism by learning the essential concepts in the context and response in an unsupervised manner. The proposed model, referred to as Mask \\& Focus maps the input context to a sequence of concepts which are then used to generate the response concepts. Together, the context and the response concepts generate the final response. In order to learn context concepts from the training data automatically, we \\emph{mask} words in the input and observe the effect of masking on response generation. We train our model to learn those response concepts that have high mutual information with respect to the context concepts, thereby guiding the model to \\emph{focus} on the context concepts. Mask \\& Focus achieves significant improvement over the existing baselines in several established metrics for dialogues.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.04976v1"
	},
	{
		"title": "Benign Examples: Imperceptible changes can enhance image translation performance ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Light Field Angular Super‐Resolution via a Geometry‐Aware Network ",
		"abstract": "The acquisition of light field images with high angular resolution is costly. Although many methods have been proposed to improve the angular resolution of a sparsely-sampled light field, they always focus on the light field with a small baseline, which is captured by a consumer light field camera. By making full use of the intrinsic \\textit{geometry} information of light fields, in this paper we propose an end-to-end learning-based approach aiming at angularly super-resolving a sparsely-sampled light field with a large baseline. Our model consists of two learnable modules and a physically-based module. Specifically, it includes a depth estimation module for explicitly modeling the scene geometry, a physically-based warping for novel views synthesis, and a light field blending module specifically designed for light field reconstruction. Moreover, we introduce a novel loss function to promote the preservation of the light field parallax structure. Experimental results over various light field datasets including large baseline light field images demonstrate the significant superiority of our method when compared with state-of-the-art ones, i.e., our method improves the PSNR of the second best method up to 2 dB in average, while saves the execution time 48$\\times$. In addition, our method preserves the light field parallax structure better.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.11263v1"
	},
	{
		"title": "Side Information Dependence as a Regularizer for Analyzing Human Brain Conditions across Cognitive Experiments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Probabilistic Inference for Predicate Constraint Satisfaction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Strategyproof Mechanism for Friends and Enemies Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Epistemic Integrity Constraints for Ontology‐Based Data Management ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generative Adversarial Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Self‐Paced Robust Learning for Leveraging Clean Labels in Noisy Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Why We Go Where We Go: Profiling User Decisions on Choosing POIs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A Deep Neural Network Model of Particle Thermal Radiation in Packed Bed  ",
		"abstract": "Prediction of particle radiative heat transfer flux is an important task in the large discrete granular systems, such as pebble bed in power plants and industrial fluidized beds. For particle motion and packing, discrete element method (DEM) now is widely accepted as the excellent Lagrangian approach. For thermal radiation, traditional methods focus on calculating the obstructed view factor directly by numerical algorithms. The major challenge for the simulation is that the method is proven to be time-consuming and not feasible to be applied in the practical cases. In this work, we propose an analytical model to calculate macroscopic effective conductivity from particle packing structures Then, we develop a deep neural network (DNN) model used as a predictor of the complex view factor function. The DNN model is trained by a large dataset and the computational speed is greatly improved with good accuracy. It is feasible to perform real-time simulation with DNN model for radiative heat transfer in large pebble bed. The trained model also can be coupled with DEM and used to analyze efficiently the directional radiative conductivity, anisotropic factor and wall effect of the particle thermal radiation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.13142v1"
	},
	{
		"title": "COTSAE: CO‐Training of Structure and Attribute Embeddings for Entity Alignment ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "CORE: Automatic Molecule Optimization Using Copy & Refine Strategy ",
		"abstract": "Molecule optimization is about generating molecule $Y$ with more desirable properties based on an input molecule $X$. The state-of-the-art approaches partition the molecules into a large set of substructures $S$ and grow the new molecule structure by iteratively predicting which substructure from $S$ to add. However, since the set of available substructures $S$ is large, such an iterative prediction task is often inaccurate especially for substructures that are infrequent in the training data. To address this challenge, we propose a new generating strategy called \"Copy & Refine\" (CORE), where at each step the generator first decides whether to copy an existing substructure from input $X$ or to generate a new substructure, then the most promising substructure will be added to the new molecule. Combining together with scaffolding tree generation and adversarial training, CORE can significantly improve several latest molecule optimization methods in various measures including drug likeness (QED), dopamine receptor (DRD2) and penalized LogP. We tested CORE and baselines using the ZINC database and CORE obtained up to 11% and 21% relatively improvement over the baselines on success rate on the complete test set and the subset with infrequent substructures, respectively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.05910v1"
	},
	{
		"title": "Stochastic Approximate Gradient Descent via the Langevin Algorithm ",
		"abstract": "We introduce a novel and efficient algorithm called the stochastic approximate gradient descent (SAGD), as an alternative to the stochastic gradient descent for cases where unbiased stochastic gradients cannot be trivially obtained. Traditional methods for such problems rely on general-purpose sampling techniques such as Markov chain Monte Carlo, which typically requires manual intervention for tuning parameters and does not work efficiently in practice. Instead, SAGD makes use of the Langevin algorithm to construct stochastic gradients that are biased in finite steps but accurate asymptotically, enabling us to theoretically establish the convergence guarantee for SAGD. Inspired by our theoretical analysis, we also provide useful guidelines for its practical implementation. Finally, we show that SAGD performs well experimentally in popular statistical and machine learning problems such as the expectation-maximization algorithm and the variational autoencoders.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.05519v1"
	},
	{
		"title": "Balancing Quality and Human Involvement: an Effective Approach to Interactive Neural Machine Translation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Distributed Representations for Arithmetic Word Problems ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Zero‐shot Text‐to‐SQL Learning with Auxiliary Task ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Optimal Decision Trees Using Caching Branch‐and‐Bound Search ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "A comparison of architectures and pretraining methods for contextualized multilingual word embeddings ",
		"abstract": "The lack of annotated data in many languages is a well-known challenge within the field of multilingual natural language processing (NLP). Therefore, many recent studies focus on zero-shot transfer learning and joint training across languages to overcome data scarcity for low-resource languages. In this work we (i) perform a comprehensive comparison of state-ofthe-art multilingual word and sentence encoders on the tasks of named entity recognition (NER) and part of speech (POS) tagging; and (ii) propose a new method for creating multilingual contextualized word embeddings, compare it to multiple baselines and show that it performs at or above state-of-theart level in zero-shot transfer settings. Finally, we show that our method allows for better knowledge sharing across languages in a joint training setting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10169v1"
	},
	{
		"title": "Novel Is Not Always Better: On the Relation between Novelty and Dominance Pruning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Capturing Greater Context for Question Generation ",
		"abstract": "Automatic question generation can benefit many applications ranging from dialogue systems to reading comprehension. While questions are often asked with respect to long documents, there are many challenges with modeling such long documents. Many existing techniques generate questions by effectively looking at one sentence at a time, leading to questions that are easy and not reflective of the human process of question generation. Our goal is to incorporate interactions across multiple sentences to generate realistic questions for long documents. In order to link a broad document context to the target answer, we represent the relevant context via a multi-stage attention mechanism, which forms the foundation of a sequence to sequence model. We outperform state-of-the-art methods on question generation on three question-answering datasets -- SQuAD, MS MARCO and NewsQA.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.10274v1"
	},
	{
		"title": "Multi‐Source Domain Adaptation for Text Classification via DistanceNet‐Bandits ",
		"abstract": "Domain adaptation performance of a learning algorithm on a target domain is a function of its source domain error and a divergence measure between the data distribution of these two domains. We present a study of various distance-based measures in the context of NLP tasks, that characterize the dissimilarity between domains based on sample estimates. We first conduct analysis experiments to show which of these distance measures can best differentiate samples from same versus different domains, and are correlated with empirical results. Next, we develop a DistanceNet model which uses these distance measures, or a mixture of these distance measures, as an additional loss function to be minimized jointly with the task's loss function, so as to achieve better unsupervised domain adaptation. Finally, we extend this model to a novel DistanceNet-Bandit model, which employs a multi-armed bandit controller to dynamically switch between multiple source domains and allow the model to learn an optimal trajectory and mixture of domains for transfer to the low-resource target domain. We conduct experiments on popular sentiment analysis datasets with several diverse domains and show that our DistanceNet model, as well as its dynamic bandit variant, can outperform competitive baselines in the context of unsupervised domain adaptation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.04362v3"
	},
	{
		"title": "Repeated Multimarket Contact with Private Monitoring: A Belief‐Free Approach ",
		"abstract": "This paper studies repeated games where two players play multiple duopolistic games simultaneously (multimarket contact). A key assumption is that each player receives a noisy and private signal about the other's actions (private monitoring or observation errors). There has been no game-theoretic support that multimarket contact facilitates collusion or not, in the sense that more collusive equilibria in terms of per-market profits exist than those under a benchmark case of one market. An equilibrium candidate under the benchmark case is belief-free strategies. We are the first to construct a non-trivial class of strategies that exhibits the effect of multimarket contact from the perspectives of simplicity and mild punishment. Strategies must be simple because firms in a cartel must coordinate each other with no communication. Punishment must be mild to an extent that it does not hurt even the minimum required profits in the cartel. We thus focus on two-state automaton strategies such that the players are cooperative in at least one market even when he or she punishes a traitor. Furthermore, we identify an additional condition (partial indifference), under which the collusive equilibrium yields the optimal payoff.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1607.03583v3"
	},
	{
		"title": "AutoCompress: An Automatic DNN Structured Pruning Framework for Ultra‐High Compression Rates ",
		"abstract": "Structured weight pruning is a representative model compression technique of DNNs to reduce the storage and computation requirements and accelerate inference. An automatic hyperparameter determination process is necessary due to the large number of flexible hyperparameters. This work proposes AutoCompress, an automatic structured pruning framework with the following key performance improvements: (i) effectively incorporate the combination of structured pruning schemes in the automatic process; (ii) adopt the state-of-art ADMM-based structured weight pruning as the core algorithm, and propose an innovative additional purification step for further weight reduction without accuracy loss; and (iii) develop effective heuristic search method enhanced by experience-based guided search, replacing the prior deep reinforcement learning technique which has underlying incompatibility with the target pruning problem. Extensive experiments on CIFAR-10 and ImageNet datasets demonstrate that AutoCompress is the key to achieve ultra-high pruning rates on the number of weights and FLOPs that cannot be achieved before. As an example, AutoCompress outperforms the prior work on automatic model compression by up to 33x in pruning rate (120x reduction in the actual parameter count) under the same accuracy. Significant inference speedup has been observed from the AutoCompress framework on actual measurements on smartphone. We release all models of this work at anonymous link: http://bit.ly/2VZ63dS.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.03141v2"
	},
	{
		"title": "Joint Super‐Resolution and Alignment of Tiny Faces ",
		"abstract": "Super-resolution (SR) and landmark localization of tiny faces are highly correlated tasks. On the one hand, landmark localization could obtain higher accuracy with faces of high-resolution (HR). On the other hand, face SR would benefit from prior knowledge of facial attributes such as landmarks. Thus, we propose a joint alignment and SR network to simultaneously detect facial landmarks and super-resolve tiny faces. More specifically, a shared deep encoder is applied to extract features for both tasks by leveraging complementary information. To exploit the representative power of the hierarchical encoder, intermediate layers of a shared feature extraction module are fused to form efficient feature representations. The fused features are then fed to task-specific modules to detect landmarks and super-resolve face images in parallel. Extensive experiments demonstrate that the proposed model significantly outperforms the state-of-the-art in both landmark localization and SR of faces. We show a large improvement for landmark localization of tiny faces (i.e., 16*16). Furthermore, the proposed framework yields comparable results for landmark localization on low-resolution (LR) faces (i.e., 64*64) to existing methods on HR (i.e., 256*256). As for SR, the proposed method recovers sharper edges and more details from LR face images than other state-of-the-art methods, which we demonstrate qualitatively and quantitatively.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08566v1"
	},
	{
		"title": "Meta‐CoTGAN: A Meta Cooperative Training Paradigm for Improving  Adversarial Text Generation ",
		"abstract": "Training generative models that can generate high-quality text with sufficient diversity is an important open problem for Natural Language Generation (NLG) community. Recently, generative adversarial models have been applied extensively on text generation tasks, where the adversarially trained generators alleviate the exposure bias experienced by conventional maximum likelihood approaches and result in promising generation quality. However, due to the notorious defect of mode collapse for adversarial training, the adversarially trained generators face a quality-diversity trade-off, i.e., the generator models tend to sacrifice generation diversity severely for increasing generation quality. In this paper, we propose a novel approach which aims to improve the performance of adversarial text generation via efficiently decelerating mode collapse of the adversarial training. To this end, we introduce a cooperative training paradigm, where a language model is cooperatively trained with the generator and we utilize the language model to efficiently shape the data distribution of the generator against mode collapse. Moreover, instead of engaging the cooperative update for the generator in a principled way, we formulate a meta learning mechanism, where the cooperative update to the generator serves as a high level meta task, with an intuition of ensuring the parameters of the generator after the adversarial update would stay resistant against mode collapse. In the experiment, we demonstrate our proposed approach can efficiently slow down the pace of mode collapse for the adversarial text generators. Overall, our proposed method is able to outperform the baseline approaches with significant margins in terms of both generation quality and diversity in the testified domains.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.11530v1"
	},
	{
		"title": "Vector Quantization‐Based Regularization for Autoencoders ",
		"abstract": "Autoencoders and their variations provide unsupervised models for learning low-dimensional representations for downstream tasks. Without proper regularization, autoencoder models are susceptible to the overfitting problem and the so-called posterior collapse phenomenon. In this paper, we introduce a quantization-based regularizer in the bottleneck stage of autoencoder models to learn meaningful latent representations. We combine both perspectives of Vector Quantized-Variational AutoEncoders (VQ-VAE) and classical denoising regularization methods of neural networks. We interpret quantizers as regularizers that constrain latent representations while fostering a similarity-preserving mapping at the encoder. Before quantization, we impose noise on the latent codes and use a Bayesian estimator to optimize the quantizer-based representation. The introduced bottleneck Bayesian estimator outputs the posterior mean of the centroids to the decoder, and thus, is performing soft quantization of the noisy latent codes. We show that our proposed regularization method results in improved latent representations for both supervised learning and clustering downstream tasks when compared to autoencoders using other bottleneck structures.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.11062v2"
	},
	{
		"title": "ManyModalQA: Modality Disambiguation and QA over Diverse Inputs ",
		"abstract": "We present a new multimodal question answering challenge, ManyModalQA, in which an agent must answer a question by considering three distinct modalities: text, images, and tables. We collect our data by scraping Wikipedia and then utilize crowdsourcing to collect question-answer pairs. Our questions are ambiguous, in that the modality that contains the answer is not easily determined based solely upon the question. To demonstrate this ambiguity, we construct a modality selector (or disambiguator) network, and this model gets substantially lower accuracy on our challenge set, compared to existing datasets, indicating that our questions are more ambiguous. By analyzing this model, we investigate which words in the question are indicative of the modality. Next, we construct a simple baseline ManyModalQA model, which, based on the prediction from the modality selector, fires a corresponding pre-trained state-of-the-art unimodal QA model. We focus on providing the community with a new manymodal evaluation set and only provide a fine-tuning set, with the expectation that existing datasets and approaches will be transferred for most of the training, to encourage low-resource generalization without large, monolithic training sets for each new task. There is a significant gap between our baseline models and human performance; therefore, we hope that this challenge encourages research in end-to-end modality disambiguation and multimodal QA models, as well as transfer learning. Code and data available at: https://github.com/hannandarryl/ManyModalQA",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.08034v1"
	},
	{
		"title": "Crowd‐assisted Disaster Scene Assessment with Human‐AI Interactive Attention ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Explanations for Inconsistency‐Tolerant Query Answering under Existential Rules ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Modular Robot Design Synthesis with Deep Reinforcement Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Unsupervised Attributed Multiplex Network Embedding ",
		"abstract": "Nodes in a multiplex network are connected by multiple types of relations. However, most existing network embedding methods assume that only a single type of relation exists between nodes. Even for those that consider the multiplexity of a network, they overlook node attributes, resort to node labels for training, and fail to model the global properties of a graph. We present a simple yet effective unsupervised network embedding method for attributed multiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that maximizes the mutual information between local patches of a graph, and the global representation of the entire graph. We devise a systematic way to jointly integrate the node embeddings from multiple graphs by introducing 1) the consensus regularization framework that minimizes the disagreements among the relation-type specific node embeddings, and 2) the universal discriminator that discriminates true samples regardless of the relation types. We also show that the attention mechanism infers the importance of each relation type, and thus can be useful for filtering unnecessary relation types as a preprocessing step. Extensive experiments on various downstream tasks demonstrate that DMGI outperforms the state-of-the-art methods, even though DMGI is fully unsupervised.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.06750v2"
	},
	{
		"title": "A Knowledge Transfer Framework for Differentially Private Sparse Learning ",
		"abstract": "We study the problem of estimating high dimensional models with underlying sparse structures while preserving the privacy of each training example. We develop a differentially private high-dimensional sparse learning framework using the idea of knowledge transfer. More specifically, we propose to distill the knowledge from a \"teacher\" estimator trained on a private dataset, by creating a new dataset from auxiliary features, and then train a differentially private \"student\" estimator using this new dataset. In addition, we establish the linear convergence rate as well as the utility guarantee for our proposed method. For sparse linear regression and sparse logistic regression, our method achieves improved utility guarantees compared with the best known results (Kifer et al., 2012; Wang and Gu, 2019). We further demonstrate the superiority of our framework through both synthetic and real-world data experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.06322v1"
	},
	{
		"title": "Sanity Checks for Saliency Metrics ",
		"abstract": "Saliency maps are a popular approach to creating post-hoc explanations of image classifier outputs. These methods produce estimates of the relevance of each pixel to the classification output score, which can be displayed as a saliency map that highlights important pixels. Despite a proliferation of such methods, little effort has been made to quantify how good these saliency maps are at capturing the true relevance of the pixels to the classifier output (i.e. their \"fidelity\"). We therefore investigate existing metrics for evaluating the fidelity of saliency methods (i.e. saliency metrics). We find that there is little consistency in the literature in how such metrics are calculated, and show that such inconsistencies can have a significant effect on the measured fidelity. Further, we apply measures of reliability developed in the psychometric testing literature to assess the consistency of saliency metrics when applied to individual saliency maps. Our results show that saliency metrics can be statistically unreliable and inconsistent, indicating that comparative rankings between saliency methods generated using such metrics can be untrustworthy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01451v1"
	},
	{
		"title": "DeepAlerts: Deep Learning Based Multi‐horizon Alerts for Clinical Deterioration on Oncology Hospital Wards ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Analysis of One‐to‐One Matching Mechansims via SAT Solving: Impossibilities for Universal Axioms ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ERNIE 2.0: A Continual Pre‐training Framework for Language Understanding ",
		"abstract": "Recently, pre-trained models have achieved state-of-the-art results in various language understanding tasks, which indicates that pre-training on large-scale corpora may play a crucial role in natural language processing. Current pre-training procedures usually focus on training the model with several simple tasks to grasp the co-occurrence of words or sentences. However, besides co-occurring, there exists other valuable lexical, syntactic and semantic information in training corpora, such as named entity, semantic closeness and discourse relations. In order to extract to the fullest extent, the lexical, syntactic and semantic information from training corpora, we propose a continual pre-training framework named ERNIE 2.0 which builds and learns incrementally pre-training tasks through constant multi-task learning. Experimental results demonstrate that ERNIE 2.0 outperforms BERT and XLNet on 16 tasks including English tasks on GLUE benchmarks and several common tasks in Chinese. The source codes and pre-trained models have been released at https://github.com/PaddlePaddle/ERNIE.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.12412v2"
	},
	{
		"title": "Merging Weak and Active Supervision for Semantic Parsing ",
		"abstract": "A semantic parser maps natural language commands (NLs) from the users to executable meaning representations (MRs), which are later executed in certain environment to obtain user-desired results. The fully-supervised training of such parser requires NL/MR pairs, annotated by domain experts, which makes them expensive to collect. However, weakly-supervised semantic parsers are learnt only from pairs of NL and expected execution results, leaving the MRs latent. While weak supervision is cheaper to acquire, learning from this input poses difficulties. It demands that parsers search a large space with a very weak learning signal and it is hard to avoid spurious MRs that achieve the correct answer in the wrong way. These factors lead to a performance gap between parsers trained in weakly- and fully-supervised setting. To bridge this gap, we examine the intersection between weak supervision and active learning, which allows the learner to actively select examples and query for manual annotations as extra supervision to improve the model trained under weak supervision. We study different active learning heuristics for selecting examples to query, and various forms of extra supervision for such queries. We evaluate the effectiveness of our method on two different datasets. Experiments on the WikiSQL show that by annotating only 1.8% of examples, we improve over a state-of-the-art weakly-supervised baseline by 6.4%, achieving an accuracy of 79.0%, which is only 1.3% away from the model trained with full supervision. Experiments on WikiTableQuestions with human annotators show that our method can improve the performance with only 100 active queries, especially for weakly-supervised parsers learnt from a cold start.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.12986v1"
	},
	{
		"title": "Enhancing natural language inference using new and expanded training data sets and new learning models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Efficient Projection‐Free Online Methods with Stochastic Recursive Gradient ",
		"abstract": "This paper focuses on projection-free methods for solving smooth Online Convex Optimization (OCO) problems. Existing projection-free methods either achieve suboptimal regret bounds or have high per-iteration computational costs. To fill this gap, two efficient projection-free online methods called ORGFW and MORGFW are proposed for solving stochastic and adversarial OCO problems, respectively. By employing a recursive gradient estimator, our methods achieve optimal regret bounds (up to a logarithmic factor) while possessing low per-iteration computational costs. Experimental results demonstrate the efficiency of the proposed methods compared to state-of-the-arts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.09396v2"
	},
	{
		"title": "Optical Flow in Deep Visual Tracking ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "An Objective for Hierarchical Clustering in Euclidean Space and its Connection to Bisecting K‐means ",
		"abstract": "This paper explores hierarchical clustering in the case where pairs of points have dissimilarity scores (e.g. distances) as a part of the input. The recently introduced objective for points with dissimilarity scores results in every tree being a 1/2 approximation if the distances form a metric. This shows the objective does not make a significant distinction between a good and poor hierarchical clustering in metric spaces. Motivated by this, the paper develops a new global objective for hierarchical clustering in Euclidean space. The objective captures the criterion that has motivated the use of divisive clustering algorithms: that when a split happens, points in the same cluster should be more similar than points in different clusters. Moreover, this objective gives reasonable results on ground-truth inputs for hierarchical clustering. The paper builds a theoretical connection between this objective and the bisecting k-means algorithm. This paper proves that the optimal 2-means solution results in a constant approximation for the objective. This is the first paper to show the bisecting k-means algorithm optimizes a natural global objective over the entire tree.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.13235v1"
	},
	{
		"title": "Structured Sparsification of Gated Recurrent Neural Networks ",
		"abstract": "Recently, a lot of techniques were developed to sparsify the weights of neural networks and to remove networks' structure units, e.g. neurons. We adjust the existing sparsification approaches to the gated recurrent architectures. Specifically, in addition to the sparsification of weights and neurons, we propose sparsifying the preactivations of gates. This makes some gates constant and simplifies LSTM structure. We test our approach on the text classification and language modeling tasks. We observe that the resulting structure of gate sparsity depends on the task and connect the learned structure to the specifics of the particular tasks. Our method also improves neuron-wise compression of the model in most of the tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.05585v1"
	},
	{
		"title": "TapNet: Multivariate Time Series Classificationwith Attentional Prototype Network ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Weakly Supervised Sequence Tagging from Noisy Rules ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Partial Label Learning with Batch Label Correction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Data Programming using Continuous and Quality‐Guided Labeling Functions ",
		"abstract": "Scarcity of labeled data is a bottleneck for supervised learning models. A paradigm that has evolved for dealing with this problem is data programming. An existing data programming paradigm allows human supervision to be provided as a set of discrete labeling functions (LF) that output possibly noisy labels to input instances and a generative modelfor consolidating the weak labels. We enhance and generalize this paradigm by supporting functions that output a continuous score (instead of a hard label) that noisily correlates with labels. We show across five applications that continuous LFs are more natural to program and lead to improved recall. We also show that accuracy of existing generative models is unstable with respect to initialization, training epochs, and learning rates. We give control to the data programmer to guide the training process by providing intuitive quality guides with each LF. We propose an elegant method of incorporating these guides into the generative model. Our overall method, called CAGE, makes the data programming paradigm more reliable than other tricks based on initialization, sign-penalties, or soft-accuracy constraints.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09860v1"
	},
	{
		"title": "Crowd Counting with Decomposed Uncertainty ",
		"abstract": "Research in neural networks in the field of computer vision has achieved remarkable accuracy for point estimation. However, the uncertainty in the estimation is rarely addressed. Uncertainty quantification accompanied by point estimation can lead to a more informed decision, and even improve the prediction quality. In this work, we focus on uncertainty estimation in the domain of crowd counting. With increasing occurrences of heavily crowded events such as political rallies, protests, concerts, etc., automated crowd analysis is becoming an increasingly crucial task. The stakes can be very high in many of these real-world applications. We propose a scalable neural network framework with quantification of decomposed uncertainty using a bootstrap ensemble. We demonstrate that the proposed uncertainty quantification method provides additional insight to the crowd counting problem and is simple to implement. We also show that our proposed method exhibits the state of the art performances in many benchmark crowd counting datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1903.07427v3"
	},
	{
		"title": "Low‐variance Black‐box Gradient Estimates for the Plackett‐Luce Distribution ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "BAR ‐ A Reinforcement Learning Agent for Bounding‐Box Automated Refinement ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "MA‐DST: Multi‐Attention‐Based Scalable Dialog State Tracking ",
		"abstract": "Task oriented dialog agents provide a natural language interface for users to complete their goal. Dialog State Tracking (DST), which is often a core component of these systems, tracks the system's understanding of the user's goal throughout the conversation. To enable accurate multi-domain DST, the model needs to encode dependencies between past utterances and slot semantics and understand the dialog context, including long-range cross-domain references. We introduce a novel architecture for this task to encode the conversation history and slot semantics more robustly by using attention mechanisms at multiple granularities. In particular, we use cross-attention to model relationships between the context and slots at different semantic levels and self-attention to resolve cross-domain coreferences. In addition, our proposed architecture does not rely on knowing the domain ontologies beforehand and can also be used in a zero-shot setting for new domains or unseen slot values. Our model improves the joint goal accuracy by 5% (absolute) in the full-data setting and by up to 2% (absolute) in the zero-shot setting over the present state-of-the-art on the MultiWoZ 2.1 dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.08898v1"
	},
	{
		"title": "Hierarchical Reinforcement Learning for Open‐Domain Dialog ",
		"abstract": "Open-domain dialog generation is a challenging problem; maximum likelihood training can lead to repetitive outputs, models have difficulty tracking long-term conversational goals, and training on standard movie or online datasets may lead to the generation of inappropriate, biased, or offensive text. Reinforcement Learning (RL) is a powerful framework that could potentially address these issues, for example by allowing a dialog model to optimize for reducing toxicity and repetitiveness. However, previous approaches which apply RL to open-domain dialog generation do so at the word level, making it difficult for the model to learn proper credit assignment for long-term conversational rewards. In this paper, we propose a novel approach to hierarchical reinforcement learning, VHRL, which uses policy gradients to tune the utterance-level embedding of a variational sequence model. This hierarchical approach provides greater flexibility for learning long-term, conversational rewards. We use self-play and RL to optimize for a set of human-centered conversation metrics, and show that our approach provides significant improvements -- in terms of both human evaluation and automatic metrics -- over state-of-the-art dialog models, including Transformers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07547v3"
	},
	{
		"title": "Structure‐Aware Feature Fusion for Unsupervised Domain Adaptation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Multi‐Modal Biomarker Representations via Globally Aligned Longitudinal Enrichments ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning from Interventions using Hierarchical Policies for Safe Learning ",
		"abstract": "Learning from Demonstrations (LfD) via Behavior Cloning (BC) works well on multiple complex tasks. However, a limitation of the typical LfD approach is that it requires expert demonstrations for all scenarios, including those in which the algorithm is already well-trained. The recently proposed Learning from Interventions (LfI) overcomes this limitation by using an expert overseer. The expert overseer only intervenes when it suspects that an unsafe action is about to be taken. Although LfI significantly improves over LfD, the state-of-the-art LfI fails to account for delay caused by the expert's reaction time and only learns short-term behavior. We address these limitations by 1) interpolating the expert's interventions back in time, and 2) by splitting the policy into two hierarchical levels, one that generates sub-goals for the future and another that generates actions to reach those desired sub-goals. This sub-goal prediction forces the algorithm to learn long-term behavior while also being robust to the expert's reaction time. Our experiments show that LfI using sub-goals in a hierarchical policy framework trains faster and achieves better asymptotic performance than typical LfD.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.02241v1"
	},
	{
		"title": "Individual‐Based Stability in Hedonic Diversity Games ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "PIQA: Reasoning about Physical Commonsense in Natural Language ",
		"abstract": "To apply eyeshadow without a brush, should I use a cotton swab or a toothpick? Questions requiring this kind of physical commonsense pose a challenge to today's natural language understanding systems. While recent pretrained models (such as BERT) have made progress on question answering over more abstract domains - such as news articles and encyclopedia entries, where text is plentiful - in more physical domains, text is inherently limited due to reporting bias. Can AI systems learn to reliably answer physical common-sense questions without experiencing the physical world? In this paper, we introduce the task of physical commonsense reasoning and a corresponding benchmark dataset Physical Interaction: Question Answering or PIQA. Though humans find the dataset easy (95% accuracy), large pretrained models struggle (77%). We provide analysis about the dimensions of knowledge that existing models lack, which offers significant opportunities for future research.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11641v1"
	},
	{
		"title": "Smart Predict‐and‐Optimize for Hard Combinatorial Optimization Problems ",
		"abstract": "Combinatorial optimization assumes that all parameters of the optimization problem, e.g. the weights in the objective function is fixed. Often, these weights are mere estimates and increasingly machine learning techniques are used to for their estimation. Recently, Smart Predict and Optimize (SPO) has been proposed for problems with a linear objective function over the predictions, more specifically linear programming problems. It takes the regret of the predictions on the linear problem into account, by repeatedly solving it during learning. We investigate the use of SPO to solve more realistic discrete optimization problems. The main challenge is the repeated solving of the optimization problem. To this end, we investigate ways to relax the problem as well as warmstarting the learning and the solving. Our results show that even for discrete problems it often suffices to train by solving the relaxation in the SPO loss. Furthermore, this approach outperforms, for most instances, the state-of-the-art approach of Wilder, Dilkina, and Tambe. We experiment with weighted knapsack problems as well as complex scheduling problems and show for the first time that a predict-and-optimize approach can successfully be used on large-scale combinatorial optimization problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10092v1"
	},
	{
		"title": "Verb Class Induction with Partial Supervision ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Contextual Parameter Generation for Knowledge Graph Link Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "InteractE: Improving Convolution‐based Knowledge Graph Embeddings by Increasing Feature Interactions ",
		"abstract": "Most existing knowledge graphs suffer from incompleteness, which can be alleviated by inferring missing links based on known facts. One popular way to accomplish this is to generate low-dimensional embeddings of entities and relations, and use these to make inferences. ConvE, a recently proposed approach, applies convolutional filters on 2D reshapings of entity and relation embeddings in order to capture rich interactions between their components. However, the number of interactions that ConvE can capture is limited. In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE. InteractE is based on three key ideas -- feature permutation, a novel feature reshaping, and circular convolution. Through extensive experiments, we find that InteractE outperforms state-of-the-art convolutional link prediction baselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%, 7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets respectively. The results validate our central hypothesis -- that increasing feature interaction is beneficial to link prediction performance. We make the source code of InteractE available to encourage reproducible research.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.00219v3"
	},
	{
		"title": "Optimal Attack against Autoregressive Models by Manipulating the Environment ",
		"abstract": "We describe an optimal adversarial attack formulation against autoregressive time series forecast using Linear Quadratic Regulator (LQR). In this threat model, the environment evolves according to a dynamical system; an autoregressive model observes the current environment state and predicts its future values; an attacker has the ability to modify the environment state in order to manipulate future autoregressive forecasts. The attacker's goal is to force autoregressive forecasts into tracking a target trajectory while minimizing its attack expenditure. In the white-box setting where the attacker knows the environment and forecast models, we present the optimal attack using LQR for linear models, and Model Predictive Control (MPC) for nonlinear models. In the black-box setting, we combine system identification and MPC. Experiments demonstrate the effectiveness of our attacks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1902.00202v3"
	},
	{
		"title": "Identifying Model Weakness with Adversarial Examiner ",
		"abstract": "Machine learning models are usually evaluated according to the average case performance on the test set. However, this is not always ideal, because in some sensitive domains (e.g. autonomous driving), it is the worst case performance that matters more. In this paper, we are interested in systematic exploration of the input data space to identify the weakness of the model to be evaluated. We propose to use an adversarial examiner in the testing stage. Different from the existing strategy to always give the same (distribution of) test data, the adversarial examiner will dynamically select the next test data to hand out based on the testing history so far, with the goal being to undermine the model's performance. This sequence of test data not only helps us understand the current model, but also serves as constructive feedback to help improve the model in the next iteration. We conduct experiments on ShapeNet object classification. We show that our adversarial examiner can successfully put more emphasis on the weakness of the model, preventing performance estimates from being overly optimistic.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.11230v1"
	},
	{
		"title": "Bursting the Filter Bubble: Fairness‐Aware Network Link Prediction ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Comprehensive Recommender Systems: Time‐Aware Unified Recommendations Based on Listwise Ranking of Implicit Cross‐Network Data ",
		"abstract": "The abundance of information in web applications make recommendation essential for users as well as applications. Despite the effectiveness of existing recommender systems, we find two major limitations that reduce their overall performance: (1) inability to provide timely recommendations for both new and existing users by considering the dynamic nature of user preferences, and (2) not fully optimized for the ranking task when using implicit feedback. Therefore, we propose a novel deep learning based unified cross-network solution to mitigate cold-start and data sparsity issues and provide timely recommendations for new and existing users.Furthermore, we consider the ranking problem under implicit feedback as a classification task, and propose a generic personalized listwise optimization criterion for implicit data to effectively rank a list of items. We illustrate our cross-network model using Twitter auxiliary information for recommendations on YouTube target network. Extensive comparisons against multiple time aware and cross-network base-lines show that the proposed solution is superior in terms of accuracy, novelty and diversity. Furthermore, experiments conducted on the popular MovieLens dataset suggest that the proposed listwise ranking method outperforms existing state-of-the-art ranking techniques.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2008.13516v1"
	},
	{
		"title": "How to Ask Better Questions? A Large‐Scale Multi‐Domain Dataset for Rewriting Ill‐Formed Questions ",
		"abstract": "We present a large-scale dataset for the task of rewriting an ill-formed natural language question to a well-formed one. Our multi-domain question rewriting MQR dataset is constructed from human contributed Stack Exchange question edit histories. The dataset contains 427,719 question pairs which come from 303 domains. We provide human annotations for a subset of the dataset as a quality estimate. When moving from ill-formed to well-formed questions, the question quality improves by an average of 45 points across three aspects. We train sequence-to-sequence neural models on the constructed dataset and obtain an improvement of 13.2% in BLEU-4 over baseline methods built from other data resources. We release the MQR dataset to encourage research on the problem of question rewriting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09247v1"
	},
	{
		"title": "Facility Location Problem with Capacity Constraints: Algorithmic and Mechanism Design Perspectives ",
		"abstract": "We consider the facility location problem in the one-dimensional setting where each facility can serve a limited number of agents from the algorithmic and mechanism design perspectives. From the algorithmic perspective, we prove that the corresponding optimization problem, where the goal is to locate facilities to minimize either the total cost to all agents or the maximum cost of any agent is NP-hard. However, we show that the problem is fixed-parameter tractable, and the optimal solution can be computed in polynomial time whenever the number of facilities is bounded, or when all facilities have identical capacities. We then consider the problem from a mechanism design perspective where the agents are strategic and need not reveal their true locations. We show that several natural mechanisms studied in the uncapacitated setting either lose strategyproofness or a bound on the solution quality for the total or maximum cost objective. We then propose new mechanisms that are strategyproof and achieve approximation guarantees that almost match the lower bounds.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09813v1"
	},
	{
		"title": "ScaleNet ‐ Improve CNNs through Recursively Rescaling Objects ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Copy or Rewrite: Hybrid Summarization with Hierarchical Reinforcement Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multi‐Scale Self‐Attention for Text Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Balancing the Tradeoff between Profit and Fairness in Rideshare Platforms During High‐Demand Hours ",
		"abstract": "Rideshare platforms, when assigning requests to drivers, tend to maximize profit for the system and/or minimize waiting time for riders. Such platforms can exacerbate biases that drivers may have over certain types of requests. We consider the case of peak hours when the demand for rides is more than the supply of drivers. Drivers are well aware of their advantage during the peak hours and can choose to be selective about which rides to accept. Moreover, if in such a scenario, the assignment of requests to drivers (by the platform) is made only to maximize profit and/or minimize wait time for riders, requests of a certain type (e.g. from a non-popular pickup location, or to a non-popular drop-off location) might never be assigned to a driver. Such a system can be highly unfair to riders. However, increasing fairness might come at a cost of the overall profit made by the rideshare platform. To balance these conflicting goals, we present a flexible, non-adaptive algorithm, \\lpalg, that allows the platform designer to control the profit and fairness of the system via parameters $\\alpha$ and $\\beta$ respectively. We model the matching problem as an online bipartite matching where the set of drivers is offline and requests arrive online. Upon the arrival of a request, we use \\lpalg to assign it to a driver (the driver might then choose to accept or reject it) or reject the request. We formalize the measures of profit and fairness in our setting and show that by using \\lpalg, the competitive ratios for profit and fairness measures would be no worse than $\\alpha/e$ and $\\beta/e$ respectively. Extensive experimental results on both real-world and synthetic datasets confirm the validity of our theoretical lower bounds. Additionally, they show that $\\lpalg$ under some choice of $(\\alpha, \\beta)$ can beat two natural heuristics, Greedy and Uniform, on \\emph{both} fairness and profit.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08388v2"
	},
	{
		"title": "Conquering the CNN Over‐Parameterization Dilemma: A Volterra Filtering Approach for Action Recognition ",
		"abstract": "The importance of inference in Machine Learning (ML) has led to an explosive number of different proposals in ML, and particularly in Deep Learning. In an attempt to reduce the complexity of Convolutional Neural Networks, we propose a Volterra filter-inspired Network architecture. This architecture introduces controlled non-linearities in the form of interactions between the delayed input samples of data. We propose a cascaded implementation of Volterra Filtering so as to significantly reduce the number of parameters required to carry out the same classification task as that of a conventional Neural Network. We demonstrate an efficient parallel implementation of this Volterra Neural Network (VNN), along with its remarkable performance while retaining a relatively simpler and potentially more tractable structure. Furthermore, we show a rather sophisticated adaptation of this network to nonlinearly fuse the RGB (spatial) information and the Optical Flow (temporal) information of a video sequence for action recognition. The proposed approach is evaluated on UCF-101 and HMDB-51 datasets for action recognition, and is shown to outperform state of the art CNN approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.09616v3"
	},
	{
		"title": "AvgOut: A Simple Output‐Probability Measure to Eliminate Dull Responses ",
		"abstract": "Many sequence-to-sequence dialogue models tend to generate safe, uninformative responses. There have been various useful efforts on trying to eliminate them. However, these approaches either improve decoding algorithms during inference, rely on hand-crafted features, or employ complex models. In our work, we build dialogue models that are dynamically aware of what utterances or tokens are dull without any feature-engineering. Specifically, we start with a simple yet effective automatic metric, AvgOut, which calculates the average output probability distribution of all time steps on the decoder side during training. This metric directly estimates which tokens are more likely to be generated, thus making it a faithful evaluation of the model diversity (i.e., for diverse models, the token probabilities should be more evenly distributed rather than peaked at a few dull tokens). We then leverage this novel metric to propose three models that promote diversity without losing relevance. The first model, MinAvgOut, directly maximizes the diversity score through the output distributions of each batch; the second model, Label Fine-Tuning (LFT), prepends to the source sequence a label continuously scaled by the diversity score to control the diversity level; the third model, RL, adopts Reinforcement Learning and treats the diversity score as a reward signal. Moreover, we experiment with a hybrid model by combining the loss terms of MinAvgOut and RL. All four models outperform their base LSTM-RNN model on both diversity and relevance by a large margin, and are comparable to or better than competitive baselines (also verified via human evaluation). Moreover, our approaches are orthogonal to the base model, making them applicable as an add-on to other emerging better dialogue models in the future.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.05467v1"
	},
	{
		"title": "Graph‐Hist: Graph Classification from Latent Feature Histograms with Application to Bot Detection ",
		"abstract": "Neural networks are increasingly used for graph classification in a variety of contexts. Social media is a critical application area in this space, however the characteristics of social media graphs differ from those seen in most popular benchmark datasets. Social networks tend to be large and sparse, while benchmarks are small and dense. Classically, large and sparse networks are analyzed by studying the distribution of local properties. Inspired by this, we introduce Graph-Hist: an end-to-end architecture that extracts a graph's latent local features, bins nodes together along 1-D cross sections of the feature space, and classifies the graph based on this multi-channel histogram. We show that Graph-Hist improves state of the art performance on true social media benchmark datasets, while still performing well on other benchmarks. Finally, we demonstrate Graph-Hist's performance by conducting bot detection in social media. While sophisticated bot and cyborg accounts increasingly evade traditional detection methods, they leave artificial artifacts in their conversational graph that are detected through graph classification. We apply Graph-Hist to classify these conversational graphs. In the process, we confirm that social media graphs are different than most baselines and that Graph-Hist outperforms existing bot-detection models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.01180v1"
	},
	{
		"title": "Fast Adaptively Weighted Matrix Factorization for Recommendation with Implicit Feedback ",
		"abstract": "Recommendation from implicit feedback is a highly challenging task due to the lack of the reliable observed negative data. A popular and effective approach for implicit recommendation is to treat unobserved data as negative but downweight their confidence. Naturally, how to assign confidence weights and how to handle the large number of the unobserved data are two key problems for implicit recommendation models. However, existing methods either pursuit fast learning by manually assigning simple confidence weights, which lacks flexibility and may create empirical bias in evaluating user's preference; or adaptively infer personalized confidence weights but suffer from low efficiency. To achieve both adaptive weights assignment and efficient model learning, we propose a fast adaptively weighted matrix factorization (FAWMF) based on variational auto-encoder. The personalized data confidence weights are adaptively assigned with a parameterized neural network (function) and the network can be inferred from the data. Further, to support fast and stable learning of FAWMF, a new specific batch-based learning algorithm fBGD has been developed, which trains on all feedback data but its complexity is linear to the number of observed data. Extensive experiments on real-world datasets demonstrate the superiority of the proposed FAWMF and its learning algorithm fBGD.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2003.01892v1"
	},
	{
		"title": "Justification‐Based Reliability in Machine Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generalizable Resource Allocation in Stream Processing via Deep Reinforcement Learning ",
		"abstract": "This paper considers the problem of resource allocation in stream processing, where continuous data flows must be processed in real time in a large distributed system. To maximize system throughput, the resource allocation strategy that partitions the computation tasks of a stream processing graph onto computing devices must simultaneously balance workload distribution and minimize communication. Since this problem of graph partitioning is known to be NP-complete yet crucial to practical streaming systems, many heuristic-based algorithms have been developed to find reasonably good solutions. In this paper, we present a graph-aware encoder-decoder framework to learn a generalizable resource allocation strategy that can properly distribute computation tasks of stream processing graphs unobserved from training data. We, for the first time, propose to leverage graph embedding to learn the structural information of the stream processing graphs. Jointly trained with the graph-aware decoder using deep reinforcement learning, our approach can effectively find optimized solutions for unseen graphs. Our experiments show that the proposed model outperforms both METIS, a state-of-the-art graph partitioning algorithm, and an LSTM-based encoder-decoder model, in about 70% of the test cases.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08517v1"
	},
	{
		"title": "Hypernym Detection Using Strict Partial Order Networks ",
		"abstract": "This paper introduces Strict Partial Order Networks (SPON), a novel neural network architecture designed to enforce asymmetry and transitive properties as soft constraints. We apply it to induce hypernymy relations by training with is-a pairs. We also present an augmented variant of SPON that can generalize type information learned for in-vocabulary terms to previously unseen ones. An extensive evaluation over eleven benchmarks across different tasks shows that SPON consistently either outperforms or attains the state of the art on all but one of these benchmarks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.10572v2"
	},
	{
		"title": "The Complexity of Computing Maximin Share Allocations on Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Semantic Attachments for HTN Planning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Human‐Machine Collaboration for Fast Land Cover Mapping ",
		"abstract": "We propose incorporating human labelers in a model fine-tuning system that provides immediate user feedback. In our framework, human labelers can interactively query model predictions on unlabeled data, choose which data to label, and see the resulting effect on the model's predictions. This bi-directional feedback loop allows humans to learn how the model responds to new data. Our hypothesis is that this rich feedback allows human labelers to create mental models that enable them to better choose which biases to introduce to the model. We compare human-selected points to points selected using standard active learning methods. We further investigate how the fine-tuning methodology impacts the human labelers' performance. We implement this framework for fine-tuning high-resolution land cover segmentation models. Specifically, we fine-tune a deep neural network -- trained to segment high-resolution aerial imagery into different land cover classes in Maryland, USA -- to a new spatial area in New York, USA. The tight loop turns the algorithm and the human operator into a hybrid system that can produce land cover maps of a large area much more efficiently than the traditional workflows. Our framework has applications in geospatial machine learning settings where there is a practically limitless supply of unlabeled data, of which only a small fraction can feasibly be labeled through human efforts.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1906.04176v3"
	},
	{
		"title": "Fast Nonparametric Estimation of Class Proportions in the Positive‐Unlabeled Classification Setting ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Graph Representations for Higher‐Order Logic and Theorem Proving ",
		"abstract": "This paper presents the first use of graph neural networks (GNNs) for higher-order proof search and demonstrates that GNNs can improve upon state-of-the-art results in this domain. Interactive, higher-order theorem provers allow for the formalization of most mathematical theories and have been shown to pose a significant challenge for deep learning. Higher-order logic is highly expressive and, even though it is well-structured with a clearly defined grammar and semantics, there still remains no well-established method to convert formulas into graph-based representations. In this paper, we consider several graphical representations of higher-order logic and evaluate them against the HOList benchmark for higher-order theorem proving.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1905.10006v2"
	},
	{
		"title": "Trading‐Off Static and Dynamic Regret in Online Least‐Squares and Beyond ",
		"abstract": "Recursive least-squares algorithms often use forgetting factors as a heuristic to adapt to non-stationary data streams. The first contribution of this paper rigorously characterizes the effect of forgetting factors for a class of online Newton algorithms. For exp-concave and strongly convex objectives, the algorithms achieve the dynamic regret of $\\max\\{O(\\log T),O(\\sqrt{TV})\\}$, where $V$ is a bound on the path length of the comparison sequence. In particular, we show how classic recursive least-squares with a forgetting factor achieves this dynamic regret bound. By varying $V$, we obtain a trade-off between static and dynamic regret. In order to obtain more computationally efficient algorithms, our second contribution is a novel gradient descent step size rule for strongly convex functions. Our gradient descent rule recovers the order optimal dynamic regret bounds described above. For smooth problems, we can also obtain static regret of $O(T^{1-\\beta})$ and dynamic regret of $O(T^\\beta V^*)$, where $\\beta \\in (0,1)$ and $V^*$ is the path length of the sequence of minimizers. By varying $\\beta$, we obtain a trade-off between static and dynamic regret.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03118v2"
	},
	{
		"title": "Attending to Entities for Better Text Understanding ",
		"abstract": "Recent progress in NLP witnessed the development of large-scale pre-trained language models (GPT, BERT, XLNet, etc.) based on Transformer (Vaswani et al. 2017), and in a range of end tasks, such models have achieved state-of-the-art results, approaching human performance. This demonstrates the power of the stacked self-attention architecture when paired with a sufficient number of layers and a large amount of pre-training data. However, on tasks that require complex and long-distance reasoning where surface-level cues are not enough, there is still a large gap between the pre-trained models and human performance. Strubell et al. (2018) recently showed that it is possible to inject knowledge of syntactic structure into a model through supervised self-attention. We conjecture that a similar injection of semantic knowledge, in particular, coreference information, into an existing model would improve performance on such complex problems. On the LAMBADA (Paperno et al. 2016) task, we show that a model trained from scratch with coreference as auxiliary supervision for self-attention outperforms the largest GPT-2 model, setting the new state-of-the-art, while only containing a tiny fraction of parameters compared to GPT-2. We also conduct a thorough analysis of different variants of model architectures and supervision configurations, suggesting future directions on applying similar techniques to other problems.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04361v1"
	},
	{
		"title": "Distributed Primal‐Dual Optimization for Online Multi‐Task Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Associating Natural Language Comment and Source Code Entities ",
		"abstract": "Comments are an integral part of software development; they are natural language descriptions associated with source code elements. Understanding explicit associations can be useful in improving code comprehensibility and maintaining the consistency between code and comments. As an initial step towards this larger goal, we address the task of associating entities in Javadoc comments with elements in Java source code. We propose an approach for automatically extracting supervised data using revision histories of open source projects and present a manually annotated evaluation dataset for this task. We develop a binary classifier and a sequence labeling model by crafting a rich feature set which encompasses various aspects of code, comments, and the relationships between them. Experiments show that our systems outperform several baselines learning from the proposed supervision.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06728v1"
	},
	{
		"title": "True Nonlinear Dynamics from Incomplete Networks ",
		"abstract": "We study nonlinear dynamics on complex networks. Each vertex $i$ has a state $x_i$ which evolves according to a networked dynamics to a steady-state $x_i^*$. We develop fundamental tools to learn the true steady-state of a small part of the network, without knowing the full network. A naive approach and the current state-of-the-art is to follow the dynamics of the observed partial network to local equilibrium. This dramatically fails to extract the true steady state. We use a mean-field approach to map the dynamics of the unseen part of the network to a single node, which allows us to recover accurate estimates of steady-state on as few as 5 observed vertices in domains ranging from ecology to social networks to gene regulation. Incomplete networks are the norm in practice, and we offer new ways to think about nonlinear dynamics when only sparse information is available.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.06722v1"
	},
	{
		"title": "EPOC: Efficient Perception via Optimal Communication ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ALOHA: Artificial Learning of Human Attributes for Dialogue Agents ",
		"abstract": "For conversational AI and virtual assistants to communicate with humans in a realistic way, they must exhibit human characteristics such as expression of emotion and personality. Current attempts toward constructing human-like dialogue agents have presented significant difficulties. We propose Human Level Attributes (HLAs) based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters. Tropes are characteristics of fictional personalities that are observed recurrently and determined by viewers' impressions. By combining detailed HLA data with dialogue data for specific characters, we present a dataset, HLA-Chat, that models character profiles and gives dialogue agents the ability to learn characters' language styles through their HLAs. We then introduce a three-component system, ALOHA (which stands for Artificial Learning of Human Attributes), that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model. Our preliminary experiments demonstrate that two variations of ALOHA, combined with our proposed dataset, can outperform baseline models at identifying the correct dialogue responses of chosen target characters, and are stable regardless of the character's identity, the genre of the show, and the context of the dialogue.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.08293v3"
	},
	{
		"title": "InvNet: Encoding Geometric and Statistical Invariances \\\\ in Deep Generative Models ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "That and There: Judging the Intent of Pointing Actions with Robotic Arms ",
		"abstract": "Collaborative robotics requires effective communication between a robot and a human partner. This work proposes a set of interpretive principles for how a robotic arm can use pointing actions to communicate task information to people by extending existing models from the related literature. These principles are evaluated through studies where English-speaking human subjects view animations of simulated robots instructing pick-and-place tasks. The evaluation distinguishes two classes of pointing actions that arise in pick-and-place tasks: referential pointing (identifying objects) and locating pointing (identifying locations). The study indicates that human subjects show greater flexibility in interpreting the intent of referential pointing compared to locating pointing, which needs to be more deliberate. The results also demonstrate the effects of variation in the environment and task context on the interpretation of pointing. Our corpus, experiments and design principles advance models of context, common sense reasoning and communication in embodied communication.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.06602v1"
	},
	{
		"title": "Beyond Digital Domain: Fooling Deep learning Based Recognition System in Physical World ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": " An Analysis Framework for Metric Voting based on LP Duality ",
		"abstract": "Distortion-based analysis has established itself as a fruitful framework for comparing voting mechanisms. m voters and n candidates are jointly embedded in an (unknown) metric space, and the voters submit rankings of candidates by non-decreasing distance from themselves. Based on the submitted rankings, the social choice rule chooses a winning candidate; the quality of the winner is the sum of the (unknown) distances to the voters. The rule's choice will in general be suboptimal, and the worst-case ratio between the cost of its chosen candidate and the optimal candidate is called the rule's distortion. It was shown in prior work that every deterministic rule has distortion at least 3, while the Copeland rule and related rules guarantee worst-case distortion at most 5; a very recent result gave a rule with distortion $2+\\sqrt{5} \\approx 4.236$.   We provide a framework based on LP-duality and flow interpretations of the dual which provides a simpler and more unified way for proving upper bounds on the distortion of social choice rules. We illustrate the utility of this approach with three examples. First, we give a fairly simple proof of a strong generalization of the upper bound of 5 on the distortion of Copeland, to social choice rules with short paths from the winning candidate to the optimal candidate in generalized weak preference graphs. A special case of this result recovers the recent $2+\\sqrt{5}$ guarantee. Second, using this generalized bound, we show that the Ranked Pairs and Schulze rules have distortion $\\Theta(\\sqrt(n))$. Finally, our framework naturally suggests a combinatorial rule that is a strong candidate for achieving distortion 3, which had also been proposed in recent work. We prove that the distortion bound of 3 would follow from any of three combinatorial conjectures we formulate.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07162v3"
	},
	{
		"title": "Learning Geo‐Contextual Embeddings for Commuting Flow Prediction ",
		"abstract": "Predicting commuting flows based on infrastructure and land-use information is critical for urban planning and public policy development. However, it is a challenging task given the complex patterns of commuting flows. Conventional models, such as gravity model, are mainly derived from physics principles and limited by their predictive power in real-world scenarios where many factors need to be considered. Meanwhile, most existing machine learning-based methods ignore the spatial correlations and fail to model the influence of nearby regions. To address these issues, we propose Geo-contextual Multitask Embedding Learner (GMEL), a model that captures the spatial correlations from geographic contextual information for commuting flow prediction. Specifically, we first construct a geo-adjacency network containing the geographic contextual information. Then, an attention mechanism is proposed based on the framework of graph attention network (GAT) to capture the spatial correlations and encode geographic contextual information to embedding space. Two separate GATs are used to model supply and demand characteristics. A multitask learning framework is used to introduce stronger restrictions and enhance the effectiveness of the embedding representation. Finally, a gradient boosting machine is trained based on the learned embeddings to predict commuting flows. We evaluate our model using real-world datasets from New York City and the experimental results demonstrate the effectiveness of our proposal against the state of the art.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2005.01690v1"
	},
	{
		"title": "FuzzE: Fuzzy Fairness Evaluation of Offensive Language Classifiers on African‐American English ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Probabilistic Reasoning across the Causal Hierarchy ",
		"abstract": "We propose a formalization of the three-tier causal hierarchy of association, intervention, and counterfactuals as a series of probabilistic logical languages. Our languages are of strictly increasing expressivity, the first capable of expressing quantitative probabilistic reasoning---including conditional independence and Bayesian inference---the second encoding do-calculus reasoning for causal effects, and the third capturing a fully expressive do-calculus for arbitrary counterfactual queries. We give a corresponding series of finitary axiomatizations complete over both structural causal models and probabilistic programs, and show that satisfiability and validity for each language are decidable in polynomial space.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.02889v4"
	},
	{
		"title": "Latent Relation Language Models ",
		"abstract": "In this paper, we propose Latent Relation Language Models (LRLMs), a class of language models that parameterizes the joint distribution over the words in a document and the entities that occur therein via knowledge graph relations. This model has a number of attractive properties: it not only improves language modeling performance, but is also able to annotate the posterior probability of entity spans for a given text through relations. Experiments demonstrate empirical improvements over both a word-based baseline language model and a previous approach that incorporates knowledge graph information. Qualitative analysis further demonstrates the proposed model's ability to learn to predict appropriate relations in context.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.07690v1"
	},
	{
		"title": "Modelling Form‐Meaning Systematicity with Linguistic and Visual Features ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Pay Your Trip for Traffic Congestion: Dynamic Pricing in Traffic‐Aware Road Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Weighted‐Sampling Audio Adversarial Example Attack ",
		"abstract": "Recent studies have highlighted audio adversarial examples as a ubiquitous threat to state-of-the-art automatic speech recognition systems. Thorough studies on how to effectively generate adversarial examples are essential to prevent potential attacks. Despite many research on this, the efficiency and the robustness of existing works are not yet satisfactory. In this paper, we propose~\\textit{weighted-sampling audio adversarial examples}, focusing on the numbers and the weights of distortion to reinforce the attack. Further, we apply a denoising method in the loss function to make the adversarial attack more imperceptible. Experiments show that our method is the first in the field to generate audio adversarial examples with low noise and high audio robustness at the minute time-consuming level.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1901.10300v4"
	},
	{
		"title": "One Homonym per Translation ",
		"abstract": "The study of homonymy is vital to resolving fundamental problems in lexical semantics. In this paper, we propose four hypotheses that characterize the unique behavior of homonyms in the context of translations, discourses, collocations, and sense clusters. We present a new annotated homonym resource that allows us to test our hypotheses on existing WSD resources. The results of the experiments provide strong empirical evidence for the hypotheses. This study represents a step towards a computational method for distinguishing between homonymy and polysemy, and constructing a definitive inventory of coarse-grained senses.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1904.08533v2"
	},
	{
		"title": "Automatic Fact‐guided Sentence Modification ",
		"abstract": "Online encyclopediae like Wikipedia contain large amounts of text that need frequent corrections and updates. The new information may contradict existing content in encyclopediae. In this paper, we focus on rewriting such dynamically changing articles. This is a challenging constrained generation task, as the output must be consistent with the new information and fit into the rest of the existing document. To this end, we propose a two-step solution: (1) We identify and remove the contradicting components in a target text for a given claim, using a neutralizing stance model; (2) We expand the remaining text to be consistent with the given claim, using a novel two-encoder sequence-to-sequence model with copy attention. Applied to a Wikipedia fact update dataset, our method successfully generates updated sentences for new claims, achieving the highest SARI score. Furthermore, we demonstrate that generating synthetic data through such rewritten sentences can successfully augment the FEVER fact-checking training dataset, leading to a relative error reduction of 13%.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.13838v2"
	},
	{
		"title": "Real‐Time Route Search by Locations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Actor Critic Deep Reinforcement Learning for Neural Malware Control ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Emu: Enhancing Multilingual Sentence Embeddings with Semantic Specialization ",
		"abstract": "We present Emu, a system that semantically enhances multilingual sentence embeddings. Our framework fine-tunes pre-trained multilingual sentence embeddings using two main components: a semantic classifier and a language discriminator. The semantic classifier improves the semantic similarity of related sentences, whereas the language discriminator enhances the multilinguality of the embeddings via multilingual adversarial training. Our experimental results based on several language pairs show that our specialized embeddings outperform the state-of-the-art multilingual sentence embedding model on the task of cross-lingual intent classification using only monolingual labeled data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.06731v2"
	},
	{
		"title": "Harmonious Coexistence of Structured Weight Pruning and Ternarization for Deep Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Low Resource Sequence Tagging with Weak Labels ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Point‐Based Methods for Model Checking in Partially Observable Markov Decision Processes ",
		"abstract": "Autonomous systems are often required to operate in partially observable environments. They must reliably execute a specified objective even with incomplete information about the state of the environment. We propose a methodology to synthesize policies that satisfy a linear temporal logic formula in a partially observable Markov decision process (POMDP). By formulating a planning problem, we show how to use point-based value iteration methods to efficiently approximate the maximum probability of satisfying a desired logical formula and compute the associated belief state policy. We demonstrate that our method scales to large POMDP domains and provides strong bounds on the performance of the resulting policy.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.03809v1"
	},
	{
		"title": "IVFS: Simple and Efficient Feature Selection for High Dimensional Topology Preservation ",
		"abstract": "Feature selection is an important tool to deal with high dimensional data. In unsupervised case, many popular algorithms aim at maintaining the structure of the original data. In this paper, we propose a simple and effective feature selection algorithm to enhance sample similarity preservation through a new perspective, topology preservation, which is represented by persistent diagrams from the context of computational topology. This method is designed upon a unified feature selection framework called IVFS, which is inspired by random subset method. The scheme is flexible and can handle cases where the problem is analytically intractable. The proposed algorithm is able to well preserve the pairwise distances, as well as topological patterns, of the full data. We demonstrate that our algorithm can provide satisfactory performance under a sharp sub-sampling rate, which supports efficient implementation of our proposed method to large scale datasets. Extensive experiments validate the effectiveness of the proposed feature selection scheme.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2004.01299v1"
	},
	{
		"title": "Tandem Inference: An Out‐of‐Core Streaming Algorithm For Very Large‐Scale Relational Inference ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Hybrid compositional reasoning for reactive synthesis from finite‐horizon specifications ",
		"abstract": "LTLf synthesis is the automated construction of a reactive system from a high-level description, expressed in LTLf, of its finite-horizon behavior. So far, the conversion of LTLf formulas to deterministic finite-state automata (DFAs) has been identified as the primary bottleneck to the scalabity of synthesis. Recent investigations have also shown that the size of the DFA state space plays a critical role in synthesis as well.   Therefore, effective resolution of the bottleneck for synthesis requires the conversion to be time and memory performant, and prevent state-space explosion. Current conversion approaches, however, which are based either on explicit-state representation or symbolic-state representation, fail to address these necessities adequately at scale: Explicit-state approaches generate minimal DFA but are slow due to expensive DFA minimization. Symbolic-state representations can be succinct, but due to the lack of DFA minimization they generate such large state spaces that even their symbolic representations cannot compensate for the blow-up.   This work proposes a hybrid representation approach for the conversion. Our approach utilizes both explicit and symbolic representations of the state-space, and effectively leverages their complementary strengths. In doing so, we offer an LTLf to DFA conversion technique that addresses all three necessities, hence resolving the bottleneck. A comprehensive empirical evaluation on conversion and synthesis benchmarks supports the merits of our hybrid approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08145v3"
	},
	{
		"title": "Delay‐Adaptive Distributed Stochastic Optimization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Robust Gradient‐based Markov Subsampling  ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fixed‐Horizon Temporal Difference Methods for Stable Reinforcement Learning ",
		"abstract": "We explore fixed-horizon temporal difference (TD) methods, reinforcement learning algorithms for a new kind of value function that predicts the sum of rewards over a $\\textit{fixed}$ number of future time steps. To learn the value function for horizon $h$, these algorithms bootstrap from the value function for horizon $h-1$, or some shorter horizon. Because no value function bootstraps from itself, fixed-horizon methods are immune to the stability problems that plague other off-policy TD methods using function approximation (also known as \"the deadly triad\"). Although fixed-horizon methods require the storage of additional value functions, this gives the agent additional predictive power, while the added complexity can be substantially reduced via parallel updates, shared weights, and $n$-step bootstrapping. We show how to use fixed-horizon value functions to solve reinforcement learning problems competitively with methods such as Q-learning that learn conventional value functions. We also prove convergence of fixed-horizon temporal difference methods with linear and general function approximation. Taken together, our results establish fixed-horizon TD methods as a viable new way of avoiding the stability problems of the deadly triad.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03906v2"
	},
	{
		"title": "Fine‐Grained Entity Typing for Domain Independent Entity Linking ",
		"abstract": "Neural entity linking models are very powerful, but run the risk of overfitting to the domain they are trained in. For this problem, a domain is characterized not just by genre of text but even by factors as specific as the particular distribution of entities, as neural models tend to overfit by memorizing properties of frequent entities in a dataset. We tackle the problem of building robust entity linking models that generalize effectively and do not rely on labeled entity linking data with a specific entity distribution. Rather than predicting entities directly, our approach models fine-grained entity properties, which can help disambiguate between even closely related entities. We derive a large inventory of types (tens of thousands) from Wikipedia categories, and use hyperlinked mentions in Wikipedia to distantly label data and train an entity typing model. At test time, we classify a mention with this typing model and use soft type predictions to link the mention to the most similar candidate entity. We evaluate our entity linking system on the CoNLL-YAGO dataset (Hoffart et al., 2011) and show that our approach outperforms prior domain-independent entity linking systems. We also test our approach in a harder setting derived from the WikilinksNED dataset (Eshel et al., 2017) where all the mention-entity pairs are unseen during test time. Results indicate that our approach generalizes better than a state-of-the-art neural model on the dataset.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05780v2"
	},
	{
		"title": "Subsidy Allocations in the Presence of Income Shocks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Diachronic Embedding for Temporal Knowledge Graph Completion ",
		"abstract": "Knowledge graphs (KGs) typically contain temporal facts indicating relationships among entities at different times. Due to their incompleteness, several approaches have been proposed to infer new facts for a KG based on the existing ones-a problem known as KG completion. KG embedding approaches have proved effective for KG completion, however, they have been developed mostly for static KGs. Developing temporal KG embedding models is an increasingly important problem. In this paper, we build novel models for temporal KG completion through equipping static models with a diachronic entity embedding function which provides the characteristics of entities at any point in time. This is in contrast to the existing temporal KG embedding approaches where only static entity features are provided. The proposed embedding function is model-agnostic and can be potentially combined with any static model. We prove that combining it with SimplE, a recent model for static KG embedding, results in a fully expressive model for temporal KG completion. Our experiments indicate the superiority of our proposal compared to existing baselines.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.03143v1"
	},
	{
		"title": "Sequence Generation with Optimal‐Transport‐Enhanced Reinforcement Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Fairness in Network Representation by Latent Structural Heterogeneity in Observational Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Learning Efficient Representations for Fake Speech Detection ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Morphism‐based learning for structured data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Zero‐shot Learning for Automatic Phonemic Transcription ",
		"abstract": "Automatic phonemic transcription tools are useful for low-resource language documentation. However, due to the lack of training sets, only a tiny fraction of languages have phonemic transcription tools. Fortunately, multilingual acoustic modeling provides a solution given limited audio training data. A more challenging problem is to build phonemic transcribers for languages with zero training data. The difficulty of this task is that phoneme inventories often differ between the training languages and the target language, making it infeasible to recognize unseen phonemes. In this work, we address this problem by adopting the idea of zero-shot learning. Our model is able to recognize unseen phonemes in the target language without any training data. In our model, we decompose phonemes into corresponding articulatory attributes such as vowel and consonant. Instead of predicting phonemes directly, we first predict distributions over articulatory attributes, and then compute phoneme distributions with a customized acoustic model. We evaluate our model by training it using 13 languages and testing it using 7 unseen languages. We find that it achieves 7.7% better phoneme error rate on average over a standard multilingual model.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.11781v1"
	},
	{
		"title": "Select, Answer and Explain: Interpretable Multi‐hop Reading Comprehension over Multiple Documents ",
		"abstract": "Interpretable multi-hop reading comprehension (RC) over multiple documents is a challenging problem because it demands reasoning over multiple information sources and explaining the answer prediction by providing supporting evidences. In this paper, we propose an effective and interpretable Select, Answer and Explain (SAE) system to solve the multi-document RC problem. Our system first filters out answer-unrelated documents and thus reduce the amount of distraction information. This is achieved by a document classifier trained with a novel pairwise learning-to-rank loss. The selected answer-related documents are then input to a model to jointly predict the answer and supporting sentences. The model is optimized with a multi-task learning objective on both token level for answer prediction and sentence level for supporting sentences prediction, together with an attention-based interaction between these two tasks. Evaluated on HotpotQA, a challenging multi-hop RC data set, the proposed SAE system achieves top competitive performance in distractor setting compared to other existing systems on the leaderboard.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.00484v4"
	},
	{
		"title": "Dual Adversarial Co‐Learning for Multi‐Domain Text Classification ",
		"abstract": "In this paper we propose a novel dual adversarial co-learning approach for multi-domain text classification (MDTC). The approach learns shared-private networks for feature extraction and deploys dual adversarial regularizations to align features across different domains and between labeled and unlabeled data simultaneously under a discrepancy based co-learning framework, aiming to improve the classifiers' generalization capacity with the learned features. We conduct experiments on multi-domain sentiment classification datasets. The results show the proposed approach achieves the state-of-the-art MDTC performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.08203v1"
	},
	{
		"title": "Limitations of Incentive Compatibility on Discrete Type Spaces ",
		"abstract": "In the design of incentive compatible mechanisms, a common approach is to enforce incentive compatibility as constraints in programs that optimize over feasible mechanisms. Such constraints are often imposed on sparsified representations of the type spaces, such as their discretizations or samples, in order for the program to be manageable. In this work, we explore limitations of this approach, by studying whether all dominant strategy incentive compatible mechanisms on a set $T$ of discrete types can be extended to the convex hull of $T$.   Dobzinski, Fu and Kleinberg (2015) answered the question affirmatively for all settings where types are single dimensional. It is not difficult to show that the same holds when the set of feasible outcomes is downward closed. In this work we show that the question has a negative answer for certain non-downward-closed settings with multi-dimensional types. This result should call for caution in the use of the said approach to enforcing incentive compatibility beyond single-dimensional preferences and downward closed feasible outcomes.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.01046v2"
	},
	{
		"title": "CASIE: Extracting Cybersecurity Event Information from Text ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "On Swap Convexity of Voting Rules  ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Interactive Fiction Games: A Colossal Adventure ",
		"abstract": "A hallmark of human intelligence is the ability to understand and communicate with language. Interactive Fiction games are fully text-based simulation environments where a player issues text commands to effect change in the environment and progress through the story. We argue that IF games are an excellent testbed for studying language-based autonomous agents. In particular, IF games combine challenges of combinatorial action spaces, language understanding, and commonsense reasoning. To facilitate rapid development of language-based agents, we introduce Jericho, a learning environment for man-made IF games and conduct a comprehensive study of text-agents across a rich set of games, highlighting directions in which agents can improve.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05398v3"
	},
	{
		"title": " DGE: Deep Generative Network Embedding Based on Commonality and Individuality ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "QASC: A Dataset for Question Answering via Sentence Composition ",
		"abstract": "Composing knowledge from multiple pieces of texts is a key challenge in multi-hop question answering. We present a multi-hop reasoning dataset, Question Answering via Sentence Composition(QASC), that requires retrieving facts from a large corpus and composing them to answer a multiple-choice question. QASC is the first dataset to offer two desirable properties: (a) the facts to be composed are annotated in a large corpus, and (b) the decomposition into these facts is not evident from the question itself. The latter makes retrieval challenging as the system must introduce new concepts or relations in order to discover potential decompositions. Further, the reasoning model must then learn to identify valid compositions of these retrieved facts using common-sense reasoning. To help address these challenges, we provide annotation for supporting facts as well as their composition. Guided by these annotations, we present a two-step approach to mitigate the retrieval challenges. We use other multiple-choice datasets as additional training data to strengthen the reasoning model. Our proposed approach improves over current state-of-the-art language models by 11% (absolute). The reasoning and retrieval problems, however, remain unsolved as this model still lags by 20% behind human performance.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.11473v2"
	},
	{
		"title": "Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks ",
		"abstract": "Textual entailment is a fundamental task in natural language processing. Most approaches for solving the problem use only the textual content present in training data. A few approaches have shown that information from external knowledge sources like knowledge graphs (KGs) can add value, in addition to the textual content, by providing background knowledge that may be critical for a task. However, the proposed models do not fully exploit the information in the usually large and noisy KGs, and it is not clear how it can be effectively encoded to be useful for entailment. We present an approach that complements text-based entailment models with information from KGs by (1) using Personalized PageR- ank to generate contextual subgraphs with reduced noise and (2) encoding these subgraphs using graph convolutional networks to capture KG structure. Our technique extends the capability of text models exploiting structural and semantic information found in KGs. We evaluate our approach on multiple textual entailment datasets and show that the use of external knowledge helps improve prediction accuracy. This is particularly evident in the challenging BreakingNLI dataset, where we see an absolute improvement of 5-20% over multiple text-based entailment models.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.02060v2"
	},
	{
		"title": "What Is It You Really Want of Me? Generalized Reward Learning with Biased Beliefs about Domain Dynamics ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Adversarial Cross‐Domain Action Recognition with Co‐Attention ",
		"abstract": "Action recognition has been a widely studied topic with a heavy focus on supervised learning involving sufficient labeled videos. However, the problem of cross-domain action recognition, where training and testing videos are drawn from different underlying distributions, remains largely under-explored. Previous methods directly employ techniques for cross-domain image recognition, which tend to suffer from the severe temporal misalignment problem. This paper proposes a Temporal Co-attention Network (TCoN), which matches the distributions of temporally aligned action features between source and target domains using a novel cross-domain co-attention mechanism. Experimental results on three cross-domain action recognition datasets demonstrate that TCoN improves both previous single-domain and cross-domain methods significantly under the cross-domain setting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10405v1"
	},
	{
		"title": "An Information‐Theoretic Quantification of Discrimination with Exempt Features ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Strongly Budget Balanced Auctions for Multi‐Sided Markets ",
		"abstract": "In two-sided markets, Myerson and Satterthwaite's impossibility theorem states that one can not maximize the gain-from-trade while also satisfying truthfulness, individual-rationality and no deficit. Attempts have been made to circumvent Myerson and Satterthwaite's result by attaining approximately-maximum gain-from-trade: the double-sided auctions of McAfee (1992) is truthful and has no deficit, and the one by Segal-Halevi et al. (2016) additionally has no surplus --- it is strongly-budget-balanced. They consider two categories of agents --- buyers and sellers, where each trade set is composed of a single buyer and a single seller. The practical complexity of applications such as supply chain require one to look beyond two-sided markets. Common requirements are for: buyers trading with multiple sellers of different or identical items, buyers trading with sellers through transporters and mediators, and sellers trading with multiple buyers. We attempt to address these settings. We generalize Segal-Halevi et al. (2016)'s strongly-budget-balanced double-sided auction setting to a multilateral market where each trade set is composed of any number of agent categories. Our generalization refines the notion of competition in multi-sided auctions by introducing the concepts of external competition and trade reduction. We also show an obviously-truthful implementation of our auction using multiple ascending prices.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08094v2"
	},
	{
		"title": "Scaling All‐Goals Updates in Reinforcement Learning Using Convolutional Neural Networks ",
		"abstract": "Being able to reach any desired location in the environment can be a valuable asset for an agent. Learning a policy to navigate between all pairs of states individually is often not feasible. An all-goals updating algorithm uses each transition to learn Q-values towards all goals simultaneously and off-policy. However the expensive numerous updates in parallel limited the approach to small tabular cases so far. To tackle this problem we propose to use convolutional network architectures to generate Q-values and updates for a large number of goals at once. We demonstrate the accuracy and generalization qualities of the proposed method on randomly generated mazes and Sokoban puzzles. In the case of on-screen goal coordinates the resulting mapping from frames to distance-maps directly informs the agent about which places are reachable and in how many steps. As an example of application we show that replacing the random actions in epsilon-greedy exploration by several actions towards feasible goals generates better exploratory trajectories on Montezuma's Revenge and Super Mario All-Stars games.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1810.02927v2"
	},
	{
		"title": "TANDA: Transfer and Adapt Pre‐Trained Transformer Models for Answer Sentence Selection ",
		"abstract": "We propose TANDA, an effective technique for fine-tuning pre-trained Transformer models for natural language tasks. Specifically, we first transfer a pre-trained model into a model for a general task by fine-tuning it with a large and high-quality dataset. We then perform a second fine-tuning step to adapt the transferred model to the target domain. We demonstrate the benefits of our approach for answer sentence selection, which is a well-known inference task in Question Answering. We built a large scale dataset to enable the transfer step, exploiting the Natural Questions dataset. Our approach establishes the state of the art on two well-known benchmarks, WikiQA and TREC-QA, achieving MAP scores of 92% and 94.3%, respectively, which largely outperform the previous highest scores of 83.4% and 87.5%, obtained in very recent work. We empirically show that TANDA generates more stable and robust models reducing the effort required for selecting optimal hyper-parameters. Additionally, we show that the transfer step of TANDA makes the adaptation step more robust to noise. This enables a more effective use of noisy datasets for fine-tuning. Finally, we also confirm the positive impact of TANDA in an industrial setting, using domain specific datasets subject to different types of noise.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04118v2"
	},
	{
		"title": "Kriging Convolutional Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Differentially Private Learning with Small Public Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Commonsense Knowledge Base Completion with Structural and Semantic Context ",
		"abstract": "Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and ConceptNet) poses unique challenges compared to the much studied conventional knowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form text to represent nodes, resulting in orders of magnitude more nodes compared to conventional KBs (18x more nodes in ATOMIC compared to Freebase (FB15K-237)). Importantly, this implies significantly sparser graph structures - a major challenge for existing KB completion methods that assume densely connected graphs over a relatively smaller set of nodes. In this paper, we present novel KB completion models that can address these challenges by exploiting the structural and semantic context of nodes. Specifically, we investigate two key ideas: (1) learning from local graph structure, using graph convolutional networks and automatic graph densification and (2) transfer learning from pre-trained language models to knowledge graphs for enhanced contextual representation of knowledge. We describe our method to incorporate information from both these sources in a joint model and provide the first empirical results for KB completion on ATOMIC and evaluation with ranking metrics on ConceptNet. Our results demonstrate the effectiveness of language model representations in boosting link prediction performance and the advantages of learning from local graph structure (+1.5 points in MRR for ConceptNet) when training on subgraphs for computational efficiency. Further analysis on model predictions shines light on the types of commonsense knowledge that language models capture well.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.02915v2"
	},
	{
		"title": "Options of Interest: Temporal Abstraction with Interest Functions ",
		"abstract": "Temporal abstraction refers to the ability of an agent to use behaviours of controllers which act for a limited, variable amount of time. The options framework describes such behaviours as consisting of a subset of states in which they can initiate, an internal policy and a stochastic termination condition. However, much of the subsequent work on option discovery has ignored the initiation set, because of difficulty in learning it from data. We provide a generalization of initiation sets suitable for general function approximation, by defining an interest function associated with an option. We derive a gradient-based learning algorithm for interest functions, leading to a new interest-option-critic architecture. We investigate how interest functions can be leveraged to learn interpretable and reusable temporal abstractions. We demonstrate the efficacy of the proposed approach through quantitative and qualitative results, in both discrete and continuous environments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.00271v1"
	},
	{
		"title": "Towards Hands‐free Visual Dialog Interactive Recommendation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Detecting Asks in Social Engineering Attacks: Impact of Linguistic and Structural Knowledge ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Bridging Maximum Likelihood and Adversarial Learning via alpha‐Divergence ",
		"abstract": "Maximum likelihood (ML) and adversarial learning are two popular approaches for training generative models, and from many perspectives these techniques are complementary. ML learning encourages the capture of all data modes, and it is typically characterized by stable training. However, ML learning tends to distribute probability mass diffusely over the data space, $e.g.$, yielding blurry synthetic images. Adversarial learning is well known to synthesize highly realistic natural images, despite practical challenges like mode dropping and delicate training. We propose an $\\alpha$-Bridge to unify the advantages of ML and adversarial learning, enabling the smooth transfer from one to the other via the $\\alpha$-divergence. We reveal that generalizations of the $\\alpha$-Bridge are closely related to approaches developed recently to regularize adversarial learning, providing insights into that prior work, and further understanding of why the $\\alpha$-Bridge performs well in practice.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2007.06178v1"
	},
	{
		"title": "Preserving Ordinal Consensus: Towards Feature Selection for Unlabeled Data ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "ICD Coding from Clinical Text Using Multi‐Filter Residual Convolutional Neural Network ",
		"abstract": "Automated ICD coding, which assigns the International Classification of Disease codes to patient visits, has attracted much research attention since it can save time and labor for billing. The previous state-of-the-art model utilized one convolutional layer to build document representations for predicting ICD codes. However, the lengths and grammar of text fragments, which are closely related to ICD coding, vary a lot in different documents. Therefore, a flat and fixed-length convolutional architecture may not be capable of learning good document representations. In this paper, we proposed a Multi-Filter Residual Convolutional Neural Network (MultiResCNN) for ICD coding. The innovations of our model are two-folds: it utilizes a multi-filter convolutional layer to capture various text patterns with different lengths and a residual convolutional layer to enlarge the receptive field. We evaluated the effectiveness of our model on the widely-used MIMIC dataset. On the full code set of MIMIC-III, our model outperformed the state-of-the-art model in 4 out of 6 evaluation metrics. On the top-50 code set of MIMIC-III and the full code set of MIMIC-II, our model outperformed all the existing and state-of-the-art models in all evaluation metrics. The code is available at https://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.00862v1"
	},
	{
		"title": "Top‐down RST Parsing Utilizing Granularity Levels in Documents ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "On the Max‐min Fair Stochastic Allocation of Indivisible Goods ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "End‐to‐End Trainable Non‐Collaborative Dialog System ",
		"abstract": "End-to-end task-oriented dialog models have achieved promising performance on collaborative tasks where users willingly coordinate with the system to complete a given task. While in non-collaborative settings, for example, negotiation and persuasion, users and systems do not share a common goal. As a result, compared to collaborate tasks, people use social content to build rapport and trust in these non-collaborative settings in order to advance their goals. To handle social content, we introduce a hierarchical intent annotation scheme, which can be generalized to different non-collaborative dialog tasks. Building upon TransferTransfo (Wolf et al. 2019), we propose an end-to-end neural network model to generate diverse coherent responses. Our model utilizes intent and semantic slots as the intermediate sentence representation to guide the generation process. In addition, we design a filter to select appropriate responses based on whether these intermediate representations fit the designed task and conversation constraints. Our non-collaborative dialog model guides users to complete the task while simultaneously keeps them engaged. We test our approach on our newly proposed ANTISCAM dataset and an existing PERSUASIONFORGOOD dataset. Both automatic and human evaluations suggest that our model outperforms multiple baselines in these two non-collaborative tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10742v1"
	},
	{
		"title": "Active Ordinal Querying for Tuplewise Similarity Learning ",
		"abstract": "Many machine learning tasks such as clustering, classification, and dataset search benefit from embedding data points in a space where distances reflect notions of relative similarity as perceived by humans. A common way to construct such an embedding is to request triplet similarity queries to an oracle, comparing two objects with respect to a reference. This work generalizes triplet queries to tuple queries of arbitrary size that ask an oracle to rank multiple objects against a reference, and introduces an efficient and robust adaptive selection method called InfoTuple that uses a novel approach to mutual information maximization. We show that the performance of InfoTuple at various tuple sizes exceeds that of the state-of-the-art adaptive triplet selection method on synthetic tests and new human response datasets, and empirically demonstrate the significant gains in efficiency and query consistency achieved by querying larger tuples instead of triplets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.04115v3"
	},
	{
		"title": "Predicting Propositional Satisfiability via End‐to‐End Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Compact Autoregressive Network ",
		"abstract": "Autoregressive networks can achieve promising performance in many sequence modeling tasks with short-range dependence. However, when handling high-dimensional inputs and outputs, the huge amount of parameters in the network lead to expensive computational cost and low learning efficiency. The problem can be alleviated slightly by introducing one more narrow hidden layer to the network, but the sample size required to achieve a certain training error is still large. To address this challenge, we rearrange the weight matrices of a linear autoregressive network into a tensor form, and then make use of Tucker decomposition to represent low-rank structures. This leads to a novel compact autoregressive network, called Tucker AutoRegressive (TAR) net. Interestingly, the TAR net can be applied to sequences with long-range dependence since the dimension along the sequential order is reduced. Theoretical studies show that the TAR net improves the learning efficiency, and requires much fewer samples for model training. Experiments on synthetic and real-world datasets demonstrate the promising performance of the proposed compact network.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03830v1"
	},
	{
		"title": "Enumerating Maximal $k$‐Plexes With Worst‐Case Time Guarantee ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Monolingual Transfer Learning via Bilingual Translators for Style‐Sensitive Paraphrase Generation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Active Goal Recognition ",
		"abstract": "To coordinate with other systems, agents must be able to determine what the systems are currently doing and predict what they will be doing in the future---plan and goal recognition. There are many methods for plan and goal recognition, but they assume a passive observer that continually monitors the target system. Real-world domains, where information gathering has a cost (e.g., moving a camera or a robot, or time taken away from another task), will often require a more active observer. We propose to combine goal recognition with other observer tasks in order to obtain \\emph{active goal recognition} (AGR). We discuss this problem and provide a model and preliminary experimental results for one form of this composite problem. As expected, the results show that optimal behavior in AGR problems balance information gathering with other actions (e.g., task completion) such as to achieve all tasks jointly and efficiently. We hope that our formulation opens the door for extensive further research on this interesting and realistic problem.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.11173v1"
	},
	{
		"title": "Fairness‐Aware Demand Prediction for New Mobility ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "History‐adaption Knowledge Incorporation Mechanism for Multi‐turn Dialogue System ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "DeepVar: An End‐to‐End Deep Learning Approach for Genomic Variant Recognition in Biomedical Literature ",
		"abstract": "We consider the problem of Named Entity Recognition (NER) on biomedical scientific literature, and more specifically the genomic variants recognition in this work. Significant success has been achieved for NER on canonical tasks in recent years where large data sets are generally available. However, it remains a challenging problem on many domain-specific areas, especially the domains where only small gold annotations can be obtained. In addition, genomic variant entities exhibit diverse linguistic heterogeneity, differing much from those that have been characterized in existing canonical NER tasks. The state-of-the-art machine learning approaches in such tasks heavily rely on arduous feature engineering to characterize those unique patterns. In this work, we present the first successful end-to-end deep learning approach to bridge the gap between generic NER algorithms and low-resource applications through genomic variants recognition. Our proposed model can result in promising performance without any hand-crafted features or post-processing rules. Our extensive experiments and results may shed light on other similar low-resource NER applications.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2006.08338v1"
	},
	{
		"title": "Querying to Find a Safe Policy Under Uncertain Safety Constraints in Markov Decision Processes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Probing Natural Language Inference Models through Semantic Fragments ",
		"abstract": "Do state-of-the-art models for language understanding already have, or can they easily learn, abilities such as boolean coordination, quantification, conditionals, comparatives, and monotonicity reasoning (i.e., reasoning about word substitutions in sentential contexts)? While such phenomena are involved in natural language inference (NLI) and go beyond basic linguistic understanding, it is unclear the extent to which they are captured in existing NLI benchmarks and effectively learned by models. To investigate this, we propose the use of semantic fragments---systematically generated datasets that each target a different semantic phenomenon---for probing, and efficiently improving, such capabilities of linguistic models. This approach to creating challenge datasets allows direct control over the semantic diversity and complexity of the targeted linguistic phenomena, and results in a more precise characterization of a model's linguistic behavior. Our experiments, using a library of 8 such semantic fragments, reveal two remarkable findings: (a) State-of-the-art models, including BERT, that are pre-trained on existing NLI benchmark datasets perform poorly on these new fragments, even though the phenomena probed here are central to the NLI task. (b) On the other hand, with only a few minutes of additional fine-tuning---with a carefully selected learning rate and a novel variation of \"inoculation\"---a BERT-based model can master all of these logic and monotonicity fragments while retaining its performance on established NLI benchmarks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.07521v2"
	},
	{
		"title": "Towards Building a Multilingual Sememe Knowledge Base: Predicting Sememes for BabelNet Synsets ",
		"abstract": "A sememe is defined as the minimum semantic unit of human languages. Sememe knowledge bases (KBs), which contain words annotated with sememes, have been successfully applied to many NLP tasks. However, existing sememe KBs are built on only a few languages, which hinders their widespread utilization. To address the issue, we propose to build a unified sememe KB for multiple languages based on BabelNet, a multilingual encyclopedic dictionary. We first build a dataset serving as the seed of the multilingual sememe KB. It manually annotates sememes for over $15$ thousand synsets (the entries of BabelNet). Then, we present a novel task of automatic sememe prediction for synsets, aiming to expand the seed dataset into a usable KB. We also propose two simple and effective models, which exploit different information of synsets. Finally, we conduct quantitative and qualitative analyses to explore important factors and difficulties in the task. All the source code and data of this work can be obtained on https://github.com/thunlp/BabelNet-Sememe-Prediction.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.01795v1"
	},
	{
		"title": "Hidden Trigger Backdoor Attacks ",
		"abstract": "With the success of deep learning algorithms in various domains, studying adversarial attacks to secure deep models in real world applications has become an important research topic. Backdoor attacks are a form of adversarial attacks on deep networks where the attacker provides poisoned data to the victim to train the model with, and then activates the attack by showing a specific small trigger pattern at the test time. Most state-of-the-art backdoor attacks either provide mislabeled poisoning data that is possible to identify by visual inspection, reveal the trigger in the poisoned data, or use noise to hide the trigger. We propose a novel form of backdoor attack where poisoned data look natural with correct labels and also more importantly, the attacker hides the trigger in the poisoned data and keeps the trigger secret until the test time. We perform an extensive study on various image classification settings and show that our attack can fool the model by pasting the trigger at random locations on unseen images although the model performs well on clean data. We also show that our proposed attack cannot be easily defended using a state-of-the-art defense algorithm for backdoor attacks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.00033v2"
	},
	{
		"title": "Solving Sum‐of‐Costs Multi‐Agent Pathfinding with Answer‐Set Programming ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Differential Equation Units: Learning Functional Forms of Activation Functions from Data ",
		"abstract": "Most deep neural networks use simple, fixed activation functions, such as sigmoids or rectified linear units, regardless of domain or network structure. We introduce differential equation units (DEUs), an improvement to modern neural networks, which enables each neuron to learn a particular nonlinear activation function from a family of solutions to an ordinary differential equation. Specifically, each neuron may change its functional form during training based on the behavior of the other parts of the network. We show that using neurons with DEU activation functions results in a more compact network capable of achieving comparable, if not superior, performance when is compared to much larger networks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.03069v1"
	},
	{
		"title": "Hierarchical Attention Network with Pairwise Loss for Chinese Zero Pronoun Resolution ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "WinoGrande: An Adversarial Winograd Schema Challenge at Scale ",
		"abstract": "The Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011), a benchmark for commonsense reasoning, is a set of 273 expert-crafted pronoun resolution problems originally designed to be unsolvable for statistical models that rely on selectional preferences or word associations. However, recent advances in neural language models have already reached around 90% accuracy on variants of WSC. This raises an important question whether these models have truly acquired robust commonsense capabilities or whether they rely on spurious biases in the datasets that lead to an overestimation of the true capabilities of machine commonsense. To investigate this question, we introduce WinoGrande, a large-scale dataset of 44k problems, inspired by the original WSC design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) systematic bias reduction using a novel AfLite algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. The best state-of-the-art methods on WinoGrande achieve 59.4-79.1%, which are 15-35% below human performance of 94.0%, depending on the amount of the training data allowed. Furthermore, we establish new state-of-the-art results on five related benchmarks - WSC (90.1%), DPR (93.1%), COPA (90.6%), KnowRef (85.6%), and Winogender (97.1%). These results have dual implications: on one hand, they demonstrate the effectiveness of WinoGrande when used as a resource for transfer learning. On the other hand, they raise a concern that we are likely to be overestimating the true capabilities of machine commonsense across all these benchmarks. We emphasize the importance of algorithmic bias reduction in existing and future benchmarks to mitigate such overestimation.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1907.10641v2"
	},
	{
		"title": "Contextual‐Bandit Based Personalized Recommendation with Time‐Varying User Interests ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Information Elicitation Mechanisms for Statistical Estimation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Finding Minimum‐Weight Link‐Disjoint Paths with a Few Common Nodes ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Class Prior Estimation with Biased Positives and Unlabeled Examples ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Recursively Binary Modification Model for Nested Named Entity Recognition ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Discourse Level Factors for Sentence Deletion in Text Simplification ",
		"abstract": "This paper presents a data-driven study focusing on analyzing and predicting sentence deletion -- a prevalent but understudied phenomenon in document simplification -- on a large English text simplification corpus. We inspect various document and discourse factors associated with sentence deletion, using a new manually annotated sentence alignment corpus we collected. We reveal that professional editors utilize different strategies to meet readability standards of elementary and middle schools. To predict whether a sentence will be deleted during simplification to a certain level, we harness automatically aligned data to train a classification model. Evaluated on our manually annotated data, our best models reached F1 scores of 65.2 and 59.7 for this task at the levels of elementary and middle school, respectively. We find that discourse level factors contribute to the challenging task of predicting sentence deletion for simplification.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.10384v4"
	},
	{
		"title": "Parameterized Indexed Value Function for Efficient Exploration in Reinforcement Learning ",
		"abstract": "It is well known that quantifying uncertainty in the action-value estimates is crucial for efficient exploration in reinforcement learning. Ensemble sampling offers a relatively computationally tractable way of doing this using randomized value functions. However, it still requires a huge amount of computational resources for complex problems. In this paper, we present an alternative, computationally efficient way to induce exploration using index sampling. We use an indexed value function to represent uncertainty in our action-value estimates. We first present an algorithm to learn parameterized indexed value function through a distributional version of temporal difference in a tabular setting and prove its regret bound. Then, in a computational point of view, we propose a dual-network architecture, Parameterized Indexed Networks (PINs), comprising one mean network and one uncertainty network to learn the indexed value function. Finally, we show the efficacy of PINs through computational experiments.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.10577v2"
	},
	{
		"title": "Uncertainty Aware Graph Gaussian Process for Semi‐Supervised Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Schema‐Guided Multi‐Domain Dialogue State Tracking with Graph Attention Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Generative Attention Networks for Multi‐Agent Behavioral Modeling ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Effective Modeling of Encoder‐Decoder Architecture for Joint Entity and Relation Extraction ",
		"abstract": "A relation tuple consists of two entities and the relation between them, and often such tuples are found in unstructured text. There may be multiple relation tuples present in a text and they may share one or both entities among them. Extracting such relation tuples from a sentence is a difficult task and sharing of entities or overlapping entities among the tuples makes it more challenging. Most prior work adopted a pipeline approach where entities were identified first followed by finding the relations among them, thus missing the interaction among the relation tuples in a sentence. In this paper, we propose two approaches to use encoder-decoder architecture for jointly extracting entities and relations. In the first approach, we propose a representation scheme for relation tuples which enables the decoder to generate one word at a time like machine translation models and still finds all the tuples present in a sentence with full entity names of different length and with overlapping entities. Next, we propose a pointer network-based decoding approach where an entire tuple is generated at every time step. Experiments on the publicly available New York Times corpus show that our proposed approaches outperform previous work and achieve significantly higher F1 scores.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09886v1"
	},
	{
		"title": "Incorporating Label Embedding and Feature Augmentation for Multi‐Dimensional Classification ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Solving Online Threat Screening Games using Constrained Action Space Reinforcement Learning ",
		"abstract": "Large-scale screening for potential threats with limited resources and capacity for screening is a problem of interest at airports, seaports, and other ports of entry. Adversaries can observe screening procedures and arrive at a time when there will be gaps in screening due to limited resource capacities. To capture this game between ports and adversaries, this problem has been previously represented as a Stackelberg game, referred to as a Threat Screening Game (TSG). Given the significant complexity associated with solving TSGs and uncertainty in arrivals of customers, existing work has assumed that screenees arrive and are allocated security resources at the beginning of the time window. In practice, screenees such as airport passengers arrive in bursts correlated with flight time and are not bound by fixed time windows. To address this, we propose an online threat screening model in which screening strategy is determined adaptively as a passenger arrives while satisfying a hard bound on acceptable risk of not screening a threat. To solve the online problem with a hard bound on risk, we formulate it as a Reinforcement Learning (RL) problem with constraints on the action space (hard bound on risk). We provide a novel way to efficiently enforce linear inequality constraints on the action output in Deep Reinforcement Learning. We show that our solution allows us to significantly reduce screenee wait time while guaranteeing a bound on risk.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.08799v1"
	},
	{
		"title": "Towards Scalable Multi‐Domain Conversational Agents:The Schema‐Guided Dialogue Dataset ",
		"abstract": "Virtual assistants such as Google Assistant, Alexa and Siri provide a conversational interface to a large number of services and APIs spanning multiple domains. Such systems need to support an ever-increasing number of services with possibly overlapping functionality. Furthermore, some of these services have little to no training data available. Existing public datasets for task-oriented dialogue do not sufficiently capture these challenges since they cover few domains and assume a single static ontology per domain. In this work, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing over 16k multi-domain conversations spanning 16 domains. Our dataset exceeds the existing task-oriented dialogue corpora in scale, while also highlighting the challenges associated with building large-scale virtual assistants. It provides a challenging testbed for a number of tasks including language understanding, slot filling, dialogue state tracking and response generation. Along the same lines, we present a schema-guided paradigm for task-oriented dialogue, in which predictions are made over a dynamic set of intents and slots, provided as input, using their natural language descriptions. This allows a single dialogue system to easily support a large number of services and facilitates simple integration of new services without requiring additional training data. Building upon the proposed paradigm, we release a model for dialogue state tracking capable of zero-shot generalization to new APIs, while remaining competitive in the regular setting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.05855v2"
	},
	{
		"title": "MIDAS: Microcluster‐Based Detector of Anomalies in Edge Streams ",
		"abstract": "Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? Existing approaches aim to detect individually surprising edges. In this work, we propose MIDAS, which focuses on detecting microcluster anomalies, or suddenly arriving groups of suspiciously similar edges, such as lockstep behavior, including denial of service attacks in network traffic data. MIDAS has the following properties: (a) it detects microcluster anomalies while providing theoretical guarantees about its false positive probability; (b) it is online, thus processing each edge in constant time and constant memory, and also processes the data 162-644 times faster than state-of-the-art approaches; (c) it provides 42%-48% higher accuracy (in terms of AUC) than state-of-the-art approaches.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.04464v5"
	},
	{
		"title": "Image Formation Model Guided Deep Image Super‐Resolution ",
		"abstract": "We present a simple and effective image super-resolution algorithm that imposes an image formation constraint on the deep neural networks via pixel substitution. The proposed algorithm first uses a deep neural network to estimate intermediate high-resolution images, blurs the intermediate images using known blur kernels, and then substitutes values of the pixels at the un-decimated positions with those of the corresponding pixels from the low-resolution images. The output of the pixel substitution process strictly satisfies the image formation model and is further refined by the same deep neural network in a cascaded manner. The proposed framework is trained in an end-to-end fashion and can work with existing feed-forward deep neural networks for super-resolution and converges fast in practice. Extensive experimental results show that the proposed algorithm performs favorably against state-of-the-art methods.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1908.06444v3"
	},
	{
		"title": "Adversarial Dynamic Shapelet Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Efficient Verification of ReLU‐based Neural Networks via Dependency Analysis ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Discriminative and Robust Online Learning for Siamese Visual Tracking ",
		"abstract": "The problem of visual object tracking has traditionally been handled by variant tracking paradigms, either learning a model of the object's appearance exclusively online or matching the object with the target in an offline-trained embedding space. Despite the recent success, each method agonizes over its intrinsic constraint. The online-only approaches suffer from a lack of generalization of the model they learn thus are inferior in target regression, while the offline-only approaches (e.g., convolutional siamese trackers) lack the target-specific context information thus are not discriminative enough to handle distractors, and robust enough to deformation. Therefore, we propose an online module with an attention mechanism for offline siamese networks to extract target-specific features under L2 error. We further propose a filter update strategy adaptive to treacherous background noises for discriminative learning, and a template update strategy to handle large target deformations for robust learning. Effectiveness can be validated in the consistent improvement over three siamese baselines: SiamFC, SiamRPN++, and SiamMask. Beyond that, our model based on SiamRPN++ obtains the best results over six popular tracking benchmarks and can operate beyond real-time.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1909.02959v2"
	},
	{
		"title": "MALA: Cross‐Domain Dialogue Generation with Action Learning ",
		"abstract": "Response generation for task-oriented dialogues involves two basic components: dialogue planning and surface realization. These two components, however, have a discrepancy in their objectives, i.e., task completion and language quality. To deal with such discrepancy, conditioned response generation has been introduced where the generation process is factorized into action decision and language generation via explicit action representations. To obtain action representations, recent studies learn latent actions in an unsupervised manner based on the utterance lexical similarity. Such an action learning approach is prone to diversities of language surfaces, which may impinge task completion and language quality. To address this issue, we propose multi-stage adaptive latent action learning (MALA) that learns semantic latent actions by distinguishing the effects of utterances on dialogue progress. We model the utterance effect using the transition of dialogue states caused by the utterance and develop a semantic similarity measurement that estimates whether utterances have similar effects. For learning semantic actions on domains without dialogue states, MsALA extends the semantic similarity measurement across domains progressively, i.e., from aligning shared actions to learning domain-specific actions. Experiments using multi-domain datasets, SMD and MultiWOZ, show that our proposed model achieves consistent improvements over the baselines models in terms of both task completion and language quality.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.08442v2"
	},
	{
		"title": "REST: Performance Improvement of a Black Box Model via RL‐based Spatial Transformation ",
		"abstract": "In recent years, deep neural networks (DNN) have become a highly active area of research, and shown remarkable achievements on a variety of computer vision tasks. DNNs, however, are known to often make overconfident yet incorrect predictions on out-of-distribution samples, which can be a major obstacle to real-world deployments because the training dataset is always limited compared to diverse real-world samples. Thus, it is fundamental to provide guarantees of robustness to the distribution shift between training and test time when we construct DNN models in practice. Moreover, in many cases, the deep learning models are deployed as black boxes and the performance has been already optimized for a training dataset, thus changing the black box itself can lead to performance degradation. We here study the robustness to the geometric transformations in a specific condition where the black-box image classifier is given. We propose an additional learner, \\emph{REinforcement Spatial Transform learner (REST)}, that transforms the warped input data into samples regarded as in-distribution by the black-box models. Our work aims to improve the robustness by adding a REST module in front of any black boxes and training only the REST module without retraining the original black box model in an end-to-end manner, i.e. we try to convert the real-world data into training distribution which the performance of the black-box model is best suited for. We use a confidence score that is obtained from the black-box model to determine whether the transformed input is drawn from in-distribution. We empirically show that our method has an advantage in generalization to geometric transformations and sample efficiency.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.06610v1"
	},
	{
		"title": "All You Need Is Boundary: Toward Arbitrary‐Shaped Text Spotting ",
		"abstract": "Recently, end-to-end text spotting that aims to detect and recognize text from cluttered images simultaneously has received particularly growing interest in computer vision. Different from the existing approaches that formulate text detection as bounding box extraction or instance segmentation, we localize a set of points on the boundary of each text instance. With the representation of such boundary points, we establish a simple yet effective scheme for end-to-end text spotting, which can read the text of arbitrary shapes. Experiments on three challenging datasets, including ICDAR2015, TotalText and COCO-Text demonstrate that the proposed method consistently surpasses the state-of-the-art in both scene text detection and end-to-end text recognition tasks.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.09550v1"
	},
	{
		"title": "TellTail: Fast Scoring and Detection of Dense Subgraphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Universal Value Iteration Networks: When Spatially‐invariant is Not Universal ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Scalable Variational Bayesian Kernel Selection for Sparse Gaussian Process Regression ",
		"abstract": "This paper presents a variational Bayesian kernel selection (VBKS) algorithm for sparse Gaussian process regression (SGPR) models. In contrast to existing GP kernel selection algorithms that aim to select only one kernel with the highest model evidence, our proposed VBKS algorithm considers the kernel as a random variable and learns its belief from data such that the uncertainty of the kernel can be interpreted and exploited to avoid overconfident GP predictions. To achieve this, we represent the probabilistic kernel as an additional variational variable in a variational inference (VI) framework for SGPR models where its posterior belief is learned together with that of the other variational variables (i.e., inducing variables and kernel hyperparameters). In particular, we transform the discrete kernel belief into a continuous parametric distribution via reparameterization in order to apply VI. Though it is computationally challenging to jointly optimize a large number of hyperparameters due to many kernels being evaluated simultaneously by our VBKS algorithm, we show that the variational lower bound of the log-marginal likelihood can be decomposed into an additive form such that each additive term depends only on a disjoint subset of the variational variables and can thus be optimized independently. Stochastic optimization is then used to maximize the variational lower bound by iteratively improving the variational approximation of the exact posterior belief via stochastic gradient ascent, which incurs constant time per iteration and hence scales to big data. We empirically evaluate the performance of our VBKS algorithm on synthetic and massive real-world datasets.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.02641v1"
	},
	{
		"title": "Control Flow Graph Embedding based on Multi‐Instance Decomposition for Bug Localization ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Storytelling from an Image Stream Using Scene Graphs ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Justifying All Differences Using Pseudo‐Boolean Reasoning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Natural Image Matting via Guided Contextual Attention ",
		"abstract": "Over the last few years, deep learning based approaches have achieved outstanding improvements in natural image matting. Many of these methods can generate visually plausible alpha estimations, but typically yield blurry structures or textures in the semitransparent area. This is due to the local ambiguity of transparent objects. One possible solution is to leverage the far-surrounding information to estimate the local opacity. Traditional affinity-based methods often suffer from the high computational complexity, which are not suitable for high resolution alpha estimation. Inspired by affinity-based method and the successes of contextual attention in inpainting, we develop a novel end-to-end approach for natural image matting with a guided contextual attention module, which is specifically designed for image matting. Guided contextual attention module directly propagates high-level opacity information globally based on the learned low-level affinity. The proposed method can mimic information flow of affinity-based methods and utilize rich features learned by deep neural networks simultaneously. Experiment results on Composition-1k testing set and alphamatting.com benchmark dataset demonstrate that our method outperforms state-of-the-art approaches in natural image matting. Code and models are available at https://github.com/Yaoyi-Li/GCA-Matting.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2001.04069v1"
	},
	{
		"title": "Relevance‐Promoting Language Model for Short‐Text Conversation ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion ",
		"abstract": "Learning joint embedding space for various modalities is of vital importance for multimodal fusion. Mainstream modality fusion approaches fail to achieve this goal, leaving a modality gap which heavily affects cross-modal fusion. In this paper, we propose a novel adversarial encoder-decoder-classifier framework to learn a modality-invariant embedding space. Since the distributions of various modalities vary in nature, to reduce the modality gap, we translate the distributions of source modalities into that of target modality via their respective encoders using adversarial training. Furthermore, we exert additional constraints on embedding space by introducing reconstruction loss and classification loss. Then we fuse the encoded representations using hierarchical graph neural network which explicitly explores unimodal, bimodal and trimodal interactions in multi-stage. Our method achieves state-of-the-art performance on multiple datasets. Visualization of the learned embeddings suggests that the joint embedding space learned by our method is discriminative. code is available at: \\url{https://github.com/TmacMai/ARGF_multimodal_fusion}",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1911.07848v4"
	},
	{
		"title": "Stochastically Robust Personalized Ranking for LSH Recommendation Retrieval ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Task and Motion Planning is PSPACE‐Complete ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "GraphER: Token‐Centric Entity Resolution with Graph Convolutional Neural Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Parameterised Resource‐Bounded ATL ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Multimodal Interaction‐Aware Trajectory Prediction in Crowded Space ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Towards Scale‐Free Rain Streak Removal via Self‐Supervised Fractal Band Learning ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Convolutional Hierarchical Attention Network for Query‐Focused Video Summarization ",
		"abstract": "Previous approaches for video summarization mainly concentrate on finding the most diverse and representative visual contents as video summary without considering the user's preference. This paper addresses the task of query-focused video summarization, which takes user's query and a long video as inputs and aims to generate a query-focused video summary. In this paper, we consider the task as a problem of computing similarity between video shots and query. To this end, we propose a method, named Convolutional Hierarchical Attention Network (CHAN), which consists of two parts: feature encoding network and query-relevance computing module. In the encoding network, we employ a convolutional network with local self-attention mechanism and query-aware global attention mechanism to learns visual information of each shot. The encoded features will be sent to query-relevance computing module to generate queryfocused video summary. Extensive experiments on the benchmark dataset demonstrate the competitive performance and show the effectiveness of our approach.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/2002.03740v3"
	},
	{
		"title": "Stereoscopic Image Super‐Resolution with Stereo Consistent Feature ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Group‐Wise Dynamic Dropout Based on Latent Semantic Variations ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "FACT: Fused Attention for Clothing Transfer with Generative Adversarial Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Region‐based Global Reasoning Networks ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Estimating the Density of States of Boolean Satisfiability Problems on Classical and Quantum Computing Platforms ",
		"abstract": "Given a Boolean formula $\\phi(x)$ in conjunctive normal form (CNF), the density of states counts the number of variable assignments that violate exactly $e$ clauses, for all values of $e$. Thus, the density of states is a histogram of the number of unsatisfied clauses over all possible assignments. This computation generalizes both maximum-satisfiability (MAX-SAT) and model counting problems and not only provides insight into the entire solution space, but also yields a measure for the \\emph{hardness} of the problem instance. Consequently, in real-world scenarios, this problem is typically infeasible even when using state-of-the-art algorithms. While finding an exact answer to this problem is a computationally intensive task, we propose a novel approach for estimating density of states based on the concentration of measure inequalities. The methodology results in a quadratic unconstrained binary optimization (QUBO), which is particularly amenable to quantum annealing-based solutions. We present the overall approach and compare results from the D-Wave quantum annealer against the best-known classical algorithms such as the Hamze-de Freitas-Selby (HFS) algorithm and satisfiability modulo theory (SMT) solvers.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1910.13088v1"
	},
	{
		"title": "Meta‐Learning PAC‐Bayes Priors in Model Averaging ",
		"abstract": "Nowadays model uncertainty has become one of the most important problems in both academia and industry. In this paper, we mainly consider the scenario in which we have a common model set used for model averaging instead of selecting a single final model via a model selection procedure to account for this model's uncertainty to improve reliability and accuracy of inferences. Here one main challenge is to learn the prior over the model set. To tackle this problem, we propose two data-based algorithms to get proper priors for model averaging. One is for meta-learner, the analysts should use historical similar tasks to extract the information about the prior. The other one is for base-learner, a subsampling method is used to deal with the data step by step. Theoretically, an upper bound of risk for our algorithm is presented to guarantee the performance of the worst situation. In practice, both methods perform well in simulations and real data studies, especially with poor quality data.",
		"bibtex": "",
		"pdf_url": "http://arxiv.org/pdf/1912.11252v2"
	},
	{
		"title": "MaskGEC: Improving Neural Grammatical Error Correction via Dynamic Masking ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	},
	{
		"title": "Mining on Heterogeneous Manifolds for Zero‐shot Cross‐modal Image Retrieval ",
		"abstract": "",
		"bibtex": "",
		"pdf_url": ""
	}
]